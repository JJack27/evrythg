Technische Universität München
Optimization in Communications Engineering Laboratory Instructions
Univ.-Prof. Dr.-Ing. Wolfgang Utschick
Dipl.-Ing. David Neumann
Department of Electrical Engineering and Information Technology
Associate Institute for Signal Processing
Contents
1 Introduction
2 Gradient-Based Algorithms
2.1 Introduction . . . . . . . . . . . . . . . . .
2.2 MIMO Multiple Access Channel . . . . . .
2.3 Precoder Optimization . . . . . . . . . . .
2.3.1 Gradient Step . . . . . . . . . . . .
2.3.2 Projection Step . . . . . . . . . . .
2.4 Covariance Optimization . . . . . . . . . .
2.4.1 Gradient Step . . . . . . . . . . . .
2.4.2 Projection Step . . . . . . . . . . .
2.5 Complete Algorithm . . . . . . . . . . . .
2.6 Step-Size Control Methods . . . . . . . . .
2.6.1 Open Loop Step-Size Rule . . . . .
2.6.2 Exact Line Search . . . . . . . . .
2.6.3 Generalized Armijo Step-Size Rule
4 Lagrangian Duality and Solution Methods for Dual Problems
4.1 Network Flow Problem with Variable Arc Capacities . . . . . . . . . . . . .
4.2 Dual Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Subgradient Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3 Linear Programming and Interior-Point Methods
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Interior Point Algorithms for Linear Programs . . . . . . .
3.2.1 Standard Formulation for Linear Programming . .
3.2.2 Primal Interior Point Algorithm . . . . . . . . . .
3.2.3 Primal-Dual Interior Point Algorithm . . . . . . .
3.2.4 Predictor-Corrector Method . . . . . . . . . . . .
3.3 Networks and Flows . . . . . . . . . . . . . . . . . . . . .
3.3.1 Graphical Representation of Networks . . . . . . .
3.3.2 Linear Network Flow Problems . . . . . . . . . .
3.3.3 Linear Multicommodity Flow Problems . . . . . .
3.4 Examples for Flow Problems in Communication Networks
3.4.1 Maximum Data Throughput . . . . . . . . . . . .
Cutting Plane Method . . . . . . . . .
Multi-Commodity Flow Problem . . .
Primal Recovery . . . . . . . . . . . .
4.6.1 General Primal Recovery . . .
4.6.2 Cutting Plane Primal Recovery
4.6.3 Subgradient Primal Recovery
Modularity of the Dual Decomposition
5 Conic Optimization and SDPT3
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . .
5.2 Conic Optimization . . . . . . . . . . . . . . . . . . . .
5.2.1 Examples of Proper Cones . . . . . . . . . . . .
5.2.2 Standard Conic Form and Related Problems . . .
5.3 SDPT3 . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4 Linear Precoder Design in the Vector Broadcast Channel
5.4.1 Power Optimization . . . . . . . . . . . . . . . .
5.4.2 Problem Reformulation . . . . . . . . . . . . . .
5.5 WSR Maximization in MIMO MAC . . . . . . . . . . .
6 Nonconvex Optimization
6.1 Monotonic Optimization: Branch, Reduce, and Bound . . . .
6.1.1 Branching . . . . . . . . . . . . . . . . . . . . . . . .
6.1.2 Reduction . . . . . . . . . . . . . . . . . . . . . . . .
6.1.3 Bounding . . . . . . . . . . . . . . . . . . . . . . . .
6.1.4 The Algorithm . . . . . . . . . . . . . . . . . . . . .
6.2 Suboptimal Solution: Gradient Ascent . . . . . . . . . . . . .
6.3 Zero-Forcing Solution . . . . . . . . . . . . . . . . . . . . .
6.3.1 Optimal Zero-Forcing Solution: Exhaustive Search . .
6.3.2 Suboptimal Zero-Forcing Solution: Greedy Allocation
6.4 Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . .
Chapter 1
Introduction
For the programming tasks in this optimization laboratory, we recommend to use Matlab 7.9 or
a newer Matlab version. The latest Matlab version can be obtained at https://matlab.rbg.tum.de/.
In this chapter, the standard optimization tool CVX for Matlab is introduced. We compare this
optimization modeling language and its interior-point solvers with solution approaches that are
based on the Karush-Kuhn-Tucker (KKT) conditions.
Introduction to CVX
A standard toolbox for solving convex optimization problems in Matlab is CVX [2], which is
available for free from http://cvxr.com/cvx/. More specifically, CVX turns Matlab into
an optimization modeling language for disciplined convex programming (DCP)—a methodology for constructing convex optimization problems proposed by Michael Grant, Stephen Boyd,
and Yinyu Ye [3]. The toolbox consists of a limited set of construction rules, i.e., the DCP ruleset, for analyzing and efficiently solving important classes of convex optimization problems.
For example, CVX is capable of dealing with linear programs (LPs), second-order cone programs (SOCPs), semidefinite programs (SDPs), and any other convex optimization programs
that adhere to the DCP ruleset. These problems can rapidly and automatically be verified as
convex and converted to a form that the standard CVX interior-point solvers SeDuMi [5] and
SDPT3 [6] support. However, note that CVX is in general incapable of verifying whether a
problem is convex or not.
The advantage of CVX over directly using the interior-point solvers is that the CVX modeling
specifications can be constructed using common Matlab operations and functions, and standard
Matlab code can be freely mixed with these specifications. This makes it easy to implement
convex optimization problems in Matlab and read the code when employing CVX. For example,
the CVX specification of the LP
Ax ≤ b
Chapter 1. Introduction
with variable x ∈ Rn and m inequality constraints reads as follows:
n = size(A,2);
cvx_begin
variable x(n);
minimize( c' * x );
subject to
A * x <= b;
cvx_end
optimization
begin loading optimization structure
variable definition
objective function
definition of the constraint set
% reformulation and solution of the ...
The newest version of CVX and the CVX users’ guide can be obtained from
http://cvxr.com/cvx/download/.
TASK 1.1
Download and read the CVX users’ guide [2].
TASK 1.2
Install CVX in the folder for your Matlab simulations according to [2, Appendix A]:
• Retrieve the latest version of CVX from http://cvxr.com/cvx/download/ and
unpack the file in your simulations folder, e.g., home/user/simulations for a
Linux system or D:/user/simulations if you are on Windows.
• Start Matlab and change to the location of CVX, e.g., by typing either
cd home/user/simulations/cvx
cd D:/user/simulations/cvx.
• To setup CVX, type the command cvx_setup. This program sets the Matlab paths
for the CVX program files and runs a simple test problem.
• To save the path for subsequent Matlab sessions, either type savepath or follow the
instructions by cvx_setup.
Now, CVX should be ready for use. For example, you can try CVX by entering either of the
examples in [2, Chapter 2].
Communication over Parallel Gaussian Channels – Waterfilling Solution
The first problem we consider is to transmit information from one source S to one terminal T
over n parallel Gaussian channels. Each of these channels i ∈ {1, . . . , n} has an input xi ∈ C
and an output yi ∈ C. The output of the i-th channel can be expressed as
yi = hi xi + ηi ,
(1.1)
where hi ∈ C denotes the complex-valued channel coefficient and ηi ∼ NC (0, σi ) the circularly symmetric additive white Gaussian noise. Note that the channels are orthogonal, i.e.,
there is no interference between the channels.
From information theory, it is known that the capacity of the i-th channel is equal to
ci = log2 1 +
|hi |2 pi
(1.2)
if pi is the power available at the input xi [1, Chapter 9]. Furthermore, the rate ci can then
be achieved on the i-th channel by choosing xi ∼ NC (0, pi ). Let us now assume that the
information rate on the i-th channel is actually given by its capacity, i.e.,
ri (pi ) = log2 (1 + γi pi ) ,
(1.3)
where γi = |hi |2 /σi > 0 specifies the quality of the channel. Given these conditions, we want
to determine the maximum rate n ri (pi ) that can be reliably transmitted over the n parallel
channels if the sum of the powers pi is limited. In other words, we want to solve the following
optimization problem, where P > 0 is the available power budget for all channels:
[ Change of basis in logarithm ]
[ log(3)/log(2) - log2(3) ]
PROGRAMMING TASK 1.3
Implement an algorithm that takes the channel coefficients h1 , . . . , hn , the noise variances
σ1 , . . . , σn , and the available sum transmit power P as inputs and that uses CVX (with SDPT3
as solver) to compute the optimal solution to problem (1.4).
1 Deliverables (Matlab code file): waterfilling_cvx.m
• Function definition:
function [R,p,mu] = waterfilling_cvx(h,s,P)
2 Input Specification:
• h: vector of channel coefficients h1 , . . . , hn
• s: vector of noise variances σ1 , . . . , σn
• P: available sum transmit power P
3 Output Specification:
• R: value of the maximal sum rate R⋆
• p: vector of optimal transmit powers p⋆ , . . . , p⋆
• mu: value of the optimal Lagrangian multiplier µ⋆
4 Verification:
• Most of the functions that have to be implemented can be tested for correctness with
the provided test scripts test_Xxxx.m
For example, use the call test_waterfilling_cvx.
The optimal solution to problem (1.4) can also be obtained from the Karush-Kuhn-Tucker
(KKT) conditions in analytical form. If µ denotes the Lagrangian multiplier corresponding
to the inequality constraint n pi ≤ P , the optimal transmit powers are given by
ln(2)µ⋆
if γi > ln(2)µ⋆ ,
otherwise
− ,0 ,
ln(2)µ
pi = max
(1.5)
where µ⋆ can be determined from the equation
− ,0
(1.6)
While the optimal solution is completely specified by (1.5) and (1.6), the actual values of the
pi ’s need to be computed iteratively. For ease of notation we substitute w⋆ = ln(2)µ⋆ and
ci = γi . Without loss of generality, suppose that c1 ≤ . . . ≤ cn , which obviously results in
p⋆ ≥ . . . ≥ p⋆ . Now we define k ⋆ as the index given by
k ⋆ = k ∈ {1, . . . , N } : w⋆ > ck and w⋆ ≤ ck+1 .
(1.7)
If k ⋆ is known, the optimal power allocations are given by
w ⋆ − ci
for i ∈ {1, . . . , k ⋆ },
for i ∈ {k ⋆ + 1, . . . , n},
where w =
i=1 ci
(1.8)
The integer k ⋆ is simply found by successively checking the hypotheses k ⋆ = 1, . . . , n. That
is, start with the assumtion k ⋆ = 1, calculate the corresponding w⋆ given by (1.8) and then
check the conditions in (1.7). If the conditions do not hold, check the next hypothesis. The
solution to the considered problem is referred to as waterfilling with w⋆ as the water level. It
is illustrated in Figure 1.1, which explains where the term waterfilling originates from.
PROGRAMMING TASK 1.4
σ1 , . . . , σn , and the available sum transmit power P as inputs and that computes the optimal
waterfilling solution to problem (1.4) using the waterfilling algorithm.
1 Deliverables (Matlab code file): waterfilling.m
function [R,p,mu] = waterfilling(h,s,P)
• P: available sum transmit power
4 Hint(s):
• First, reorder γ1 , . . . , γn such that γ1 ≤ . . . ≤ γn and determine k ⋆ ∈ {1, . . . , n}.
\todo{TASK 1.5}
Measure and compare the execution times of your two functions waterfilling_cvx.m
and waterfilling.m for different input parameters. Which of the two solutions is more
efficient? Try to explain the results.
The Gaussian MIMO Point-to-Point Channel – Worst Case Noise Covariance
For the next problem, we use a linear multiple-input multiple-output (MIMO) communication
model, where the source S sends information over an n×m complex channel to the destination
T that is subject to additive and circular symmetric complex Gaussian noise. The received
signal y ∈ Cm at the destination is given by
(1.9)
where x ∈ Cn comprises the n scalar channel inputs, H ∈ Cm×n is the complex channel gain
matrix, and the additive noise is η ∼ NC (0, Cη ) which is zero-mean and whose covariance
matrix is Cη = E[ηη H ].
The achievable rate of this system is given by the mutual information I(y; x) and reads as
−1
R = log2 det Im + Cη HQH H
(1.10)
if we assume Gaussian inputs x ∼ NC (0, Q) with zero-mean and covariance matrix Q =
E[xxH ]. In what follows, we assume Q to be fixed and Cη to vary over time.
Even though Cη is assumed to vary, the total noise power shall be limited, which can be expressed as the constraint
E[ η 2 ] = tr Cη ≤ N.  (1.11)
[ The trace of a matrix is equal to the sum of the eigenvalues ]
Based on these assumptions, the worst case achievable sum rate is
Rworst-case = min log2 det Im + Cη HQH H
Cη 0
(1.12)
where Cη
0 expresses that Cη must be positive semidefinite. Note that this optimization
problem is convex, i.e., the KKT conditions are sufficient.
For solving (1.12), it is advantageous to introduce the eigenvalue decomposition (EVD) of the
noise covariance matrix as
(1.13)
with the unitary modal matrix V ∈ Cm×m and the diagonal matrix Σ containing the eigenvalues σi along the diagonal. With the EVD of Cη , the constraint of (1.12) can be rewritten
σi ≤ N
σi ≥ 0
(1.14)
∀ i ∈ {1, . . . , m}.
We see that they are independent of the eigenvectors of Cη , i.e., the columns of V , contrary to
the utility function that is rewritten as
R = log2 det Im + V Σ −1 V H X
= − log2 det
Im + Σ −1/2 V H XV Σ −1/2
(1.15)
with X = HQH H . Hence, the achievable rate R can be minimized with respect to the
eigenvectors of Cη without taking into account the constraints. The objective is minimized if
the determinant in the second line of (1.15) is maximized.
From Hadamard’s inequality, we know that the determinant of a nonnegative definite matrix is
upper bounded by the product of its diagonal elements and the upper bound can only be reached
if the matrix is diagonal (e.g., see [4]). Moreover, since the inverse A−1 is diagonal only if A
is diagonal, the matrix Im + Σ −1/2 V H XV Σ −1/2 must be diagonal. To reach this, we must
choose V such that it diagonalizes V H XV . That is, V has to be the unitary modal matrix of
the EVD of the positive semidefinite matrix X, i.e.,
with the diagonal matrix Ψ = diag(ψ1 , . . . , ψm ) of eigenvalues ψi ≥ 0 for all i ∈ {1, . . . , m}.
With this optimal choice of the modal matrix V of Cη , the achievable rate R can be expressed
R = log2 det Im + Σ −1 Ψ
log2 1 +
(1.16)
From this result and (1.14), we can conclude that the remaining optimization only depends on
the eigenvalues σi , i ∈ {1, . . . , m}, of Cη . In other words, we must solve
Rworst-case = min
σi ≥0
(1.17)
to find the worst-case achievable rate Rworst-case .
TASK 1.6
Show that the objective function of problem (1.17) is convex.
From this observation, it follows that the optimization problem is convex, i.e., we have the
minimization of a convex objective function over a convex (polyhedral) constraint set.
\todo{TASK 1.7}
If you try using CVX to solve problem (1.17), it will not work. Think about the reason why
CVX is not applicable in this case.
The optimal solution to the convex optimization problem in (1.17) can be obtained from its
KKT conditions. If µ ≥ 0 denotes the Lagrangian multiplier corresponding to the inequality
constraint m σi ≤ N , and λi ≥ 0 denote the Lagrangian multipliers corresponding to the
inequality constraints σi ≥ 0, i ∈ {1, . . . , m}.
From the KKT conditions, one can verify the following solution structure:
0
ψi = 0,
σi =
2 + 4ψ µ′ ψ > 0,
where µ′ =
µ ln(2)
(1.18)
is given via the implicit equation
2N +
ψi + 4ψi µ′ .
ψi =
(1.19)
REFERENCES
Since the right hand side of (1.19) is continuous and increasing in µ′ , its optimum solution may
be found via a simple fixed point search, e.g., a bisection search or a Newton method. A lower
2N + m ψi − m ψ 2
bound for µ′ is µ′
lower = 0 and an upper bound is given by µupper =
PROGRAMMING TASK 1.8
Implement an algorithm that takes the eigenvalues ψ1 , . . . , ψm of X and the maximal sum
noise power N as inputs and that computes the optimal solution to problem (1.17) given
in (1.18).
1 Deliverables (Matlab code file): worstcaseRate.m
function [R,s,mu] = worstcaseRate(p,N)
• N: maximum total noise power
• p: vector of the effective transmit powers ψ1 , . . . , ψn
• R: value of the worst-case sum rate Rworst-case
• s: vector of minimizing noise variances σ1 , . . . , σm
• You can use the Matlab function fzero.m to obtain the optimal value for µ′ .
References
[1] T. M. Cover and J. A. Thomas, Elements of Information Theory, John Wiley & Sons,
2nd ed., 2006.
[2] M. Grant and S. Boyd, CVX: Matlab Software for Disciplined Convex programming,
version 1.21. cvxr.com/cvx, Apr. 2011.
[3] M. Grant, S. Boyd, and Y. Ye, Disciplined convex programming, in Global Optimization:
from Theory to Implementation, Nonconvex Optimization and Its Applications, L. Liberti
and N. Maculan, eds., Springer, New York, 2006, pp. 155–210.
[4] R. A. Horn and C. R. Johnson, Matrix Analysis, Cambridge University Press, New York,
MD, USA, 1st ed., 1990. Corrected reprint of the 1985 original.
[5] J. F. Sturm, Using SeDuMi 1.02, a MATLAB Toolbox for Optimization over Symmetric
Cones, Optimization Methods and Software, 11 (1999), pp. 625–653.
i=1 ψi .
[6] K. Toh, R. Tütüncü, and M. Todd, SDPT3—A Matlab software package for semidefinite
programming, Optimization Methods and Software, 11 (1999), pp. 545–581.
Chapter 2
Gradient-Based Algorithms
2.1 Introduction
In classical optimization theory, gradient methods are used to solve unconstrained minimization or maximization problems. The gradient of a cost function defines the direction of the
steepest ascent. Moving along the gradient or the negative gradient leads to a local maximum
or minimum. In a concave/convex1 optimization problem, the local maximum/minimum is
unique and the acquired solution is the global optimum. Due to its almost intuitive understanding, its simple formulation, its numerical stability and efficient computation, gradient methods
are among the most frequently used techniques for solving optimization problems.
Given a constrained optimization problem, moving along the direction of steepest ascent/descent may however lead to a solution that lies outside the constrained set. To overcome this
problem, in 1964 Goldstein and independently Levitin and Polyak in 1965, proposed a gradientprojection method, that provides an extension of standard gradient algorithms for constrained
optimization problems.

The projected-gradient method applies to optimization problems in the
max f (X)
(2.1)
Given that f is a continuously differentiable function over a nonempty closed convex set C under a Lipschitz assumption on the gradient , _v('140502123932') (2.2)
converges to a stationary point for a → ∞ when certain conditions on the stepsize(s) $s^{(a)}$ are fulfilled.
In (2.2), the operator PC defines a projection of its argument to the convex set C, c.f.,
(2.1). Again, if f is concave, X (∞) is the global maximizer of f .
In the following, will will refer to both cases brieﬂy as convex optimization problems.
13 
Chapter 2. Gradient-Based Algorithms

TASK 2.1
• Is the projection unique? Why (not)?
[ only orthogonal projections are unique ]
• How can the projection be formulated mathematically?  [ _cf('140501165820') ]

The simple update rule (2.2) makes the gradient-projection method an attractive approach, if
∇f and PC (·) can be calculated efficiently. Furthermore, if the speed of convergence is significant, additional efforts may be necessary in order to optimize the stepsize parameter s(a) .
In the first part of this chapter, we will apply the projected-gradient method to maximize the
sum transmit data rate in a multi-point to point multiple-antenna system for a given sum power
constraint. In the second part of this chapter, we will apply optimal and suboptimal stepsize
control algorithms, that ensure convergence and balance the speed of convergence with additional computational efforts.
2.2 MIMO Multiple Access Channel
In the MIMO Multiple Access Channel (MAC) model, a set of K transmitters simultaneously
accesses a physical resource to transmit data to a single receiver.
Similarly to the Point-to-Point MIMO channel (see Chapter 1), each of the $K$ transmitters is equipped with $n$ antennas and the single receiver is equipped with $m$ antennas.
The received signal vector is given by K k=1
where $H_k \in \mathbb{C}^{m \times n}$ denotes the k-th transmitter’s channel matrix, 
[ $W_k \in \mathbb C^{n \times n}$ ]
denotes the precoder matrix of the input signal,
xk ∼ NC (0, In ) comprises the n scalar channel inputs of the k-th transmitter and η ∼ NC (0, Cη ) denotes an additive noise distortion.In the following we assume Cη = In.  
With the covariances [-matrices] of the precoded input signals
$Q_k = \operatorname{E}[W_k x_k x_k^H W_k^H ] = Wk Wk$ , the achievable data rate in the MAC (using dirty paper coding techniques [3]) is given by
(2.4)
(2.5)
_v('140501193431')
_14_
PROGRAMMING TASK 2.2
Implement a function to compute R(W1 , . . . , WK ).
1 Deliverables (Matlab code file): rateW.m
• Function definition: function R = rateW(W,H)
• H: m × n × K set of channel matrices H1 , . . . , HK
• W: n × n × K set of precoders W1 , . . . , WK
• R: achievable sum rate R
4 Hints:
• Make sure the return value is a real number.
PROGRAMMING TASK 2.3
Implement a function to compute R(Q1 , . . . , QK ).
1 Deliverables (Matlab code file): rateQ.m
• Function definition: function R = rateQ(Q,H)
• Q: n × n × K set of covariance matrices Q1 , . . . , QK
Imposing a sum power constraint leads to a convex optimization problem with either the set of
precoder matrices {W1 , . . . , WK } = {Wk }K , or the set of covariance matrices {Qk }K
as optimization variables.
The respective optimization problems are given by
_v('140502130621')
Although (2.6) and (2.7) yield the same result, 2 the gradient-based optimization approaches for solving (2.6) and (2.7) show significant differences in terms of formulation of the projection PC , computational complexity, and the convergence speed of the resulting algorithms.  
This is true only, if {Wk }K have full row/column rank. Note that the number of subchannels ℓ per transmitter
can be preselected by choosing a reduced size precoder matrix W ∈ Cn×ℓ with ℓ < n. In this case, the optimization
is non-convex and the retrieved precoder W yields a suboptimal sumrate. In this tutorial, we restrict ourselves to
the computation of full rank n × n precoder matrices to preserve convexity.
_15_
2.3 Precoder Optimization
2.3.1 Gradient Step
In order to perform a projected gradient step (2.2) for the problem in (2.6), we have to calculate
the gradient of R(W1 , . . . , WK ) by taking the derivative with respect to the precoder matrices
Wk . In general, the derivative of a function f (X) with respect to a matrix X ∈ Cn×n is
defined element-wise as
 δf (X)
δf (X)
. . . δ[X]1,n
δ[X]1,1
δf (X)  .
(2.8)
δ[X]n,1 . . . δ[X]n,n
where [X]i,j = eT Xej denotes the j-th scalar element of the i-th row of X. 
Since the cost function R is a real valued function with complex arguments we can use the Wirtinger derivative to compute the gradient (for details see [5]). 
With (2.8) we calculate the Wirtinger derivative of (2.5) element-wise for the i-th row and the j-th column element, for each of the K
precoder matrices as
δR(W1 , . . . , WK )
δ[Wk ]i,j
log2 det Im +
ℓ=1
ln det Im +
ln 2 δ[Wk i,j
tr  Im +
ln 2
1 T H
ln 2 i k
H k Wk e j e T H k 
Im +
H k Wk e j ,
('140501184819')
where we have used the identities δ ln det(X) = tr(X −1 δX) and tr(AB) = tr(BA)
[ invariance of the trace in cyclic rotations ][6].
arranging the elements we obtain the matrix derivative for each of the K precoder matrices.
We denote the components of the gradient as
ln 2 k
(2.9)
The total gradient ∇R(W1 , . . . , WK ) is then the set of the K derivatives
∇R(W1 , . . . , WK ) = {V1 , . . . , VK } .
(2.10)
In our case, the gradient step in (2.2) refers to a simultaneous step for all precoder matrices.
This is denoted by the set notation
(a)′ K
}k=1
+ s(a) Vk }k=1 ,
(2.11)
(a)′
where we Wk denotes the intermediate, unconstrained result of the gradient step for the k-th
precoder matrix. In the following section, we skip the iteration index (·)(a) for the sake of a
brief notation.
PROGRAMMING TASK 2.4
Implement a function to compute the gradient ∇R(W1 , . . . , WK ).
1 Deliverables (Matlab code file): gradW.m
• Function definition: function grad = gradW(H,W)
• grad: n × n × K set of derivatives V1 , . . . , VK
2.3.2 Projection Step
To complete the update (2.11), the projection PC ({W1 , . . . , WK }) onto the constraint set C
must be performed. In our problem setup, C is the manifold of sets of K non-negative definite
matrices Wk Wk that fullfil the sum power constraint in (2.5). The (orthogonal) projection
can be written as
PC ({Wk }K ) = {Wk + Ek ⋆ }K ,
(2.12)
where E ⋆ is the solution to the minimization problem
{Ek }K = arg min
E1 ,...,EK k=1
||Ek ||2
||Wk + Ek ||2 ≤ P.
(2.13)
The constraint set of this minimization problem corresponds to a Kn2 dimensional ball, and
the projection to a mapping onto the surface of this ball. An illustration is given in Fig. 2.1.
The Lagrangian function (c.f., [1][2]) corresponding to (2.13) is given by
tr(Ek Ek ) + µ
L(E1 , . . . , EK , λ) =
tr (Wk + Ek )(Wk + Ek )H − P
(2.14)
{Ek }K
PC ({Wk }K )
Figure 2.1: Projection onto the constraint set
where µ is the Lagrangian multiplier. From the solution of setting the Wirtinger derivative of
(2.14) with respect to {E ∗ }K to zero, we find that at the optimality point µ⋆ the condition
Ek = −
1 + µ⋆
(2.15)
must hold. The trivial case, when {Wk } already fulfills the sum power constraint, corresponds
to µ⋆ = 0 and, thus, Ek = 0 =⇒ PC ({Wk }) = {Wk }. Otherwise we have µ⋆ > 0 and we
use (2.15) and the sum power constraint which leads to the projection
Ek }K
′ ||2
ℓ=1 ||Wℓ F
(2.16)
The obvious result of the Lagrangian optimization is that the projection onto the constraint set
can be performed by a scaling (2.16) of the precoder matrices. The simplicity of the projection
step is an advantage of the precoder approach when using the gradient-projection technique.
PROGRAMMING TASK 2.5
Implement the projection for the set of precoder matrices {Wk }K .
1 Deliverables (Matlab code file): projW.m
• Function definition: function WP = projW(W,P)
(a+1)
• WP: n × n × K set of projected precoders W1
2.4 Covariance Optimization
2.4.1 Gradient Step
To perform a gradient step on the set of covariance matrices {Qk }K , the Wirtinger derivative
of the cost function R with respect to {Qk }K must be calculated.
TASK 2.6
Calculate the Wirtinger derivative _v('140501193956') 
for (2.4)[ cf. 140501193431 ] to construct the unconstrained gradient step. 
Proceed at first element-wise and then rearrange the matrix elements, as it has been shown before for the precoder matrices.
Similar to the precoder approach, we can now use the gradient matrices Vk for an unconstrained
gradient step on the set of covariances matrices
{Qk }K = {Qk + s(a) Vk }K .
(2.17)
PROGRAMMING TASK 2.7
Implement a function to compute the gradient ∇R(Q1 , . . . , QK ).
1 Deliverables (Matlab code file): gradQ.m
• Function definition: function grad = gradQ(H,Q)
2.4.2 Projection Step
The projection of the unconstrained covariance matrices {Q′ }K after the gradient step is
k k=1
based on the same principle as for the precoder matrices.
The full derivation of the covariance projection step is shown in [4].
cf. 140502101553
In this section we highlight the main results only. The projection
PC ({Q′ , . . . , QK }) to the manifold of K non-negative definite matrices Qk with the sum
power constraint (2.4) can be written as
PC ({Q′ }k=1 ) = {Q⋆ }K = arg min
Q1 ,...,QK k=1
0∀k
(2.18)
tr(Qk ) ≤ P.
Through analysis of the KKT conditions it can be shown that the optimal covariance matrices [ $Q_k^*$ ] must have the same eigenbasis [ $U_k$ ] as the respective unconstraint matrices [ $Q_k^'$ ] 
optimization problem in (2.18) can thus be reformulated to
(2.19)
where λ′ and λk,i are the ith eigenvalues of Q′ and Q⋆ respectively. That is, we want to
project an Kn-dimensional vector onto the scaled standard (Kn − 1)-simplex.
Let µ⋆ > 0 denote the optimal Lagrangian multiplier to the transmit power constraint in the
non-trivial case. The optimal eigenvalues are given by
(2.20)
and the sum power constraint can be formulated as
(2.21)
k=1 i=1
This problem closely resembles the waterfilling problem for which the solution is known from
Chapter 1.
Since this approach requires the computation of the eigenvalue decompositions of all covariance matrices Q′ , . . . , Q′ , the computational effort is significantly higher in comparison to the
simple scaling that needed to be performed for projection of the precoder matrices. However,
the covariance approach provides a higher speed of convergence than the precoder approach
for most scenarios as we will see later on.
PROGRAMMING TASK 2.8
Implement the projection for the set of covariance matrices {Qk }K .
1 Deliverables (Matlab code file): projQ.m
• Function definition: function QP = projQ(Q,P)
• QP: n × n × K set of projected covariance matrices Q1
2.5 Complete Algorithm
In this section we put together an algorithm for solving the sum rate maximization problems
in (2.7) and (2.6). As a first simple approach we implement a projected gradient algorithm with
a fixed step size.
For the termination condition we use
(X (a) − X (a−1) )/s(a)
(2.22)
which is an approximation of the gradient projected onto the tangent cone of the constraint set
at X (a−1) .
PROGRAMMING TASK 2.9
Implement a general projected gradient algorithm based on (2.1) and (2.2). 
cf. 140502123932
Use a fixed step size of s(a) = 1 and the termination condition in (2.22) with ζ = 10−10 .
1 Deliverables (Matlab code file): projGrad.m
function [xOpt fOpt] = projGrad(fun,grad,proj,x,nIter)
• fun: objective function f (X)
• grad: gradient of the objective function ∇f (X)
• proj: projection PC (X) onto the constraint set C
• x: initial value X (0)
• nIter: maximum number of iterations
• xOpt: resulting optimization variables
• fOpt: corresponding value of the objective function
• Calculate the squared Frobenius norm like this:
gApprox = (x − xOld)/s;
frobNorm = gApprox(:)'*gApprox(:);
_21_
• Make sure that the initial value lies within the feasible set
\todo{How to check this?}
PROGRAMMING TASK 2.10
Implement a function that plots the value of the objective function with respect to the iterations a = 1, · · · , N when using the projected gradient algorithm to solve the sum rate
maximization problems in (2.7) and (2.6)
cf. 140502130621
respectively.
1 Deliverables (Matlab code file): plotObjValues.m
• Function definition: function = plotObjValues(H,P,nIter)
• nIter: number of iterations N
3 Hints:
• To use the cost, gradient and projection functions implemented earlier as arguments of the projected gradient algorithm projGrad the number of arguments has to be reduced. This can be done by creating a new function handle, e.g. grad = ...  @(x)gradW(x,H). Now it is possible to call grad(W) with one argument. The
local variable H, which has to exist when the function handle is created, is always
used as the second argument.
• To test the function generate complex Gaussian distributed channel coeffcients
H = (randn(m,n,K)+ 1i*randn(m,n,K))/sqrt(2) 
and use an arbitrary positive real number for the transmit power P .
2.6 Step-Size Control Methods
Step size control plays a crucial role in Gradient algorithms with respect to the algorithms’
convergence behaviours. While until now we have set the step-size s(a) = 1, we can see from
the invocation of plotObjValues.m with different values for the transmit power P that this
does lead to suboptimal convergence behavior in most cases. We can notice that for some
simulations the projected-gradient steps do not converge to the optimal solution at all. Instead,
an oscillating behavior in the vicinity of some sub-optimal point is exhibited.
A straight-forward attempt on addressing this issue could be to probe different (fixed) step-size
values successively and check for an improvement of the result and the optimality of the solution
via the (sufficient) KKT conditions. While this "manual" step-size optimization is possible in
a oﬄine simulation, it is not suitable for the case that the gradient algorithm is implemented
in a real world scenario, e.g., a mobile transmitter base station. For that reason, various step
size control algorithms have become known in literature that assure convergence to the optimal
solution and balance convergence speed with the required computational cost.
2.6.1 Open Loop Step-Size Rule
For any step size control that satisfies the two conditions
lim s(a) = 0 and
a→∞
s(a) = ∞,
(2.23)
the convergence to the stationary point of the cost function is guaranteed. An obvious choice
that satisfies the conditions is the harmonic series
s(a) =
a = {1, . . . , ∞}
(2.24)
where c ∈ R+ denotes an arbitrary real positive constant. Note however, that this exogenous
choice for the step-size lacks practical usability, since the algorithm needs infinite time to converge to the optimum. If a finite number of gradient steps is performed then. The quality and
speed of convergence depends on the definite choice of c.
PROGRAMMING TASK 2.11
Extend the projected gradient function with an additional optional parameter which determines the method for the step size control. Add two choices for the parameter: 'fixed'
and 'open_loop'. Implement the open loop step size control with s(a) = a ,
{1, . . . , ∞}.
function [xOpt fOpt] =
projGrad(fun,grad,proj,x,nIter,method)
• nIter: number of iterations
• method: optional parameter determining the step size control method. Either
'fixed' or 'open_loop'. Defaults to 'fixed'.
• You can use exist('method','var') to check whether method is provided.
2.6.2 Exact Line Search
The step-size control itself is a one-dimensional optimization problem that can be stated for
each gradient iteration as
max f (PC (X (a) + sVk )).
(2.25)
Again the solution to (2.25) is unique due to the convexity of f . When f is analytic, Lagrangian
optimization can be used to tackle this optimization problem. In this case, the Wirtinger derivative must be computed and the optimal solution for s is formulated as an eigenvalue problem.
Since (2.25) is a one-dimensional optimization problem, for practical purposes the solution
can be obtained via well known numerical methods, e.g., Newtons method, or the Bisection
method, which does not require computation of the Wirtinger derivative, but multiple numerical evaluations of f only.
PROGRAMMING TASK 2.12
Extend the projected gradient algorithm with the additional choice of method='optimal'
which selects the optimal line search as step size control
• method: optional parameter determining the step size control method.
• Use fminunc to solve for the optimal step size.
σ=1
exact line
search solution
f (X (a) )
Armijo’s solution
f (X (a) + sV (a) )
β 3 smax smax β 2
smax β 1
smax
Figure 2.2: The Armijo rule for β = 2 exemplified for σ = 2 and σ =
(coincidentally) both values of σ lead to the same Armijo step size.
For s0 = smin ,
The computational effort to compute the exact line search is very high and makes this approach undesirable in practical systems. The Armijo rule is an inexact line search method for unconstrained optimization problems which has been extended to the case of the constrained
projected-gradient method [2]. 
The generalized Armijo rule ensures convergence to the optimum solution even for the constrained case, if the step size is parametrized as
(2.26)
with $0 < \beta < 1$ as an iteration-independent constant, and $s_0^{(a)}$ as an iteration-dependent that itself must be bounded above and below by two iteration independent positive real numbers
$0 < s^{\min} ≤ s_0^{a} ≤ s^{\max}< \infty$.
The iteration-dependent parameter $b(a) \in \mathbb{N}_0$ is used for an exponential scaling of s0 via the basis β.
Since N0 ⊂ R, the optimal step-size w.r.t. (2.25)
is obtained via (2.26) with probability zero. The Armijo solution however is guaranteed to lie
in a ǫ interval that encloses the optimum solution and ensures that ǫ → 0 as a → ∞. The
parameter b(a) must be obtained dynamically for each gradient step according to the Armijo
rule.
The Armijo rule [1] is known from the lecture to this course. The general idea behind the
Armijo rule is that very large or very small step-sizes must relate to a significant increase in the
cost function in order to qualify for application. 
This relation is measured by the slope of the gradient and a scaling constant $\sigma$ from that the intersection of the cost function and the σ-scaled first order linear approximation of the cost function is derived. The parameter b ∈ N0 is then obtained by finding the pair of adjacent stepsize parameters b↑ and b↓ that inclose the intersection
_25_
point for a defined value of σ. For sake of simplicity we only search in the increasing direction.
That is, if the initial step size $s_0^{(a)}$ leads to a point below the intersection point with the cost function we choose b = 0. 
Otherwise, the Armijo step size is found by successively increasing
b(a) by 1, until the evaluation of the σ-scaled linear approximation undertakes the cost function
f . That process is described mathematically in terms of the combinatorial optimization
˜(a) =
arg max
f (PC (X (a) + s0 β b V (a) ))
|b↑ − b↓ | = 1
(2.27)
f (PC (X (a) + s0 β b↑ V (a) )) − f (X (a) ) ≥ σ PTC (X (a) ) (V (a) )
(2.28)
(2.29)
s0 β b ↑
f (PC (X (a) + s0 β b↓ V (a) )) − f (X (a) ) ≤ σ PTC (X (a) ) (V (a) )
s0 β b ↓
where $P_{T_C}(X^{(a)})$ performs a projection of the gradient onto the tangent cone at $X^{(a)}$.
\todo{Understand that}
The actual choice is then b(a) = max(˜(a) , 0). A visualization of the Armijo rule is depicted in Figure 2.2.
In general, PTC (X (a) ) must be derived analytically, similarly to the way the projection on the constraint set PC has been derived for the precoder and the covariance approach earlier in this
chapter. Furthermore, the additional projection operation must be performed which increases
the computational costs of the step-size control. In order to overcome this burden, the tangent
cone projection can be estimated via the constraint set projection. This (under-)estimation is
given as
(2.30)
The resulting approximated relations (2.28) and (2.29) then read as
. (2.31)
PROGRAMMING TASK 2.13
Implement the Armijo step size control of s(a) for the projected gradient algorithm (method='armijo'. Use the Armijo parameter set β = 1/2 and σ = 0.2. As a heuristic (a) (0) for the initial step size, we choose s0 = 2s(a−1) . Choose s0 = 100 for the initial step size in the first iteration.
PROGRAMMING TASK 2.14
Update the plot function, to plot the results for the different step size control methods.
TASK 2.15
Plot the results for different problem sizes, and different parameters for the step-size control
methods.
• What are the advantages/disadvantages of the different step-size control methods?
• How does the optimization with respect to the precoders compare with the optimization with respect to the covariance matrices?
[1] M. S. Bazaraa, H. D. Sherali, and C. M. Shetty, Nonlinear Programming – Theory
and Algorithms, John Wiley & Sons, 3rd ed., 2006.
[2] D. P. Bertsekas, A. NediÄĞ, and A. E. Ozdaglar, Convex Analysis and Optimization,
Athena Scientific, 2003.
[3] M. H. M. Costa, Writing on Dirty Paper, IEEE Transactions on Information Theory, 29
(1983), pp. 439–441.
[4] R. Hunger, D. A. Schmidt, M. Joham, and W. Utschick, A general covariance-based
optimization framework using orthogonal projections, Proceedings of the IEEE 9th Workshop on Signal Processing Advances in Wireless Communications (SPAWC), (2008),
pp. 76–80.
[5] M. Joham, MIMO Systems, Vorlesungsskript, Technische UniversitÃďt MÃĳnchen, 2011.
[6] K. B. Petersen and M. S. Pedersen, The Matrix Cookbook, http://matrixcookbook.com,
2008.
Chapter 3
Linear Programming and Interior-Point
Methods
3.1 Introduction
Within operations research and optimization, linear programming has the longest history – back
to the 1940’s when Dantzig invented his simplex algorithm [3]. Yet it remains the most important class of continuous optimization problems. State-of-the-art large scale linear programming
solvers are entirely based on interior point methods, initially proposed by Karmarker [6], which
offer both best theoretical and practical performance. This part focuses on three renowned
methods: the primal barrier algorithm (Sec. 3.2.2), the primal-dual path following algorithm
(Sec. 3.2.3), and the predictor-corrector algorithm (Sec. 3.2.4). A comprehensive survey and
in-depth discussion of interior point methods for linear programming can be found in [9].
Linear network ﬂow problems constitute a subclass of linear programs of particular practical
and theoretical relevance. For example, ﬂow problems play a key role in research and implementation of todays wired and wireless communication networks [2]. The earliest linear
network ﬂow problems have been studied in the 1930’s by Tolstoi [8], cf. [7], which resembles a transportation problem that can be formulated as a minimum cost multicommodity ﬂow
problem. Later in the 1950’s, Harris and Ross [5] and Ford and Fulkerson [4] studied the
maximum ﬂow and the minimum cut problem, cf. [7], which resulted in the famous maximumﬂow minimum-cut theorem. In Sec. 3.3, the fundamentals of linear network ﬂow problems are
explained. Examples for the minimum cost and maximum ﬂow problems in communication
networks are studied in Sec. 3.4. A comprehensive introduction to networks and ﬂows can be
found in [1].

Chapter 3. Linear Programming and Interior-Point Methods
3.2 Interior Point Algorithms for Linear Programs
3.2.1 Standard Formulation for Linear Programming
All linear programs can be transformed into the following standard formulation
min cT x
Ax = b, x ≥ 0,
(3.1)
where x, c ∈ Rn , b ∈ Rm and A is a m × n matrix. To transform a problem that is not in standard form it is sometimes necessary to include additional variables.
A feasible point x satisfies the constraints Ax = b and x ≥ 0. All feasible points form the feasible set. A point is strictly feasible if it is feasible and x > 0.

TASK 3.1
Before you read on write down the KKT conditions for the standard LP and find the formulation of the dual problem.
[ _cf('140517092151') ]

PROGRAMMING TASK 3.2
Write a function that solves linear programs in standard formulation using CVX.
1 Deliverables (matlab code file): linprog_cvx.m
function [x,y,s] = linprog_cvx(c,A,b)
2 Input specification:
• c,A,b: problem data which defines the linear program in standard form (3.1)
3 Output specification:
• x,y,s: resulting estimates of the optimal primal and dual variables
\todo{ what exactly are $s$ ,$y$ - if I use formulation (6.12) from the script there is only one dual variable $y$ ]
3.2.2 Primal Interior Point Algorithm
Historically the first interior point algorithms that appeared were operating in the primal domain. The basic idea is to solve the approximate problem
min cT x − τ
log(xj )
Ax = b, x > 0.
(3.2)
The approximate problem is well defined on the domain of the logarithmic objective function,
i.e., the interior {x : x > 0} of the inequality constraint set {x : x ≥ 0}.
For τ → 0 the solution x⋆ to (3.2) approaches the solution to the primal problem (3.1). The
central path C is the set of all x⋆ , which form a path leading to the optimal solution x⋆ . The
primal IP algorithm follows the central path by solving (3.2) repeatedly and reducing τ by a
constant factor in each step, where the result from the previous optimization is used as a starting
point for the next one.
The KKT conditions for a solution x = x⋆ of (3.2) are given by
AT y + τ X −1 1 − c = 0,
Ax − b = 0,
(3.3)
x > 0,
where X is a diagonal matrix with the elements of x as entries along the diagonal and 1 is a
vector of all ones. This can also be restated as a mapping FP from Rn+m to Rn+m
FP (x, y) = 0,
x > 0.
(3.4)
To find the solution to (3.4), we use the iterative Newton method. For an estimate (x, y) of the
optimal solution, the search direction (∆x, ∆y) is given by the solution of
FP (x, y)
= −FP (x, y),
(3.5)
where FP is the Jacobian of FP , or
−τ X −2 AT
c − AT y − τ X −1 1
b − Ax
(3.6)
The new estimate is
(x, y) + α(∆x, ∆y).
(3.7)
The step size alpha α ∈ (0, 1] has to be chosen such that the condition x > 0 is always satisfied,
e.g.
,1 .
(3.8)
α = 0.99995 min
j:∆xj <0 −∆xj
There are more sophisticated dynamic choices for the step size []. For simplicity we stick to
the one in (3.8) throughout this chapter.
Note that the solution does not have to be calculated exactly for each iteration of the Newton
algorithm. In fact, it is also possible to do one iteration of the Newton algorithm for one iteration
of the IP algorithm.
After each iteration of the IP algorithm τ is multiplied with a constant β ∈ (0, 1).
TASK 3.3
Think about the following questions:
• Why can we not choose a very small initial τ to directly calculate close to optimal
primal variables?
• What are efficient ways to solve the linear system of equations in (3.6)?
PROGRAMMING TASK 3.4
Write an IP algorithm based on the description in this section. Use (3.6) to calculate the
search directions and (3.8) to calculate the step size α. Choose an appropriate β for the
update of τ and an appropriate termination criterion based on the parameter τ (terminate
when τ < ζ ). For initial estimates of the variables use x = 1 and y = 0.
1 Deliverables (matlab code file): IPPrimal.m
function [x,y] = IPPrimal(c,A,b,beta,tau,zeta)
• beta: optional parameter that controls the progression of the algorithm (default:
β = 0.5)
• tau: optional parameter defining a starting value for τ (default: τ = 1)
• zeta: optional parameter controlling the termination of the algorithm (default: ζ =
0.0001)
• x,y: resulting estimates of the optimal primal and dual variables
3.2.3 Primal-Dual Interior Point Algorithm
In this section, we develop an approach for a primal-dual IP algorithm. Let us recap some
results from duality theory. The dual problem to (3.1) is given by
max bT y
AT y + s = c, s ≥ 0
(3.9)
The KKT conditions for a primal-dual optimal solution (x, y, s) = (x⋆ , y ⋆ , s⋆ ) of both (3.1)
and (3.9) are given by
A y + s − c = 0,
XS1 = 0,
(3.10)
(x, s) ≥ 0.
X and S are diagonal matrices with the elements of x and s, respectively, as entries along the
diagonals, and 1 is a vector of all ones.
A point (x, y, s) is feasible if the primal and dual feasibility conditions are fulfilled, i.e.,
Ax = b,
A y + s = c,
(3.11)
For any feasible point (x, y, s), the duality gap is given by
d = cT x − bT y ≥ 0.
(3.12)
The duality gap d vanishes at optimal points.

TASK 3.5
Find a formulation for the duality gap d(x, s) depending only on x and s. Use the primal
and dual feasibility conditions.
[ _cf('140522124654') ]

Analogously to (3.4), we restate the (3.10) as a mapping
F (x, y, s) = 0,
We can calculate the search direction (∆xaff , ∆y aff , ∆z aff ) as the solution to
0 AT I
∆xaff
0  ∆y aff  = −rb 
A 0
S 0 X
∆saff
(3.13)
(3.14)
with the residuals rb = Ax − b, rc = AT y + s − c and rs = XS1. The matrix I denotes the
identity matrix. The search direction based on (3.14) is called the affine scaling direction. In
general using the affine search direction to find the optimum does not lead to good performance
since often only very small step lengths α ≪ 1 are possible.
This issue is dealt with in the primal-dual IP algorithms by biasing the search toward the interior
of the feasible set, keeping the components of x and s from getting too close to the boundary.
This centering is achieved by modifying the equation system in (3.10) resulting in the following
system of equations:
XS1 = τ 1,
(3.15)
The only difference is on the right hand side of the complementary equation with the addition
of a parameter τ . Note that the equation system (3.15) is equivalent to (3.3), i.e., solutions to
(3.15) lie on the central path.
For the primal-dual IP algorithm we take Newton steps towards a point on the central path,
which results in a faster progress compared to pure Newton steps. To describe this biased
search direction, we introduce a centering parameter σ ∈ (0, 1) and a duality measure based
on the duality gap1
d(x, s)
(3.16)
With τ = σµ, we calculate the search direction as a Newton step based on the equation system
(3.17)
0  ∆y  =  −rb  .
σµ1 − rs
Note that the search direction can be decomposed into
(∆x, ∆y, ∆z) = (∆xaff , ∆y aff , ∆z aff ) + (∆xc , ∆y c , ∆z c ),
where (∆xc , ∆y c , ∆z c ) is the centering direction which solves
0  ∆y c  =  0  .
σµ1
(3.18)
(3.19)
The new estimates for the primal and dual variables are given by
(3.20)
(x, y, s) + α(∆x, ∆y, ∆s),
where the step size α has to be chosen in a way such that (x, s) > 0. A possible choice is
α = 0.99995 min min
j:∆xj <0
, min
j:∆sj <0
(3.21)

TASK 3.6
Based on the linear system of equations (3.17) we can derive a formulation D∆y = rD by
substitution of ∆s and ∆x, where D is a positive definite matrix.
• Find the expressions for D, rD and the substitutions of ∆s and ∆x.
• What is the advantage of this reformulation? How can the new problem be solved?
[ _cf('140522120705') ]

PROGRAMMING TASK 3.7
For our primal-dual IP algorithm we choose a constant centering parameter σ ∈ (0, 1). In
each step calculate the duality measure µ, the search direction according to (3.17), with your
results from Task 3.6, and update the current estimates of the optimal variables, considering
the step size α. The algorithm is terminated if the duality measure drops below a predefined
accuracy threshold ζ.
For points (x, y, s) that are not feasible d(x, s) gives only an estimate of the duality gap. Nevertheless, this
estimate remains a good choice for the adaption of the parameter τ .
1 Deliverables (matlab code file): IPPrimalDual.m
function [x,y,s] =
IPPrimalDual(c,A,b,sigma,zeta)
• sigma: optional parameter defining the centering parameter σ (default: σ = 0.5 )
3.2.4 Predictor-Corrector Method
Another approach is the predictor-corrector method, which is also based on the equation system
for the primal dual method in (3.15). There are two differences to the primal-dual approach in
the previous section. First we choose the centering parameter σ dynamically and second we use
second order information to calculate an additional correcting direction to make faster progress
towards the optimal points on the central path. If we have estimates (x, y, s) of the primal
and dual variables, the optimal search directions (∆x⋆ , ∆y ⋆ , ∆s⋆ ) for a certain centering
parameter σ are the solutions to the following nonlinear system of equations
F (x + ∆x⋆ , y + ∆y ⋆ , s + ∆s⋆ ) =  0  ,
(3.22)
which can be reformulated to
0  ∆y ⋆  = 
σµ1 − rs − ∆X ∆S 1
(3.23)
We can see that there is a nonlinear term ∆X ⋆ ∆S ⋆ 1 on the right hand side, which does not
appear when using the Newton method to calculate the search direction.
The idea is now to calculate the actual search direction in two steps. First we calculate the affine
scaling direction (∆xaff , ∆y aff , ∆z aff ) by solving (3.14). We use it to calculate a corrector
component of the search direction by solving the system of equations
(3.24)
0  ∆y cor  = 
−∆X aff ∆S aff 1
Additionally, we compute the centering parameter
µaff
(3.25)
with
µaff = d(x + αaff ∆xaff , s + αaff ∆saff )/n.
(3.26)
µaff is the hypothetical value of µ that would result from a step in the affine scaling direction
and αaff is the step size given by (3.21) calculated for the affine scaling direction. The intuition
behind this choice of σ is that, if we can do a large step in the affine scaling direction before
hitting any constraint, we can choose a small centering parameter. On the other hand, if there
is only a small improvement going in the affine direction before hitting a constraint, we need a
larger centering parameter.
With the new centering parameter σ, we can calculate the centering component of the search
direction by solving (3.19). Actually, the combined centering-corrector component can be
calculated by solving
(3.27)
0  ∆y cc  = 
aff
σµ1 − ∆X ∆S 1
This gives us our search direction as
(∆x, ∆y, ∆z) = (∆xaff , ∆y aff , ∆z aff ) + (∆xcc , ∆y cc , ∆z cc ).
(3.28)
As with the other IP algorithms, we update the estimates by moving along the search direction
with a step size α according to (3.21) such that (x, s) > 0.
PROGRAMMING TASK 3.8
Write a predictor corrector IP algorithm for a linear program. In each iteration first solve
(3.14) for the affine scaling direction and then use it to calculate σ given by (3.25). With both
σ and the affine scaling direction calculate the combined centering-corrector component
by solving (3.27) to get the total search direction given by (3.28). Then update the current
estimates with an appropriate step size α. The algorithm is terminated if the duality measure
drops below a predefined accuracy threshold ζ.
1 Deliverables (Matlab code file): IPPredictorCorrector.m
IPPredictorCorrector(c,A,b,zeta)
• For both of the linear equation systems (3.14) and (3.27) the left hand side is the
same. You can use this fact together with the results in Task 3.6 to make the algorithm more efficient.
TASK 3.9
• What are the advantages/disadvantages of the different methods?
• How do the different algorithms compare with respect to complexity per iteration?
3.3 Networks and Flows
3.3.1 Graphical Representation of Networks

We consider linear network ﬂow optimization problems, which are an important subclass of general linear programming problems. A network ﬂow problem is an optimization problem defined on a graph. A directed graph G = (N, A) is defined by a finite set of nodes $N$ and a
finite set of arcs A.2 Without loss of generality, we represent the node set by $N = {1, . . . , |N |}$
and each node by its index i ∈ N . Each arc connects two nodes in an ordered fashion, i.e., it
leaves some node (tail) and enters another node (head).


Each arc can therefore be represented by the triple (i, j, m), where i is its tail node, j is its head node, and m a unique index which
enumerates all arcs. The index is necessary to allow for multiple arcs with the same tail and
head nodes. Without loss of generality, we represent the arc set by the unique arc indices
$A = {1, . . . , |A|}$ and denote the arcs leaving (entering) i by O(i) ∈ A (I(i) ∈ A).

We consider only connected graphs, i.e., graphs whose node sets can not be split into two disjoint
sets such that no arc connects both parts. Figure 3.1 visualizes an example for a directed graph
with all the corresponding definitions.

A convenient description of the relations between nodes and arcs is given by the node-arc incidence matrix $M \in \mathbb{R}^{N \times A}$. Its rows and columns correspond to the nodes and the arcs, respectively, according their respective index. Its elements are defined as 
(3.29)
This means that in each column, corresponding to an arc, there is exactly one entry +1 and one entry −1, which reside in the rows corresponding to the arcs tail node and head node [ -1 means leaving ]

Nodes and arcs are sometimes also called vertices and edges, respectively.
We assume that no arc leaves and enters the same node.
6/2/7
13/1/8
5/1/
9/2/6
11/1/9
Figure 3.1: Example of a directed graph with nodes N = {1, . . . , 5} and arcs A = {1, . . . , 14}.
The triple m/um /wm denotes the index, capacity, and cost coefficient of each arc.
respectively. The incidence matrix M ∈ R5×14 of the example graph in Fig. 3.1 is given by
+1 +1 −1
0 −1
 −1
0 +1 +1 +1 +1
0 
M =  0 −1
0 +1 +1 +1 +1 −1
 0
0 +1 +1
0 −1 
0 −1 +1 +1
(3.30)
Note that for any connected graph the rank of the incidence matrix is |N | − 1. That is, it has
exactly |N | − 1 linearly independent rows and columns.

3.3.2 Linear Network Flow Problems
Network ﬂow problems or transportation problems deal with optimally transporting one or multiple commodities [ In economics, a commodity is a marketable item produced to satisfy wants or needs.[1] Economic commodities comprise goods and services ]
through a capacitated network. In communication networks, the commodity is usually information organized in data streams or packets. The main difference between communication networks and transportation networks for real goods, e.g. oil, natural gas, electricity, etc., is that the destinations are interested not only in the amount of information, but in a particular piece of information from a particular source. This leads to multicommodity ﬂow problems in Sec. 3.3.3, where multiple different information ﬂows share a common network.

For this project, we consider the scenario with infinitely divisible commodities, which serves well as
an approximation for most data stream and packet networks.4

The following definitions are the ingredients to define a simple network ﬂow problem: A supply and demand vector is a vector $d \in \mathbb{R}^N$  that defines for each node i the available supply of the commodity (di > 0) or the demand of the commodity (di < 0). If di = 0, then node i neither has nor need any amount of the commodity.

A ﬂow on a graph G = (N, A) is a vector x ∈ R|A| with nonnegative entries. xm quantifies the amount of the commodity that is transported on
arc m from its tail to its head. The ﬂow conservation law (Kirchhoff current law) states that the difference between the total outgoing ﬂow and the total incoming ﬂow must meet the net supply or demand at each node. It can be stated as follows:
(3.31)
In vector-matrix notation the ﬂow conservation law can be equivalently stated as
(3.32)

Flow problems with indivisible or integer divisible commodities are combinatorial problems and often very difficult to solve.
The arc capacity vector on a graph is a nonnegative vector u ∈ R|A| that defines the maximum
total ﬂow for each arc. Fig. 3.1 shows an example for an arc capacity assignment. The capacity
constraint refers to the inequality
(3.33)
The cost vector is a vector w ∈ R|A| that assigns a cost per unit ﬂow on each arc. The total
cost of a ﬂow x is the inner product wT x of the cost vector w with the ﬂow x.

TASK 3.10
Determine the number of linearly independent equality constraints in the ﬂow conservation
law for a connected graph. Give a necessary and sufficient condition on the supply and
demand vector d such that there exists a nonnegative ﬂow that satisfies the ﬂow conservation
law.
With those preliminaries, we can define the linear minimum cost ﬂow problem as the problem
of finding a (nonnegative) ﬂow x that obeys the ﬂow conservation law, fulfills the capacity
constraint, and has the lowest possible total cost.
TASK 3.11
Formulate the linear minimum cost ﬂow problem with the minimum number of inequality
(2|A|) and equality (|N | − 1 + |A|) constraints in linear programming primal standard form,
see Sec. 3.2.1. Introduce slack variables as necessary.
We also define the maximum ﬂow problem as the problem of finding a (nonnegative) ﬂow x
that carries the maximum amount of the commodity from a source node s ∈ N to a destination
node t ∈ N while satisfying the ﬂow conservation law at all other nodes i ∈ N \ {s, t} with
di = 0 and fulfilling the capacity constraint.
TASK 3.12
Formulate the maximum ﬂow problem with the minimum number of inequality (2|A|) and
equality (|N | − 2 + |A|) constraints in linear programming primal standard form, see
Sec. 3.2.1. Introduce slack variables as necessary.
Field
Description
IPWN(n).x
IPWN(n).y
IPWN(n).distance
IPWN(n).weight
x coordinate of each wireless node
y coordinate of each wireless node
Matrix of distances between all pairs of nodes
Vector of commodity weights
Table 3.1: Description of network data structure IPWN in IPNetworks.mat
3.3.3 Linear Multicommodity Flow Problems
The extension to multiple commodities is strait forward. We denote by C = {1, . . . , |C|} the
set of commodities and by xc ∈ R|A| and dc ∈ R|N | the ﬂow and the supply and demand
vector, respectively, of commodity c. Furthermore, let u ∈ R|A| be the capacity vector of the
network.
The ﬂow of all commodities has to be individually conserved, i.e., the ﬂow conservation law
(3.32) must be satisfied by each commodity separately. The multicommodity ﬂow conservation
law is expressed as
(3.34)
where M is the node-arc incidence matrix of the network, which is the same for all commodities. However, since the commodities share the same network, i.e., they share the capacity of
the network, the capacity constraint couples the ﬂows of all commodities. The multicommodity
capacity constraint is given by
(3.35)
This constraint is often also referred to as coupling constraint.
TASK 3.13
Formulate the linear minimum cost multicommodity network ﬂow problem with the minimum number of inequality (|C||A| + |A|) and equality (|C||N | − |C| + |A|) constraints
in primal standard form, see Sec. 3.2.1. The linear cost coefficient vector for commodity c
is wc ∈ R|A| . Introduce slack variables as necessary. Visualize the block structure of the
equality constraint matrix and find an upper bound on the number of nonzero elements in
the matrix.
In this section, we analyze a simple communication problem, namely, a maximum throughput
problem with multiple commodities, using the interior point algorithms developed in Sec. 3.2.
Simulation data are provided in the file IPNetworks.mat. The structure array IPWN stores
a number of wireless networks. The n-th network is stored in IPWN(n). Table 3.1 explains
the structure fields.
3.4.1 Maximum Data Throughput
We consider a very simple wireless communication model. Let N the set of communication
devices enumerated from 1 to |N |. Let dij > 1 denote their distance for any two devices
i, j ∈ N . We consider a communication link to be established between i and j if dij ≤ dmax
with capacity
cij = log2 (1 + γij ) ,
(3.36)
where
P0 −α
(3.37)
N0 ij
denotes the link signal-to-noise ration (SNR). This resembles a Shannon rate communication
model with error-free finite rate links. Furthermore, the links are established orthogonally to
each other and therefore cause no interference. The graph G = (N, A) representing the network
is obtained by assigning one arc m ∈ A for each link ij with dij ≤ dmax .
γij =
We consider 4 simultaneous connections (commodities), i.e., C = {1, 2, 3, 4}. The first connection sends data from the left most node (minimal x coordinate) to the right most node (maximal x coordinate). The second connections is between the same nodes but in reverse direction.
Connections three and four are from the top most node to the bottom most node and vice versa.
The goal is to maximize the weighted sum of the connection rates rc , i.e.,
(3.38)
The weights λc can be interpreted as priorities.
PROGRAMMING TASK 3.14
Analyze the weighted sum rate in the networks IPWN(1) to IPWN(5) with respect to the
path loss exponent α. Use the steps α ∈ {2, 2.5, 3, . . . , 6}. Visualize your results in an
appropriate plot. Use P0 = 1000 for the signal power, N0 = 1 for the noise power and
dmax = 5 for the maximum link distance. The distance information is stored in the matrix
IPWN(n).distance the rate weight vector is stored in IPWN(n).weight.
[1] R. Ahuja, T. Magnanti, and J. Orlin, Networks Flows, Prentice Hall, 1993.
[2] D. Bertsekas and R. Gallager, Data Networks, Prentice-Hall, Englewood Cliffs, NJ,
2nd ed., 1992.
[3] G. Dantzig, Maximization of a Linear Function of Variables Subject to Linear Inequalities,
1947. [published in T.C. Koopmans (ed.), Activity Analysis of Production and Allocation,
Wiley & Chapman-Hall, New York-London, 1951].
[4] L. Ford and D. Fulkerson, Maximal ﬂow through a network, Tech. Rep. Research Memorandum RM-1400, The RAND Corporation, Santa Monica, California, 1954. [published
in Canadian Journal of Mathematics 8 (1956) 399–404].
[5] T. Harris and F. Ross, Fundamentals of a Method for Evaluating Rail Net Capacities,
Tech. Rep. Research Memorandum RM-1573, The RAND Corporation, Santa Monica,
California, 1955.
[6] N. Karmarkar, A New Polynomial-time Algorithm for Linear Programming, Combinatorica, 4 (1984), pp. 373–395.
[7] A. Schrijver, On the History of the Transportation and Maximum Flow Problems, Mathematical Programming, 91 (2002), pp. 437–445.
[8] A. Tolstoi, Metody nakhozhdeniya naimen’shego summovogo kilometrazha pri
planirovanii perevozok v prostranstve [Russian: Methods of finding the minimal total kilometrage in cargotransportation planning in space], Planirovanie Perevozok, Sbornik pervyi [Russian: Transportation Planning, Volume I], Transpechat’ NKPS [TransPress of the
National Commissariat of Transportation], (1930), pp. 23–55.
[9] S. Wright, Primal-Dual Interior-Point Methods, Society for Industrial and Applied Mathematics, 1997.
Chapter 4
Lagrangian Duality and Solution
Methods for Dual Problems
Duality theory is one of the most important tools in convex optimization. It provides an alternative formulation of the original optimization problem that is sometimes easier to solve or that
provides interesting insights into the problem structure. The theory often seems difficult to understand for beginners, because of the various, apparently self-evident results and possibilities
for geometric interpretations.
There is an abstract approach to the dual formulation via the KKT-conditions and cone theory.
However, here we will give another exposition that is taken from the book of Boyd and Vandenberghe [3], where the Lagrange function is understood to penalize constraint violations and
rewards points that fulfill constraints.
The general convex optimization problem is
p⋆ = min f (x)
(4.1)
g i (x) ≤ 0,
h (x) = 0,
i ∈ {1, . . . , I}
j ∈ {1, . . . , J} .
(4.2)
The functions f : Rd → R and g i : Rd → R, i ∈ {1, . . . , I} are assumed convex and
hj : Rd → R, j ∈ {1, . . . , J} linear. The abstract constraint set S ⊂ Rd is also convex.
Usually, we have S = Rd . However, for situations where we do partial dualization it is useful
to retain the set S in the formulation, because it can serve as a container for constraints that are
not dualized. For ease of notation, we will also use the vector notations
g(x) ≤ 0,
h(x) = 0
(4.3)
Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems
which are to be understood as component-wise (in-)equalities. We introduce the equivalent
optimization problem
I0 (hj (x))
I− (g i (x)) +
p⋆ = min f (x) +
(4.4)
I− (z) =
if z ≤ 0,
+ ∞, else
I0 (z) =
if z = 0,
+ ∞, else.
(4.5)
We replace I− and I0 by linear underestimators
λz ≤ I− (z),
∀ z ∈ R, λ ≥ 0
µz ≤ I0 (z),
(4.6)
The severity of the penalty terms depends on the magnitude of λ and µ. We define the dual
function as the solution of the relaxed minimization problem for given penalty parameters µ
and λ ≥ 0,
µj hj (x).
λi g i (x) +
ϕ(λ, µ) = inf f (x) +
(4.7)
The augmented objective function is known as the Lagrange function,
L(x, λ, µ) = f (x) + λT g(x) + µT h(x),
(4.8)
where we introduced vector notation to get rid of the cumbersome sum-notation. With these
definitions, the dual problem is defined as
λ∈RI , µ∈RJ
ϕ(λ, µ)
s. t. λ ≥ 0.
(4.9)
The term duality refers to the fact that a convex minimization problem is replaced by an equivalent concave maximization problem. That both problems are equivalent is the important result
from duality theory:
Theorem 4.0.1: Strong Duality Theorem
If the convex optimization problem (4.1) satisfies certain regularity conditions (for example,
Slater’s condition, see [3]), then the dual function as defined in (4.7) is concave and the primal
and dual optimization problems are equivalent in the sense that
(4.10)
Furthermore, we have
ϕ(λ, µ) ≤ f (x)
∀ x ∈ S ∩ X and µ ∈ RJ , λ ∈ RI , λ ≥ 0.
(4.11)
From a conceptual viewpoint, duality theory has been succesfully used in communications
engineering to analyze layered network protocols [4]. It has been shown that, for example, the
TCP/IP protocol can be viewed as the implementation of a dual optimization algorithm for a
certain dual decomposition of a utility maximization problem. Such analysis provides a useful
tool for the understanding of traditional network protocols, on the one hand, and it is a source
of inspiration for new protocols, e. g. by using different optimization algorithms, on the other
hand.
In this project, we will develop the two mainstays of practical dual optimization, namely the
subgradient and the cutting plane algorithms. In fact, these algorithms are general purpose
tools and can be used for all convex optimization problems, not only those that arise from dual
decomposition. They only require subdifferentiability of the objective function and are, thus,
applicable to the duals of convex optimization problems. This generality comes at the cost of
relatively slower convergence compared to algorithms that use first or second order derivative
information of the objective function, as for example the gradient method encountered in Chapter 2 or Newton-type methods. As such, they should only be used when necessary, i. e., when
differentiability of the objective function is not guaranteed, hence their association with dual
optimization problems, which have convex and non-differentiable objective functions.
4.1 Network Flow Problem with Variable Arc Capacities
We will illustrate the dual decomposition approach at the hand of the network ﬂow problem
already encountered in Chapter 3. At that time, we used fixed arc capacities. However, in
wireless networks they are variable and interdependent due to shared resources and interference.
Therefore, we will allow the arc capacities u to vary in an abstract capacity region C, where
every parameter allocation is associated with a set of arc capacities u ∈ C.
A typical example of such a capacity region would be the achievable rates in a multiple point
to point MIMO scenario, see Chapter 2.
It is then possible to define a rate maximization problem or, more generally, a network utility
maximization (NUM) problem where physical layer parameters are chosen to maximize the
transmission rate and where the achievable rate in the network is given as the solution of a ﬂow
problem.
In our examples, the layering is achieved by dualizing the capacity constraints x ≤ u, which
allows us to decompose the overall problem into simpler problems as we shall see presently.
The network utility maximization with variable arc capacities is given by
maximize
s∈R,x∈R|A| ,u∈R|A|
U (s)
M ′ x = 0,
(4.12)
0 ≤ x ≤ u,
For the optimization problem to be convex we need a concave utility function U (s). The scalar s
is usually the information rate, i. e., c selects the rate injected by the source node. The capacity
region C is assumed to be convex, which can in practice be justified by using time-sharing
arguments: for two points u1 , u2 ∈ C a point λu1 + (1 − λ)u2 can be achieved by using
the resource allocation u1 for λ percent of the total time and using u2 the remaining (1 − λ)
percent of the time. Finally, the matrix M ′ ∈ {−1, 0, +1}(N −2)×|A| , N the number of nodes
and |A| the number of arcs, is the reduced node-arc-incidence matrix that has an entry −1 at
position (i, j) if arc j enters node i, +1 if arc j leaves node i and 0 if arc j neither enters nor
leaves node i.
TASK 4.1
What is the difference between (4.12) and the network ﬂow problems in Chapter 3.
4.2 Dual Decomposition
We will use a partial dual decomposition technique for the capacity constraints only. To this
end, we define a container for the remaining constraints such that the optimization problem
becomes
(s,x)∈ S,u∈C
(4.13)
(s, x) ∈ R × R≥0 :
s = cT x, M ′ x = 0
(4.14)
The Lagrangian of this optimization problem reads
L(s, x, u, λ) = U (s) + λT (u − x),
(4.15)
where we took into account the fact that instead of a convex minimization problem we have a
concave maximization problem. The dual function D(λ) is the supremum of the Lagrangian
with respect to the primal variables (s, x, u) for given dual variables λ ≥ 0, i. e.,
D(λ) =
(s,x) ∈S,u∈C
U (s) + λT (u − x).
(4.16)
The supremum of this sum can be written as the sum of suprema, because the constraints for
u and (s, x) are no longer coupled after we removed x ≤ u from the constraint set, hence
D(λ) = sup
(s,x)∈ S
U (s) − λT x + sup λT u.
(4.17)
The dual function is decomposed into two parts that can be evaluated independently. Simple
evaluation of the dual function requires the solution of two optimization subproblems that are
easier to solve than the original (primal) optimization problem. The first term in (4.17) is
known as the network layer subproblem and is generally easy to solve, for example with the
methods developed in Chapter 3 to solve the minimum arc-cost single-commodity ﬂow problem adjusted for the concave utility function U . The terminology refers to the OSI model for
network protocols and the ﬂow parameters x and s are usually situated in the network layer of
the OSI model.
The second term in (4.17) is commonly referred to as the physical layer subproblem, because
the optimal arc capacities u correspond to physical layer parameters as for example transmit
power covariance matrices or scheduling coefficients.
The dual variables λ can be interpreted as link costs. From duality theory we know that λa > 0
if the capacity constraint for link a is active. In this case, we say that there is demand of size
λa for link a. The physical layer subproblem will allocate resources with a preference for links
with high demand, because the demands are positive weights of the objective function. On the
other hand, in the network layer subproblem allocation of ﬂows to links a with high demands
is penalized by the same amount λa and ﬂow solutions that attribute large ﬂows to links with
small demands are preferred. The dual problem
min D(λ)
λ≥0
(4.18)
can be understood as finding an equilibrium demand vector λ.
The concept of any dual algorithm is to iteratively evaluate the dual function and update the
dual variables until a solution λ⋆ of the dual problem is found. A primal feasible configuration
s⋆ , x⋆ , u⋆ can be found by methods for primal recovery as will be explained in Section 4.6. Algorithm 1 illustrates the general concept of an algorithm. The dual variable update rules along
with convergence criteria are discussed in Sections 4.3 and 4.4. Primal recovery is covered in
Section 4.6.
Initialize ǫ > 0, λ1 , ℓ = 1
while not converged do
s⋆ , x⋆ ← arg max U (s) − λT x : s = cT x, M ′ x = 0, x ≥ 0
s∈R,x∈R|A|
← arg max λT u : u ∈ C
u∈R|A|
d+ ← U (s⋆ ) − λT (xℓ − u⋆ )
sℓ , xℓ , uℓ ← primal recovery
λℓ+1 ← dual variable update
ℓ=ℓ+1
check convergence
Algorithm 1: Dual Algorithm
4.3 Subgradient Method
The subgradient method is the non-differentiable analogue of the gradient descent algorithm.
Contrary to this latter method, the attribute descent does not figure in the name of the subgradient method, because (negative) subgradients do not necessarily point into directions of descent.
There is a plethora of stepsize rules for the gradient algorithm that ensure a relatively fast, i. e.,
linear, convergence. For the subgradient algorithm, there is no general scheme to choose good
step sizes. Finally, for a continously differentiable function there is a simple convergence criterion: ∇f < ε. Such a criterion is not available and one usually aborts the subgradient
algorithm after a suitably large number of steps.
Despite all these apparent drawbacks, the subgradient method enjoys the same popularity in
dual optimization problems as does the gradient descent algorithm for differentiable problems.
A strong argument for subgradient methods is that they often allow for a semi-distributed solution, where the dual problem is solved distributed but dual variables need to be exchanged in
every iteration, see for example [5].
We denote by s⋆ , x⋆ and u⋆ the maximizing arguments in (4.17) for given dual variables λℓ .
They are obtained from algorithms used to solve the inner optimization problems. The dual
function value then reads
D(λℓ ) = U (s⋆ ) − λℓ x⋆ + λℓ u⋆
(4.19)
and a subgradient of D at λℓ is given by [8]
By choosing αℓ by means of a stepsize rule that guarantees convergence, the subgradient
method for the dual variable update is
λℓ+1 = max(λℓ − αℓ (u⋆ − x⋆ ), 0),
(4.20)
where the maximum is taken component-wise and implements an orthogonal projection onto
the set λ ∈ R|A| : λ ≥ 0 . It is relatively easy to show, that all stepsize rules with
and αl → 0 lead to convergent algorithms. It is common to use
(4.21)
a + bℓ
where a and b are used to exert some control on the initial steps. Most of the time one simply
puts a = 0, b = 1. Consequently, subgradient algorithms are oftentimes prohibitively slow to
converge.
PROGRAMMING TASK 4.2
We will implement the subgradient algorithm described above for the utility function
U (s) = log(1 + s)
(4.22)
C = u ∈ R|A| : u ≤ 1 .
(4.23)
and a generic physical layer
In order to focus on the subgradient algorithm, we provide a function pl(lambda) in the
file pl.m that returns
(4.24)
u⋆ = arg max λT u : u ∈ C
and a function nl(M,terminal,source,lambda) in the file nl.m that returns
(s⋆ , x⋆ ) = arg max
U (s) − λT x : s = cT x, M ′ x = 0, x ≥ 0
(4.25)
for given dual variables λ and a given (full) node-arc incidence matrix M , source node
source and terminal node terminal. The vector c used is a vector of all zeros with a
one at the index corresponding to the source node.
The file networkflow_subgradient.m provides a template for the subgradient implementation. Complete the subgradient algorithm. The final primal solution found by the
subgradient algorithm (s⋆ , xℓ , u⋆ ) does not, in general, correspond to the primal optimal
solution. However, because the physical layer subproblem is strictly convex, one can show
that the iterates u⋆ converge to the primal optimal solution u⋆ .
Use the final iterate u⋆ to compute an optimal utility function value and ﬂow of the maxℓ
ﬂow problem with fixed physical layer u⋆ . Use the provided cvx template at the bottom of
the file. Note that this is the problem you solved in Chapter 3 with the linear utility replaced
by a log-utility function. Use a plot of the value of the dual function over the iterations to
check convergence. Is there a better way to check for convergence?
Compare your solution with the reference solution provided by cvx using the function
[x,u,lambda,util] = networkflow_cvx(M,terminal,source) in the file
networkflow_cvx.m.
The node-arc incidence matrix can be read from incidence.mat. Use node 1 as source
and node 4 as terminal.
1 Deliverables (matlab code file): networkflow_subgradient.m
function [x,u,lambda,util,D]
= networkflow_subgradient(M,terminal,source)
• Plot of dual function values over iterations
• M: node-arc incidence matrix
• terminal: index of the terminal
• source: index of the source
• x: ﬂow solution
• u: capacity solution
• lambda: final dual variables
• util: utility function value
• D: dual function value over iterations
4.4 Cutting Plane Method
Kelley’s cutting plane method [6] uses an approach that is different from most other optimization algorithms. Instead of using local derivative information to find another iterate of the dual
variables in the vicinity of the current one, the cutting plane method constructs a global approximation of the dual function out of subgradients. In contrast to the subgradient algorithm, a
convergence criterion is readily available.
The subgradient inequality
D(λ) ≥ D(λk ) + ξk (λ − λk )
∀ λ ∈ R|A|
(4.26)
holds for all pairs (λk , ξk ), ξk ∈ ∂D(λk ) and, as a consequence, one can even take the maximum over a finite number of such equations,
D(λ) ≥ max
1≤k≤ℓ
D(λi ) + ξk (λ − λk )
∀ λ ∈ R|A| .
(4.27)
The cutting plane method uses such a piecewise linear outer approximation of the dual function
and minimizes the approximation instead of the original dual function. In the context of the
cutting plane algorithm, the subgradients ξk are called (hyper-)planes or simply cuts, because
the subgradients can be visualized as hyperplanes that are tangent to the epigraph of D.
The replacement problem of (4.9) is called the cutting plane Master Problem: at iteration ℓ
solve
d⋆ = min Dℓ (λ),
(4.28)
Dℓ (λ) = max
D(λk ) + ξk (λ − λk )
(4.29)
is the ℓ-th cutting plane outer approximation of the dual function. Let λℓ be the solution of
(4.28). From (4.27) it follows that
d⋆ = min Dℓ (λ) ≤ min D(λ) = p⋆ ,
(4.30)
which yields a lower bound for the optimal value p⋆ . Furthermore, it follows from the strong
duality theorem 4.0.1 adjusted for concave maximization that
D(λ) ≥ p⋆
∀ λ ∈ R|A| , λ ≥ 0.
(4.31)
As a consequence, d+ := D(λ⋆ ) yields an upper bound for the optimal value p⋆ . Combining
both bounds and information from previous iterations we get
dℓ ≤ p⋆ ≤ min d+ .
(4.32)
This “sandwiching” of the optimal value gives rise to a formidable stopping criterion for the
algorithm: for a given relative tolerance ε the cutting plane algorithm terminates at iteration L
with a solution that is at least within ε percent of the optimum if
min1≤k≤L d+ − d⋆
(4.33)
Note that a relative convergence criterion may not be suited for problems with solutions close
to zero.
As long as the convergence criterion is not met, the cutting plane model Dℓ needs to be refined.
The usual variable update rule uses λℓ+1 = λ⋆ , which is rather intuitive. The subgradient
ξℓ+1 ∈ ∂D(λℓ+1 ) is added to the model and the iterations continue.
Replacing the original dual optimization problem by a sequence of cutting plane master problems works well, because the master problem (4.28) is cheap to solve. By using standard
techniques from linear programming, the master problem (4.28) can be reformulated as an LP.
We introduce the dummy variable r and obtain
d⋆ = min
λ≥0,r∈R
(4.34)
r ≥ D(λk ) + ξk (λ − λk ),
∀ 1 ≤ k ≤ ℓ.
(4.35)
One can see from this formulation that in each new iteration of the cutting plane, one constraint
is added to the master problem. We will see in Section 4.6 that the dual of the master problem
can be used for primal recovery, i. e., generating a set of primal variables that is close to optimal
for the primal problem.
As in the subgradient method, let sℓ , x⋆ and u⋆ denote the maximizing arguments in (4.17) for
given dual variables λℓ and ξℓ = u⋆ − x⋆ a subgradient. If we plug in the dual function value
and the subgradient, we can write the constraints in (4.34) as [2]
r ≥ U (sk ) + λT (u⋆ − x⋆ ) ,
(4.36)
PROGRAMMING TASK 4.3
We will develop a cutting plane algorithm for the optimization problem described in Programming Task 4.2.
Use the functions pl(lambda) and
nl(M,terminal,source,lambda) as before. The node-arc incidence matrix
can be read from incidence.mat. Use node 1 as source and node 4 as terminal. For
the cutting plane algorithm, you can use a relative convergence criterion of ε = 0.01 (use
(4.32) and (4.33)).
The file networkflow_cuttingplane.m provides a template for the cutting plane
algorithm. Complete the cutting algorithm and calculate a primal utility and ﬂow solution as
you did for the subgradient algorithm. Use the u⋆ , 1 ≤ k ≤ ℓ that correspond to the lowest
dual function value. Note that the cutting plane algorithm does not generate a sequence of
monotonically decreasing dual function values.
networkflow_cvx.m. Plot the value of the dual function over iterations. Add plots with
upper and lower bounds for the primal optimal solution over iterations.
Compare the speed of convergence of both methods. Is the comparison at hand of dual function values over iterations fair? Use Matlab’s tic and toc functions to compare execution
times.
1 Deliverables (matlab code file): networkflow_cuttingplane.m
function [x,u,lambda,util,D,LB,UB]
= networkflow_cuttingplane(M,terminal,source)
• Plot of dual function values and upper and lower bounds over iterations
• LB: lower bounds for utility over iterations
• UB: upper bounds for utility over iterations
4.5 Multi-Commodity Flow Problem
The dual decomposition we used for the single commodity ﬂow problem can be adapted relatively easily to the multi-commodity case. An advantage in terms of simplicity of this particular
decomposition is that the network layer subproblem in (4.17) for the multi-commodity problem
with m commodities decomposes into m independent single commodity ﬂow problems. The
multi-commodity ﬂow problem is given by
maximize U (s)
subject to sc = cT xc ,
0≤
c ∈ {1, . . . , m}
(4.37)
which looks similar to (4.13) except that s now has multiple components and there is a separate
ﬂow-vector for each commodity. Furthermore, each commodity may have different sources
and destinations, which is why there is one node-arc incidence matrix Mc for each commodity
whith the respective source and destination rows deleted. The commodities are coupled via the
capacity constraint and the objective function U . We choose a sum-separable utility function
(4.38)
Uc (sc )
U (s) =
in order to achieve the separation of the network layer hinted to above. One example would be
to choose a weighted sum rate utility function
(4.39)
with positive weights wc > 0. Another possibility is the proportional fairness utility function
wc log(sc ).
(4.40)
One can show that the dual function associated with the multi-commodity ﬂow problem (4.37)
and dualized capacity constraints is given by
U (s) −
(4.41)
m·|A|
(s, x) ∈ Rm × R≥0
: ∀ c ∈ {1, . . . , m}
sc = cT xc , Mc xc = 0
(4.42)
The network layer subproblem can be separated into m single-commodity subproblems as
(s,x)∈ Sc
Uc (sc ) − λT xc
(4.43)
(sc , xc ) ∈ R × R≥0 :
(4.44)
PROGRAMMING TASK 4.4
We will modify both algorithms such that they can handle multi-commodity ﬂow problems.
We use the separable utility function
log(1 + sc )
(4.45)
and the same physical layer as before. Modify both files networkflow_subgradient
and networkflow_cuttingplane such that they accept source and terminal vectors
of equal dimensions as input. Each source-terminal combination corresponds to the source
and terminal of one of the communication links in the network (users). Use to commodities,
one with node 1 as source and node 4 as terminal and one with node 5 as source and node
3 as terminal.
1 Deliverables (matlab code file):
• networkflow_subgradient.m
• networkflow_cuttingplane.m
• terminal: index vector of the terminal nodes
• source: index vector of the source nodes
4.6 Primal Recovery
We recall the convex primal optimization problem
min f (x)
(4.46)
hj (x) = 0,
j ∈ {1, . . . , J}
(4.47)
and the dual optimization problem
λ∈RI ,µ∈RJ
s. t. λi ≥ 0,
i ∈ {1, . . . , I} ,
(4.48)
where ϕ was given by
ϕ(λ, µ) = inf f (x) + λT g(x) + µT h(x).
(4.49)
Convergence of the dual optimization algorithm means
ϕ(λℓ , µℓ ) → ϕ∗ = f ∗ ,
(4.50)
where the equality is due to strong duality and the sequence (λℓ , µℓ ) may have to be replaced
by a subsequence. This means that we can infer the optimal function value from the iterates
of dual function values. However, the dual variables do not contain information about the
primal variables that achieve optimality. This would be a serious drawback if there were no
efficient methods to recover a primal solution, because in most practical cases it is of paramount
interest to know how optimality can be achieved and not what the optimal value is. For example,
in power minimization with respect to quality of service constraints, one would like to know
how to allocate powers. In rate-optimal scheduling one is primarily interested in knowing the
optimal schedule and the optimal rate only has informative value.
Either by evaluating the dual function (4.7) or its subgradient will any dual optimization algorithm generate a sequence (xℓ )ℓ∈N of primal variables and most of the time it is not computationally expensive to evaluate f (xℓ ), g(xℓ ), and h(xℓ ): these are usually linear combinations
of subgradients and dual function values. Thus, we assume that at iteration ℓ the available
information produced by the dual algorithm is
Iℓ = (xk , λk , µk , fk , gk , hk , ϕk )1≤k≤ℓ
(4.51)
where fk = f (xk ) etc. Primal recovery is concerned with the calculation of a feasible set
of primal variables that yields a good (near optimal) function value. As the primal variables
(xℓ )ℓ∈N produced by the dual algorithm need not be feasible, we augment the information with
an interior (Slater) point x0 with g i (x0 ) < 0, hj (x0 ) = 0 and arbitrary λ0 , µ0 , ϕ0 . In many
cases 0 ∈ X and f (0) = 0 and the augmentation is trivial. In other cases, augmentation can
be performed by means of a feasibility test as described in xx.
4.6.1 General Primal Recovery
There is a canonical way to obtain a feasible point xn from the available information Iℓ , which
we will describe in the following. See also the book of Bazaraa [1] for an in-depth account. Let
use define the ℓ-dimensional unit simplex
α ∈ Rℓ+1 :
αk = 1, αk ≥ 0, k ∈ {0, . . . , ℓ}
(4.52)
By convexity of f we know that
(4.53)
The same is true for the convex constraints g i . Note also that by linearity of hj we have
(4.54)
We also know that the intersection of the convex hull of the primal variables (xk )0≤k≤ℓ with
the feasible set is non-empty,
conv {xk : k = 0, . . . , ℓ} ∩ X = ∅,
(4.55)
because x0 ∈ X. In fact, this is the only reason for augmenting the information with x0 .
The following linear program gives a reasonable approximation of the primal solution.
αk gk ≤ 0,
(4.56)
αk hk = 0,
(4.57)
Intuitively, a primal feasible solution can be obtained by setting α0 = 1, because x0 was chosen
feasible. However, f (x0 ) will be far from the optimal value, in general. One would now select
another point xk , which is probably infeasible, but has a better (smaller) function value f (xk ).
If, in addition, h(xk ) = 0 and if the g i (xk ) are small, one can choose αk just so large that
(1 − αk )x0 + αk xk hits the boundary of X, i. e., as soon as some (1 − αk )g i (x0 ) + αk g i (xk )
becomes zero. The function value f ((1 − αk )x0 + αk xk ) will be an improvement over the
“safe” value f (x0 ), because of (4.53).
4.6.1.1 Implementation for Multi-Commodity Flow Problem
Any of the two algorithms developed above generate a sequence of primal optimal variables
x⋆ , u⋆ , s⋆ that may, however, be infeasible with respect to the capacity constraints. The multiℓ ℓ
commodity utility maximization problem (4.37) always has x = 0 as a feasible point and it is
interior with respect to the capacity constraints (we assume that there is a set of physical layer
parameters that achieve non-zero capacity on all links simultaneously). The primal objective
function values are Uℓ = U (s⋆ ) and the values of the inequality constraint functions are
i ∈ {1, . . . , |A|} .
(4.58)
With the adaptions necessary to proceed from convex minimization to concave maximization,
the general primal recovery problem can be stated as
αk gk ≥ 0,
i ∈ {1, . . . , |A|}
(4.59)
with U0 = 0, x0 = 0 and g0 = 0
PROGRAMMING TASK 4.5
We will develop a general primal recovery routine that takes a set of (infeasible) primal
variables with associated utility function and constraint values as input and computes feasible primal variables as described above for the multi-commodity ﬂow problem. Use
the file primal_recovery.m with function definition [alpha,x,u,util] = primal_recovery(X,U,S). Use x0 = 0, s0 = 0, u0 = 0, U (x0 ) = 0 to augment the set
of primal variables with a “safe” feasible point.
Use (4.59) and (4.58) to find the optimal primal recovery for the given input variables. Remember that the result of the general primal recovery LP gives a lower bound on the utility
function value and not the actual utility function value (cf. 4.53). Use the LP solver developed in Chapter 3 for the primal recovery LP. (You can use cvx for comparison.)
In a second step, call the primal recovery routine from within the iteration loop in
networkflow_cuttingplane.m
networkflow_subgradient.m.
Store the utility function values that can be achieved with the primal recovery in
Util_pr. Modify the function definitions of networkflow_cuttingplane.m
and networkflow_subgradient.m to incorporate Util_pr as one of the output
arguments. Modify the functions that plot the dual function values over iterations and add
a curve for the primal recovery over iterations.
Can the primal recovery be used in the subgradient algorithm to define a convergence criterion? What would be possible drawbacks?
1 Deliverables (matlab code file): primal_recovery.m
function [alpha,x,u,util] =
primal_recovery(X,U,S)
• X: primal ﬂow variables over iterations
• U: primal capacity variables over iterations
• S: primal “s” values over iterations
• alpha: coefficients of the optimal convex combination
• x: feasible ﬂow variables
• u: feasible capacity variables
If the cutting plane algorithm is used to solve (4.48), the primal recovery solution from (4.56)
is computed automatically! We will see why this is so in the following.
The Lagrangian is:
L(x, λ, µ) = f (x) + λT g(x) + µT h(x)
(4.60)
ϕ(λ, µ) = inf L(x, λ, µ)
(4.61)
and the dual function is
The cutting plane model after ℓ iterations is
ϕℓ (λ, µ) = min ϕ(λk , µk ) + ξk (λ − λk ) + ζk (µ − µk )
(4.62)
where ξk ∈ ∂λ ϕ(λk , µk ) and ζk ∈ ∂µ ϕ(λk , µk ) are partial subgradients. We choose ξk =
g(xk ) and ζk = h(xk ) as partial subgradients where xk are the primal variables obtained when
evaluating the dual function (4.49), i. e., the infimum in (4.49) at (λm , µm ) is attained for xm .
The cutting plane master problem, which is solved at the ℓ-th iteration, is
max ϕℓ (λ, µ)
s. t. λ ≥ 0
(4.63)
and this can be rewritten as LP,
− min −r
s. t. λ ≥ 0,
(4.64)
r ≤ ϕ(λm , µm ) + ξk (λ − λk ) + ζk (µ − µk )
(4.65)
We will now show that the dual problem of this cutting plane problem is exactly the general
primal recovery problem (4.56). First, we write the Lagrangian of this LP as
Γ (r, λ, µ, α) = −r +
αk r − ϕ(λk , µk ) − ξk (λ − λk ) − ζk (µ − µk )
= r −1 +
(4.67)
αk −ϕ(λk , µk ) + ξk λk + ζk µk
(4.66)
(4.68)
ψ(α) = inf Γ (r, µ, λ, α)
(4.69)
By inspecting the first term in (4.66) we see that ψ(α) = −∞ if ℓ αk = 1. From the
second term we conclude that ψ(α) = −∞ if k=1 αk ξk > 0 (componentwise and because
λ ≥ 0) and from the third term we deduce that ψ(α) = −∞ if ℓ αk ξk = 0. Hence, we
do not change the dual problem if we impose constraints on the dual variables α such that the
dual problem of the cutting plane master problem becomes
α≥0 r,µ,λ
αk = 1,
(4.70)
αk ξk ≤ 0,
(4.71)
αk ζk = 0.
max inf Γ (r, µ, λ, α)
(4.72)
On this constraint set the Lagrange function Γ can be simplified as
Γ (r, λ, α) = −
αk −ϕ(λk , µk ) + ξk λk + ζk µk .
(4.73)
The terms involving r and µ have vanished because of the constraints. The infimum for the
≥ 0.
term involving λ is trivially assumed for λ = 0, because λ ≥ 0 and −
k=1 αk ξk
Hence, the simplified (but equivalent) dual problem reads
(4.74)
(4.75)
(4.76)
α≥0
(4.77)
We now recall that the subgradients are ξk = g(xk ) and ζk = h(xk ) and the dual function ϕ is
ϕ(λk , µk ) = f (xk ) + λT ξk + µT ζk , so that (4.74) can be rewritten as
αk f (xk )
(4.79)
αk g(xk ) ≤ 0,
(4.80)
αk h(xk ) = 0.
(4.78)
(4.81)
which we recognize as the primal recovery problem (4.56). In summary, the primal recovery
for the cutting plane method at iteration ℓ is
(4.82)
where the coefficients αk are the dual variables of the cutting plane master problem at iteration
PROGRAMMING TASK 4.6
Use the file primal_recovery_cuttingplane.m and complete the function
primal_recovery_cuttingplane(X,U,S,alpha) that calculates the primal recovery for the multi-commodity ﬂow problem when the cutting plane algorithm is used.
Pass the dual variables of the current cutting plane iterate as alpha.
Invoke the function from within the cutting plane algorithm as you did for the general recovery. Compare the results and execution times with primal_recovery.m.
1 Deliverables (matlab code file): primal_recovery_cuttingplane.m
function [x,u,util]
= primal_recovery_cuttingplane(X,U,S,alpha)
• alpha: dual variables of cutting plane master problem
The subgradient method does not provide feasible primal recovery for free. However, the following result is often used, despite the fact that primal recovery is infeasible [7].
Theorem 4.6.1: Subgradient Ergodic Primal Recovery
Let xk be the primal variables generated by the subgradient algorithm. Then
x = lim
(4.83)
exists, is feasible, and f (x⋆ ) = minx∈S f (x) s. t. x ∈ X.
PROGRAMMING TASK 4.7
Complete the function primal_recovery_subgradient(X,U,S) in the file
primal_recovery_subgradient.m with the infeasible primal recovery described above. Add the infeasible primal recovery to the subgradient algorithm in
networkflow_subgradient. Store the results in Util_pr_infeasible and
modify the function definition of networkflow_subgradient to incorporate
Util_pr_infeasible as output argument. Modify the plots with dual and primal
function values over iterations and add a curve for the infeasible primal recovery over
iterations.
1 Deliverables (matlab code file): primal_recovery_subgradient.m
= primal_recovery_subgradient(X,U,S)
4.7 Modularity of the Dual Decomposition
We mentioned that the dual decomposition with respect to the capacity constraints decomposes
the the optimization problem into physical layer and network layer subproblems. In fact, the
algorithms were designed to handle generic physical and network layers.
PROGRAMMING TASK 4.8: (Optional)
We replace the simplified physical layer
(4.84)
with the multi-point to point MIMO channel discussed in Chapter 2. In this case, the capacity region C is given as the convex combination of rate points that correspond to certain
transmit covariance power allocations. The physical layer then is a weighted sum rate maximization and an implementation of supu∈C λT u is provided by pl_mimo(lambda) in
the file pl_mimo.m. Replace the simple physical layer pl(lambda) with the more realistic pl_mimo(lambda) for the cutting plane algorithm. Note that the weighted sum rate
maximization problem has to be solved at every iteration and the overall algorithm will be
slow to converge.
Thanks to the modularity, all primal recovery functions can be reused. You do not have to
submit your solutions of this exercise.
function [x,u,lambda,util,D,LB,UB,Util_pr]
• Util_pr: utility function values from cutting plane primal recovery over iterations
[1] M. S. Bazaraa, H. D. Sherali, and C. M. Shetty, Nonlinear Programming: Theory and
Algorithms, John Wiley & Sons, 3rd edition ed., June 2006.
[3] S. Boyd and L. Vandenberghe, Convex Optimization, Cambridge University Press, 2006.
[4] M. Chiang, S. Low, A. Calderbank, and J. Doyle, Layering as Optimization Decomposition: A Mathematical Theory of Network Architectures, Proceedings of the IEEE, 95
(2007), pp. 255 –312.
[5] B. Johansson, P. Soldati, and M. Johansson, Mathematical decomposition techniques
for distributed cross-layer optimization of data networks, IEEE JSAC, 24 (2006), pp. 1535
– 1547.
[6] J. J. Kelley, The Cutting-Plane method for solving convex programs, Journal of the Society for Industrial and Applied Mathematics, 8 (1960), pp. 703–712.
[7] T. Larsson, M. Patriksson, and A. Strömberg, Ergodic, primal convergence in dual
subgradient schemes for convex programming, Mathematical Programming, 86 (1999),
pp. 283–312.
[8] Utschick and Gerdes, Lecture notes - optimization in communications.
Chapter 5
Conic Optimization and SDPT3
5.1 Introduction
The great successes of linear programming – the general theory as well as the existence of
efficient interior-point solvers for linear programs (LPs) – motivated researchers to extend the
results and methods to the nonlinear case. The widest class of optimization problems to which
the basic results of linear programming have been extended is the class of convex optimization
problems [7]. For this purpose, a convex problem needs to be transformed into conic form, i.e.,
into an optimization problem with linear objective and a constraint set that is the intersection
of a closed convex cone and an affine subspace. The two most famous conic programming
formulations are second-order cone programs (SOCPs), which are also referred to as conic
quadratic programs (cf. [1, Chapter 3]), and semidefinite programs (SDPs). A comprehensive
study and various applications of SOCPs and SDPs can for example be found in [1, 2]. Two
standard interior-point solvers that can be used to numerically solve both SOCPs and SDPs in
Matlab are SeDuMi [8] and SDPT3 [9] – both are also included within CVX [4].
The conic optimization framework is a useful tool in the physical layer design of communication systems. As a first example, we look at the quality of service (QoS) based multiuser
transmit beamforming design in this part of the laboratory. This typical scenario arises in the
cellular downlink when a centralized transmitter is equipped with multiple transmit antennas
and serves the demands of several receivers. An important step towards the determination of
an optimal solution in the QoS based linear beamformer design is the application of convex optimization methods, especially the reformulation into conic form. As a second example of how
conic optimization techniques can be applied in communications engineering, we consider the
weighted sum rate (WSR) maximization in the MIMO multiple-access channel (MAC). The
optimization problems obtained from the two communication scenarios can either be solved by
means of CVX, which eventually calls one of the aforementioned solvers, or by directly using
SDPT3.
Chapter 5. Conic Optimization and SDPT3
5.2 Conic Optimization
This section gives a brief introduction to conic optimization. The notions of a proper cone and
generalized inequalities are explained, and the formulations of the two most important conic
optimization problems – SOCPs and SDPs – are presented.
Without loss of generality, standard convex optimization problems can be formulated with an
objective function that is linear in the optimization variable x and which is defined and minimized over a convex set X , i.e.,
min c, x
(5.1)
Here, c, x denotes the inner product between the constant c and the optimization variable
x. Note that if c, x ∈ Rn , then c, x = cT x. To analyze problem (5.1), the constraint set X
usually has to be described with convex inequality constraints and affine equality constraints.
The traditional way is to provide a list of inequalities and affine equations of the form
gi (x) ≤ 0, ∀i ∈ {1, . . . , ℓ},
aj , x − bj = 0, ∀j ∈ {1, . . . , m},
where each of the ℓ functions gi : Rn → R is convex. This guarantees the convexity of X as
the intersection of convex level sets is convex again. For conic optimization problems, a more
elegant way to describe the feasible region consists of defining X as the intersection of an affine
subspace and a proper cone. In fact, this is the basis for conic optimization.
Definition. A set K ⊂ Rn is a cone if it is closed under positive scalar multiplication, i.e., if
αx ∈ K, ∀α > 0.
(5.2)
We say that a cone K ⊂ Rn is a proper cone if it satisfies the following properties:
• K is convex, i.e., it is closed under addition (x1 + x2 ∈ K for all x1 , x2 ∈ K),
• K is closed, i.e., it contains its boundary,
• K is solid, i.e., it has nonempty interior,
• K is pointed, i.e., it contains no lines (if x ∈ K and −x ∈ K, then x = 0).
Every proper cone K ⊂ Rn defines a partial ordering on Rn . Associated with this partial
ordering is the idea of generalized inequalities.
Definition. Let K ⊂ Rn be a proper cone. The generalized inequality x K y denotes that
y − x ∈ K and defines a partial ordering on K. Similarly, the strict generalized inequality
x ≺K y denotes that y − x ∈ int(K) and defines a strict partial ordering on K.
These inequalities can be understood as generalizations of the linear orderings on R, which are
denoted by the relation symbols ≤ and <. Similar to these ordinary inequalities, generalized
inequalities feature the following properties:
is preserved under addition, i.e., if x
is transitive, i.e., if x
z then x
is preserved under nonnegative scaling, i.e., if x
y and α ≥ 0, then αx
is antisymmetric, i.e., if x
y and y
y and x
y and u
v, then x + u
y, then x = y.
However, in contrast to the linear ordering that always exists on R, two elements need not be
comparable with respect to a generalized inequality defined by the proper cone K, i.e., x K y
does not necessarily imply y ≺K x. For this reason, defining the minimum or maximum
element of a set is more complicated in the context of generalized inequalities (e.g., see [2,
Section 2.6]).
5.2.1 Examples of Proper Cones
A special case of a proper cone is the set of nonnegative real numbers K = R+ , its induced
generalized inequalities K (≺K ) are the ordinary inequalities ≤ (<) on R. Other important
proper cones and their associated generalized inequalities are
• the nonnegative orthant Rn and the componentwise inequality:
xi ≥ yi , ∀i ∈ {1, . . . , n};
• the second-order cone Ln+1 = [t, xT ]T ∈ Rn+1 : x 2 ≤ t, t ≥ 0 , which is also
called the Lorentz cone or the quadratic cone, and the corresponding norm inequality:
• the semidefinite cone S+ = Q ∈ Rn×n : Q = QT , xT Qx ≥ 0, ∀x ∈ Rn , which consists of all symmetric n × n matrices that are positive semidefinite, and the associated
linear matrix inequality:
Note that this cone “lives” in the space S n = Q ∈ Rn×n : Q = QT of symmetric
n × n matrices and that the inner product between Q and R is defined as Q, R =
tr(QR) for Q, R ∈ S n .
5.2.2 Standard Conic Form and Related Problems
Having defined the notions of proper cones and generalized inequalities, we are now in the
position to define a conic optimization problem.
Definition. Let K be a proper cone that induces the generalized inequality
tion problem that can be expressed as
An optimiza-
(5.3)
aj , x = bj , ∀j ∈ {1, . . . , m},
is called a conic optimization (in standard form). Note that the convex constraint set X of a
conic optimization problem is the intersection of a proper cone K and an affine subspace that
is specified by the parameters aj and bj , j ∈ {1, . . . , m}.
The probably best known conic form problems are linear programs (LPs). A linear program
is an optimization problem with a linear objective function that is minimized (or maximized)
over a polyhedral constraint set. In standard form, the polyhedral constraint set of the linear
program is given as the intersection of the proper cone Rn and and affine subspace specified
by a system of linear equalities:
x ≥ 0,
(5.4)
where c ∈ Rn , b ∈ Rm , and A ∈ Rm×n such that rank(A) = m < n. Here, the generalized
inequality is equivalent to the ordinary componentwise vector-inequality.
Conic form problems involving Lorentz cones (second-order cones) that are defined via the
Euclidean norm belong to the class of second-order cone programs (SOCPs). The standard
form of an SOCP is
(5.5)
where c ∈ Rn , b ∈ Rm , and A ∈ Rm×n such that rank(A) = m < n. The class of SOCPs
includes LPs and convex quadratic programs as special cases [6].
A class of conic optimization problems that is even more general than that of SOCPs is the
class of semidefinite programs (SDPs). These are conic form problems that involve the proper
cone S+ , i.e., the cone of symmetric n × n matrices that are positive semidefinite. In standard
form, an SDP is expressed as
(5.6)
Aj , X = bj , ∀j ∈ {1, . . . , m},
where Aj ∈ S n and bj ∈ R for all j ∈ {1, . . . , m}. If we apply the definition of the inner
product C, X for C, X ∈ S n , problem (5.6) results in
tr(CX)
(5.7)
tr(Aj X) = bj , ∀j ∈ {1, . . . , m}.
As mentioned above, SDPs are more general than SOCPs (and thus also LPs). That is, any
SOCP can be recast as an equivalent SDP by appropriate reformulation with the Schur complement [6].
It can be shown that the KKT conditions and the theory of Lagrangian duality can be extended
to conic optimization problems [2]. Assuming that a conic problem and its corresponding
dual problem satisfy the conditions for strong duality, generalized versions of interior-point
methods can be applied to numerically determine an optimal solution. To this end, logarithmic
barrier functions for the constraints x ≥ 0, x L 0 and X 0 need to be introduced. These
logarithmic barriers are defined by means of generalized logarithms ψ(x).
• For K = R+ , the generalized algorithm is of course the ordinary logarithm. Since the
componentwise inequality x ≥ 0 can be represented by n scalar inequalities xi ≥ 0, ∀i ∈
{1, . . . , n}, the generalized logarithm for the nonnegative orthant R+ can be defined as
the sum of the logarithms of the elements of x, i.e.,
log xi .
ψ(x) =
• For the second-order cone Ln+1 =
ized logarithm can be defined as
[t, xT ]T ∈ Rn+1 : x
ψ [t, xT ]T = log t2 − x
≤ t, t ≥ 0 , the general-
• Finally, the generalized logarithm for the semidefinite cone S+ can be defined as
ψ(Q) = log det(Q).
The generalized logarithm ψ for the proper cone K behaves like the ordinary logarithm along
any ray in K. It has to satisfy several other properties like being concave and twice continuously
differentiable which we do not elaborate on here. However, if ψ is a generalized logarithm for
K, then φ(x) = −ψ(x) is the logarithmic barrier function for the constraint x K 0.
5.3 SDPT3
SDPT3 is a software that is designed to solve semidefinite-quadratic-linear conic programming
problems (SQLPs) whose constraint sets are given as the Cartesian products of semidefinite
cones, second-order cones, nonnegative orthants and Euclidean spaces, and whose objective
functions are sums of linear functions and log-barrier terms associated with the constraint
cones [9]. In particular, SDPT3 uses primal-dual interior-point methods to solve SQLPs of
the following primal form:
tr(Cj Xj )
νj log det(Xj )
cq,T xq − νi log ψ(xq )
tr(As Xj ), . . . , tr(As Xj )
∈ {1, . . . , ns },
Aq xq + Aℓ xℓ + Au xu = b ∈ Rm ,
∈ L , ∀i ∈ {1, . . . , nq },
(5.8)
Optimization problems of this kind are termed standard SQLPs in [9] and have the properties
listed below:
• S+j is the semidefinite cone of order sj so that Xj , j ∈ {1, . . . , ns }, denote the ns
positive semidefinite variables; the matrices Cj , As , . . . , As must be real symmetric
matrices of dimension sj × sj , i.e., Cj , Aj,1 , . . . , As ∈ S sj , for all j ∈ {1, . . . , ns }.
• Lqi is the Lorentz (or second-order/quadratic) cone of order qi so that xq , i ∈ {1, . . . , nq },
denote the nq quadratic variables; cq is a vector in Rqi and Aq ∈ Rm×qi is a constraint
matrix associated with the i-th quadratic variable, i ∈ {1, . . . , nq }.
• Rnℓ is the nonnegative orthant of dimension nℓ , which means that xℓ denotes the vector
of nonnegative real (or linear) variables; cℓ is a nonnegative real vector of dimension nℓ
and Aℓ is a real m × nℓ constraint matrix associated with xℓ .
• Rnu is the Euclidean space of dimension nu so that xu denotes the vector of unrestricted
variables; cu is a real vector of dimension nu and Au is a real m × nu constraint matrix
associated with the vector of unrestricted variables.
• ψ(xi ) denotes the generalized logarithm for second-order cones so that −ψ(xq ) is the
corresponding barrier function.
• νj , νi , and νk are given nonnegative parameters that specify how the log-barrier terms
associated with the different constraint cones contribute to the objective function.
In some cases, it is easier to set up SQLPs in SDPT3 with the dual form of (5.8):
[νj log det(Zj ) + sj νj (1 − log νj )]
[νi log ψ(zi ) + νi (1 − log νi )] +
yk A s + Z j = C j ,
Aq,T y + zi = cq ,
zi ∈ L qi ,
Aℓ,T y + z ℓ = cℓ ,
[νk log zk + νk (1 − log νk )]
∀j ∈ {1, . . . , ns },
(5.9)
Au,T y = cu ,
∀i ∈ {1, . . . , nq },
TASK 5.1
Download and read the SDPT3 users’ guide [9]. The latest version can be obtained from
http://www.math.nus.edu.sg/~mattohkc/sdpt3.html.
Although SDPT3 is part of the CVX installation, we recommend not to use that version because
this may cause problems when you want to use both SDPT3 directly and with CVX.
TASK 5.2
Install SDPT3 in the folder for your Matlab simulations:
• Retrieve the latest version of SDPT3, which can be obtained from
http://www.math.nus.edu.sg/~mattohkc/sdpt3.html
and unpack the file in your simulations folder, e.g., home/user/simulations for
a Linux system or D:/user/simulations if you are on Windows.
• Start Matlab and change to the location of SDPT3, e.g., by typing either
cd home/user/simulations/SDPT3−4.0 (Linux) or
cd D:/user/simulations/SDPT3−4.0 (Windows).
• In the Matlab command window, type
>> Installmex
This step may be skipped if you do not have to generate the mex files.
• After that, to see whether you have installed SDPT3 correctly, type
>> startup
>> sqlpdemo
• To save the path for subsequent Matlab sessions, you can either type savepath or
add the corresponding SDPT3 paths to your startup file.
Now, SDPT3 should be ready for you to use. Note that SDPT3-4.0 is built for Matlab version
7.4 or later releases, it may not work for earlier versions.
A typical application of conic optimization in communications is the linear precoder design in
the vector broadcast scenario, where one centralized multi-antenna transmitter serves several
single-antenna receivers [10]. In this context, the precoder is defined as a linear transformation on the transmitted symbols. To this end, we assume a linear Gaussian channel model
with perfect channel state information at the receivers’ and the transmitter’s sides. That is, the
channel parameters are fixed for the beamformer design. For the design, the following qualityof-service (QoS) problem is investigated: minimize the dissipated total transmit power subject
to minimum SINR requirements. These problems can be reformulated such that standard conic
optimization toolboxes, e.g., SDPT3, can numerically solve them.
Figure 5.1: Block diagram of the considered vector broadcast channel.
The detailed block diagram of the considered communication system with a centralized transmitter is shown in Figure 5.1. At each time instant, a block of independent zero-mean unitvariance symbols s = [s1 , . . . , sK ]T ∈ CK is linearly transformed with the precoder
T = [t1 , . . . , tK ] ∈ CN ×K
(5.10)
and transmitted over the channels h1 , . . . , hK ∈ CN to K receivers. The received signal yk
(of receiver k) is distorted by the superimposed complex Gaussian noise ηk ∼ NC (0, σk ). That
ti si + ηk ,
(5.11)
where tk and sk denote the beamformer and the data signal intended for receiver k and the
other precoded data symbols si with i = k result in interference.
In the following, we try to improve the system performance by varying the precoder T . For this
purpose, we simplify the notation by combining all channel vectors in the matrix H ∈ CK×N
such that the received signal vector reads as
(5.12)
5.4.1 Power Optimization
The goal is a power efficient design of the precoder T that is quantified by the receivers’ quality
of service (QoS) and the resources of the transmitter. Here, the users’ data rates are used as
QoS measures. Expressed in terms of the mutual information, the achievable rates read as
rk = log2 (1 + SINRk )
∀ k ∈ {1, . . . , K},
(5.13)
and the signal-to-interference-plus-noise-ratio (SINR) is
SINRk =
|[HT ]k,k |2
i=k |[HT ]k,i | + σk
(5.14)
where σk = E[|ηk |2 ] > 0 and [A]k,i denotes the element in the k-th row and the i-th column
of matrix A. The metric that specifies the use of system resources is the average transmitted
power and is defined as
(5.15)
P = E[ T s 2 ] = tr(T H T ).
Note that the SINR metric and the average power metric conﬂict, i.e., one cannot maximize the
SINRs while also minimizing the power, and vice versa.
The task is to minimize the average transmitted power subject to satisfying the minimum rate
requirements ρk , k ∈ {1, . . . , K}. That is,
tr(T H T )
∀ k ∈ {1, . . . , K}.
(5.16)
Since rk is a bijective function of SINRk , (5.17) can equivalently be represented as a standard
power minimization with SINR lower bounds γk = 2ρk − 1, k ∈ {1, . . . , K}, i.e., (cf. [10])
(5.17)
Note that this problem might be infeasible. For K > N and sufficiently large ρk , it might be
impossible to satisfy all constraints simultaneously, even though infinite transmit power can be
used. A simple test to check whether the positive rate targets are achievable is given in [5]: if
0 < 2−ρk ≤ 1 for all k ∈ {1, . . . , K} and additionally
2−ρk > K − rank{H},
(5.18)
then there exists a T ∈ CN ×K with finite power satisfying all rate constraints simultaneously.
In what follows, the task is to solve this power minimization problem based on the powerful framework of conic optimization which allows for efficient numerical solutions using standard optimization toolboxes, e.g., SDPT3 [9]. Specifically, the power optimization problem
in (5.17), which is nonconvex in this representation, will be formulated as a convex SOCP or
SDP problem.
5.4.2 Problem Reformulation
The standard SINR problem formulation in (5.17) is nonconvex. In order to obtain a convex
optimization problem with linear objective function and a convex constraint set, a real-valued
slack variable P is introduced and an extra constraint is added to obtain
(5.19)
The variable P can be understood as an upper bound on the transmit power. Minimizing this
upper bound is equivalent to minimizing the average transmit power itself.
Before reformulating (5.19) as an SOCP, note that due to the structure of the problem formulation, the argument T is not defined uniquely. The terms |[HT ]k,i |2 and tr{T H T } are
independent with respect to a diagonal phase scaling of T from the right. That is, if T is optimal, then so is T diag(ej φ1 , . . . , ej φK ). For this reason, in the sequel it is restricted (without
loss of generality) to terms T which have the following properties: Re{[HT ]k,k } ≥ 0 and
Im{[HT ]k,k } = 0 for all k ∈ {1, . . . , K}. Taking this into account, the constraints of (5.19)
can be recast as SOC constraints.
The power constraint in (5.19) can be reformulated using tr{X H X} = i Xei 2 = vec(X) 2 ,
where vec(·) is the column-stacking operator and ei denotes the i-th canonical unit vector, as
vec(T )
(5.20)
Taking the square root of both sides, this inequality is equivalent to the SOC constraint
(5.21)
L 0.
The SINR constraints can also be recast as SOC constraints. For this purpose, we use the fact
that i=k |[HT ]k,i |2 = eT HT 2 − |[HT ]k,k |2 to obtain
|[HT ]k,k |2 ≥ T H H H ek
k ∈ {1, . . . , K}.
(5.22)
Since Re{[HT ]k,k } ≥ 0 and Im{[HT ]k,k } = 0 for k ∈ {1, . . . , K} and the right-hand side
of (5.22) is equal to eT HT , σk 2 , one can take the square root of both sides, resulting in
T H H H ek
Re{[HT ]k,k } ≥
k ∈ {1, . . . , K},
(5.23)
which is equivalent to the SOC constraints
γk Re [HT ]k,k
Using (5.21) and (5.24), and defining p =
given by
P , problem (5.19) is reformulated as a SOCP,
∈ LN K+1 ,
1 + γ1k Re{[HT ]k,k }
Im{[HT ]k,k } = 0
(5.24)
(5.25)
Thus, the problem is convex and moreover, it can efficiently be solved by either using CVX or
implementing this problem formulation into a standard SOCP solver as provided in SDPT3 [9].
PROGRAMMING TASK 5.3
Implement the feasibility test in (5.18) and the SOC formulation in (5.25) into a Matlab function that takes the channel matrix H, the vector of minimum rate targets ρ = [ρ1 , . . . , ρK ]T ,
and the vector of noise variances σ = [σ1 , . . . , σK ]T as inputs, and that uses CVX (with
SDPT3 as solver) to compute the optimal solution to problem (5.25).
1 Deliverables (Matlab code file): PMinVectorBC_cvx.m
function [P,T,status] = PMinVectorBC_cvx(H,rho,sigma2)
• H: channel gain matrix H
• rho: minimum rate target vector ρ
• sigma: vector of noise variances σ
• P: minimum transmit power P ⋆
• T: optimal transmit precoder T ⋆
• status: the status information of the optimization with CVX
• First, determine the number of transmit antennas and users in the system with the
dimensions of H. Then, test the target vector on feasibility using (5.18). If feasible,
the optimization in with CVX can directly be implemented into CVX. Note that the
variable T and the Lorentz-cone have to be implemented in its complex valued form.
TASK 5.4
Rewrite the conic form problem in (5.25) into the standard dual-form (5.9) that can directly
be implemented into SDPT3. For this purpose, follow the next two steps:
• Reformulate the constraints in (5.25) in terms of t = vec(T ) ∈ CN K . To this end,
note that eT HT ei = (eT ⊗ eT H) vec(T ), where A ⊗ B ∈ Cnp×mq denotes the
Kronecker product (kron(A,B) in Matlab) of the two matrices A ∈ Cn×m and
• Transform the resulting complex-valued problem formulation into its equivalent realˆ
valued form, i.e., rewrite the problem in terms of t = [Re{t}T , Im{t}T ]T ∈ R2KN .
PROGRAMMING TASK 5.5
Implement the feasibility test in (5.18) and the resulting SOC formulation of TASK 5.4
into the Matlab function PMinVectorBC_sdpt3.m that takes the channel matrix H, the
vector of minimum rate targets ρ = [ρ1 , . . . , ρK ]T , and the vector of noise variances
σ = [σ1 , . . . , σK ]T as inputs, and that uses SDPT3 to compute the optimal solution to
problem (5.25).
1 Deliverables (Matlab code file): PMinVectorBC_sdpt3.m
• Function
definition:
function [P,T,status] = ...
PMinVectorBC_sdpt3(H,rho)
• status: the status information of the optimization
Figure 5.2: System model of considered multiple-access scenario, where the users 1 and 2 as
well as the terminal T are equipped with multiple antennas.
• Implement the SOC into SDPT3 dual-form (5.9) using y = [p, tT ]T as variable vector. The evaluation of the SDPT3 programming results and the accuracy evaluation
is already implemented into the Matlab function PMinVectorBC_sdpt3.m.
5.5 WSR Maximization in MIMO MAC
In this example from multiuser communications, we discuss the weighted sum rate (WSR)
maximization problem in a multiple-access scenario. In particular, we assume that two users 1
and 2 which are equipped with n1 and n2 transmit antennas, respectively, transmit information
to one terminal T that has m antennas. The system model is depicted in Figure 5.2.
Let x1 ∈ Rn1 and x2 ∈ Rn2 be the channel inputs at the two users, y ∈ Rm be the received
signal at the terminal, and let Hi ∈ Rm×ni denote the real-valued channel gain matrix from
user i ∈ {1, 2} to the terminal T . Then,
Hi xi + η,
(5.26)
where η ∼ N (0, Im ) is the additive white Gaussian noise received at the terminal. Note that,
without loss of generality, we have assumed here that the channels are real-valued in order to
obtain real-valued optimization problems afterwards.
From information theory, it is known that the capacity region of this Gaussian MAC channel
is equal to
log2 det Im + H1 Q1 H1 ,
r2 ≤ log2 det Im + H2 Q2 H2 ,
r1 + r2 ≤ log2 det Im + H1 Q1 H1 + H2 Q2 H2 ,
CMAC = r ∈ R2 : r1 ≤
Q1 ∈ S+1 , Q2 ∈ S+2 , tr(Q1 ) ≤ P1 , tr(Q2 ) ≤ P2
(5.27)
if the available transmit powers at the two users are given by P1 and P2 [3, Chapter 9]. Moreover,
all rate vectors r ∈ CMAC can be achieved by having user 1 and user 2 choose Gaussian inputs
x1 ∼ N (0, Q1 ) and x2 ∼ N (0, Q2 ) with appropriate transmit covariance matrices Q1 and
Q2 that satisfy the power constraints, respectively.
A standard problem in communications engineering is the weighted sum rate (WSR) maximization problem over some rate region R ∈ RK , which in general reads as
max wT r
(5.28)
for some w ∈ RK . For the Gaussian MAC with two users, i.e., R = CMAC , it can be shown
that this WSR maximization becomes
Q1 ,Q2
w1 − w2
log2 det Im + H1 Q1 H1 +
log2 det Im + H1 Q1 H1 + H2 Q2 H2
Q1 ∈ S+1 ,
Q2 ∈ S+2 ,
tr(Q1 ) = P1 ,
tr(Q2 ) = P2
(5.29)
if w1 ≥ w2 . This is a convex optimization problem satisfying the ruleset of disciplined convex
programming, which can therefore be solved by means of CVX.
PROGRAMMING TASK 5.6
Implement an algorithm that takes the channels H1 , H2 , the available transmit powers
P1 , P2 , and the weight vector w ∈ R2 as inputs, and that uses CVX (with SDPT3 as solver)
to compute the optimal solution to problem (5.29).
1 Deliverables (Matlab code file): wsr_mimo_mac_cvx.m
function [Q1,Q2] = wsr_mimo_mac_cvx(H1,H2,P1,P2,w)
• H1: channel gain matrix H1
• H2: channel gain matrix H2
• P1: available transmit power at user 1
• P2: available transmit power at user 2
• w: weight vector w
• Q1: optimal transmit covariance matrix Q1 of user 1
• Q2: optimal transmit covariance matrix Q⋆ of user 2
• First, determine whether w1 > w2 , w1 < w2 , or w1 = w2 . If w1 < w2 , the roles of
users 1 and 2 must be switched in (5.29). If w1 = w2 = w, the objective function
reduces to the sum rate r1 +r2 =
is simply scaled with w.
log2 det Im + H1 Q1 H1 + H2 Q2 H2 , which
While the considered WSR maximization problem is not a conic problem, it can be expressed
as a standard SQLP. To see this, we first reformulate (5.29) as an equivalent minimization
problem:
min −α1 log2 det Im + H1 Q1 H1 − α2 log2 det Im + H1 Q1 H1 + H2 Q2 H2
tr(Q2 ) = P2 ,
(5.30)
where α1 = w1 −w2 ≥ 0 and α2 = w2 ≥ 0 for w1 ≥ w2 . In a next step, we introduce two
auxiliary variables X1 = Im + H1 Q1 H1 ∈ S+ and X2 = Im + H1 Q1 H1 + H2 Q2 ∈ S+
to obtain
min −α1 log2 det (X1 ) − α2 log2 det (X2 )
X1 ∈ S + ,
X1 − H 1 Q 1 H 1 = I m ,
X2 ∈ S + ,
(5.31)
X2 − H 1 Q 1 H 1 − H 2 Q 2 H 2 = I m .
Observe that this is almost an SQLP in standard form. All we need to do now to actually obtain
one is to reformulate the equality constraints in an appropriate manner. To this end, let us first
consider the power constraints. Obviously, we have
tr(Q1 ) = tr(In1 Q1 ) = P1 ,
tr(Q2 ) = tr(In2 Q2 ) = P2 ,
(5.32)
and since In1 ∈ S n1 and In2 ∈ S n2 , the two scalar power constraints already match the required
form. However, rewriting the matrix equalities to match the standard SQLP form is more comT
plicated. The constraint X1 − H1 Q1 H1 = Im means that, for all i, j ∈ {1, . . . , m},
[X1 ]i,j − [H1 Q1 H1 ]i,j = δi,j =
if i = j,
(5.33)
This can equivalently be written as
tr(eT X1 ej ) − tr(eT H1 Q1 H1 ej ) = tr(ej eT X1 ) − tr(H1 ej eT H1 Q1 ) = δi,j ,
(5.34)
where ei denotes the i-th canonical unit vector. Since ej eT and H1 ej eT H1 are not symmetric
except for the case i = j, we need to formulate the equality constraints in a different way. For
this purpose, note that [X1 ]i,j = [X1 ]j,i and [H1 Q1 H1 ]i,j = [H1 Q1 H1 ]j,i . Consequently,
we can equivalently express (5.33) as
[X1 ]i,j + [X1 ]j,i − [H1 Q1 H1 ]i,j − [H1 Q1 H1 ]j,i = 2δi,j ,
(5.35)
tr((ej eT + ei eT ) X1 ) + tr(−H1 (ej eT + ei eT )H1 Q1 ) = 2δi,j ,
(5.36)
A1 (i,j)
A2 (i,j)
where A1 (i, j) ∈ S m and A2 (i, j) ∈ S n1 for all i, j ∈ {1, . . . , m}. Moreover, note that
we need to specify above constraints only for i ∈ {1, . . . , m} and j ∈ {i, . . . , m} since only
redundant constraints would be obtained by switching i and j. As a result, m(m + 1)/2 scalar
equality constraints in the form of (5.36) are required to express the matrix equality constraint
X1 −H1 Q1 H1 = Im , and the same obviously applies for X2 −H1 Q1 H1 −H2 Q2 H2 = Im .
Together with the two power constraints, m(m + 1) + 2 scalar equality constraints are hence
necessary to express all equality constraints of problem (5.31). If all these constraints are
stacked in a vector of dimension m(m + 1) + 2, an equivalent reformulation of the WSR
maximization problem (5.29) in standard SQLP form is obtained.
PROGRAMMING TASK 5.7
P1 , P2 , and the weight vector w ∈ R2 as inputs, and that uses SDPT3 to compute the
optimal solution to problem (5.29). To this end, use the reformulation of the WSR maximization problem in standard SQLP form.
1 Deliverables (Matlab code file): wsr_mimo_mac.m
function [Q1,Q2] = wsr_mimo_mac(H1,H2,P1,P2,w)
• First, determine whether w1 > w2 , w1 < w2 , or w1 = w2 again.
TASK 5.8
Measure and compare the execution times of your two functions wsr_mimo_mac and
wsr_mimo_mac_cvx for different input parameters. Which of the two solutions is more
Note that if we solve problem (5.29) for given channels H1 , H2 , transmit powers P1 , P2 , and
one particular weight vector, we obtain a point on the boundary of CMAC . Therefore, we can
evaluate the boundary of the capacity region of the two-user MIMO MAC by solving WSR
maximization problems over CMAC for different weight vectors w ∈ R2 . In, particular, the
boundary of CMAC can be determined with arbitrary precision by varying the ratio of the weights
w2 from zero to infinity.
PROGRAMMING TASK 5.9
P1 , P2 , and a collection of weight vectors w1 , . . . , wL ∈ R2 as inputs, and that determines
L rate vectors r1 , . . . , rL that belong to the boundary of CMAC . To this end, use your func⋆
tion wsr_mimo_mac to obtain rℓ as the optimizer of the WSR maximization problem with
weight vector wℓ , ℓ ∈ {1, . . . , L}.
1 Deliverables (Matlab code file): c_mimo_mac.m
function R = c_mimo_mac(H1,H2,P1,P2,W)
2×L
• W: matrix of weight vectors W = [w1 , . . . , wL ] ∈ R+
• R: matrix of rate vectors R = [r1 , . . . , rL ] ∈ R+
• The function wsr_mimo_mac only determines the optimal covariance matrices Q⋆
and Q⋆ . The optimal rate vector r ⋆ is then obtained as
2 log2 det Im + H1 Q1 H1
H1 Q⋆ H1 + H2 Q2 H2 − 2 log2 det
Im + H 1 Q ⋆ H 1
if w1 > w2 , or
log2 det Im + H1 Q⋆ H1 + H2 Q2 H2 − 2 log2 det Im + H2 Q⋆ H2
2 log2 det Im + H2 Q2 2
if w1 < w2 . If w1 = w2 , both options yield an optimal rate vector, which hence is
not unique in general.
TASK 5.10
Let rk,max = maxℓ=1,...,L eT rℓ , k ∈ {1, 2}. Plot the capacity region CMAC of the twok
user MIMO MAC as the convex hull of the rate vectors r1 , . . . , rL ,
for different input parameters.
r1,max
r2,max
[1] A. Ben-Tal and A. Nemirovski, Lectures on Modern Convex Optimization. Analysis,
Algorithms, and Engineering Applications., Society for Industrieal and Applied Mathematics, Philadelphia, PA, USA, 2001.
[2] S. Boyd and L. Vandenberghe, Convex Optimization, Cambridge University Press, New
York, NY, USA, 1st ed., Mar. 2004.
[3] T. M. Cover and J. A. Thomas, Elements of Information Theory, John Wiley & Sons,
[4] M. Grant and S. Boyd, CVX: Matlab Software for Disciplined Convex Programming,
Feb. 2009.
[5] R. Hunger and M. Joham, A Complete Description of the QoS Feasibility Region in the
Vector Broadcast Channel, IEEE Transactions on Signal Processing, 57 (2010), pp. 698–
713.
[6] M. S. Lobo, L. Vandenberghe, S. Boyd, and H. Lebret, Applications of Second-Order
Cone Programming, Linear Algebra and its Applications, 284 (1998), pp. 193–228.
[7] Y. Nesterov and A. Nemirovski, Interior Point Polynomial Algorithms in Convex Programming, Studies in Applied Mathematics (SIAM), Philadelphia, PA, USA, 1994.
[8] J. F. Sturm, Using SeDuMi 1.02, a MATLAB Toolbox for Optimization over Symmetric
[9] K. Toh, R. Tütüncü, and M. Todd, SDPT3—A Matlab software package for semidefinite
[10] A. Wiesel, Y. C. Eldar, and S. Shamai, Linear Precoding via Conic Optimization for
Fixed MIMO Receivers, IEEE Transactions on Signal Processing, 54 (2006), pp. 161–176.
Chapter 6
Nonconvex Optimization
In Chapter 2, the problem of maximizing the sum rate of a MIMO multiple access channel
(MAC) under a sum power constraint was considered under the assumption that successive
interference cancellation is applied. However, to reduce the complexity of encoding and decoding, practical implementations of communication systems usually rely on so-called linear
transceivers, where nonlinear operations (encoding, detection, . . . ) are only applied to single
data streams while all filtering operations that involve more than one data stream have to be
linear (e.g., [2]).
When the MIMO MAC considered in Chapter 2 is restricted to linear transceivers, the signals
transmitted by all other users cause interference to the signal of user k, and the sum rate can
be written as
−1
(6.1)
log2 det In + Hk Im +
R(Q1 , . . . , QK ) =
where we have used the same notations as in Chapter 2. Unfortunately, this sum rate expression
is no longer a concave function of the covariance matrices Qk , so that the sum rate optimization
problem1
Q1 0,...,QK 0
R(Q1 , . . . , QK )
(6.2)
is no longer a convex problem. Consequently, linear transceivers simplify the implementation
of a transmit strategy in a real system, but they make the procedure of optimizing the transmit
strategy more involved.
In this chapter, we study various approaches to find optimal and suboptimal solutions of the sum
rate optimization (6.2) with linear transceivers in the special case of n = 1 transmit antenna at
We use
0 to denote that a matrix is positive semidefinite.
Chapter 6. Nonconvex Optimization
each user terminal. In this case, the transmit covariance matrices Qk are reduced to scalars qk ,
and the channel matrices Hk become vectors hH . Thus, the sum rate optimization reads as
q1 ≥0,...,qK ≥0
log2 1 + qk hH Im +
qk ≤ P. (6.3)
6.1 Monotonic Optimization: Branch, Reduce, and Bound
Even though problem (6.3) is a nonconvex problem, it is possible to find its globally optimal
solution by means of monotonic optimization. To this end, we introduce a new function defined
−1 
hℓ yℓ hH  hk  . (6.4)
log2 1 + xk hH Im +
R(x1 , . . . , xK , y1 , . . . , yK ) =
Note that this function satisfies R(q1 , . . . , qK , q1 , . . . , qK ) = R(q1 , . . . , qK ).
TASK 6.1
Show that R(x1 , . . . , xK , y1 , . . . , yK ) with xk ≥ 0 and yk ≥ 0 is non-decreasing in all xk
and non-increasing in all yk . Hint: ∂(A(y) ) = −A(y)−1 ∂A(y) A(y)−1 .
PROGRAMMING TASK 6.2
Implement a function to compute R(x1 , . . . , xK ) or R(x1 , . . . , xK , y1 , . . . , yK ) for a power
vector x or for a pair of vectors (x, y), respectively.
1 Deliverables (Matlab code file): sumrate_SIMO.m
• Function definition: function R = sumrate_SIMO(H,x,y)
• H: m × 1 × K set of channel vectors h1 , . . . , hK
• x: column vector [x1 , . . . , xK ]T
• y (optional): column vector [y1 , . . . , yK ]T
• R: R(x1 , . . . , xK , y1 , . . . , yK ) if y is provided, R(x1 , . . . , xK ) otherwise
• You can use exist('y','var') to check whether y is provided.
Figure 6.1: Schematic of the branch-reduce-and-bound method: feasible region (gray), branching (dashed), and reduction (dotted).
• It suffices to implement R(x1 , . . . , xK , y1 , . . . , yK ) and to set y=x; if y is not provided.
Problem (6.3) can now be solved using a modified version of the branch-reduce-and-bound
(BRB) algorithm from [3]. We first discuss the three main steps and summarize the algorithm
afterwards.
6.1.1 Branching
Consider a set B = [a, b] = {q | a ≤ q ≤ b} of power vectors q = [q1 , . . . , qK ]T , where
the inequalities have to be understood component-wise. Let us call such a set box, and let
B = {B0 , B1 , . . . } be a set of boxes.
The branch step in the BRB algorithm then consists in cutting a box [a, b] ∈ B along its
longest edge into two subboxes (bisectional rectangular subdivision). To this end, we first find
the direction of the longest edge
k ⋆ = arg max
k∈{1,...,K}
(6.5)
bk − ak .
and then replace the box by the two new boxes:
a, b −
bk ⋆ − a k ⋆
ek ⋆ , a +
ek ⋆ , b
\ {[a, b]}
(6.6)
where ek is the kth canonical unit vector, which has a one in the kth element and zeros elsewhere.
A visualization of the branching can be seen in Fig. 6.1.
6.1.2 Reduction
Each box B = [a, b] might contain both feasible and infeasible power vectors q, i.e.,
B = q ∈ B 1T q ≤ P ∪ q ∈ B 1T q > P
(6.7)
where 1 is the all-ones vector. The smallest box B ′ ⊆ B which still contains all feasible vectors
q ∈ B, i.e., q ∈ B 1T q ≤ P ⊆ B ′ , is called the reduction of B.
For the problem under consideration a rule to compute the reduction can be obtained from
geometrical considerations. For a box B = [a, b] with a ≥ 0 that contains at least one feasible
power vector, the reduced box B ′ is given by B ′ = [a, b′ ] with
b′ = min a + (P − 1T a)1, b
(6.8)
where the minimum has to be taken element-wise.
A visualization of the reduction step can be seen in Fig. 6.1.
PROGRAMMING TASK 6.3
Implement a function to compute the reduction B ′ of a box B = [a, b].
1 Deliverables (Matlab code file): reduction.m
• Function definition: function [a,b] = reduction(P,a,b)
• P: maximum sum power P
• a: column vector [a1 , . . . , aK ]T specifying the lower boundary of the box B
• b: column vector [b1 , . . . , bK ]T specifying the upper boundary of the box B
• a: column vector [a1 , . . . , aK ]T specifying the lower boundary of the reduced box
• b: column vector [b1 , . . . , bK ]T specifying the upper boundary of the reduced box
4 Hint:
• You may assume that the function is only called for boxes which contain at least one
feasible power vector.
6.1.3 Bounding
Consider a box B = [a, b]. Due to the monotonicity properties shown in Task 6.1, the inequality
R(q1 , . . . , qK ) = R(q1 , . . . , qK , q1 , . . . , qK ) ≤ R(b1 , . . . , bK , a1 , . . . , aK )
(6.9)
holds for all q ∈ [a, b]. Therefore, U ([a, b]) = R(b1 , . . . , bK , a1 , . . . , aK ) is an upper bound
to R(q1 , . . . , qK ), q ∈ [a, b]. Even though this bound is an utopian bound, i.e., there is usually
no q ∈ [a, b] fulfilling (6.9) with equality, the bound becomes tight as b − a → 0. This
property is called consistency [3].
On the other hand, it is obvious that evaluating R(q1 , . . . , qK ) for any feasible q ′ ∈ [a, b]
delivers a lower bound to the optimal rate in the box [a, b], i.e.,
max R(q1 , . . . , qK ) ≥ R(q1 , . . . , qK ).
(6.10)
q∈[a,b]
For instance, we can use L([a, b]) = R(a1 , . . . , aK ) as lower bound since a is feasible whenever there exists at least one feasible q ∈ [a, b].
Note that
U = max U (B)
(6.11)
is an upper bound to R(q1 , . . . , qK ) for all q ∈
while
L = max LB
(6.12)
is a lower bound to the rate R(qopt,1 , . . . , qopt,K ) at the optimal power vector qopt ∈
6.1.4 The Algorithm
We initialize the branch-reduce-and-bound algorithm with a set B = {B0 }, where B0 is the
reduction of RK , i.e., the minimal box containing all feasible power vectors. This initial box is
given by B0 = [0, P 1] (cf. Fig. 6.1).
Then, the following steps are repeated until convergence:
1. Find the box with the highest upper bound, i.e.,
[a, b] = arg max U (B)
(6.13)
and perform a branching with this box.
2. Replace the new boxes obtained in the branch step by their respective reductions.
3. Compute upper and lower bounds for the new reduced boxes.
4. Break if U − L ≤ ǫ, where ǫ is the desired accuracy, and U and L are defined in (6.11)
and (6.12), respectively.
The solution to problem (6.3) is then given by the vector a corresponding to the lower bound
L in (6.12), i.e.,
qsolution = a with [a, b] = arg max LB .
(6.14)
Due to Step 4 of above algorithm, the solution is a so-called ǫ-optimal solution, which means
that the rate achieved with this power vector is guaranteed to be at most ǫ away from the actual
global optimum Ropt , i.e.,
R(qsolution,1 , . . . , qsolution,K ) ∈ [Ropt − ǫ, Ropt ].
(6.15)
Convergence of the method can be shown based on the observation that the bounds become
tight for b − a → 0 [3].
PROGRAMMING TASK 6.4
Implement the branch-reduce-and-bound algorithm described above.
1 Deliverables (Matlab code file): brb.m
function [q_opt,optval]=brb(f,red,a_0,b_0,epsilon)
• f: handle to a function R=f(x,y) which computes R(x1 , . . . , xK , y1 , . . . , yK )
• red: handle to a function [a b]=red(a,b) which computes a reduction of [a, b]
• a_0: column vector [a1 , . . . , aK ]T specifying the lower boundary of the initial box
• b_0: column vector [b1 , . . . , bK ]T specifying the upper boundary of the initial box
• epsilon: desired accuracy ǫ
• q_opt: optimizer qopt corresponding to an ǫ-optimal solution of (6.3)
• optval: R(qopt,1 , . . . , qopt,K )
• You can run an optimization using your brb implementation by calling the provided
helper function [R q] = srmax_brb(H,P) for some set of channels H and some
maximum power P .
• That is, to check your program with the provided verification function use
test('srmax_brb').
5 Hints:
• We use the function handles f and red in order to allow a generic implementation, which could also be used to solve other optimization problems. Inside brb.m,
you can use f(x,y) and red(a,b) just like normal functions. The correct definition of the function handles for the optimization under consideration is done in the
provided helper function [R q] = srmax_brb(H,P), so that you do not have to
worry about how to pass such handles to the brb function.
• Note that the functions f(x,y) and red(a,b) do not require the channels or the
sum power as arguments.
6.2 Suboptimal Solution: Gradient Ascent
The disadvantage of the method is that its computational worst-case complexity is exponential
in the number of variables, which is K in our case.
TASK 6.5
Test your brb implementation by calling [R q] = srmax_brb(H,P) after loading a small
and a large scenario by the help of the provided function load_example('small') and
load_example('large'), respectively. What do you observe? Hint: Add some debug
output to your brb implementation (e.g., print U − L after each 100 iterations).
If a solution with less complexity is desired, it might be necessary to resort to a local method,
which does not necessarily find the global optimum of the nonconvex problem (6.3). As an
example, let us study a gradient-projection algorithm.
The derivative of R with respect to a power qj is given by
ln 2 · 1 + qj hH Cj hj
qk |hH Ck hj |2
ln 2 · 1 + qk hH Ck hk
(6.16)
C k = Im +
(6.17)
PROGRAMMING TASK 6.6
Implement a function to compute the gradient
at position q = x.
1 Deliverables (Matlab code file): gradient_SIMO.m
• Function definition: function grad = gradient_SIMO(H,x)
• grad: the value of
Note that the powers qk can be considered as 1 × 1 covariance matrices Q and the constraint
set of problem (6.3) is the same as the one in Section 2.4. Therefore, the projection to the
constraint set implemented in Section 2.4 can be reused.2
The eigenvalue decomposition used in Section 2.4 could be skipped since it is trivial for 1 × 1 matrices, but
reusing the implementation with eigenvalue decomposition should work properly, too.
PROGRAMMING TASK 6.7
Implement a gradient-projection algorithm to find a locally optimal solution of problem (6.3).
1 Deliverables (Matlab code file): srmax_gradient.m
function [R q] = srmax_gradient(H,P,q)
• q: column vector [q1 , . . . , qK ]T containing the initialization
• R: sum rate achieved at the local optimum
• q: column vector [q1 , . . . , qK ]T containing the powers at the local optimum
• Check your program by looking at the simulation results plotted by
plot_gradient, which are averaged over 100 channel realizations. Your
average achieved rate should always lie below the average of the globally optimal
rate, and it should lie close to the optimal solution for small values of P .
• Use sumrate_SIMO(H,q) from Programming Task 6.2 to evaluate the sum rate
for given q.
• Use gradient_SIMO(H,x) from Programming Task 6.6 to compute the gradient
at q = x.
• You can use the projected gradient implementation from Chapter 2
6.3 Zero-Forcing Solution
A variation of problem (6.3) is the maximization of the sum rate under so-called zero-forcing
constraints [1, 4], i.e., we enforce that the receiver applies linear receive filters in a way that no
interference between streams of different users is present after the filtering operation. The data
transmission can then be described by
(6.18)
where vk is the receive filter for the data stream of user k. To cancel out interference for any
data symbols xℓ and any trasmit powers qℓ , we need that vk hℓ = 0 for all k and all ℓ = k. For
ℓ = k, we can choose vk hk = 1 without loss of generality since scaling the receive filter vk
does not change the signal-to-noise ratio and, thus, has no inﬂuence on the achievable rate.
In matrix notation, the zero-forcing constraints can be written as
V H =  .  h1 . . . hK = IK .
(6.19)
This equation can only be fulfilled for K ≤ m, and the solution is given by V = H H H
i.e., V has to be the Moore-Penrose pseudo-inverse3 of the joint channel matrix H.
To be able to also handle the case K > m, we have to introduce a set of active users K ⊂
{1, . . . , K} with cardinality |K| ≤ m, where qk = 0 has to hold for all k ∈ K. Let k(i) denote
4 in the set K. The zero-forcing constraints can then be written as
the ith user
vk(1)
VK HK =  .  hk(1) . . . hk(|K|) = I|K|
(6.20)
vk(|K|)
which is fulfilled by
(6.21)
With this receive filters, the effective channel of a user k ∈ K including the receive filters
is vk hk = 1, the variance of the filtered noise is σk = vk Im vk = vk vk , all inter-user
interference is canceled, and the achievable rate is given by
rk = log2 1 + qk · 1/σk .
(6.22)
Consequently, for a given set of users K, the sum rate optimization problem becomes
qk(1) ,...,qk(|K|)
−2
σk(i) qk(i)
qk(i) ≤ P, qk(i) ≥ 0, ∀i ∈ {1, . . . , |K|}
(6.23)
which is equivalent to the waterfilling problem (1.4) from Chapter 1.
PROGRAMMING TASK 6.8
Implement a function that computes the optimal zero-forcing sum rate for a given set of
active users K.
1 Deliverables (Matlab code file): sumrate_zf.m
Even though there are other possible solutions for the case K < m, the Moore-Penrose pseudo-inverse is the
optimal solution with respect to the sum rate optimization since it is the minimal norm solution and, thus, leads to
the lowest possible noise amplification (cf., e.g., [4]).
The order of the users within the set can be chosen arbitrary.
• Function definition: function [R q] = sumrate_zf(H,P,a)
• a: column vector [a1 , . . . , aK ]T where ak = 1 if k ∈ K and ak = 0 otherwise
• R: sum rate achieved at the waterfilling solution
• q: column vector [q1 , . . . , qK ]T containing the powers at the waterfilling solution
• Use waterfilling(h,s,P) from Programming Task 1.4 in Chapter 1 to compute
the waterfilling solution.
• Return qk = 0 for all k ∈ K.
Knowing a method to compute the optimal rate for a given set of active users K, we still have
to find the optimal K. This problem is treated in the following subsections.
6.3.1 Optimal Zero-Forcing Solution: Exhaustive Search
Let R(K) denote the optimal value of (6.23) for given K. We then have to solve
K⊆{1,...,K}
R(K) s. t. |K| ≤ m
(6.24)
which is a combinatorial problem.
The globally optimal solution can be found with high complexity by testing all possible sets K.
PROGRAMMING TASK 6.9
Implement a function that computes the optimal zero-forcing sum rate by testing all possible
sets K.
1 Deliverables (Matlab code file): srmax_zf_exhaustive.m
function [R q] = srmax_zf_exhaustive(H,P)
• R: sum rate achieved at the globally optimal zero-forcing solution
• q: column vector [q1 , . . . , qK ]T containing the powers at the globally optimal zeroforcing solution
• Make use of sumrate_zf(H,P,s) from Programming Task 6.8.
To avoid the high computational complexity of an exhaustive search (espcially for large numbers
of user K such as in load_example('large')), we implement a suboptimal solution based
on a so-called greedy allocation [1]. The algorithm performs a successive allocation, i.e., one
user after another is added to the set of active users.
The algorithm is initialized with an empty set K = ∅. Then, a series of allocation steps is
performed where each step works as follows. Given a set K of active users with |K| < m, we
k ⋆ = arg max R({k} ∪ K)
(6.25)
k∈{1,...,K}\K
which can be solved by a linear search, i.e., by testing all possible k. If R({k} ∪ K) ≥ R(K),
the algorithm replaces K ← {k} ∪ K and proceeds to the next allocation step. Otherwise, the
algorithm terminates, and K is the obtained suboptimal solution. The algorithm also terminates
if a set of cardinality |K| = m has been found so that no further users can be added.
The number of rates R(K) that have to be computed is quadratic in the number of users for
the greedy algorithm while it is exponential in the case of an exhaustive search. Therefore, the
greedy allocation can be applied for large numbers of users, which is not true for the exhaustive
search.
PROGRAMMING TASK 6.10
Implement a function that computes a suboptimal zero-forcing sum rate by performing a
greedy allocation.
1 Deliverables (Matlab code file): srmax_zf_greedy.m
function [R q] = srmax_zf_greedy(H,P)
• R: sum rate achieved at the suboptimal zero-forcing solution
• q: column vector [q1 , . . . , qK ]T containing the powers at the suboptimal zero-forcing
solution
6.4 Comparison
Since the problem with zero-forcing constraints has a more restrictive constraint set, its optimal solution always has to lie below the optimal solution of the problem without zero-forcing
constraints. Moreover, it is clear that the suboptimal algorithm proposed for each of the problems must perform worse than the respective globally optimal solution. This behavior can be
observed by plotting the average sum rate achieved with each of the algorithms.
TASK 6.11
Compare the four algorithms by calling plot_all. Zoom in to see the different behavior
at low, intermediate, and high values of P .
It is known that zero-forcing becomes optimal for very low power (where only one stream is
transmitted in the optimal strategy) and very high power (where suppression of interference
becomes crucial), but a performance gap compared to the branch-reduce-and-bound solution
without zero-forcing should be observable at intermediate SNR.
Since problem (6.24) is a discrete optimization problem, the greedy allocation finds the globally
optimal set K at least in some cases while a suboptimal set is chosen in other cases. Therefore,
the difference of the achieved rates Rexhaustive − Rgreedy is either zero or positive, yielding a
positive difference on average.
Similar considerations are true for the comparison of the BRB solution and the gradient solution. Since the gradient-projection method converges to a local optimum, its achieved rate is
equal to the globally optimal rate if the local optimum is also the global one, but it is lower
if the local optimum is not the global one. However, it has to be taken into account that the
BRB algorithm only finds an ǫ-optimal solution. Therefore, it might happen that the grandient
method delivers a higher sum rate than the BRB algorithm, but in that case, the difference is
never more than ǫ. Nevertheless, the gradient solution should be worse on average at least for
sufficiently small ǫ.
[1] G. Dimic and N. Sidiropoulos, On downlink beamforming with greedy user selection:
performance analysis and a simple new algorithm, IEEE Transactions on Signal Processing, 53 (2005), pp. 3857–3868.
[2] D. P. Palomar and Y. Jiang, MIMO Transceiver Design via Majorization Theory, Foundations and Trends® in Communications and Information Theory, 3 (2006), pp. 331–551.
[3] H. Tuy, F. Al-Khayyal, and P. Thach, Monotonic Optimization: Branch and Cut Methods, in Essays and Surveys in Global Optimization, Springer, New York, NY, USA, 2005,
ch. 2, pp. 39–78.
[4] A. Wiesel, Y. Eldar, and S. Shamai, Zero-Forcing Precoding and Generalized Inverses,
IEEE Transactions on Signal Processing, 56 (2008), pp. 4409–4418.
