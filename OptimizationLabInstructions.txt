Technische Universität München

Optimization in Communications Engineering Laboratory
Instructions
Univ.-Prof. Dr.-Ing. Wolfgang Utschick
Dipl.-Ing. David Neumann

Department of Electrical Engineering and Information Technology
Associate Institute for Signal Processing
Univ.-Prof. Dr.-Ing. Wolfgang Utschick

Contents
1 Introduction

3

2 Gradient-Based Algorithms
2.1 Introduction . . . . . . . . . . . . . . . . .
2.2 MIMO Multiple Access Channel . . . . . .
2.3 Precoder Optimization . . . . . . . . . . .
2.3.1 Gradient Step . . . . . . . . . . . .
2.3.2 Projection Step . . . . . . . . . . .
2.4 Covariance Optimization . . . . . . . . . .
2.4.1 Gradient Step . . . . . . . . . . . .
2.4.2 Projection Step . . . . . . . . . . .
2.5 Complete Algorithm . . . . . . . . . . . .
2.6 Step-Size Control Methods . . . . . . . . .
2.6.1 Open Loop Step-Size Rule . . . . .
2.6.2 Exact Line Search . . . . . . . . .
2.6.3 Generalized Armijo Step-Size Rule

.
.
.
.
.
.
.
.
.
.
.
.
.

12
12
13
15
15
16
18
18
18
20
21
22
23
24

.
.
.
.
.
.
.
.
.
.
.
.

28
28
29
29
29
31
34
36
36
37
39
39
40

4 Lagrangian Duality and Solution Methods for Dual Problems
4.1 Network Flow Problem with Variable Arc Capacities . . . . . . . . . . . . .
4.2 Dual Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Subgradient Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

42
44
45
46

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

3 Linear Programming and Interior-Point Methods
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Interior Point Algorithms for Linear Programs . . . . . . .
3.2.1 Standard Formulation for Linear Programming . .
3.2.2 Primal Interior Point Algorithm . . . . . . . . . .
3.2.3 Primal-Dual Interior Point Algorithm . . . . . . .
3.2.4 Predictor-Corrector Method . . . . . . . . . . . .
3.3 Networks and Flows . . . . . . . . . . . . . . . . . . . . .
3.3.1 Graphical Representation of Networks . . . . . . .
3.3.2 Linear Network Flow Problems . . . . . . . . . .
3.3.3 Linear Multicommodity Flow Problems . . . . . .
3.4 Examples for Flow Problems in Communication Networks
3.4.1 Maximum Data Throughput . . . . . . . . . . . .

1

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

Contents

4.4
4.5
4.6

4.7

Cutting Plane Method . . . . . . . . .
Multi-Commodity Flow Problem . . .
Primal Recovery . . . . . . . . . . . .
4.6.1 General Primal Recovery . . .
4.6.2 Cutting Plane Primal Recovery
4.6.3 Subgradient Primal Recovery
Modularity of the Dual Decomposition

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

5 Conic Optimization and SDPT3
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . .
5.2 Conic Optimization . . . . . . . . . . . . . . . . . . . .
5.2.1 Examples of Proper Cones . . . . . . . . . . . .
5.2.2 Standard Conic Form and Related Problems . . .
5.3 SDPT3 . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4 Linear Precoder Design in the Vector Broadcast Channel
5.4.1 Power Optimization . . . . . . . . . . . . . . . .
5.4.2 Problem Reformulation . . . . . . . . . . . . . .
5.5 WSR Maximization in MIMO MAC . . . . . . . . . . .

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

6 Nonconvex Optimization
6.1 Monotonic Optimization: Branch, Reduce, and Bound . . . .
6.1.1 Branching . . . . . . . . . . . . . . . . . . . . . . . .
6.1.2 Reduction . . . . . . . . . . . . . . . . . . . . . . . .
6.1.3 Bounding . . . . . . . . . . . . . . . . . . . . . . . .
6.1.4 The Algorithm . . . . . . . . . . . . . . . . . . . . .
6.2 Suboptimal Solution: Gradient Ascent . . . . . . . . . . . . .
6.3 Zero-Forcing Solution . . . . . . . . . . . . . . . . . . . . .
6.3.1 Optimal Zero-Forcing Solution: Exhaustive Search . .
6.3.2 Suboptimal Zero-Forcing Solution: Greedy Allocation
6.4 Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.

49
51
54
55
57
60
61

.
.
.
.
.
.
.
.
.

63
63
64
65
65
67
70
71
72
75

.
.
.
.
.
.
.
.
.
.

81
82
83
83
84
85
87
88
90
91
92

Chapter 1

Introduction
For the programming tasks in this optimization laboratory, we recommend to use Matlab 7.9 or
a newer Matlab version. The latest Matlab version can be obtained at https://matlab.rbg.tum.de/.
In this chapter, the standard optimization tool CVX for Matlab is introduced. We compare this
optimization modeling language and its interior-point solvers with solution approaches that are
based on the Karush-Kuhn-Tucker (KKT) conditions.

Introduction to CVX
A standard toolbox for solving convex optimization problems in Matlab is CVX [2], which is
available for free from http://cvxr.com/cvx/. More speciﬁcally, CVX turns Matlab into
an optimization modeling language for disciplined convex programming (DCP)—a methodology for constructing convex optimization problems proposed by Michael Grant, Stephen Boyd,
and Yinyu Ye [3]. The toolbox consists of a limited set of construction rules, i.e., the DCP ruleset, for analyzing and eﬃciently solving important classes of convex optimization problems.
For example, CVX is capable of dealing with linear programs (LPs), second-order cone programs (SOCPs), semideﬁnite programs (SDPs), and any other convex optimization programs
that adhere to the DCP ruleset. These problems can rapidly and automatically be veriﬁed as
convex and converted to a form that the standard CVX interior-point solvers SeDuMi [5] and
SDPT3 [6] support. However, note that CVX is in general incapable of verifying whether a
problem is convex or not.
The advantage of CVX over directly using the interior-point solvers is that the CVX modeling
speciﬁcations can be constructed using common Matlab operations and functions, and standard
Matlab code can be freely mixed with these speciﬁcations. This makes it easy to implement
convex optimization problems in Matlab and read the code when employing CVX. For example,
the CVX speciﬁcation of the LP
min

cT x

s. t.
3

Ax ≤ b

Chapter 1. Introduction

with variable x ∈ Rn and m inequality constraints reads as follows:
1
2
3
4
5
6
7

n = size(A,2);
cvx_begin
variable x(n);
minimize( c' * x );
subject to
A * x <= b;
cvx_end
optimization

%
%
%
%

begin loading optimization structure
variable definition
objective function
definition of the constraint set

% reformulation and solution of the ...

The newest version of CVX and the CVX users’ guide can be obtained from
http://cvxr.com/cvx/download/.
TASK 1.1
Download and read the CVX users’ guide [2].

TASK 1.2
Install CVX in the folder for your Matlab simulations according to [2, Appendix A]:
• Retrieve the latest version of CVX from http://cvxr.com/cvx/download/ and
unpack the ﬁle in your simulations folder, e.g., home/user/simulations for a
Linux system or D:/user/simulations if you are on Windows.
• Start Matlab and change to the location of CVX, e.g., by typing either
cd home/user/simulations/cvx

or
cd D:/user/simulations/cvx.

• To setup CVX, type the command cvx_setup. This program sets the Matlab paths
for the CVX program ﬁles and runs a simple test problem.
• To save the path for subsequent Matlab sessions, either type savepath or follow the
instructions by cvx_setup.
Now, CVX should be ready for use. For example, you can try CVX by entering either of the
examples in [2, Chapter 2].

Communication over Parallel Gaussian Channels – Waterﬁlling Solution
The ﬁrst problem we consider is to transmit information from one source S to one terminal T
over n parallel Gaussian channels. Each of these channels i ∈ {1, . . . , n} has an input xi ∈ C
and an output yi ∈ C. The output of the i-th channel can be expressed as
yi = hi xi + ηi ,
4

(1.1)

Chapter 1. Introduction
2
where hi ∈ C denotes the complex-valued channel coeﬃcient and ηi ∼ NC (0, σi ) the circularly symmetric additive white Gaussian noise. Note that the channels are orthogonal, i.e.,
there is no interference between the channels.

From information theory, it is known that the capacity of the i-th channel is equal to
ci = log2 1 +

|hi |2 pi
2
σi

(1.2)

if pi is the power available at the input xi [1, Chapter 9]. Furthermore, the rate ci can then
be achieved on the i-th channel by choosing xi ∼ NC (0, pi ). Let us now assume that the
information rate on the i-th channel is actually given by its capacity, i.e.,
ri (pi ) = log2 (1 + γi pi ) ,

(1.3)

2
where γi = |hi |2 /σi > 0 speciﬁes the quality of the channel. Given these conditions, we want
to determine the maximum rate n ri (pi ) that can be reliably transmitted over the n parallel
i=1
channels if the sum of the powers pi is limited. In other words, we want to solve the following
optimization problem, where P > 0 is the available power budget for all channels:
n

n

R⋆ = max

p1 ,...,pn

log2 (1 + γi pi )

s. t.

i=1

i=1

pi ≤ P,

(1.4)

\todo{How to implement a sum constraint in cvx?}
\todo{Conversion maximization to minimization problem?}

PROGRAMMING TASK 1.3
Implement an algorithm that takes the channel coeﬃcients h1 , . . . , hn , the noise variances
2
2
σ1 , . . . , σn , and the available sum transmit power P as inputs and that uses CVX (with SDPT3
as solver) to compute the optimal solution to problem (1.4).
1 Deliverables (Matlab code ﬁle): waterfilling_cvx.m
• Function deﬁnition:
function [R,p,mu] = waterfilling_cvx(h,s,P)

2 Input Speciﬁcation:
• h: vector of channel coeﬃcients h1 , . . . , hn
2
2
• s: vector of noise variances σ1 , . . . , σn

• P: available sum transmit power P
3 Output Speciﬁcation:
• R: value of the maximal sum rate R⋆
• p: vector of optimal transmit powers p⋆ , . . . , p⋆
n
1
• mu: value of the optimal Lagrangian multiplier µ⋆
4 Veriﬁcation:

5

Chapter 1. Introduction

• Most of the functions that have to be implemented can be tested for correctness with
the provided test scripts test_Xxxx.m
For example, use the call test_waterfilling_cvx.
The optimal solution to problem (1.4) can also be obtained from the Karush-Kuhn-Tucker
(KKT) conditions in analytical form. If µ denotes the Lagrangian multiplier corresponding
to the inequality constraint n pi ≤ P , the optimal transmit powers are given by
i=1
1
ln(2)µ⋆

p⋆ =
i

0

−

1
γi

if γi > ln(2)µ⋆ ,
otherwise

⇔

1
1
− ,0 ,
⋆
ln(2)µ
γi

⋆
pi = max

(1.5)

where µ⋆ can be determined from the equation
n

n

p⋆ =
i
i=1

max
i=1

1
1
− ,0
⋆
ln(2)µ
γi

(1.6)

= P.

While the optimal solution is completely speciﬁed by (1.5) and (1.6), the actual values of the
1
pi ’s need to be computed iteratively. For ease of notation we substitute w⋆ = ln(2)µ⋆ and
1
ci = γi . Without loss of generality, suppose that c1 ≤ . . . ≤ cn , which obviously results in
p⋆ ≥ . . . ≥ p⋆ . Now we deﬁne k ⋆ as the index given by
n
1

k ⋆ = k ∈ {1, . . . , N } : w⋆ > ck and w⋆ ≤ ck+1 .

(1.7)

If k ⋆ is known, the optimal power allocations are given by
p⋆
i

=

w ⋆ − ci

0

for i ∈ {1, . . . , k ⋆ },

⋆

for i ∈ {k ⋆ + 1, . . . , n},

where w =

P+

k⋆
i=1 ci
.
⋆
k

(1.8)

The integer k ⋆ is simply found by successively checking the hypotheses k ⋆ = 1, . . . , n. That
is, start with the assumtion k ⋆ = 1, calculate the corresponding w⋆ given by (1.8) and then
check the conditions in (1.7). If the conditions do not hold, check the next hypothesis. The
solution to the considered problem is referred to as waterﬁlling with w⋆ as the water level. It
is illustrated in Figure 1.1, which explains where the term waterﬁlling originates from.
PROGRAMMING TASK 1.4
Implement an algorithm that takes the channel coeﬃcients h1 , . . . , hn , the noise variances
2
2
σ1 , . . . , σn , and the available sum transmit power P as inputs and that computes the optimal
waterﬁlling solution to problem (1.4) using the waterﬁlling algorithm.
1 Deliverables (Matlab code ﬁle): waterfilling.m
• Function deﬁnition:
function [R,p,mu] = waterfilling(h,s,P)

2 Input Speciﬁcation:
• h: vector of channel coeﬃcients h1 , . . . , hn
6

Chapter 1. Introduction

c7
c6
c5
w⋆

p⋆
4
p⋆
3
p⋆
1

p⋆
2

c4

c3

c2
c1

Figure 1.1: Illustration of the waterﬁlling solution for communication over 7 parallel channels.
2
2
• s: vector of noise variances σ1 , . . . , σn

• P: available sum transmit power
3 Output Speciﬁcation:
• R: value of the maximal sum rate R⋆
• p: vector of optimal transmit powers p⋆ , . . . , p⋆
n
1
• mu: value of the optimal Lagrangian multiplier µ⋆
4 Hint(s):
• First, reorder γ1 , . . . , γn such that γ1 ≤ . . . ≤ γn and determine k ⋆ ∈ {1, . . . , n}.
TASK 1.5
Measure and compare the execution times of your two functions waterfilling_cvx.m
and waterfilling.m for diﬀerent input parameters. Which of the two solutions is more
eﬃcient? Try to explain the results.

The Gaussian MIMO Point-to-Point Channel – Worst Case Noise Covariance
For the next problem, we use a linear multiple-input multiple-output (MIMO) communication
model, where the source S sends information over an n×m complex channel to the destination
T that is subject to additive and circular symmetric complex Gaussian noise. The received
7

Chapter 1. Introduction

signal y ∈ Cm at the destination is given by
(1.9)

y = Hx + η,

where x ∈ Cn comprises the n scalar channel inputs, H ∈ Cm×n is the complex channel gain
matrix, and the additive noise is η ∼ NC (0, Cη ) which is zero-mean and whose covariance
matrix is Cη = E[ηη H ].
The achievable rate of this system is given by the mutual information I(y; x) and reads as
−1
R = log2 det Im + Cη HQH H

(1.10)

if we assume Gaussian inputs x ∼ NC (0, Q) with zero-mean and covariance matrix Q =
E[xxH ]. In what follows, we assume Q to be ﬁxed and Cη to vary over time.
Even though Cη is assumed to vary, the total noise power shall be limited, which can be expressed as the constraint
(1.11)
E[ η 2 ] = tr Cη ≤ N.
2
Based on these assumptions, the worst case achievable sum rate is
−1
Rworst-case = min log2 det Im + Cη HQH H
Cη 0

s. t.

tr Cη ≤ N,

(1.12)

where Cη
0 expresses that Cη must be positive semideﬁnite. Note that this optimization
problem is convex, i.e., the KKT conditions are suﬃcient.
For solving (1.12), it is advantageous to introduce the eigenvalue decomposition (EVD) of the
noise covariance matrix as
Cη = V ΣV H
(1.13)
with the unitary modal matrix V ∈ Cm×m and the diagonal matrix Σ containing the eigenvalues σi along the diagonal. With the EVD of Cη , the constraint of (1.12) can be rewritten
as
n
i=1

σi ≤ N

σi ≥ 0

(1.14)

∀ i ∈ {1, . . . , m}.

We see that they are independent of the eigenvectors of Cη , i.e., the columns of V , contrary to
the utility function that is rewritten as
R = log2 det Im + V Σ −1 V H X
= − log2 det

Im + Σ −1/2 V H XV Σ −1/2

−1

,

(1.15)

with X = HQH H . Hence, the achievable rate R can be minimized with respect to the
eigenvectors of Cη without taking into account the constraints. The objective is minimized if
the determinant in the second line of (1.15) is maximized.
From Hadamard’s inequality, we know that the determinant of a nonnegative deﬁnite matrix is
upper bounded by the product of its diagonal elements and the upper bound can only be reached
8

Chapter 1. Introduction

if the matrix is diagonal (e.g., see [4]). Moreover, since the inverse A−1 is diagonal only if A
is diagonal, the matrix Im + Σ −1/2 V H XV Σ −1/2 must be diagonal. To reach this, we must
choose V such that it diagonalizes V H XV . That is, V has to be the unitary modal matrix of
the EVD of the positive semideﬁnite matrix X, i.e.,
X = V Ψ V H,
with the diagonal matrix Ψ = diag(ψ1 , . . . , ψm ) of eigenvalues ψi ≥ 0 for all i ∈ {1, . . . , m}.
With this optimal choice of the modal matrix V of Cη , the achievable rate R can be expressed
as
R = log2 det Im + Σ −1 Ψ
m

log2 1 +

=
i=1

ψi
σi

(1.16)

.

From this result and (1.14), we can conclude that the remaining optimization only depends on
the eigenvalues σi , i ∈ {1, . . . , m}, of Cη . In other words, we must solve
m

log2 1 +

Rworst-case = min

σi ≥0

i=1

ψi
σi

m

s. t.
i=1

σi ≤ N

(1.17)

to ﬁnd the worst-case achievable rate Rworst-case .
TASK 1.6
Show that the objective function of problem (1.17) is convex.
From this observation, it follows that the optimization problem is convex, i.e., we have the
minimization of a convex objective function over a convex (polyhedral) constraint set.
TASK 1.7
If you try using CVX to solve problem (1.17), it will not work. Think about the reason why
CVX is not applicable in this case.
The optimal solution to the convex optimization problem in (1.17) can be obtained from its
KKT conditions. If µ ≥ 0 denotes the Lagrangian multiplier corresponding to the inequality
constraint m σi ≤ N , and λi ≥ 0 denote the Lagrangian multipliers corresponding to the
i=1
inequality constraints σi ≥ 0, i ∈ {1, . . . , m}.
From the KKT conditions, one can verify the following solution structure:

0
ψi = 0,
σi =
ψi
1
2 + 4ψ µ′ ψ > 0,
− +
ψ
i
i
2

where µ′ =

1
µ ln(2)

2

(1.18)

i

is given via the implicit equation
m

2N +

m
2
ψi + 4ψi µ′ .

ψi =
i=1

i=1

9

(1.19)

REFERENCES

Since the right hand side of (1.19) is continuous and increasing in µ′ , its optimum solution may
be found via a simple ﬁxed point search, e.g., a bisection search or a Newton method. A lower
2
′
2N + m ψi − m ψ 2
bound for µ′ is µ′
lower = 0 and an upper bound is given by µupper =
i=1
i=1
PROGRAMMING TASK 1.8
Implement an algorithm that takes the eigenvalues ψ1 , . . . , ψm of X and the maximal sum
noise power N as inputs and that computes the optimal solution to problem (1.17) given
in (1.18).
1 Deliverables (Matlab code ﬁle): worstcaseRate.m
• Function deﬁnition:
function [R,s,mu] = worstcaseRate(p,N)

2 Input Speciﬁcation:
• N: maximum total noise power
• p: vector of the eﬀective transmit powers ψ1 , . . . , ψn
3 Output Speciﬁcation:
• R: value of the worst-case sum rate Rworst-case
⋆
⋆
• s: vector of minimizing noise variances σ1 , . . . , σm

• mu: value of the optimal Lagrangian multiplier µ⋆
4 Hint(s):
• You can use the Matlab function fzero.m to obtain the optimal value for µ′ .

References
[1] T. M. Cover and J. A. Thomas, Elements of Information Theory, John Wiley & Sons,
2nd ed., 2006.
[2] M. Grant and S. Boyd, CVX: Matlab Software for Disciplined Convex programming,
version 1.21. cvxr.com/cvx, Apr. 2011.
[3] M. Grant, S. Boyd, and Y. Ye, Disciplined convex programming, in Global Optimization:
from Theory to Implementation, Nonconvex Optimization and Its Applications, L. Liberti
and N. Maculan, eds., Springer, New York, 2006, pp. 155–210.
[4] R. A. Horn and C. R. Johnson, Matrix Analysis, Cambridge University Press, New York,
MD, USA, 1st ed., 1990. Corrected reprint of the 1985 original.
[5] J. F. Sturm, Using SeDuMi 1.02, a MATLAB Toolbox for Optimization over Symmetric
Cones, Optimization Methods and Software, 11 (1999), pp. 625–653.

10

m
i=1 ψi .

REFERENCES

[6] K. Toh, R. Tütüncü, and M. Todd, SDPT3—A Matlab software package for semideﬁnite
programming, Optimization Methods and Software, 11 (1999), pp. 545–581.

11

Chapter 2

Gradient-Based Algorithms
2.1 Introduction
In classical optimization theory, gradient methods are used to solve unconstrained minimization or maximization problems. The gradient of a cost function deﬁnes the direction of the
steepest ascent. Moving along the gradient or the negative gradient leads to a local maximum
or minimum. In a concave/convex1 optimization problem, the local maximum/minimum is
unique and the acquired solution is the global optimum. Due to its almost intuitive understanding, its simple formulation, its numerical stability and eﬃcient computation, gradient methods
are among the most frequently used techniques for solving optimization problems.
Given a constrained optimization problem, moving along the direction of steepest ascent/descent may however lead to a solution that lies outside the constrained set. To overcome this
problem, in 1964 Goldstein and independently Levitin and Polyak in 1965, proposed a gradientprojection method, that provides an extension of standard gradient algorithms for constrained
optimization problems. The projected-gradient method applies to optimization problems in the
form
max f (X)
s.t.: X ∈ C.
(2.1)
X

Given that f is a continuously diﬀerentiable function over a nonempty closed convex set C
under a Lipschitz assumption on the gradient ∇f ,
X (a+1) = PC X (a) + s(a) ∇f (X (a) )

(2.2)

converges to a stationary point for a → ∞ when certain conditions on the stepsize(s) s(a) are
fulﬁlled. In (2.2), the operator PC deﬁnes a projection of its argument to the convex set C, c.f.,
(2.1). Again, if f is concave, X (∞) is the global maximizer of f .
1

In the following, will will refer to both cases brieﬂy as convex optimization problems.

12

Chapter 2. Gradient-Based Algorithms

TASK 2.1

• Is the projection unique? Why (not)?

• How can the projection be formulated mathematically?
The simple update rule (2.2) makes the gradient-projection method an attractive approach, if
∇f and PC (·) can be calculated eﬃciently. Furthermore, if the speed of convergence is significant, additional eﬀorts may be necessary in order to optimize the stepsize parameter s(a) .
In the ﬁrst part of this chapter, we will apply the projected-gradient method to maximize the
sum transmit data rate in a multi-point to point multiple-antenna system for a given sum power
constraint. In the second part of this chapter, we will apply optimal and suboptimal stepsize
control algorithms, that ensure convergence and balance the speed of convergence with additional computational eﬀorts.

2.2 MIMO Multiple Access Channel
In the MIMO Multiple Access Channel (MAC) model, a set of K transmitters simultaneously
accesses a physical resource to transmit data to a single receiver.
Similarly to the Point-to-Point MIMO channel (see Chapter 1), each of the K transmitters is
equipped with n antennas and the single receiver is equipped with m antennas. The received
signal vector is given by
K

H k Wk x k + η

y=

(2.3)

k=1

where Hk ∈ Cm×n denotes the k-th transmitter’s channel matrix, Wk ∈ Cn×n denotes
the precoder matrix of the input signal, xk ∼ NC (0, In ) comprises the n scalar channel inputs of the k-th transmitter and η ∼ NC (0, Cη ) denotes an additive noise distortion. In
the following we assume Cη = In . With the covariances of the precoded input signals
H
H
Qk = E[Wk xk xk H Wk ] = Wk Wk , the achievable data rate in the MAC (using dirty paper coding techniques [3]) is given by
K

Hk Qk H H )

(2.4)

H
Hk Wk Wk H H ).

R = log2 det(Im +

(2.5)

k=1
K

= log2 det(Im +
k=1

PROGRAMMING TASK 2.2
Implement a function to compute R(W1 , . . . , WK ).
1 Deliverables (Matlab code ﬁle): rateW.m
• Function deﬁnition: function R = rateW(W,H)
2 Input Speciﬁcation:
13

Chapter 2. Gradient-Based Algorithms
(a)

(a)

• H: m × n × K set of channel matrices H1 , . . . , HK
(a)

(a)

• W: n × n × K set of precoders W1 , . . . , WK
3 Output Speciﬁcation:
• R: achievable sum rate R
4 Hints:
• Make sure the return value is a real number.

PROGRAMMING TASK 2.3
Implement a function to compute R(Q1 , . . . , QK ).
1 Deliverables (Matlab code ﬁle): rateQ.m
• Function deﬁnition: function R = rateQ(Q,H)
2 Input Speciﬁcation:
(a)

(a)

• H: m × n × K set of channel matrices H1 , . . . , HK
(a)

(a)

• Q: n × n × K set of covariance matrices Q1 , . . . , QK
3 Output Speciﬁcation:
• R: achievable sum rate R
4 Hints:
• Make sure the return value is a real number.

Imposing a sum power constraint leads to a convex optimization problem with either the set of
precoder matrices {W1 , . . . , WK } = {Wk }K , or the set of covariance matrices {Qk }K
k=1
k=1
as optimization variables. The respective optimization problems are given by
K

K

max

W1 ,...,WK

H
H k Wk Wk H H )

log2 det(Im +

s.t.
k=1

k=1

and
max

H

log2 det(Im +

(2.6)

K

K
Q1 ,...,QK

||Wk ||2 ≤ P
F

Hk Qk H )

s.t.
k=1

k=1

tr(Qk ) ≤ P.

(2.7)

Although (2.6) and (2.7) yield the same result, 2 the gradient-based optimization approaches
for solving (2.6) and (2.7) show signiﬁcant diﬀerences in terms of formulation of the projection
PC , computational complexity, and the convergence speed of the resulting algorithms.
2

This is true only, if {Wk }K have full row/column rank. Note that the number of subchannels ℓ per transmitter
k=1
can be preselected by choosing a reduced size precoder matrix W ∈ Cn×ℓ with ℓ < n. In this case, the optimization
is non-convex and the retrieved precoder W yields a suboptimal sumrate. In this tutorial, we restrict ourselves to
the computation of full rank n × n precoder matrices to preserve convexity.

14

Chapter 2. Gradient-Based Algorithms

2.3 Precoder Optimization
2.3.1 Gradient Step
In order to perform a projected gradient step (2.2) for the problem in (2.6), we have to calculate
the gradient of R(W1 , . . . , WK ) by taking the derivative with respect to the precoder matrices
Wk . In general, the derivative of a function f (X) with respect to a matrix X ∈ Cn×n is
deﬁned element-wise as
 δf (X)

δf (X)
. . . δ[X]1,n
δ[X]1,1
δf (X)  .
. 
..
. 
= .
(2.8)
.
.
. 

δX
δf (X)
δf (X)
δ[X]n,1 . . . δ[X]n,n

where [X]i,j = eT Xej denotes the j-th scalar element of the i-th row of X. Since the cost
i
function R is a real valued function with complex arguments we can use the Wirtinger derivative to compute the gradient (for details see [5]). With (2.8) we calculate the Wirtinger derivative of (2.5) element-wise for the i-th row and the j-th column element, for each of the K
precoder matrices as
δR(W1 , . . . , WK )
∗
δ[Wk ]i,j
=

=

=

=

=

δ
log2 det Im +
∗
δ[Wk ]i,j


K
H
Hℓ Wℓ WℓH Hℓ
ℓ=1


1
δ
ln det Im +
∗]

ln 2 δ[Wk i,j


1
tr  Im +
ln 2

1
tr  Im +
ln 2
1 T H
e H
ln 2 i k

K

K
ℓ=1
ℓ=k




H
H
H
Hℓ Wℓ WℓH Hℓ + Hk Wk Wk Hk 

−1

H
Hℓ Wℓ WℓH Hℓ
ℓ=1
−1

K

δ
H
H
H k Wk Wk H k 
∗
δ[Wk ]i,j


H
H k Wk e j e T H k 
i

H
Hℓ Wℓ WℓH Hℓ
ℓ=1

−1

K
H
Hℓ Wℓ WℓH Hℓ

Im +



H k Wk e j ,

ℓ=1

where we have used the identities δ ln det(X) = tr(X −1 δX) and tr(AB) = tr(BA) [6]. By
arranging the elements we obtain the matrix derivative for each of the K precoder matrices.
We denote the components of the gradient as
δR(W1 , . . . , WK )
1
Vk =
HH
=
∗
δWk
ln 2 k

−1

K
H
Hℓ Wℓ WℓH Hℓ

Im +

H k Wk .

(2.9)

ℓ=1

The total gradient ∇R(W1 , . . . , WK ) is then the set of the K derivatives
∇R(W1 , . . . , WK ) = {V1 , . . . , VK } .
15

(2.10)

Chapter 2. Gradient-Based Algorithms

In our case, the gradient step in (2.2) refers to a simultaneous step for all precoder matrices.
This is denoted by the set notation
(a)′ K
}k=1

{Wk

(a)

= {Wk

K
+ s(a) Vk }k=1 ,

(2.11)

(a)′

where we Wk denotes the intermediate, unconstrained result of the gradient step for the k-th
precoder matrix. In the following section, we skip the iteration index (·)(a) for the sake of a
brief notation.
PROGRAMMING TASK 2.4
Implement a function to compute the gradient ∇R(W1 , . . . , WK ).
1 Deliverables (Matlab code ﬁle): gradW.m
• Function deﬁnition: function grad = gradW(H,W)
2 Input Speciﬁcation:
(a)

(a)

• H: m × n × K set of channel matrices H1 , . . . , HK
(a)

(a)

• W: n × n × K set of precoders W1 , . . . , WK
3 Output Speciﬁcation:
(a)

(a)

• grad: n × n × K set of derivatives V1 , . . . , VK

2.3.2 Projection Step
′
′
To complete the update (2.11), the projection PC ({W1 , . . . , WK }) onto the constraint set C
must be performed. In our problem setup, C is the manifold of sets of K non-negative deﬁnite
H
matrices Wk Wk that fullﬁl the sum power constraint in (2.5). The (orthogonal) projection
can be written as
′
′
PC ({Wk }K ) = {Wk + Ek ⋆ }K ,
(2.12)
k=1
k=1

where E ⋆ is the solution to the minimization problem
K

K
⋆
{Ek }K = arg min
k=1

E1 ,...,EK k=1

||Ek ||2
F

s.t.
k=1

′
||Wk + Ek ||2 ≤ P.
F

(2.13)

The constraint set of this minimization problem corresponds to a Kn2 dimensional ball, and
the projection to a mapping onto the surface of this ball. An illustration is given in Fig. 2.1.
The Lagrangian function (c.f., [1][2]) corresponding to (2.13) is given by
K

K
H
tr(Ek Ek ) + µ

L(E1 , . . . , EK , λ) =
k=1

k=1

16

′
′
tr (Wk + Ek )(Wk + Ek )H − P

(2.14)

Chapter 2. Gradient-Based Algorithms

{sVk }K
k=1
{Wk }K
k=1

⋆
{Ek }K
k=1

′
PC ({Wk }K )
k=1

C

Figure 2.1: Projection onto the constraint set
where µ is the Lagrangian multiplier. From the solution of setting the Wirtinger derivative of
(2.14) with respect to {E ∗ }K to zero, we ﬁnd that at the optimality point µ⋆ the condition
k=1
K
k=1

⋆
Ek = −

µ⋆
1 + µ⋆

K
′
Wk

(2.15)

k=1

′
must hold. The trivial case, when {Wk } already fulﬁlls the sum power constraint, corresponds
⋆
′
′
to µ⋆ = 0 and, thus, Ek = 0 =⇒ PC ({Wk }) = {Wk }. Otherwise we have µ⋆ > 0 and we
use (2.15) and the sum power constraint which leads to the projection

′
PC ({Wk }K )
k=1

=

′
{Wk

+

⋆
Ek }K
k=1

K

P

′
Wk
K
′ ||2
ℓ=1 ||Wℓ F

=

.

(2.16)

k=1

The obvious result of the Lagrangian optimization is that the projection onto the constraint set
can be performed by a scaling (2.16) of the precoder matrices. The simplicity of the projection
step is an advantage of the precoder approach when using the gradient-projection technique.
PROGRAMMING TASK 2.5
(a)

Implement the projection for the set of precoder matrices {Wk }K .
k=1
1 Deliverables (Matlab code ﬁle): projW.m
• Function deﬁnition: function WP = projW(W,P)
2 Input Speciﬁcation:
(a)

(a)

• W: n × n × K set of precoders W1 , . . . , WK
• P: available sum transmit power P
3 Output Speciﬁcation:
17

Chapter 2. Gradient-Based Algorithms
(a+1)

• WP: n × n × K set of projected precoders W1

(a+1)

, . . . , WK

2.4 Covariance Optimization
2.4.1 Gradient Step
To perform a gradient step on the set of covariance matrices {Qk }K , the Wirtinger derivative
k=1
of the cost function R with respect to {Qk }K must be calculated.
k=1
TASK 2.6
1 ,...,Q
Calculate the Wirtinger derivative Vk = δR(QδQT K ) for (2.4) to construct the unconk
strained gradient step. Proceed at ﬁrst element-wise and then rearrange the matrix elements,
as it has been shown before for the precoder matrices.

Similar to the precoder approach, we can now use the gradient matrices Vk for an unconstrained
gradient step on the set of covariances matrices
(a)′

(a)

{Qk }K = {Qk + s(a) Vk }K .
k=1
k=1

(2.17)

PROGRAMMING TASK 2.7
Implement a function to compute the gradient ∇R(Q1 , . . . , QK ).
1 Deliverables (Matlab code ﬁle): gradQ.m
• Function deﬁnition: function grad = gradQ(H,Q)
2 Input Speciﬁcation:
(a)

(a)

• H: m × n × K set of channel matrices H1 , . . . , HK
(a)

(a)

• Q: n × n × K set of covariance matrices Q1 , . . . , QK
3 Output Speciﬁcation:
(a)

(a)

• grad: n × n × K set of derivatives V1 , . . . , VK

2.4.2 Projection Step
The projection of the unconstrained covariance matrices {Q′ }K after the gradient step is
k k=1
based on the same principle as for the precoder matrices. The full derivation of the covariance
projection step is shown in [4]. In this section we highlight the main results only. The projection

18

Chapter 2. Gradient-Based Algorithms
′
PC ({Q′ , . . . , QK }) to the manifold of K non-negative deﬁnite matrices Qk with the sum
1
power constraint (2.4) can be written as
K
K
PC ({Q′ }k=1 ) = {Q⋆ }K = arg min
k k=1
k

Q1 ,...,QK k=1

Q′ − Qk

2
F

s. t.

0∀k

Qk
K

and
k=1

(2.18)

tr(Qk ) ≤ P.

Through analysis of the KKT conditions it can be shown that the optimal covariance matrices Q⋆ must have the same eigenbasis Uk as the respective unconstraint matrices Q′ . The
k
k
optimization problem in (2.18) can thus be reformulated to
K

λ⋆ · · · λ⋆
1,1
K,n

K

n

(λ′
k,i

= arg min
k=1 i=1

− λk,i ) s. t. λk,i ≥ 0,

n

k=1 i=1

λk,i ≤ P

(2.19)

⋆
where λ′ and λk,i are the ith eigenvalues of Q′ and Q⋆ respectively. That is, we want to
k,i
k
k
project an Kn-dimensional vector onto the scaled standard (Kn − 1)-simplex.

Let µ⋆ > 0 denote the optimal Lagrangian multiplier to the transmit power constraint in the
non-trivial case. The optimal eigenvalues are given by
λ⋆ = λ′ − µ⋆
k,i
k,i

+

(2.20)

.

and the sum power constraint can be formulated as
K

n

λ⋆ = P
k,i

(2.21)

k=1 i=1

This problem closely resembles the waterﬁlling problem for which the solution is known from
Chapter 1.
Since this approach requires the computation of the eigenvalue decompositions of all covariance matrices Q′ , . . . , Q′ , the computational eﬀort is signiﬁcantly higher in comparison to the
1
K
simple scaling that needed to be performed for projection of the precoder matrices. However,
the covariance approach provides a higher speed of convergence than the precoder approach
for most scenarios as we will see later on.
PROGRAMMING TASK 2.8
(a)

Implement the projection for the set of covariance matrices {Qk }K .
k=1
1 Deliverables (Matlab code ﬁle): projQ.m
• Function deﬁnition: function QP = projQ(Q,P)
2 Input Speciﬁcation:
(a)

(a)

• Q: n × n × K set of covariance matrices Q1 , . . . , QK
• P: available sum transmit power P
19

Chapter 2. Gradient-Based Algorithms

3 Output Speciﬁcation:
(a+1)

• QP: n × n × K set of projected covariance matrices Q1

(a+1)

, . . . , QK

2.5 Complete Algorithm
In this section we put together an algorithm for solving the sum rate maximization problems
in (2.7) and (2.6). As a ﬁrst simple approach we implement a projected gradient algorithm with
a ﬁxed step size.
For the termination condition we use
(X (a) − X (a−1) )/s(a)

2
F

< ζ,

(2.22)

which is an approximation of the gradient projected onto the tangent cone of the constraint set
at X (a−1) .
PROGRAMMING TASK 2.9
Implement a general projected gradient algorithm based on (2.1) and (2.2). Use a ﬁxed step
size of s(a) = 1 and the termination condition in (2.22) with ζ = 10−10 .
1 Deliverables (Matlab code ﬁle): projGrad.m
• Function deﬁnition:
function [xOpt fOpt] = projGrad(fun,grad,proj,x,nIter)

2 Input Speciﬁcation:
• fun: objective function f (X)
• grad: gradient of the objective function ∇f (X)
• proj: projection PC (X) onto the constraint set C
• x: initial value X (0)
• nIter: maximum number of iterations
3 Output Speciﬁcation:
• xOpt: resulting optimization variables
• fOpt: corresponding value of the objective function
4 Hints:
• Calculate the squared Frobenius norm like this:

1
2

gApprox = (x − xOld)/s;
frobNorm = gApprox(:)'*gApprox(:);

20

Chapter 2. Gradient-Based Algorithms

• Make sure that the initial value lies within the feasible set

PROGRAMMING TASK 2.10
Implement a function that plots the value of the objective function with respect to the iterations a = 1, · · · , N when using the projected gradient algorithm to solve the sum rate
maximization problems in (2.7) and (2.6) respectively.
1 Deliverables (Matlab code ﬁle): plotObjValues.m
• Function deﬁnition: function = plotObjValues(H,P,nIter)
2 Input Speciﬁcation:
(a)

(a)

• H: m × n × K set of channel matrices H1 , . . . , HK
• P: available sum transmit power P
• nIter: number of iterations N
3 Hints:

• To use the cost, gradient and projection functions implemented earlier as arguments
of the projected gradient algorithm projGrad the number of arguments has to be
reduced. This can be done by creating a new function handle, e.g. grad = ...
@(x)gradW(x,H). Now it is possible to call grad(W) with one argument. The
local variable H, which has to exist when the function handle is created, is always
used as the second argument.
• To test the function generate complex Gaussian distributed channel coeﬃcients
H = (randn(m,n,K)+ 1i*randn(m,n,K))/sqrt(2) and use an arbitrary
positive real number for the transmit power P .

2.6 Step-Size Control Methods
Step size control plays a crucial role in Gradient algorithms with respect to the algorithms’
convergence behaviours. While until now we have set the step-size s(a) = 1, we can see from
the invocation of plotObjValues.m with diﬀerent values for the transmit power P that this
does lead to suboptimal convergence behavior in most cases. We can notice that for some
simulations the projected-gradient steps do not converge to the optimal solution at all. Instead,
an oscillating behavior in the vicinity of some sub-optimal point is exhibited.
A straight-forward attempt on addressing this issue could be to probe diﬀerent (ﬁxed) step-size
values successively and check for an improvement of the result and the optimality of the solution
via the (suﬃcient) KKT conditions. While this "manual" step-size optimization is possible in
a oﬄine simulation, it is not suitable for the case that the gradient algorithm is implemented
in a real world scenario, e.g., a mobile transmitter base station. For that reason, various step

21

Chapter 2. Gradient-Based Algorithms

size control algorithms have become known in literature that assure convergence to the optimal
solution and balance convergence speed with the required computational cost.
2.6.1 Open Loop Step-Size Rule
For any step size control that satisﬁes the two conditions
∞

lim s(a) = 0 and

a→∞

a=1

s(a) = ∞,

(2.23)

the convergence to the stationary point of the cost function is guaranteed. An obvious choice
that satisﬁes the conditions is the harmonic series
s(a) =

c
,
a

a = {1, . . . , ∞}

(2.24)

where c ∈ R+ denotes an arbitrary real positive constant. Note however, that this exogenous
choice for the step-size lacks practical usability, since the algorithm needs inﬁnite time to converge to the optimum. If a ﬁnite number of gradient steps is performed then. The quality and
speed of convergence depends on the deﬁnite choice of c.
PROGRAMMING TASK 2.11
Extend the projected gradient function with an additional optional parameter which determines the method for the step size control. Add two choices for the parameter: 'fixed'
1
and 'open_loop'. Implement the open loop step size control with s(a) = a ,
a =
{1, . . . , ∞}.
1 Deliverables (Matlab code ﬁle): projGrad.m
• Function deﬁnition:
function [xOpt fOpt] =
projGrad(fun,grad,proj,x,nIter,method)

2 Input Speciﬁcation:
• fun: objective function f (X)
• grad: gradient of the objective function ∇f (X)
• proj: projection PC (X) onto the constraint set C
• x: initial value X (0)
• nIter: number of iterations
• method: optional parameter determining the step size control method. Either
'fixed' or 'open_loop'. Defaults to 'fixed'.
3 Output Speciﬁcation:
• xOpt: resulting optimization variables
22

Chapter 2. Gradient-Based Algorithms

• fOpt: corresponding value of the objective function
4 Hints:
• You can use exist('method','var') to check whether method is provided.

2.6.2 Exact Line Search
The step-size control itself is a one-dimensional optimization problem that can be stated for
each gradient iteration as
(a)
max f (PC (X (a) + sVk )).
(2.25)
s

Again the solution to (2.25) is unique due to the convexity of f . When f is analytic, Lagrangian
optimization can be used to tackle this optimization problem. In this case, the Wirtinger derivative must be computed and the optimal solution for s is formulated as an eigenvalue problem.
Since (2.25) is a one-dimensional optimization problem, for practical purposes the solution
can be obtained via well known numerical methods, e.g., Newtons method, or the Bisection
method, which does not require computation of the Wirtinger derivative, but multiple numerical evaluations of f only.
PROGRAMMING TASK 2.12
Extend the projected gradient algorithm with the additional choice of method='optimal'
which selects the optimal line search as step size control
1 Deliverables (Matlab code ﬁle): projGrad.m
• Function deﬁnition:
function [xOpt fOpt] =
projGrad(fun,grad,proj,x,nIter,method)

2 Input Speciﬁcation:
• fun: objective function f (X)
• grad: gradient of the objective function ∇f (X)
• proj: projection PC (X) onto the constraint set C
• x: initial value X (0)
• nIter: number of iterations
• method: optional parameter determining the step size control method.
3 Output Speciﬁcation:
• xOpt: resulting optimization variables
• fOpt: corresponding value of the objective function
4 Hints:
• Use fminunc to solve for the optimal step size.

23

Chapter 2. Gradient-Based Algorithms

σ=1
exact line
search solution

σ=

1
2

σ=

1
4

b↓
b↓
f (X (a) )

b↑

b↑

Armijo’s solution
s
f (X (a) + sV (a) )

β 3 smax smax β 2
0
0

smax β 1
0

smax
0

1
1
Figure 2.2: The Armijo rule for β = 2 exempliﬁed for σ = 2 and σ =
(coincidentally) both values of σ lead to the same Armijo step size.

1
4.

For s0 = smin ,
0

2.6.3 Generalized Armijo Step-Size Rule
The computational eﬀort to compute the exact line search is very high and makes this approach
undesirable in practical systems. The Armijo rule is an inexact line search method for unconstrained optimization problems which has been extended to the case of the constrained
projected-gradient method [2]. The generalized Armijo rule ensures convergence to the optimum solution even for the constrained case, if the step size is parametrized as
(a)

s(a) = s0 β b

(a)

(2.26)
(a)

with 0 < β < 1 as an iteration-independent constant, and s0 as an iteration-dependent that
itself must be bounded above and below by two iteration independent positive real numbers
(a)
0 < smin ≤ s0 ≤ smax < ∞. The iteration-dependent parameter b(a) ∈ N0 is used for an
0
0
(a)
exponential scaling of s0 via the basis β. Since N0 ⊂ R, the optimal step-size w.r.t. (2.25)
is obtained via (2.26) with probability zero. The Armijo solution however is guaranteed to lie
in a ǫ interval that encloses the optimum solution and ensures that ǫ → 0 as a → ∞. The
parameter b(a) must be obtained dynamically for each gradient step according to the Armijo
rule.
The Armijo rule [1] is known from the lecture to this course. The general idea behind the
Armijo rule is that very large or very small step-sizes must relate to a signiﬁcant increase in the
cost function in order to qualify for application. This relation is measured by the slope of the
gradient and a scaling constant σ from that the intersection of the cost function and the σ-scaled
ﬁrst order linear approximation of the cost function is derived. The parameter b ∈ N0 is then obtained by ﬁnding the pair of adjacent stepsize parameters b↑ and b↓ that inclose the intersection
24

Chapter 2. Gradient-Based Algorithms

point for a deﬁned value of σ. For sake of simplicity we only search in the increasing direction.
(a)
That is, if the initial step size s0 leads to a point below the intersection point with the cost
function we choose b = 0. Otherwise, the Armijo step size is found by successively increasing
b(a) by 1, until the evaluation of the σ-scaled linear approximation undertakes the cost function
f . That process is described mathematically in terms of the combinatorial optimization
˜(a) =
b

arg max
b∈{b↑ ,b↓ }

(a)

f (PC (X (a) + s0 β b V (a) ))

s.t.

|b↑ − b↓ | = 1

(2.27)

and
(a)

f (PC (X (a) + s0 β b↑ V (a) )) − f (X (a) ) ≥ σ PTC (X (a) ) (V (a) )

2
F

(a)

(2.28)

(a)

(2.29)

s0 β b ↑

and
(a)

f (PC (X (a) + s0 β b↓ V (a) )) − f (X (a) ) ≤ σ PTC (X (a) ) (V (a) )

2
F

s0 β b ↓

where PTC (X (a) ) performs a projection of the gradient onto the tangent cone at X (a) . The
actual choice is then b(a) = max(˜(a) , 0). A visualization of the Armijo rule is depicted in
b
Figure 2.2.
In general, PTC (X (a) ) must be derived analytically, similarly to the way the projection on the
constraint set PC has been derived for the precoder and the covariance approach earlier in this
chapter. Furthermore, the additional projection operation must be performed which increases
the computational costs of the step-size control. In order to overcome this burden, the tangent
cone projection can be estimated via the constraint set projection. This (under-)estimation is
given as
PTC (X (a) ) (V (a) )

2
F

(a)

≥

PC (X (a) + s0 β b V (a) ) − X (a)

2
F

(2.30)

(a)
( s0 β b )2

The resulting approximated relations (2.28) and (2.29) then read as
(a)

(a)

f (PC (X (a) + s0 β b V (a) )) − f (X (a) )

σ

PC (X (a) + s0 β b V (a) ) − X (a)
(a)

s0 β b

2
F

. (2.31)

PROGRAMMING TASK 2.13
Implement the Armijo step size control of s(a) for the projected gradient algorithm
(method='armijo'. Use the Armijo parameter set β = 1/2 and σ = 0.2. As a heuristic
(a)
(0)
for the initial step size, we choose s0 = 2s(a−1) . Choose s0 = 100 for the initial step
size in the ﬁrst iteration.
1 Deliverables (Matlab code ﬁle): projGrad.m
• Function deﬁnition:
function [xOpt fOpt] =
projGrad(fun,grad,proj,x,nIter,method)

2 Input Speciﬁcation:
25

REFERENCES

• fun: objective function f (X)
• grad: gradient of the objective function ∇f (X)
• proj: projection PC (X) onto the constraint set C
• x: initial value X (0)
• nIter: number of iterations
• method: optional parameter determining the step size control method.
3 Output Speciﬁcation:
• xOpt: resulting optimization variables
• fOpt: corresponding value of the objective function

PROGRAMMING TASK 2.14
Update the plot function, to plot the results for the diﬀerent step size control methods.
1 Deliverables (Matlab code ﬁle): plotObjValues.m
• Function deﬁnition: function = plotObjValues(H,P,nIter)
2 Input Speciﬁcation:
(a)

(a)

• H: m × n × K set of channel matrices H1 , . . . , HK
• P: available sum transmit power P
• nIter: number of iterations N

TASK 2.15
Plot the results for diﬀerent problem sizes, and diﬀerent parameters for the step-size control
methods.
• What are the advantages/disadvantages of the diﬀerent step-size control methods?
• How does the optimization with respect to the precoders compare with the optimization with respect to the covariance matrices?

References
[1] M. S. Bazaraa, H. D. Sherali, and C. M. Shetty, Nonlinear Programming – Theory
and Algorithms, John Wiley & Sons, 3rd ed., 2006.
[2] D. P. Bertsekas, A. NediÄĞ, and A. E. Ozdaglar, Convex Analysis and Optimization,
Athena Scientiﬁc, 2003.
26

REFERENCES

[3] M. H. M. Costa, Writing on Dirty Paper, IEEE Transactions on Information Theory, 29
(1983), pp. 439–441.
[4] R. Hunger, D. A. Schmidt, M. Joham, and W. Utschick, A general covariance-based
optimization framework using orthogonal projections, Proceedings of the IEEE 9th Workshop on Signal Processing Advances in Wireless Communications (SPAWC), (2008),
pp. 76–80.
[5] M. Joham, MIMO Systems, Vorlesungsskript, Technische UniversitÃďt MÃĳnchen, 2011.
[6] K. B. Petersen and M. S. Pedersen, The Matrix Cookbook, http://matrixcookbook.com,
2008.

27

Chapter 3

Linear Programming and Interior-Point
Methods
3.1 Introduction
Within operations research and optimization, linear programming has the longest history – back
to the 1940’s when Dantzig invented his simplex algorithm [3]. Yet it remains the most important class of continuous optimization problems. State-of-the-art large scale linear programming
solvers are entirely based on interior point methods, initially proposed by Karmarker [6], which
oﬀer both best theoretical and practical performance. This part focuses on three renowned
methods: the primal barrier algorithm (Sec. 3.2.2), the primal-dual path following algorithm
(Sec. 3.2.3), and the predictor-corrector algorithm (Sec. 3.2.4). A comprehensive survey and
in-depth discussion of interior point methods for linear programming can be found in [9].
Linear network ﬂow problems constitute a subclass of linear programs of particular practical
and theoretical relevance. For example, ﬂow problems play a key role in research and implementation of todays wired and wireless communication networks [2]. The earliest linear
network ﬂow problems have been studied in the 1930’s by Tolstoi [8], cf. [7], which resembles a transportation problem that can be formulated as a minimum cost multicommodity ﬂow
problem. Later in the 1950’s, Harris and Ross [5] and Ford and Fulkerson [4] studied the
maximum ﬂow and the minimum cut problem, cf. [7], which resulted in the famous maximumﬂow minimum-cut theorem. In Sec. 3.3, the fundamentals of linear network ﬂow problems are
explained. Examples for the minimum cost and maximum ﬂow problems in communication
networks are studied in Sec. 3.4. A comprehensive introduction to networks and ﬂows can be
found in [1].

28

Chapter 3. Linear Programming and Interior-Point Methods

3.2 Interior Point Algorithms for Linear Programs
3.2.1 Standard Formulation for Linear Programming
All linear programs can be transformed into the following standard formulation
min cT x

s. t.

Ax = b, x ≥ 0,

(3.1)

where x, c ∈ Rn , b ∈ Rm and A is a m × n matrix. To transform a problem that is not in
standard form it is sometimes necessary to include additional variables.
A feasible point x satisﬁes the constraints Ax = b and x ≥ 0. All feasible points form the
feasible set. A point is strictly feasible if it is feasible and x > 0.
TASK 3.1
Before you read on write down the KKT conditions for the standard LP and ﬁnd the formulation of the dual problem.

PROGRAMMING TASK 3.2
Write a function that solves linear programs in standard formulation using CVX.
1 Deliverables (matlab code ﬁle): linprog_cvx.m
• Function deﬁnition:
function [x,y,s] = linprog_cvx(c,A,b)

2 Input speciﬁcation:
• c,A,b: problem data which deﬁnes the linear program in standard form (3.1)
3 Output speciﬁcation:
• x,y,s: resulting estimates of the optimal primal and dual variables

3.2.2 Primal Interior Point Algorithm
Historically the ﬁrst interior point algorithms that appeared were operating in the primal domain. The basic idea is to solve the approximate problem
min cT x − τ

log(xj )

s. t.

Ax = b, x > 0.

(3.2)

j

The approximate problem is well deﬁned on the domain of the logarithmic objective function,
i.e., the interior {x : x > 0} of the inequality constraint set {x : x ≥ 0}.
For τ → 0 the solution x⋆ to (3.2) approaches the solution to the primal problem (3.1). The
τ
central path C is the set of all x⋆ , which form a path leading to the optimal solution x⋆ . The
τ
29

Chapter 3. Linear Programming and Interior-Point Methods

primal IP algorithm follows the central path by solving (3.2) repeatedly and reducing τ by a
constant factor in each step, where the result from the previous optimization is used as a starting
point for the next one.
The KKT conditions for a solution x = x⋆ of (3.2) are given by
τ
AT y + τ X −1 1 − c = 0,

Ax − b = 0,

(3.3)

x > 0,

where X is a diagonal matrix with the elements of x as entries along the diagonal and 1 is a
vector of all ones. This can also be restated as a mapping FP from Rn+m to Rn+m
FP (x, y) = 0,
x > 0.

(3.4)

To ﬁnd the solution to (3.4), we use the iterative Newton method. For an estimate (x, y) of the
optimal solution, the search direction (∆x, ∆y) is given by the solution of
′
FP (x, y)

∆x
= −FP (x, y),
∆y

(3.5)

′
where FP is the Jacobian of FP , or

−τ X −2 AT
A
0

c − AT y − τ X −1 1
∆x
.
=
b − Ax
∆y

(3.6)

The new estimate is
(x, y) + α(∆x, ∆y).

(3.7)

The step size alpha α ∈ (0, 1] has to be chosen such that the condition x > 0 is always satisﬁed,
e.g.
xj
,1 .
(3.8)
α = 0.99995 min
min
j:∆xj <0 −∆xj
There are more sophisticated dynamic choices for the step size []. For simplicity we stick to
the one in (3.8) throughout this chapter.

Note that the solution does not have to be calculated exactly for each iteration of the Newton
algorithm. In fact, it is also possible to do one iteration of the Newton algorithm for one iteration
of the IP algorithm.
After each iteration of the IP algorithm τ is multiplied with a constant β ∈ (0, 1).
TASK 3.3
Think about the following questions:
• Why can we not choose a very small initial τ to directly calculate close to optimal
primal variables?
• What are eﬃcient ways to solve the linear system of equations in (3.6)?
30

Chapter 3. Linear Programming and Interior-Point Methods

PROGRAMMING TASK 3.4
Write an IP algorithm based on the description in this section. Use (3.6) to calculate the
search directions and (3.8) to calculate the step size α. Choose an appropriate β for the
update of τ and an appropriate termination criterion based on the parameter τ (terminate
when τ < ζ ). For initial estimates of the variables use x = 1 and y = 0.
1 Deliverables (matlab code ﬁle): IPPrimal.m
• Function deﬁnition:
function [x,y] = IPPrimal(c,A,b,beta,tau,zeta)
2 Input speciﬁcation:
• c,A,b: problem data which deﬁnes the linear program in standard form (3.1)
• beta: optional parameter that controls the progression of the algorithm (default:
β = 0.5)
• tau: optional parameter deﬁning a starting value for τ (default: τ = 1)
• zeta: optional parameter controlling the termination of the algorithm (default: ζ =
0.0001)
3 Output speciﬁcation:
• x,y: resulting estimates of the optimal primal and dual variables

3.2.3 Primal-Dual Interior Point Algorithm
In this section, we develop an approach for a primal-dual IP algorithm. Let us recap some
results from duality theory. The dual problem to (3.1) is given by
max bT y

s. t.

AT y + s = c, s ≥ 0

(3.9)

The KKT conditions for a primal-dual optimal solution (x, y, s) = (x⋆ , y ⋆ , s⋆ ) of both (3.1)
and (3.9) are given by

T

Ax − b = 0,

A y + s − c = 0,
XS1 = 0,

(3.10)

(x, s) ≥ 0.
X and S are diagonal matrices with the elements of x and s, respectively, as entries along the
diagonals, and 1 is a vector of all ones.

31

Chapter 3. Linear Programming and Interior-Point Methods

A point (x, y, s) is feasible if the primal and dual feasibility conditions are fulﬁlled, i.e.,
Ax = b,
T

A y + s = c,

(3.11)

(x, s) ≥ 0.
For any feasible point (x, y, s), the duality gap is given by
d = cT x − bT y ≥ 0.

(3.12)

The duality gap d vanishes at optimal points.
TASK 3.5
Find a formulation for the duality gap d(x, s) depending only on x and s. Use the primal
and dual feasibility conditions.
Analogously to (3.4), we restate the (3.10) as a mapping
F (x, y, s) = 0,
(x, s) ≥ 0.
We can calculate the search direction (∆xaﬀ , ∆y aﬀ , ∆z aﬀ ) as the solution to


 

0 AT I
−rc
∆xaﬀ


 

0  ∆y aﬀ  = −rb 
A 0
−rs
S 0 X
∆saﬀ

(3.13)

(3.14)

with the residuals rb = Ax − b, rc = AT y + s − c and rs = XS1. The matrix I denotes the
identity matrix. The search direction based on (3.14) is called the aﬃne scaling direction. In
general using the aﬃne search direction to ﬁnd the optimum does not lead to good performance
since often only very small step lengths α ≪ 1 are possible.
This issue is dealt with in the primal-dual IP algorithms by biasing the search toward the interior
of the feasible set, keeping the components of x and s from getting too close to the boundary.
This centering is achieved by modifying the equation system in (3.10) resulting in the following
system of equations:
T

Ax − b = 0,

A y + s − c = 0,

XS1 = τ 1,

(3.15)

(x, s) ≥ 0.
The only diﬀerence is on the right hand side of the complementary equation with the addition
of a parameter τ . Note that the equation system (3.15) is equivalent to (3.3), i.e., solutions to
(3.15) lie on the central path.
For the primal-dual IP algorithm we take Newton steps towards a point on the central path,
which results in a faster progress compared to pure Newton steps. To describe this biased
32

Chapter 3. Linear Programming and Interior-Point Methods

search direction, we introduce a centering parameter σ ∈ (0, 1) and a duality measure based
on the duality gap1
d(x, s)
.
(3.16)
µ=
n
With τ = σµ, we calculate the search direction as a Newton step based on the equation system
(3.15)
 



∆x
−rc
0 AT I
 



(3.17)
0  ∆y  =  −rb  .
A 0
∆s
S 0 X
σµ1 − rs
Note that the search direction can be decomposed into

(∆x, ∆y, ∆z) = (∆xaﬀ , ∆y aﬀ , ∆z aﬀ ) + (∆xc , ∆y c , ∆z c ),
where (∆xc , ∆y c , ∆z c ) is the centering direction which solves
 



0
∆xc
0 AT I
 



0  ∆y c  =  0  .
A 0
σµ1
∆sc
S 0 X

(3.18)

(3.19)

The new estimates for the primal and dual variables are given by
(3.20)

(x, y, s) + α(∆x, ∆y, ∆s),

where the step size α has to be chosen in a way such that (x, s) > 0. A possible choice is
α = 0.99995 min min

min

j:∆xj <0

xj
−∆xj

, min

j:∆sj <0

sj
−∆sj

,1 .

(3.21)

TASK 3.6
Based on the linear system of equations (3.17) we can derive a formulation D∆y = rD by
substitution of ∆s and ∆x, where D is a positive deﬁnite matrix.
• Find the expressions for D, rD and the substitutions of ∆s and ∆x.
• What is the advantage of this reformulation? How can the new problem be solved?

PROGRAMMING TASK 3.7
For our primal-dual IP algorithm we choose a constant centering parameter σ ∈ (0, 1). In
each step calculate the duality measure µ, the search direction according to (3.17), with your
results from Task 3.6, and update the current estimates of the optimal variables, considering
the step size α. The algorithm is terminated if the duality measure drops below a predeﬁned
accuracy threshold ζ.
1

For points (x, y, s) that are not feasible d(x, s) gives only an estimate of the duality gap. Nevertheless, this
estimate remains a good choice for the adaption of the parameter τ .

33

Chapter 3. Linear Programming and Interior-Point Methods

1 Deliverables (matlab code ﬁle): IPPrimalDual.m
• Function deﬁnition:
function [x,y,s] =
IPPrimalDual(c,A,b,sigma,zeta)

2 Input speciﬁcation:
• c,A,b: problem data which deﬁnes the linear program in standard form (3.1)
• sigma: optional parameter deﬁning the centering parameter σ (default: σ = 0.5 )
• zeta: optional parameter controlling the termination of the algorithm (default: ζ =
0.0001)
3 Output speciﬁcation:
• x,y,s: resulting estimates of the optimal primal and dual variables

3.2.4 Predictor-Corrector Method
Another approach is the predictor-corrector method, which is also based on the equation system
for the primal dual method in (3.15). There are two diﬀerences to the primal-dual approach in
the previous section. First we choose the centering parameter σ dynamically and second we use
second order information to calculate an additional correcting direction to make faster progress
towards the optimal points on the central path. If we have estimates (x, y, s) of the primal
and dual variables, the optimal search directions (∆x⋆ , ∆y ⋆ , ∆s⋆ ) for a certain centering
parameter σ are the solutions to the following nonlinear system of equations


0


F (x + ∆x⋆ , y + ∆y ⋆ , s + ∆s⋆ ) =  0  ,
(3.22)
σµ1
which can be reformulated to



 
0 AT I
∆x⋆
−rc



 
0  ∆y ⋆  = 
−rb
A 0
.
⋆
⋆
⋆
S 0 X
∆s
σµ1 − rs − ∆X ∆S 1

(3.23)

We can see that there is a nonlinear term ∆X ⋆ ∆S ⋆ 1 on the right hand side, which does not
appear when using the Newton method to calculate the search direction.
The idea is now to calculate the actual search direction in two steps. First we calculate the aﬃne
scaling direction (∆xaﬀ , ∆y aﬀ , ∆z aﬀ ) by solving (3.14). We use it to calculate a corrector
component of the search direction by solving the system of equations


 

0 AT I
0
∆xcor


 

(3.24)
0  ∆y cor  = 
0
A 0
.
S 0 X
∆scor
−∆X aﬀ ∆S aﬀ 1
34

Chapter 3. Linear Programming and Interior-Point Methods

Additionally, we compute the centering parameter
σ=

µaﬀ
µ

3

(3.25)

with
µaﬀ = d(x + αaﬀ ∆xaﬀ , s + αaﬀ ∆saﬀ )/n.

(3.26)

µaﬀ is the hypothetical value of µ that would result from a step in the aﬃne scaling direction
and αaﬀ is the step size given by (3.21) calculated for the aﬃne scaling direction. The intuition
behind this choice of σ is that, if we can do a large step in the aﬃne scaling direction before
hitting any constraint, we can choose a small centering parameter. On the other hand, if there
is only a small improvement going in the aﬃne direction before hitting a constraint, we need a
larger centering parameter.
With the new centering parameter σ, we can calculate the centering component of the search
direction by solving (3.19). Actually, the combined centering-corrector component can be
calculated by solving


 

0 AT I
∆xcc
0


 

(3.27)
0  ∆y cc  = 
0
A 0
.
cc
aﬀ
aﬀ
S 0 X
∆s
σµ1 − ∆X ∆S 1
This gives us our search direction as
(∆x, ∆y, ∆z) = (∆xaﬀ , ∆y aﬀ , ∆z aﬀ ) + (∆xcc , ∆y cc , ∆z cc ).

(3.28)

As with the other IP algorithms, we update the estimates by moving along the search direction
with a step size α according to (3.21) such that (x, s) > 0.
PROGRAMMING TASK 3.8
Write a predictor corrector IP algorithm for a linear program. In each iteration ﬁrst solve
(3.14) for the aﬃne scaling direction and then use it to calculate σ given by (3.25). With both
σ and the aﬃne scaling direction calculate the combined centering-corrector component
by solving (3.27) to get the total search direction given by (3.28). Then update the current
estimates with an appropriate step size α. The algorithm is terminated if the duality measure
drops below a predeﬁned accuracy threshold ζ.
1 Deliverables (Matlab code ﬁle): IPPredictorCorrector.m
• Function deﬁnition:
function [x,y,s] =
IPPredictorCorrector(c,A,b,zeta)

2 Input speciﬁcation:
• c,A,b: problem data which deﬁnes the linear program in standard form (3.1)
• zeta: optional parameter controlling the termination of the algorithm (default: ζ =
0.0001)
35

Chapter 3. Linear Programming and Interior-Point Methods

3 Output speciﬁcation:
• x,y,s: resulting estimates of the optimal primal and dual variables
4 Hints:
• For both of the linear equation systems (3.14) and (3.27) the left hand side is the
same. You can use this fact together with the results in Task 3.6 to make the algorithm more eﬃcient.

TASK 3.9

• What are the advantages/disadvantages of the diﬀerent methods?

• How do the diﬀerent algorithms compare with respect to complexity per iteration?

3.3 Networks and Flows
3.3.1 Graphical Representation of Networks
We consider linear network ﬂow optimization problems, which are an important subclass of
general linear programming problems. A network ﬂow problem is an optimization problem
deﬁned on a graph. A directed graph G = (N, A) is deﬁned by a ﬁnite set of nodes N and a
ﬁnite set of arcs A.2 Without loss of generality, we represent the node set by N = {1, . . . , |N |}
and each node by its index i ∈ N . Each arc connects two nodes in an ordered fashion, i.e., it
leaves some node (tail) and enters another node (head).3 Each arc can therefore be represented
by the triple (i, j, m), where i is its tail node, j is its head node, and m a unique index which
enumerates all arcs. The index is necessary to allow for multiple arcs with the same tail and
head nodes. Without loss of generality, we represent the arc set by the unique arc indices
A = {1, . . . , |A|} and denote the arcs leaving (entering) i by O(i) ∈ A (I(i) ∈ A). We
consider only connected graphs, i.e., graphs whose node sets can not be split into two disjoint
sets such that no arc connects both parts. Figure 3.1 visualizes an example for a directed graph
with all the corresponding deﬁnitions.
A convenient description of the relations between nodes and arcs is given by the node-arc
incidence matrix M ∈ R|N |×|A| . Its rows and columns correspond to the nodes and the arcs,
respectively, according their respective index. Its elements are deﬁned as

1
if m ∈ O(i),


(3.29)
[M ]i,m = −1 if m ∈ I(i),


0
otherwise.
This means that in each column, corresponding to an arc, there is exactly one entry +1 and
one entry −1, which reside in the rows corresponding to the arcs tail node and head node,
2
3

Nodes and arcs are sometimes also called vertices and edges, respectively.
We assume that no arc leaves and enters the same node.

36

Chapter 3. Linear Programming and Interior-Point Methods

6/2/7
5

13/1/8

7/3
/3

8
1/
0/
1

3

5/1/
9

9/2/6

3/4
12/

/1
4/4

/2
8/4

1

/2
3/5
2/3
/2

2

/3
/3
14

/1
1/5

4

11/1/9

Figure 3.1: Example of a directed graph with nodes N = {1, . . . , 5} and arcs A = {1, . . . , 14}.
The triple m/um /wm denotes the index, capacity, and cost coeﬃcient of each arc.
respectively. The incidence matrix M ∈ R5×14 of the example graph in Fig. 3.1 is given by


+1 +1 −1
0
0
0 −1
0
0
0
0
0
0
0
 −1
0 +1 +1 +1 +1
0 −1
0
0
0
0 −1
0 




M =  0 −1
0 −1
0
0 +1 +1 +1 +1 −1
0
0
0 


 0
0
0
0 −1
0
0
0 −1
0 +1 +1
0 −1 
0
0
0
0
0 −1
0
0
0 −1
0 −1 +1 +1
(3.30)
Note that for any connected graph the rank of the incidence matrix is |N | − 1. That is, it has
exactly |N | − 1 linearly independent rows and columns.
3.3.2 Linear Network Flow Problems
Network ﬂow problems or transportation problems deal with optimally transporting one or multiple commodities through a capacitated network. In communication networks, the commodity
is usually information organized in data streams or packets. The main diﬀerence between communication networks and transportation networks for real goods, e.g. oil, natural gas, electricity,
etc., is that the destinations are interested not only in the amount of information, but in a particular piece of information from a particular source. This leads to multicommodity ﬂow problems
in Sec. 3.3.3, where multiple diﬀerent information ﬂows share a common network. For this
project, we consider the scenario with inﬁnitely divisible commodities, which serves well as
an approximation for most data stream and packet networks.4
The following deﬁnitions are the ingredients to deﬁne a simple network ﬂow problem: A supply
and demand vector is a vector d ∈ R|N | that deﬁnes for each node i the available supply of the
commodity (di > 0) or the demand of the commodity (di < 0). If di = 0, then node i neither
has nor need any amount of the commodity. A ﬂow on a graph G = (N, A) is a vector x ∈ R|A|
with nonnegative entries. xm quantiﬁes the amount of the commodity that is transported on
arc m from its tail to its head. The ﬂow conservation law (Kirchhoﬀ current law) states that
4

Flow problems with indivisible or integer divisible commodities are combinatorial problems and often very
diﬃcult to solve.

37

Chapter 3. Linear Programming and Interior-Point Methods

the diﬀerence between the total outgoing ﬂow and the total incoming ﬂow must meet the net
supply or demand at each node. It can be stated as follows:

m∈O(i)

xm −

xm = di ,
m∈I(i)

∀i ∈ N.

(3.31)

In vector-matrix notation the ﬂow conservation law can be equivalently stated as
M x = d.

(3.32)

The arc capacity vector on a graph is a nonnegative vector u ∈ R|A| that deﬁnes the maximum
total ﬂow for each arc. Fig. 3.1 shows an example for an arc capacity assignment. The capacity
constraint refers to the inequality
x ≤ u.
(3.33)
The cost vector is a vector w ∈ R|A| that assigns a cost per unit ﬂow on each arc. The total
cost of a ﬂow x is the inner product wT x of the cost vector w with the ﬂow x.
TASK 3.10
Determine the number of linearly independent equality constraints in the ﬂow conservation
law for a connected graph. Give a necessary and suﬃcient condition on the supply and
demand vector d such that there exists a nonnegative ﬂow that satisﬁes the ﬂow conservation
law.
With those preliminaries, we can deﬁne the linear minimum cost ﬂow problem as the problem
of ﬁnding a (nonnegative) ﬂow x that obeys the ﬂow conservation law, fulﬁlls the capacity
constraint, and has the lowest possible total cost.
TASK 3.11
Formulate the linear minimum cost ﬂow problem with the minimum number of inequality
(2|A|) and equality (|N | − 1 + |A|) constraints in linear programming primal standard form,
see Sec. 3.2.1. Introduce slack variables as necessary.
We also deﬁne the maximum ﬂow problem as the problem of ﬁnding a (nonnegative) ﬂow x
that carries the maximum amount of the commodity from a source node s ∈ N to a destination
node t ∈ N while satisfying the ﬂow conservation law at all other nodes i ∈ N \ {s, t} with
di = 0 and fulﬁlling the capacity constraint.
TASK 3.12
Formulate the maximum ﬂow problem with the minimum number of inequality (2|A|) and
equality (|N | − 2 + |A|) constraints in linear programming primal standard form, see
Sec. 3.2.1. Introduce slack variables as necessary.

38

Chapter 3. Linear Programming and Interior-Point Methods
Field

Description

IPWN(n).x
IPWN(n).y
IPWN(n).distance
IPWN(n).weight

x coordinate of each wireless node
y coordinate of each wireless node
Matrix of distances between all pairs of nodes
Vector of commodity weights

Table 3.1: Description of network data structure IPWN in IPNetworks.mat
3.3.3 Linear Multicommodity Flow Problems
The extension to multiple commodities is strait forward. We denote by C = {1, . . . , |C|} the
set of commodities and by xc ∈ R|A| and dc ∈ R|N | the ﬂow and the supply and demand
vector, respectively, of commodity c. Furthermore, let u ∈ R|A| be the capacity vector of the
network.
The ﬂow of all commodities has to be individually conserved, i.e., the ﬂow conservation law
(3.32) must be satisﬁed by each commodity separately. The multicommodity ﬂow conservation
law is expressed as
(3.34)
M xc = dc , ∀c ∈ C,
where M is the node-arc incidence matrix of the network, which is the same for all commodities. However, since the commodities share the same network, i.e., they share the capacity of
the network, the capacity constraint couples the ﬂows of all commodities. The multicommodity
capacity constraint is given by
xc ≤ u.
(3.35)
c∈C

This constraint is often also referred to as coupling constraint.
TASK 3.13
Formulate the linear minimum cost multicommodity network ﬂow problem with the minimum number of inequality (|C||A| + |A|) and equality (|C||N | − |C| + |A|) constraints
in primal standard form, see Sec. 3.2.1. The linear cost coeﬃcient vector for commodity c
is wc ∈ R|A| . Introduce slack variables as necessary. Visualize the block structure of the
equality constraint matrix and ﬁnd an upper bound on the number of nonzero elements in
the matrix.

3.4 Examples for Flow Problems in Communication Networks
In this section, we analyze a simple communication problem, namely, a maximum throughput
problem with multiple commodities, using the interior point algorithms developed in Sec. 3.2.
Simulation data are provided in the ﬁle IPNetworks.mat. The structure array IPWN stores
a number of wireless networks. The n-th network is stored in IPWN(n). Table 3.1 explains
the structure ﬁelds.

39

REFERENCES

3.4.1 Maximum Data Throughput
We consider a very simple wireless communication model. Let N the set of communication
devices enumerated from 1 to |N |. Let dij > 1 denote their distance for any two devices
i, j ∈ N . We consider a communication link to be established between i and j if dij ≤ dmax
with capacity
cij = log2 (1 + γij ) ,
(3.36)
where

P0 −α
d
(3.37)
N0 ij
denotes the link signal-to-noise ration (SNR). This resembles a Shannon rate communication
model with error-free ﬁnite rate links. Furthermore, the links are established orthogonally to
each other and therefore cause no interference. The graph G = (N, A) representing the network
is obtained by assigning one arc m ∈ A for each link ij with dij ≤ dmax .
γij =

We consider 4 simultaneous connections (commodities), i.e., C = {1, 2, 3, 4}. The ﬁrst connection sends data from the left most node (minimal x coordinate) to the right most node (maximal x coordinate). The second connections is between the same nodes but in reverse direction.
Connections three and four are from the top most node to the bottom most node and vice versa.
The goal is to maximize the weighted sum of the connection rates rc , i.e.,
λc r c .

(3.38)

c∈C

The weights λc can be interpreted as priorities.
PROGRAMMING TASK 3.14
Analyze the weighted sum rate in the networks IPWN(1) to IPWN(5) with respect to the
path loss exponent α. Use the steps α ∈ {2, 2.5, 3, . . . , 6}. Visualize your results in an
appropriate plot. Use P0 = 1000 for the signal power, N0 = 1 for the noise power and
dmax = 5 for the maximum link distance. The distance information is stored in the matrix
IPWN(n).distance the rate weight vector is stored in IPWN(n).weight.

References
[1] R. Ahuja, T. Magnanti, and J. Orlin, Networks Flows, Prentice Hall, 1993.
[2] D. Bertsekas and R. Gallager, Data Networks, Prentice-Hall, Englewood Cliﬀs, NJ,
2nd ed., 1992.
[3] G. Dantzig, Maximization of a Linear Function of Variables Subject to Linear Inequalities,
1947. [published in T.C. Koopmans (ed.), Activity Analysis of Production and Allocation,
Wiley & Chapman-Hall, New York-London, 1951].
[4] L. Ford and D. Fulkerson, Maximal ﬂow through a network, Tech. Rep. Research Memorandum RM-1400, The RAND Corporation, Santa Monica, California, 1954. [published
in Canadian Journal of Mathematics 8 (1956) 399–404].
40

REFERENCES

[5] T. Harris and F. Ross, Fundamentals of a Method for Evaluating Rail Net Capacities,
Tech. Rep. Research Memorandum RM-1573, The RAND Corporation, Santa Monica,
California, 1955.
[6] N. Karmarkar, A New Polynomial-time Algorithm for Linear Programming, Combinatorica, 4 (1984), pp. 373–395.
[7] A. Schrijver, On the History of the Transportation and Maximum Flow Problems, Mathematical Programming, 91 (2002), pp. 437–445.
[8] A. Tolstoi, Metody nakhozhdeniya naimen’shego summovogo kilometrazha pri
planirovanii perevozok v prostranstve [Russian: Methods of ﬁnding the minimal total kilometrage in cargotransportation planning in space], Planirovanie Perevozok, Sbornik pervyi [Russian: Transportation Planning, Volume I], Transpechat’ NKPS [TransPress of the
National Commissariat of Transportation], (1930), pp. 23–55.
[9] S. Wright, Primal-Dual Interior-Point Methods, Society for Industrial and Applied Mathematics, 1997.

41

Chapter 4

Lagrangian Duality and Solution
Methods for Dual Problems
Duality theory is one of the most important tools in convex optimization. It provides an alternative formulation of the original optimization problem that is sometimes easier to solve or that
provides interesting insights into the problem structure. The theory often seems diﬃcult to understand for beginners, because of the various, apparently self-evident results and possibilities
for geometric interpretations.
There is an abstract approach to the dual formulation via the KKT-conditions and cone theory.
However, here we will give another exposition that is taken from the book of Boyd and Vandenberghe [3], where the Lagrange function is understood to penalize constraint violations and
rewards points that fulﬁll constraints.
The general convex optimization problem is
p⋆ = min f (x)
x∈ S

s. t. x ∈ X

(4.1)

where
X=

x ∈ Rd :

g i (x) ≤ 0,
j

h (x) = 0,

i ∈ {1, . . . , I}

j ∈ {1, . . . , J} .

(4.2)

The functions f : Rd → R and g i : Rd → R, i ∈ {1, . . . , I} are assumed convex and
hj : Rd → R, j ∈ {1, . . . , J} linear. The abstract constraint set S ⊂ Rd is also convex.
Usually, we have S = Rd . However, for situations where we do partial dualization it is useful
to retain the set S in the formulation, because it can serve as a container for constraints that are
not dualized. For ease of notation, we will also use the vector notations
g(x) ≤ 0,

h(x) = 0

42

(4.3)

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

which are to be understood as component-wise (in-)equalities. We introduce the equivalent
optimization problem
J

I
x∈ S

I0 (hj (x))

I− (g i (x)) +

p⋆ = min f (x) +

(4.4)

j=1

i=1

where
0,

I− (z) =

if z ≤ 0,

and

+ ∞, else

I0 (z) =

0,

if z = 0,

+ ∞, else.

(4.5)

We replace I− and I0 by linear underestimators
λz ≤ I− (z),

∀ z ∈ R, λ ≥ 0

and

µz ≤ I0 (z),

∀ z ∈ R.

(4.6)

The severity of the penalty terms depends on the magnitude of λ and µ. We deﬁne the dual
function as the solution of the relaxed minimization problem for given penalty parameters µ
and λ ≥ 0,
J

I
x∈ S

µj hj (x).

λi g i (x) +

ϕ(λ, µ) = inf f (x) +
i=1

(4.7)

j=1

The augmented objective function is known as the Lagrange function,
L(x, λ, µ) = f (x) + λT g(x) + µT h(x),

(4.8)

where we introduced vector notation to get rid of the cumbersome sum-notation. With these
deﬁnitions, the dual problem is deﬁned as
d⋆ =

max

λ∈RI , µ∈RJ

ϕ(λ, µ)

s. t. λ ≥ 0.

(4.9)

The term duality refers to the fact that a convex minimization problem is replaced by an equivalent concave maximization problem. That both problems are equivalent is the important result
from duality theory:
Theorem 4.0.1: Strong Duality Theorem
If the convex optimization problem (4.1) satisﬁes certain regularity conditions (for example,
Slater’s condition, see [3]), then the dual function as deﬁned in (4.7) is concave and the primal
and dual optimization problems are equivalent in the sense that
p⋆ = d ⋆ .

(4.10)

Furthermore, we have
ϕ(λ, µ) ≤ f (x)

∀ x ∈ S ∩ X and µ ∈ RJ , λ ∈ RI , λ ≥ 0.

(4.11)

From a conceptual viewpoint, duality theory has been succesfully used in communications
engineering to analyze layered network protocols [4]. It has been shown that, for example, the
TCP/IP protocol can be viewed as the implementation of a dual optimization algorithm for a
43

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

certain dual decomposition of a utility maximization problem. Such analysis provides a useful
tool for the understanding of traditional network protocols, on the one hand, and it is a source
of inspiration for new protocols, e. g. by using diﬀerent optimization algorithms, on the other
hand.
In this project, we will develop the two mainstays of practical dual optimization, namely the
subgradient and the cutting plane algorithms. In fact, these algorithms are general purpose
tools and can be used for all convex optimization problems, not only those that arise from dual
decomposition. They only require subdiﬀerentiability of the objective function and are, thus,
applicable to the duals of convex optimization problems. This generality comes at the cost of
relatively slower convergence compared to algorithms that use ﬁrst or second order derivative
information of the objective function, as for example the gradient method encountered in Chapter 2 or Newton-type methods. As such, they should only be used when necessary, i. e., when
diﬀerentiability of the objective function is not guaranteed, hence their association with dual
optimization problems, which have convex and non-diﬀerentiable objective functions.

4.1 Network Flow Problem with Variable Arc Capacities
We will illustrate the dual decomposition approach at the hand of the network ﬂow problem
already encountered in Chapter 3. At that time, we used ﬁxed arc capacities. However, in
wireless networks they are variable and interdependent due to shared resources and interference.
Therefore, we will allow the arc capacities u to vary in an abstract capacity region C, where
every parameter allocation is associated with a set of arc capacities u ∈ C.
A typical example of such a capacity region would be the achievable rates in a multiple point
to point MIMO scenario, see Chapter 2.
It is then possible to deﬁne a rate maximization problem or, more generally, a network utility
maximization (NUM) problem where physical layer parameters are chosen to maximize the
transmission rate and where the achievable rate in the network is given as the solution of a ﬂow
problem.
In our examples, the layering is achieved by dualizing the capacity constraints x ≤ u, which
allows us to decompose the overall problem into simpler problems as we shall see presently.
The network utility maximization with variable arc capacities is given by
maximize

s∈R,x∈R|A| ,u∈R|A|

U (s)
s = cT x,

subject to

M ′ x = 0,

(4.12)

0 ≤ x ≤ u,

u ∈ C.

For the optimization problem to be convex we need a concave utility function U (s). The scalar s
is usually the information rate, i. e., c selects the rate injected by the source node. The capacity
region C is assumed to be convex, which can in practice be justiﬁed by using time-sharing
44

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

arguments: for two points u1 , u2 ∈ C a point λu1 + (1 − λ)u2 can be achieved by using
the resource allocation u1 for λ percent of the total time and using u2 the remaining (1 − λ)
percent of the time. Finally, the matrix M ′ ∈ {−1, 0, +1}(N −2)×|A| , N the number of nodes
and |A| the number of arcs, is the reduced node-arc-incidence matrix that has an entry −1 at
position (i, j) if arc j enters node i, +1 if arc j leaves node i and 0 if arc j neither enters nor
leaves node i.
TASK 4.1
What is the diﬀerence between (4.12) and the network ﬂow problems in Chapter 3.

4.2 Dual Decomposition
We will use a partial dual decomposition technique for the capacity constraints only. To this
end, we deﬁne a container for the remaining constraints such that the optimization problem
becomes
max
U (s)
(s,x)∈ S,u∈C
(4.13)
subject to
x ≤ u,
with

|A|

S=

(s, x) ∈ R × R≥0 :

.

s = cT x, M ′ x = 0

(4.14)

The Lagrangian of this optimization problem reads
L(s, x, u, λ) = U (s) + λT (u − x),

(4.15)

where we took into account the fact that instead of a convex minimization problem we have a
concave maximization problem. The dual function D(λ) is the supremum of the Lagrangian
with respect to the primal variables (s, x, u) for given dual variables λ ≥ 0, i. e.,
sup

D(λ) =

(s,x) ∈S,u∈C

U (s) + λT (u − x).

(4.16)

The supremum of this sum can be written as the sum of suprema, because the constraints for
u and (s, x) are no longer coupled after we removed x ≤ u from the constraint set, hence
D(λ) = sup
(s,x)∈ S

U (s) − λT x + sup λT u.

(4.17)

u∈C

The dual function is decomposed into two parts that can be evaluated independently. Simple
evaluation of the dual function requires the solution of two optimization subproblems that are
easier to solve than the original (primal) optimization problem. The ﬁrst term in (4.17) is
known as the network layer subproblem and is generally easy to solve, for example with the
methods developed in Chapter 3 to solve the minimum arc-cost single-commodity ﬂow problem adjusted for the concave utility function U . The terminology refers to the OSI model for

45

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

network protocols and the ﬂow parameters x and s are usually situated in the network layer of
the OSI model.
The second term in (4.17) is commonly referred to as the physical layer subproblem, because
the optimal arc capacities u correspond to physical layer parameters as for example transmit
power covariance matrices or scheduling coeﬃcients.
The dual variables λ can be interpreted as link costs. From duality theory we know that λa > 0
if the capacity constraint for link a is active. In this case, we say that there is demand of size
λa for link a. The physical layer subproblem will allocate resources with a preference for links
with high demand, because the demands are positive weights of the objective function. On the
other hand, in the network layer subproblem allocation of ﬂows to links a with high demands
is penalized by the same amount λa and ﬂow solutions that attribute large ﬂows to links with
small demands are preferred. The dual problem
min D(λ)
λ≥0

(4.18)

can be understood as ﬁnding an equilibrium demand vector λ.
The concept of any dual algorithm is to iteratively evaluate the dual function and update the
dual variables until a solution λ⋆ of the dual problem is found. A primal feasible conﬁguration
s⋆ , x⋆ , u⋆ can be found by methods for primal recovery as will be explained in Section 4.6. Algorithm 1 illustrates the general concept of an algorithm. The dual variable update rules along
with convergence criteria are discussed in Sections 4.3 and 4.4. Primal recovery is covered in
Section 4.6.
Initialize ǫ > 0, λ1 , ℓ = 1
while not converged do
s⋆ , x⋆ ← arg max U (s) − λT x : s = cT x, M ′ x = 0, x ≥ 0
ℓ
ℓ
ℓ
s∈R,x∈R|A|
← arg max λT u : u ∈ C
ℓ
u∈R|A|
⋆
d+ ← U (s⋆ ) − λT (xℓ − u⋆ )
ℓ
ℓ
ℓ
p
p
p
sℓ , xℓ , uℓ ← primal recovery

u⋆
ℓ

λℓ+1 ← dual variable update
ℓ=ℓ+1
check convergence
end
Algorithm 1: Dual Algorithm

4.3 Subgradient Method
The subgradient method is the non-diﬀerentiable analogue of the gradient descent algorithm.
Contrary to this latter method, the attribute descent does not ﬁgure in the name of the subgradient method, because (negative) subgradients do not necessarily point into directions of descent.
There is a plethora of stepsize rules for the gradient algorithm that ensure a relatively fast, i. e.,
linear, convergence. For the subgradient algorithm, there is no general scheme to choose good
46

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

step sizes. Finally, for a continously diﬀerentiable function there is a simple convergence criterion: ∇f < ε. Such a criterion is not available and one usually aborts the subgradient
algorithm after a suitably large number of steps.
Despite all these apparent drawbacks, the subgradient method enjoys the same popularity in
dual optimization problems as does the gradient descent algorithm for diﬀerentiable problems.
A strong argument for subgradient methods is that they often allow for a semi-distributed solution, where the dual problem is solved distributed but dual variables need to be exchanged in
every iteration, see for example [5].
We denote by s⋆ , x⋆ and u⋆ the maximizing arguments in (4.17) for given dual variables λℓ .
ℓ
ℓ
ℓ
They are obtained from algorithms used to solve the inner optimization problems. The dual
function value then reads
D(λℓ ) = U (s⋆ ) − λℓ x⋆ + λℓ u⋆
ℓ
ℓ
ℓ

(4.19)

and a subgradient of D at λℓ is given by [8]
ξℓ = u⋆ − x⋆ .
ℓ
ℓ
By choosing αℓ by means of a stepsize rule that guarantees convergence, the subgradient
method for the dual variable update is
λℓ+1 = max(λℓ − αℓ (u⋆ − x⋆ ), 0),
ℓ
ℓ

(4.20)

where the maximum is taken component-wise and implements an orthogonal projection onto
the set λ ∈ R|A| : λ ≥ 0 . It is relatively easy to show, that all stepsize rules with
l∈N

αl = ∞

and αl → 0 lead to convergent algorithms. It is common to use

1
,
(4.21)
a + bℓ
where a and b are used to exert some control on the initial steps. Most of the time one simply
puts a = 0, b = 1. Consequently, subgradient algorithms are oftentimes prohibitively slow to
converge.
αℓ =

PROGRAMMING TASK 4.2
We will implement the subgradient algorithm described above for the utility function
U (s) = log(1 + s)

(4.22)

C = u ∈ R|A| : u ≤ 1 .

(4.23)

and a generic physical layer

In order to focus on the subgradient algorithm, we provide a function pl(lambda) in the
ﬁle pl.m that returns
(4.24)
u⋆ = arg max λT u : u ∈ C
ℓ
ℓ
u∈R|A|

47

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

and a function nl(M,terminal,source,lambda) in the ﬁle nl.m that returns
(s⋆ , x⋆ ) = arg max
ℓ
ℓ

s∈R,x∈R|A|

U (s) − λT x : s = cT x, M ′ x = 0, x ≥ 0
ℓ

(4.25)

for given dual variables λ and a given (full) node-arc incidence matrix M , source node
source and terminal node terminal. The vector c used is a vector of all zeros with a
one at the index corresponding to the source node.
The ﬁle networkflow_subgradient.m provides a template for the subgradient implementation. Complete the subgradient algorithm. The ﬁnal primal solution found by the
⋆
subgradient algorithm (s⋆ , xℓ , u⋆ ) does not, in general, correspond to the primal optimal
ℓ
ℓ
solution. However, because the physical layer subproblem is strictly convex, one can show
that the iterates u⋆ converge to the primal optimal solution u⋆ .
ℓ
Use the ﬁnal iterate u⋆ to compute an optimal utility function value and ﬂow of the maxℓ
ﬂow problem with ﬁxed physical layer u⋆ . Use the provided cvx template at the bottom of
ℓ
the ﬁle. Note that this is the problem you solved in Chapter 3 with the linear utility replaced
by a log-utility function. Use a plot of the value of the dual function over the iterations to
check convergence. Is there a better way to check for convergence?
Compare your solution with the reference solution provided by cvx using the function
[x,u,lambda,util] = networkflow_cvx(M,terminal,source) in the ﬁle
networkflow_cvx.m.
The node-arc incidence matrix can be read from incidence.mat. Use node 1 as source
and node 4 as terminal.
1 Deliverables (matlab code ﬁle): networkflow_subgradient.m
• Function deﬁnition:
function [x,u,lambda,util,D]
= networkflow_subgradient(M,terminal,source)
• Plot of dual function values over iterations
2 Input speciﬁcation:
• M: node-arc incidence matrix
• terminal: index of the terminal
• source: index of the source
3 Output speciﬁcation:
• x: ﬂow solution
• u: capacity solution
• lambda: ﬁnal dual variables
• util: utility function value
48

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

• D: dual function value over iterations

4.4 Cutting Plane Method
Kelley’s cutting plane method [6] uses an approach that is diﬀerent from most other optimization algorithms. Instead of using local derivative information to ﬁnd another iterate of the dual
variables in the vicinity of the current one, the cutting plane method constructs a global approximation of the dual function out of subgradients. In contrast to the subgradient algorithm, a
convergence criterion is readily available.
The subgradient inequality
T
D(λ) ≥ D(λk ) + ξk (λ − λk )

∀ λ ∈ R|A|

(4.26)

holds for all pairs (λk , ξk ), ξk ∈ ∂D(λk ) and, as a consequence, one can even take the maximum over a ﬁnite number of such equations,
D(λ) ≥ max

1≤k≤ℓ

T
D(λi ) + ξk (λ − λk )

∀ λ ∈ R|A| .

(4.27)

The cutting plane method uses such a piecewise linear outer approximation of the dual function
and minimizes the approximation instead of the original dual function. In the context of the
cutting plane algorithm, the subgradients ξk are called (hyper-)planes or simply cuts, because
the subgradients can be visualized as hyperplanes that are tangent to the epigraph of D.
The replacement problem of (4.9) is called the cutting plane Master Problem: at iteration ℓ
solve
d⋆ = min Dℓ (λ),
(4.28)
ℓ
λ≥0

where
Dℓ (λ) = max

1≤k≤ℓ

T
D(λk ) + ξk (λ − λk )

(4.29)

⋆
is the ℓ-th cutting plane outer approximation of the dual function. Let λℓ be the solution of
(4.28). From (4.27) it follows that

d⋆ = min Dℓ (λ) ≤ min D(λ) = p⋆ ,
ℓ
λ≥0

λ≥0

(4.30)

which yields a lower bound for the optimal value p⋆ . Furthermore, it follows from the strong
duality theorem 4.0.1 adjusted for concave maximization that
D(λ) ≥ p⋆

∀ λ ∈ R|A| , λ ≥ 0.

(4.31)

As a consequence, d+ := D(λ⋆ ) yields an upper bound for the optimal value p⋆ . Combining
ℓ
ℓ
both bounds and information from previous iterations we get
⋆
dℓ ≤ p⋆ ≤ min d+ .
k
1≤k≤ℓ

49

(4.32)

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

This “sandwiching” of the optimal value gives rise to a formidable stopping criterion for the
algorithm: for a given relative tolerance ε the cutting plane algorithm terminates at iteration L
with a solution that is at least within ε percent of the optimum if
min1≤k≤L d+ − d⋆
L
k
≤ ε.
|d⋆ |
L

(4.33)

Note that a relative convergence criterion may not be suited for problems with solutions close
to zero.
As long as the convergence criterion is not met, the cutting plane model Dℓ needs to be reﬁned.
The usual variable update rule uses λℓ+1 = λ⋆ , which is rather intuitive. The subgradient
ℓ
ξℓ+1 ∈ ∂D(λℓ+1 ) is added to the model and the iterations continue.
Replacing the original dual optimization problem by a sequence of cutting plane master problems works well, because the master problem (4.28) is cheap to solve. By using standard
techniques from linear programming, the master problem (4.28) can be reformulated as an LP.
We introduce the dummy variable r and obtain
d⋆ = min
ℓ

λ≥0,r∈R

s. t.

(4.34)

r

T
r ≥ D(λk ) + ξk (λ − λk ),

∀ 1 ≤ k ≤ ℓ.

(4.35)

One can see from this formulation that in each new iteration of the cutting plane, one constraint
is added to the master problem. We will see in Section 4.6 that the dual of the master problem
can be used for primal recovery, i. e., generating a set of primal variables that is close to optimal
for the primal problem.
⋆
As in the subgradient method, let sℓ , x⋆ and u⋆ denote the maximizing arguments in (4.17) for
ℓ
ℓ
given dual variables λℓ and ξℓ = u⋆ − x⋆ a subgradient. If we plug in the dual function value
ℓ
ℓ
and the subgradient, we can write the constraints in (4.34) as [2]
⋆
r ≥ U (sk ) + λT (u⋆ − x⋆ ) ,
k
k

∀ 1 ≤ k ≤ ℓ.

(4.36)

PROGRAMMING TASK 4.3
We will develop a cutting plane algorithm for the optimization problem described in Programming Task 4.2.
Use the functions pl(lambda) and
nl(M,terminal,source,lambda) as before. The node-arc incidence matrix
can be read from incidence.mat. Use node 1 as source and node 4 as terminal. For
the cutting plane algorithm, you can use a relative convergence criterion of ε = 0.01 (use
(4.32) and (4.33)).
The ﬁle networkflow_cuttingplane.m provides a template for the cutting plane
algorithm. Complete the cutting algorithm and calculate a primal utility and ﬂow solution as
you did for the subgradient algorithm. Use the u⋆ , 1 ≤ k ≤ ℓ that correspond to the lowest
k
dual function value. Note that the cutting plane algorithm does not generate a sequence of
monotonically decreasing dual function values.

50

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

Compare your solution with the reference solution provided by cvx using the function
[x,u,lambda,util] = networkflow_cvx(M,terminal,source) in the ﬁle
networkflow_cvx.m. Plot the value of the dual function over iterations. Add plots with
upper and lower bounds for the primal optimal solution over iterations.
Compare the speed of convergence of both methods. Is the comparison at hand of dual function values over iterations fair? Use Matlab’s tic and toc functions to compare execution
times.
1 Deliverables (matlab code ﬁle): networkflow_cuttingplane.m
• Function deﬁnition:
function [x,u,lambda,util,D,LB,UB]
= networkflow_cuttingplane(M,terminal,source)
• Plot of dual function values and upper and lower bounds over iterations
2 Input speciﬁcation:
• M: node-arc incidence matrix
• terminal: index of the terminal
• source: index of the source
3 Output speciﬁcation:
• x: ﬂow solution
• u: capacity solution
• lambda: ﬁnal dual variables
• util: utility function value
• D: dual function value over iterations
• LB: lower bounds for utility over iterations
• UB: upper bounds for utility over iterations

4.5 Multi-Commodity Flow Problem
The dual decomposition we used for the single commodity ﬂow problem can be adapted relatively easily to the multi-commodity case. An advantage in terms of simplicity of this particular
decomposition is that the network layer subproblem in (4.17) for the multi-commodity problem
with m commodities decomposes into m independent single commodity ﬂow problems. The

51

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

multi-commodity ﬂow problem is given by
maximize U (s)
s,x,u

subject to sc = cT xc ,
c
′
Mc xc =
m

0≤

c=1

c ∈ {1, . . . , m}

c ∈ {1, . . . , m}

0,

(4.37)

xc ≤ u,

u ∈ C,
which looks similar to (4.13) except that s now has multiple components and there is a separate
ﬂow-vector for each commodity. Furthermore, each commodity may have diﬀerent sources
′
and destinations, which is why there is one node-arc incidence matrix Mc for each commodity
whith the respective source and destination rows deleted. The commodities are coupled via the
capacity constraint and the objective function U . We choose a sum-separable utility function
m

(4.38)

Uc (sc )

U (s) =
c=1

in order to achieve the separation of the network layer hinted to above. One example would be
to choose a weighted sum rate utility function
m

(4.39)

w c sc

U (s) =
c=1

with positive weights wc > 0. Another possibility is the proportional fairness utility function
m

wc log(sc ).

U (s) =

(4.40)

c=1

One can show that the dual function associated with the multi-commodity ﬂow problem (4.37)
and dualized capacity constraints is given by
m

D(λ) = sup
(s,x)∈ S

where

U (s) −

λ T xc

S=

(4.41)

u∈C

c=1

m·|A|

(s, x) ∈ Rm × R≥0

+ sup λT u,

: ∀ c ∈ {1, . . . , m}

′
sc = cT xc , Mc xc = 0
c

.

(4.42)

The network layer subproblem can be separated into m single-commodity subproblems as
m

sup

D(λ) =
c=1

(s,x)∈ Sc

Uc (sc ) − λT xc

where

+ sup λT u,

(4.43)

u∈C

|A|

SC =

(sc , xc ) ∈ R × R≥0 :

′
sc = cT xc , Mc xc = 0
c

52

.

(4.44)

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

PROGRAMMING TASK 4.4
We will modify both algorithms such that they can handle multi-commodity ﬂow problems.
We use the separable utility function
m

log(1 + sc )

U (s) =

(4.45)

c=1

and the same physical layer as before. Modify both ﬁles networkflow_subgradient
and networkflow_cuttingplane such that they accept source and terminal vectors
of equal dimensions as input. Each source-terminal combination corresponds to the source
and terminal of one of the communication links in the network (users). Use to commodities,
one with node 1 as source and node 4 as terminal and one with node 5 as source and node
3 as terminal.
1 Deliverables (matlab code ﬁle):
• networkflow_subgradient.m
• networkflow_cuttingplane.m
• Function deﬁnition:
function [x,u,lambda,util,D]
= networkflow_subgradient(M,terminal,source)
• Function deﬁnition:
function [x,u,lambda,util,D]
= networkflow_cuttingplane(M,terminal,source)
2 Input speciﬁcation:
• M: node-arc incidence matrix
• terminal: index vector of the terminal nodes
• source: index vector of the source nodes
3 Output speciﬁcation:
• x: ﬂow solution
• u: capacity solution
• lambda: ﬁnal dual variables
• util: utility function value
• D: dual function value over iterations

53

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

4.6 Primal Recovery
We recall the convex primal optimization problem
min f (x)
x∈S

s. t. x ∈ X

(4.46)

where
d

x∈R :

X=

g i (x) ≤ 0,

hj (x) = 0,

i ∈ {1, . . . , I}

j ∈ {1, . . . , J}

(4.47)

and the dual optimization problem
max

λ∈RI ,µ∈RJ

ϕ(λ, µ)

s. t. λi ≥ 0,

i ∈ {1, . . . , I} ,

(4.48)

where ϕ was given by
ϕ(λ, µ) = inf f (x) + λT g(x) + µT h(x).
x∈S

(4.49)

Convergence of the dual optimization algorithm means
ϕ(λℓ , µℓ ) → ϕ∗ = f ∗ ,

(4.50)

where the equality is due to strong duality and the sequence (λℓ , µℓ ) may have to be replaced
by a subsequence. This means that we can infer the optimal function value from the iterates
of dual function values. However, the dual variables do not contain information about the
primal variables that achieve optimality. This would be a serious drawback if there were no
eﬃcient methods to recover a primal solution, because in most practical cases it is of paramount
interest to know how optimality can be achieved and not what the optimal value is. For example,
in power minimization with respect to quality of service constraints, one would like to know
how to allocate powers. In rate-optimal scheduling one is primarily interested in knowing the
optimal schedule and the optimal rate only has informative value.
Either by evaluating the dual function (4.7) or its subgradient will any dual optimization algorithm generate a sequence (xℓ )ℓ∈N of primal variables and most of the time it is not computationally expensive to evaluate f (xℓ ), g(xℓ ), and h(xℓ ): these are usually linear combinations
of subgradients and dual function values. Thus, we assume that at iteration ℓ the available
information produced by the dual algorithm is
Iℓ = (xk , λk , µk , fk , gk , hk , ϕk )1≤k≤ℓ

(4.51)

where fk = f (xk ) etc. Primal recovery is concerned with the calculation of a feasible set
of primal variables that yields a good (near optimal) function value. As the primal variables
(xℓ )ℓ∈N produced by the dual algorithm need not be feasible, we augment the information with
an interior (Slater) point x0 with g i (x0 ) < 0, hj (x0 ) = 0 and arbitrary λ0 , µ0 , ϕ0 . In many
cases 0 ∈ X and f (0) = 0 and the augmentation is trivial. In other cases, augmentation can
be performed by means of a feasibility test as described in xx.

54

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

4.6.1 General Primal Recovery
There is a canonical way to obtain a feasible point xn from the available information Iℓ , which
ˆ
we will describe in the following. See also the book of Bazaraa [1] for an in-depth account. Let
use deﬁne the ℓ-dimensional unit simplex
ℓ

∆ℓ :=

α ∈ Rℓ+1 :

k=0

αk = 1, αk ≥ 0, k ∈ {0, . . . , ℓ}

(4.52)

By convexity of f we know that
ℓ

ℓ

αk x k

f
k=0

≤

α k fk ,
k=0

α ∈ ∆ℓ

(4.53)

The same is true for the convex constraints g i . Note also that by linearity of hj we have
ℓ

ℓ

hj

αk x k

αk hj .
k

=

(4.54)

k=0

k=0

We also know that the intersection of the convex hull of the primal variables (xk )0≤k≤ℓ with
the feasible set is non-empty,
conv {xk : k = 0, . . . , ℓ} ∩ X = ∅,

(4.55)

because x0 ∈ X. In fact, this is the only reason for augmenting the information with x0 .
The following linear program gives a reasonable approximation of the primal solution.
ℓ

ℓ

α∈∆ℓ

α k fk
k=0

s. t.
k=0
ℓ

i
αk gk ≤ 0,

i ∈ {1, . . . , I} ,

(4.56)

j
αk hk = 0,

min

j ∈ {1, . . . , J} .

(4.57)

k=0

Intuitively, a primal feasible solution can be obtained by setting α0 = 1, because x0 was chosen
feasible. However, f (x0 ) will be far from the optimal value, in general. One would now select
another point xk , which is probably infeasible, but has a better (smaller) function value f (xk ).
If, in addition, h(xk ) = 0 and if the g i (xk ) are small, one can choose αk just so large that
(1 − αk )x0 + αk xk hits the boundary of X, i. e., as soon as some (1 − αk )g i (x0 ) + αk g i (xk )
becomes zero. The function value f ((1 − αk )x0 + αk xk ) will be an improvement over the
“safe” value f (x0 ), because of (4.53).
4.6.1.1 Implementation for Multi-Commodity Flow Problem
Any of the two algorithms developed above generate a sequence of primal optimal variables
x⋆ , u⋆ , s⋆ that may, however, be infeasible with respect to the capacity constraints. The multiℓ ℓ
ℓ
commodity utility maximization problem (4.37) always has x = 0 as a feasible point and it is
interior with respect to the capacity constraints (we assume that there is a set of physical layer
55

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

parameters that achieve non-zero capacity on all links simultaneously). The primal objective
function values are Uℓ = U (s⋆ ) and the values of the inequality constraint functions are
ℓ
m

gℓ = u⋆ −
ℓ

x⋆ ,
ℓ,c
c=1

i ∈ {1, . . . , |A|} .

(4.58)

With the adaptions necessary to proceed from convex minimization to concave maximization,
the general primal recovery problem can be stated as
ℓ

ℓ

max

α∈∆n

αk U k
k=0

s. t.
k=0

i
αk gk ≥ 0,

i ∈ {1, . . . , |A|}

(4.59)

with U0 = 0, x0 = 0 and g0 = 0
PROGRAMMING TASK 4.5
We will develop a general primal recovery routine that takes a set of (infeasible) primal
variables with associated utility function and constraint values as input and computes feasible primal variables as described above for the multi-commodity ﬂow problem. Use
the ﬁle primal_recovery.m with function deﬁnition [alpha,x,u,util] = primal_recovery(X,U,S). Use x0 = 0, s0 = 0, u0 = 0, U (x0 ) = 0 to augment the set
of primal variables with a “safe” feasible point.
Use (4.59) and (4.58) to ﬁnd the optimal primal recovery for the given input variables. Remember that the result of the general primal recovery LP gives a lower bound on the utility
function value and not the actual utility function value (cf. 4.53). Use the LP solver developed in Chapter 3 for the primal recovery LP. (You can use cvx for comparison.)
In a second step, call the primal recovery routine from within the iteration loop in
networkflow_cuttingplane.m
and
networkflow_subgradient.m.
Store the utility function values that can be achieved with the primal recovery in
Util_pr. Modify the function deﬁnitions of networkflow_cuttingplane.m
and networkflow_subgradient.m to incorporate Util_pr as one of the output
arguments. Modify the functions that plot the dual function values over iterations and add
a curve for the primal recovery over iterations.
Can the primal recovery be used in the subgradient algorithm to deﬁne a convergence criterion? What would be possible drawbacks?
1 Deliverables (matlab code ﬁle): primal_recovery.m
• Function deﬁnition:
function [alpha,x,u,util] =
primal_recovery(X,U,S)
2 Input speciﬁcation:
• X: primal ﬂow variables over iterations
• U: primal capacity variables over iterations
56

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

• S: primal “s” values over iterations
3 Output speciﬁcation:
• alpha: coeﬃcients of the optimal convex combination
• x: feasible ﬂow variables
• u: feasible capacity variables
• util: utility function value

4.6.2 Cutting Plane Primal Recovery
If the cutting plane algorithm is used to solve (4.48), the primal recovery solution from (4.56)
is computed automatically! We will see why this is so in the following.
The Lagrangian is:
L(x, λ, µ) = f (x) + λT g(x) + µT h(x)

(4.60)

ϕ(λ, µ) = inf L(x, λ, µ)

(4.61)

and the dual function is
x∈S

The cutting plane model after ℓ iterations is
T
T
ϕℓ (λ, µ) = min ϕ(λk , µk ) + ξk (λ − λk ) + ζk (µ − µk )
1≤k≤ℓ

(4.62)

where ξk ∈ ∂λ ϕ(λk , µk ) and ζk ∈ ∂µ ϕ(λk , µk ) are partial subgradients. We choose ξk =
g(xk ) and ζk = h(xk ) as partial subgradients where xk are the primal variables obtained when
evaluating the dual function (4.49), i. e., the inﬁmum in (4.49) at (λm , µm ) is attained for xm .
The cutting plane master problem, which is solved at the ℓ-th iteration, is
max ϕℓ (λ, µ)

s. t. λ ≥ 0

µ,λ

(4.63)

and this can be rewritten as LP,
− min −r
µ,λ,r

s. t. λ ≥ 0,

(4.64)

T
T
r ≤ ϕ(λm , µm ) + ξk (λ − λk ) + ζk (µ − µk )

∀ 1 ≤ k ≤ ℓ.

(4.65)

We will now show that the dual problem of this cutting plane problem is exactly the general
primal recovery problem (4.56). First, we write the Lagrangian of this LP as
ℓ

Γ (r, λ, µ, α) = −r +

k=1

T
T
αk r − ϕ(λk , µk ) − ξk (λ − λk ) − ζk (µ − µk )

αk
k=1
ℓ

+
k=1

ℓ

ℓ

ℓ

= r −1 +

−

T
α k ξk
k=1

λ−

T
α k ζk

µ+

(4.67)

k=1

T
T
αk −ϕ(λk , µk ) + ξk λk + ζk µk

57

(4.66)

(4.68)

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

and the dual function is
ψ(α) = inf Γ (r, µ, λ, α)

(4.69)

r,µ,λ
λ≥0

By inspecting the ﬁrst term in (4.66) we see that ψ(α) = −∞ if ℓ αk = 1. From the
k=1
ℓ
T
second term we conclude that ψ(α) = −∞ if k=1 αk ξk > 0 (componentwise and because
T
λ ≥ 0) and from the third term we deduce that ψ(α) = −∞ if ℓ αk ξk = 0. Hence, we
k=1
do not change the dual problem if we impose constraints on the dual variables α such that the
dual problem of the cutting plane master problem becomes
ℓ
α≥0 r,µ,λ
λ≥0

αk = 1,

(4.70)

T
αk ξk ≤ 0,

(4.71)

T
αk ζk = 0.

max inf Γ (r, µ, λ, α)

(4.72)

s. t.
k=1
ℓ
k=1
ℓ
k=1

On this constraint set the Lagrange function Γ can be simpliﬁed as
ℓ

ℓ

Γ (r, λ, α) = −

T
α k ξk

λ+
k=1

k=1

T
T
αk −ϕ(λk , µk ) + ξk λk + ζk µk .

(4.73)

The terms involving r and µ have vanished because of the constraints. The inﬁmum for the
ℓ
T
≥ 0.
term involving λ is trivially assumed for λ = 0, because λ ≥ 0 and −
k=1 αk ξk
Hence, the simpliﬁed (but equivalent) dual problem reads
ℓ
k=1
ℓ

s. t.

(4.74)
(4.75)

T
αk ξk ≤ 0,

(4.76)

T
αk ζk = 0.

α≥0

T
T
αk −ϕ(λk , µk ) + ξk λk + ζk µk

αk = 1,

max

(4.77)

k=1
ℓ
k=1
ℓ
k=1

We now recall that the subgradients are ξk = g(xk ) and ζk = h(xk ) and the dual function ϕ is

58

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

ϕ(λk , µk ) = f (xk ) + λT ξk + µT ζk , so that (4.74) can be rewritten as
k
k
ℓ

αk f (xk )

(4.79)

αk g(xk ) ≤ 0,

(4.80)

αk h(xk ) = 0.

α≥0

(4.78)

αk = 1,

max

(4.81)

k=1
ℓ

s. t.
k=1
ℓ
k=1
ℓ
k=1

which we recognize as the primal recovery problem (4.56). In summary, the primal recovery
for the cutting plane method at iteration ℓ is
ℓ

x=

αk x k

(4.82)

k=1

where the coeﬃcients αk are the dual variables of the cutting plane master problem at iteration
ℓ.
PROGRAMMING TASK 4.6
Use the ﬁle primal_recovery_cuttingplane.m and complete the function
primal_recovery_cuttingplane(X,U,S,alpha) that calculates the primal recovery for the multi-commodity ﬂow problem when the cutting plane algorithm is used.
Pass the dual variables of the current cutting plane iterate as alpha.
Invoke the function from within the cutting plane algorithm as you did for the general recovery. Compare the results and execution times with primal_recovery.m.
1 Deliverables (matlab code ﬁle): primal_recovery_cuttingplane.m
• Function deﬁnition:
function [x,u,util]
= primal_recovery_cuttingplane(X,U,S,alpha)
2 Input speciﬁcation:
• X: primal ﬂow variables over iterations
• U: primal capacity variables over iterations
• S: primal “s” values over iterations
• alpha: dual variables of cutting plane master problem
3 Output speciﬁcation:
• x: feasible ﬂow variables
59

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

• u: feasible capacity variables
• util: utility function value

4.6.3 Subgradient Primal Recovery
The subgradient method does not provide feasible primal recovery for free. However, the following result is often used, despite the fact that primal recovery is infeasible [7].
Theorem 4.6.1: Subgradient Ergodic Primal Recovery
Let xk be the primal variables generated by the subgradient algorithm. Then
1
x = lim
ℓ→∞ ℓ

ℓ

⋆

xk

(4.83)

k=1

exists, is feasible, and f (x⋆ ) = minx∈S f (x) s. t. x ∈ X.
PROGRAMMING TASK 4.7
Complete the function primal_recovery_subgradient(X,U,S) in the ﬁle
primal_recovery_subgradient.m with the infeasible primal recovery described above. Add the infeasible primal recovery to the subgradient algorithm in
networkflow_subgradient. Store the results in Util_pr_infeasible and
modify the function deﬁnition of networkflow_subgradient to incorporate
Util_pr_infeasible as output argument. Modify the plots with dual and primal
function values over iterations and add a curve for the infeasible primal recovery over
iterations.
1 Deliverables (matlab code ﬁle): primal_recovery_subgradient.m
• Function deﬁnition:
function [x,u,util]
= primal_recovery_subgradient(X,U,S)
2 Input speciﬁcation:
• X: primal ﬂow variables over iterations
• U: primal capacity variables over iterations
• S: primal “s” values over iterations
3 Output speciﬁcation:
• x: feasible ﬂow variables
• u: feasible capacity variables
• util: utility function value

60

Chapter 4. Lagrangian Duality and Solution Methods for Dual Problems

4.7 Modularity of the Dual Decomposition
We mentioned that the dual decomposition with respect to the capacity constraints decomposes
the the optimization problem into physical layer and network layer subproblems. In fact, the
algorithms were designed to handle generic physical and network layers.
PROGRAMMING TASK 4.8: (Optional)
We replace the simpliﬁed physical layer
C = u ∈ R|A| : u ≤ 1 .

(4.84)

with the multi-point to point MIMO channel discussed in Chapter 2. In this case, the capacity region C is given as the convex combination of rate points that correspond to certain
transmit covariance power allocations. The physical layer then is a weighted sum rate maximization and an implementation of supu∈C λT u is provided by pl_mimo(lambda) in
the ﬁle pl_mimo.m. Replace the simple physical layer pl(lambda) with the more realistic pl_mimo(lambda) for the cutting plane algorithm. Note that the weighted sum rate
maximization problem has to be solved at every iteration and the overall algorithm will be
slow to converge.
Thanks to the modularity, all primal recovery functions can be reused. You do not have to
submit your solutions of this exercise.
1 Deliverables (matlab code ﬁle): networkflow_cuttingplane.m
• Function deﬁnition:
function [x,u,lambda,util,D,LB,UB,Util_pr]
= networkflow_cuttingplane(M,terminal,source)
• Plot of dual function values and upper and lower bounds over iterations
2 Input speciﬁcation:
• M: node-arc incidence matrix
• terminal: index of the terminal
• source: index of the source
3 Output speciﬁcation:
• x: ﬂow solution
• u: capacity solution
• lambda: ﬁnal dual variables
• util: utility function value
• D: dual function value over iterations
• LB: lower bounds for utility over iterations
61

REFERENCES

• UB: upper bounds for utility over iterations
• Util_pr: utility function values from cutting plane primal recovery over iterations

References
[1] M. S. Bazaraa, H. D. Sherali, and C. M. Shetty, Nonlinear Programming: Theory and
Algorithms, John Wiley & Sons, 3rd edition ed., June 2006.
[2] D. P. Bertsekas, A. NediÄĞ, and A. E. Ozdaglar, Convex Analysis and Optimization,
Athena Scientiﬁc, 2003.
[3] S. Boyd and L. Vandenberghe, Convex Optimization, Cambridge University Press, 2006.
[4] M. Chiang, S. Low, A. Calderbank, and J. Doyle, Layering as Optimization Decomposition: A Mathematical Theory of Network Architectures, Proceedings of the IEEE, 95
(2007), pp. 255 –312.
[5] B. Johansson, P. Soldati, and M. Johansson, Mathematical decomposition techniques
for distributed cross-layer optimization of data networks, IEEE JSAC, 24 (2006), pp. 1535
– 1547.
[6] J. J. Kelley, The Cutting-Plane method for solving convex programs, Journal of the Society for Industrial and Applied Mathematics, 8 (1960), pp. 703–712.
[7] T. Larsson, M. Patriksson, and A. Strömberg, Ergodic, primal convergence in dual
subgradient schemes for convex programming, Mathematical Programming, 86 (1999),
pp. 283–312.
[8] Utschick and Gerdes, Lecture notes - optimization in communications.

62

Chapter 5

Conic Optimization and SDPT3
5.1 Introduction
The great successes of linear programming – the general theory as well as the existence of
eﬃcient interior-point solvers for linear programs (LPs) – motivated researchers to extend the
results and methods to the nonlinear case. The widest class of optimization problems to which
the basic results of linear programming have been extended is the class of convex optimization
problems [7]. For this purpose, a convex problem needs to be transformed into conic form, i.e.,
into an optimization problem with linear objective and a constraint set that is the intersection
of a closed convex cone and an aﬃne subspace. The two most famous conic programming
formulations are second-order cone programs (SOCPs), which are also referred to as conic
quadratic programs (cf. [1, Chapter 3]), and semideﬁnite programs (SDPs). A comprehensive
study and various applications of SOCPs and SDPs can for example be found in [1, 2]. Two
standard interior-point solvers that can be used to numerically solve both SOCPs and SDPs in
Matlab are SeDuMi [8] and SDPT3 [9] – both are also included within CVX [4].
The conic optimization framework is a useful tool in the physical layer design of communication systems. As a ﬁrst example, we look at the quality of service (QoS) based multiuser
transmit beamforming design in this part of the laboratory. This typical scenario arises in the
cellular downlink when a centralized transmitter is equipped with multiple transmit antennas
and serves the demands of several receivers. An important step towards the determination of
an optimal solution in the QoS based linear beamformer design is the application of convex optimization methods, especially the reformulation into conic form. As a second example of how
conic optimization techniques can be applied in communications engineering, we consider the
weighted sum rate (WSR) maximization in the MIMO multiple-access channel (MAC). The
optimization problems obtained from the two communication scenarios can either be solved by
means of CVX, which eventually calls one of the aforementioned solvers, or by directly using
SDPT3.

63

Chapter 5. Conic Optimization and SDPT3

5.2 Conic Optimization
This section gives a brief introduction to conic optimization. The notions of a proper cone and
generalized inequalities are explained, and the formulations of the two most important conic
optimization problems – SOCPs and SDPs – are presented.
Without loss of generality, standard convex optimization problems can be formulated with an
objective function that is linear in the optimization variable x and which is deﬁned and minimized over a convex set X , i.e.,
min c, x

s. t.

x

x ∈ X.

(5.1)

Here, c, x denotes the inner product between the constant c and the optimization variable
x. Note that if c, x ∈ Rn , then c, x = cT x. To analyze problem (5.1), the constraint set X
usually has to be described with convex inequality constraints and aﬃne equality constraints.
The traditional way is to provide a list of inequalities and aﬃne equations of the form
gi (x) ≤ 0, ∀i ∈ {1, . . . , ℓ},

aj , x − bj = 0, ∀j ∈ {1, . . . , m},
where each of the ℓ functions gi : Rn → R is convex. This guarantees the convexity of X as
the intersection of convex level sets is convex again. For conic optimization problems, a more
elegant way to describe the feasible region consists of deﬁning X as the intersection of an aﬃne
subspace and a proper cone. In fact, this is the basis for conic optimization.
Deﬁnition. A set K ⊂ Rn is a cone if it is closed under positive scalar multiplication, i.e., if
x∈K

⇔

αx ∈ K, ∀α > 0.

(5.2)

We say that a cone K ⊂ Rn is a proper cone if it satisﬁes the following properties:
• K is convex, i.e., it is closed under addition (x1 + x2 ∈ K for all x1 , x2 ∈ K),
• K is closed, i.e., it contains its boundary,
• K is solid, i.e., it has nonempty interior,
• K is pointed, i.e., it contains no lines (if x ∈ K and −x ∈ K, then x = 0).
Every proper cone K ⊂ Rn deﬁnes a partial ordering on Rn . Associated with this partial
ordering is the idea of generalized inequalities.
Deﬁnition. Let K ⊂ Rn be a proper cone. The generalized inequality x K y denotes that
y − x ∈ K and deﬁnes a partial ordering on K. Similarly, the strict generalized inequality
x ≺K y denotes that y − x ∈ int(K) and deﬁnes a strict partial ordering on K.
These inequalities can be understood as generalizations of the linear orderings on R, which are
denoted by the relation symbols ≤ and <. Similar to these ordinary inequalities, generalized
inequalities feature the following properties:
64

Chapter 5. Conic Optimization and SDPT3

•

K

is preserved under addition, i.e., if x

•

K

is transitive, i.e., if x

z then x

K

z,

•

K

is preserved under nonnegative scaling, i.e., if x

K

y and α ≥ 0, then αx

•

K

is antisymmetric, i.e., if x

y and y

K

K

K

K

y and x

y and u

K

K

v, then x + u

K

y + v,

K

αy,

y, then x = y.

However, in contrast to the linear ordering that always exists on R, two elements need not be
comparable with respect to a generalized inequality deﬁned by the proper cone K, i.e., x K y
does not necessarily imply y ≺K x. For this reason, deﬁning the minimum or maximum
element of a set is more complicated in the context of generalized inequalities (e.g., see [2,
Section 2.6]).
5.2.1 Examples of Proper Cones
A special case of a proper cone is the set of nonnegative real numbers K = R+ , its induced
generalized inequalities K (≺K ) are the ordinary inequalities ≤ (<) on R. Other important
proper cones and their associated generalized inequalities are
• the nonnegative orthant Rn and the componentwise inequality:
+
x≥y

⇔

xi ≥ yi , ∀i ∈ {1, . . . , n};

• the second-order cone Ln+1 = [t, xT ]T ∈ Rn+1 : x 2 ≤ t, t ≥ 0 , which is also
called the Lorentz cone or the quadratic cone, and the corresponding norm inequality:
t
x

L

u
v

⇔

x−v

2

≤ t − u;

n
• the semideﬁnite cone S+ = Q ∈ Rn×n : Q = QT , xT Qx ≥ 0, ∀x ∈ Rn , which consists of all symmetric n × n matrices that are positive semideﬁnite, and the associated
linear matrix inequality:

Q

R

⇔

Q−R

0.

Note that this cone “lives” in the space S n = Q ∈ Rn×n : Q = QT of symmetric
n × n matrices and that the inner product between Q and R is deﬁned as Q, R =
tr(QR) for Q, R ∈ S n .
5.2.2 Standard Conic Form and Related Problems
Having deﬁned the notions of proper cones and generalized inequalities, we are now in the
position to deﬁne a conic optimization problem.

65

Chapter 5. Conic Optimization and SDPT3

Deﬁnition. Let K be a proper cone that induces the generalized inequality
tion problem that can be expressed as
min c, x

s. t.

x

x

K

0,

K.

An optimiza-

(5.3)

aj , x = bj , ∀j ∈ {1, . . . , m},
is called a conic optimization (in standard form). Note that the convex constraint set X of a
conic optimization problem is the intersection of a proper cone K and an aﬃne subspace that
is speciﬁed by the parameters aj and bj , j ∈ {1, . . . , m}.
The probably best known conic form problems are linear programs (LPs). A linear program
is an optimization problem with a linear objective function that is minimized (or maximized)
over a polyhedral constraint set. In standard form, the polyhedral constraint set of the linear
program is given as the intersection of the proper cone Rn and and aﬃne subspace speciﬁed
+
by a system of linear equalities:
min cT x

s. t.

x∈Rn

x ≥ 0,

(5.4)

Ax = b,
where c ∈ Rn , b ∈ Rm , and A ∈ Rm×n such that rank(A) = m < n. Here, the generalized
inequality is equivalent to the ordinary componentwise vector-inequality.
Conic form problems involving Lorentz cones (second-order cones) that are deﬁned via the
Euclidean norm belong to the class of second-order cone programs (SOCPs). The standard
form of an SOCP is
min cT x

s. t.

x∈Rn

x

L

0,
(5.5)

Ax = b,
where c ∈ Rn , b ∈ Rm , and A ∈ Rm×n such that rank(A) = m < n. The class of SOCPs
includes LPs and convex quadratic programs as special cases [6].
A class of conic optimization problems that is even more general than that of SOCPs is the
class of semideﬁnite programs (SDPs). These are conic form problems that involve the proper
n
cone S+ , i.e., the cone of symmetric n × n matrices that are positive semideﬁnite. In standard
form, an SDP is expressed as
min

X∈Rn×n

C, X

s. t.

X

0,
(5.6)

Aj , X = bj , ∀j ∈ {1, . . . , m},
where Aj ∈ S n and bj ∈ R for all j ∈ {1, . . . , m}. If we apply the deﬁnition of the inner
product C, X for C, X ∈ S n , problem (5.6) results in
min

X∈Rn×n

tr(CX)

s. t.

X

0,
(5.7)

tr(Aj X) = bj , ∀j ∈ {1, . . . , m}.

66

Chapter 5. Conic Optimization and SDPT3

As mentioned above, SDPs are more general than SOCPs (and thus also LPs). That is, any
SOCP can be recast as an equivalent SDP by appropriate reformulation with the Schur complement [6].
It can be shown that the KKT conditions and the theory of Lagrangian duality can be extended
to conic optimization problems [2]. Assuming that a conic problem and its corresponding
dual problem satisfy the conditions for strong duality, generalized versions of interior-point
methods can be applied to numerically determine an optimal solution. To this end, logarithmic
barrier functions for the constraints x ≥ 0, x L 0 and X 0 need to be introduced. These
logarithmic barriers are deﬁned by means of generalized logarithms ψ(x).
• For K = R+ , the generalized algorithm is of course the ordinary logarithm. Since the
componentwise inequality x ≥ 0 can be represented by n scalar inequalities xi ≥ 0, ∀i ∈
n
{1, . . . , n}, the generalized logarithm for the nonnegative orthant R+ can be deﬁned as
the sum of the logarithms of the elements of x, i.e.,
n

log xi .

ψ(x) =
i=1

• For the second-order cone Ln+1 =
ized logarithm can be deﬁned as

[t, xT ]T ∈ Rn+1 : x

ψ [t, xT ]T = log t2 − x

2
2

2

≤ t, t ≥ 0 , the general-

.

n
• Finally, the generalized logarithm for the semideﬁnite cone S+ can be deﬁned as

ψ(Q) = log det(Q).
The generalized logarithm ψ for the proper cone K behaves like the ordinary logarithm along
any ray in K. It has to satisfy several other properties like being concave and twice continuously
diﬀerentiable which we do not elaborate on here. However, if ψ is a generalized logarithm for
K, then φ(x) = −ψ(x) is the logarithmic barrier function for the constraint x K 0.
5.3 SDPT3
SDPT3 is a software that is designed to solve semideﬁnite-quadratic-linear conic programming
problems (SQLPs) whose constraint sets are given as the Cartesian products of semideﬁnite
cones, second-order cones, nonnegative orthants and Euclidean spaces, and whose objective
functions are sums of linear functions and log-barrier terms associated with the constraint
cones [9]. In particular, SDPT3 uses primal-dual interior-point methods to solve SQLPs of

67

Chapter 5. Conic Optimization and SDPT3

the following primal form:
nq

ns
s s
tr(Cj Xj )

min
j=1

−

s
s
νj log det(Xj )

q
cq,T xq − νi log ψ(xq )
i
i
i

+
i=1

nℓ

+ cℓ,T xℓ −
ns

s. t.

ℓ
νk log xℓ + cu,T xu
k
k=1

s
s T
tr(As Xj ), . . . , tr(As Xj )
j,1
j,m

nq

+

j=1
s
Xj

i=1

∈

s
S+j , ∀j

∈ {1, . . . , ns },

xℓ = [xℓ , . . . , xℓ ℓ ]T ∈ Rnℓ ,
1
n
+

xq
i

Aq xq + Aℓ xℓ + Au xu = b ∈ Rm ,
i i

qi

∈ L , ∀i ∈ {1, . . . , nq },

xu ∈ Rnu .

(5.8)

Optimization problems of this kind are termed standard SQLPs in [9] and have the properties
listed below:
s

s
• S+j is the semideﬁnite cone of order sj so that Xj , j ∈ {1, . . . , ns }, denote the ns
s
positive semideﬁnite variables; the matrices Cj , As , . . . , As must be real symmetric
j,m
j,1
s
s
matrices of dimension sj × sj , i.e., Cj , Aj,1 , . . . , As ∈ S sj , for all j ∈ {1, . . . , ns }.
j,m

• Lqi is the Lorentz (or second-order/quadratic) cone of order qi so that xq , i ∈ {1, . . . , nq },
i
denote the nq quadratic variables; cq is a vector in Rqi and Aq ∈ Rm×qi is a constraint
i
i
matrix associated with the i-th quadratic variable, i ∈ {1, . . . , nq }.
• Rnℓ is the nonnegative orthant of dimension nℓ , which means that xℓ denotes the vector
+
of nonnegative real (or linear) variables; cℓ is a nonnegative real vector of dimension nℓ
and Aℓ is a real m × nℓ constraint matrix associated with xℓ .
• Rnu is the Euclidean space of dimension nu so that xu denotes the vector of unrestricted
variables; cu is a real vector of dimension nu and Au is a real m × nu constraint matrix
associated with the vector of unrestricted variables.
q
• ψ(xi ) denotes the generalized logarithm for second-order cones so that −ψ(xq ) is the
i
corresponding barrier function.
q
ℓ
s
• νj , νi , and νk are given nonnegative parameters that specify how the log-barrier terms
associated with the diﬀerent constraint cones contribute to the objective function.

68

Chapter 5. Conic Optimization and SDPT3

In some cases, it is easier to set up SQLPs in SDPT3 with the dual form of (5.8):
ns

max

bT y +
j=1

s
s
s
s
[νj log det(Zj ) + sj νj (1 − log νj )]

nq

+
i=1

nℓ
q
q
q
q
[νi log ψ(zi ) + νi (1 − log νi )] +

m
s
s
yk A s + Z j = C j ,
j,k

s. t.
k=1

s

s
Zj ∈ S+j ,

q
Aq,T y + zi = cq ,
i
i

q
zi ∈ L qi ,

Aℓ,T y + z ℓ = cℓ ,

k=1

ℓ
ℓ
ℓ
ℓ
[νk log zk + νk (1 − log νk )]

∀j ∈ {1, . . . , ns },

(5.9)

z ℓ ∈ Rnℓ ,
+

Au,T y = cu ,

∀i ∈ {1, . . . , nq },

y ∈ Rm .

TASK 5.1
Download and read the SDPT3 users’ guide [9]. The latest version can be obtained from
http://www.math.nus.edu.sg/~mattohkc/sdpt3.html.
Although SDPT3 is part of the CVX installation, we recommend not to use that version because
this may cause problems when you want to use both SDPT3 directly and with CVX.
TASK 5.2
Install SDPT3 in the folder for your Matlab simulations:
• Retrieve the latest version of SDPT3, which can be obtained from
http://www.math.nus.edu.sg/~mattohkc/sdpt3.html
and unpack the ﬁle in your simulations folder, e.g., home/user/simulations for
a Linux system or D:/user/simulations if you are on Windows.

• Start Matlab and change to the location of SDPT3, e.g., by typing either
cd home/user/simulations/SDPT3−4.0 (Linux) or
cd D:/user/simulations/SDPT3−4.0 (Windows).
• In the Matlab command window, type
>> Installmex

This step may be skipped if you do not have to generate the mex ﬁles.
• After that, to see whether you have installed SDPT3 correctly, type
>> startup
>> sqlpdemo

• To save the path for subsequent Matlab sessions, you can either type savepath or
add the corresponding SDPT3 paths to your startup ﬁle.

69

Chapter 5. Conic Optimization and SDPT3

Now, SDPT3 should be ready for you to use. Note that SDPT3-4.0 is built for Matlab version
7.4 or later releases, it may not work for earlier versions.

5.4 Linear Precoder Design in the Vector Broadcast Channel
A typical application of conic optimization in communications is the linear precoder design in
the vector broadcast scenario, where one centralized multi-antenna transmitter serves several
single-antenna receivers [10]. In this context, the precoder is deﬁned as a linear transformation on the transmitted symbols. To this end, we assume a linear Gaussian channel model
with perfect channel state information at the receivers’ and the transmitter’s sides. That is, the
channel parameters are ﬁxed for the beamformer design. For the design, the following qualityof-service (QoS) problem is investigated: minimize the dissipated total transmit power subject
to minimum SINR requirements. These problems can be reformulated such that standard conic
optimization toolboxes, e.g., SDPT3, can numerically solve them.
x1

s1
.
.
.

y1
hH
1

t1
xk

sk
.
.
.

.
.
.

ηk

.
.
.

x
hH
k

tk
xK

sK

η1

yk

yK
hH
K

tK

ηK

Figure 5.1: Block diagram of the considered vector broadcast channel.
The detailed block diagram of the considered communication system with a centralized transmitter is shown in Figure 5.1. At each time instant, a block of independent zero-mean unitvariance symbols s = [s1 , . . . , sK ]T ∈ CK is linearly transformed with the precoder
T = [t1 , . . . , tK ] ∈ CN ×K

(5.10)

and transmitted over the channels h1 , . . . , hK ∈ CN to K receivers. The received signal yk
2
(of receiver k) is distorted by the superimposed complex Gaussian noise ηk ∼ NC (0, σk ). That
is,
K

yk =

hH x
k

+ ηk =

hH T s
k

+ ηk =

hH
k

ti si + ηk ,

(5.11)

i=1

where tk and sk denote the beamformer and the data signal intended for receiver k and the
other precoded data symbols si with i = k result in interference.
In the following, we try to improve the system performance by varying the precoder T . For this
purpose, we simplify the notation by combining all channel vectors in the matrix H ∈ CK×N
70

Chapter 5. Conic Optimization and SDPT3

such that the received signal vector reads as
 
 H
 
η1
h1
y1
 . 
 . 
 . 
y =  .  =  .  T s +  .  = HT s + η.
.
.
.
H
ηK
hK
yK
H ∈ CK×N

(5.12)

η ∈ CK

5.4.1 Power Optimization
The goal is a power eﬃcient design of the precoder T that is quantiﬁed by the receivers’ quality
of service (QoS) and the resources of the transmitter. Here, the users’ data rates are used as
QoS measures. Expressed in terms of the mutual information, the achievable rates read as
rk = log2 (1 + SINRk )

∀ k ∈ {1, . . . , K},

(5.13)

and the signal-to-interference-plus-noise-ratio (SINR) is
SINRk =

|[HT ]k,k |2
,
2
2
i=k |[HT ]k,i | + σk

(5.14)

2
where σk = E[|ηk |2 ] > 0 and [A]k,i denotes the element in the k-th row and the i-th column
of matrix A. The metric that speciﬁes the use of system resources is the average transmitted
power and is deﬁned as
(5.15)
P = E[ T s 2 ] = tr(T H T ).

Note that the SINR metric and the average power metric conﬂict, i.e., one cannot maximize the
SINRs while also minimizing the power, and vice versa.
The task is to minimize the average transmitted power subject to satisfying the minimum rate
requirements ρk , k ∈ {1, . . . , K}. That is,
min
T

tr(T H T )

s. t.

rk ≥ ρk

∀ k ∈ {1, . . . , K}.

(5.16)

Since rk is a bijective function of SINRk , (5.17) can equivalently be represented as a standard
power minimization with SINR lower bounds γk = 2ρk − 1, k ∈ {1, . . . , K}, i.e., (cf. [10])
min
T

tr(T H T )

s. t.

|[HT ]k,k |2
≥ γk
2
2
i=k |[HT ]k,i | + σk

∀ k ∈ {1, . . . , K}.

(5.17)

Note that this problem might be infeasible. For K > N and suﬃciently large ρk , it might be
impossible to satisfy all constraints simultaneously, even though inﬁnite transmit power can be
used. A simple test to check whether the positive rate targets are achievable is given in [5]: if
0 < 2−ρk ≤ 1 for all k ∈ {1, . . . , K} and additionally
K
k=1

2−ρk > K − rank{H},

(5.18)

then there exists a T ∈ CN ×K with ﬁnite power satisfying all rate constraints simultaneously.
71

Chapter 5. Conic Optimization and SDPT3

In what follows, the task is to solve this power minimization problem based on the powerful framework of conic optimization which allows for eﬃcient numerical solutions using standard optimization toolboxes, e.g., SDPT3 [9]. Speciﬁcally, the power optimization problem
in (5.17), which is nonconvex in this representation, will be formulated as a convex SOCP or
SDP problem.
5.4.2 Problem Reformulation
The standard SINR problem formulation in (5.17) is nonconvex. In order to obtain a convex
optimization problem with linear objective function and a convex constraint set, a real-valued
slack variable P is introduced and an extra constraint is added to obtain
min
T ,P

P

s. t.

tr{T H T } ≤ P,
|[HT ]k,k |2
≥ γk
2
2
i=k |[HT ]k,i | + σk

(5.19)
∀ k ∈ {1, . . . , K}.

The variable P can be understood as an upper bound on the transmit power. Minimizing this
upper bound is equivalent to minimizing the average transmit power itself.
Before reformulating (5.19) as an SOCP, note that due to the structure of the problem formulation, the argument T is not deﬁned uniquely. The terms |[HT ]k,i |2 and tr{T H T } are
independent with respect to a diagonal phase scaling of T from the right. That is, if T is optimal, then so is T diag(ej φ1 , . . . , ej φK ). For this reason, in the sequel it is restricted (without
loss of generality) to terms T which have the following properties: Re{[HT ]k,k } ≥ 0 and
Im{[HT ]k,k } = 0 for all k ∈ {1, . . . , K}. Taking this into account, the constraints of (5.19)
can be recast as SOC constraints.
The power constraint in (5.19) can be reformulated using tr{X H X} = i Xei 2 = vec(X) 2 ,
2
2
where vec(·) is the column-stacking operator and ei denotes the i-th canonical unit vector, as
vec(T )

2
2

(5.20)

≤ P.

Taking the square root of both sides, this inequality is equivalent to the SOC constraint
√
P
(5.21)
L 0.
vec(T )
The SINR constraints can also be recast as SOC constraints. For this purpose, we use the fact
2
that i=k |[HT ]k,i |2 = eT HT 2 − |[HT ]k,k |2 to obtain
k
1+

1
γk

|[HT ]k,k |2 ≥ T H H H ek

2
2

2
+ σk ,

k ∈ {1, . . . , K}.

(5.22)

Since Re{[HT ]k,k } ≥ 0 and Im{[HT ]k,k } = 0 for k ∈ {1, . . . , K} and the right-hand side
2
of (5.22) is equal to eT HT , σk 2 , one can take the square root of both sides, resulting in
k
1+

1
T H H H ek
Re{[HT ]k,k } ≥
γk
σk
72

,
2

k ∈ {1, . . . , K},

(5.23)

Chapter 5. Conic Optimization and SDPT3

which is equivalent to the SOC constraints




1
γk Re [HT ]k,k


T H H H ek

1+




σk

Using (5.21) and (5.24), and deﬁning p =
given by
min
T ,p

p

s. t.

L

√

0,

k ∈ {1, . . . , K}.

P , problem (5.19) is reformulated as a SOCP,

p
∈ LN K+1 ,
vec(T )


1 + γ1k Re{[HT ]k,k }


K+2

∈L
T H H H ek
σk

Im{[HT ]k,k } = 0

(5.24)

∀ k ∈ {1, . . . , K},

(5.25)

∀ k ∈ {1, . . . , K}.

Thus, the problem is convex and moreover, it can eﬃciently be solved by either using CVX or
implementing this problem formulation into a standard SOCP solver as provided in SDPT3 [9].
PROGRAMMING TASK 5.3
Implement the feasibility test in (5.18) and the SOC formulation in (5.25) into a Matlab function that takes the channel matrix H, the vector of minimum rate targets ρ = [ρ1 , . . . , ρK ]T ,
2
2
and the vector of noise variances σ = [σ1 , . . . , σK ]T as inputs, and that uses CVX (with
SDPT3 as solver) to compute the optimal solution to problem (5.25).
1 Deliverables (Matlab code ﬁle): PMinVectorBC_cvx.m
• Function deﬁnition:
function [P,T,status] = PMinVectorBC_cvx(H,rho,sigma2)

2 Input Speciﬁcation:
• H: channel gain matrix H
• rho: minimum rate target vector ρ
• sigma: vector of noise variances σ
3 Output Speciﬁcation:
• P: minimum transmit power P ⋆
• T: optimal transmit precoder T ⋆
• status: the status information of the optimization with CVX
4 Hint(s):

73

Chapter 5. Conic Optimization and SDPT3

• First, determine the number of transmit antennas and users in the system with the
dimensions of H. Then, test the target vector on feasibility using (5.18). If feasible,
the optimization in with CVX can directly be implemented into CVX. Note that the
variable T and the Lorentz-cone have to be implemented in its complex valued form.

TASK 5.4
Rewrite the conic form problem in (5.25) into the standard dual-form (5.9) that can directly
be implemented into SDPT3. For this purpose, follow the next two steps:
• Reformulate the constraints in (5.25) in terms of t = vec(T ) ∈ CN K . To this end,
note that eT HT ei = (eT ⊗ eT H) vec(T ), where A ⊗ B ∈ Cnp×mq denotes the
i
k
k
Kronecker product (kron(A,B) in Matlab) of the two matrices A ∈ Cn×m and
B ∈ Cp×q .
• Transform the resulting complex-valued problem formulation into its equivalent realˆ
valued form, i.e., rewrite the problem in terms of t = [Re{t}T , Im{t}T ]T ∈ R2KN .
PROGRAMMING TASK 5.5
Implement the feasibility test in (5.18) and the resulting SOC formulation of TASK 5.4
into the Matlab function PMinVectorBC_sdpt3.m that takes the channel matrix H, the
vector of minimum rate targets ρ = [ρ1 , . . . , ρK ]T , and the vector of noise variances
2
2
σ = [σ1 , . . . , σK ]T as inputs, and that uses SDPT3 to compute the optimal solution to
problem (5.25).
1 Deliverables (Matlab code ﬁle): PMinVectorBC_sdpt3.m
• Function

deﬁnition:

function [P,T,status] = ...

PMinVectorBC_sdpt3(H,rho)

2 Input Speciﬁcation:
• H: channel gain matrix H
• rho: minimum rate target vector ρ
• sigma: vector of noise variances σ
3 Output Speciﬁcation:
• P: minimum transmit power P ⋆
• T: optimal transmit precoder T ⋆
• status: the status information of the optimization
4 Hint(s):

74

Chapter 5. Conic Optimization and SDPT3

H1

η

x1
n1
y
m
x2
n2

H2

Figure 5.2: System model of considered multiple-access scenario, where the users 1 and 2 as
well as the terminal T are equipped with multiple antennas.
ˆ
• Implement the SOC into SDPT3 dual-form (5.9) using y = [p, tT ]T as variable vector. The evaluation of the SDPT3 programming results and the accuracy evaluation
is already implemented into the Matlab function PMinVectorBC_sdpt3.m.

5.5 WSR Maximization in MIMO MAC
In this example from multiuser communications, we discuss the weighted sum rate (WSR)
maximization problem in a multiple-access scenario. In particular, we assume that two users 1
and 2 which are equipped with n1 and n2 transmit antennas, respectively, transmit information
to one terminal T that has m antennas. The system model is depicted in Figure 5.2.
Let x1 ∈ Rn1 and x2 ∈ Rn2 be the channel inputs at the two users, y ∈ Rm be the received
signal at the terminal, and let Hi ∈ Rm×ni denote the real-valued channel gain matrix from
user i ∈ {1, 2} to the terminal T . Then,
2

Hi xi + η,

y=

(5.26)

i=1

where η ∼ N (0, Im ) is the additive white Gaussian noise received at the terminal. Note that,
without loss of generality, we have assumed here that the channels are real-valued in order to
obtain real-valued optimization problems afterwards.
From information theory, it is known that the capacity region of this Gaussian MAC channel
is equal to
1
T
log2 det Im + H1 Q1 H1 ,
2
1
T
r2 ≤ log2 det Im + H2 Q2 H2 ,
2
1
T
T
r1 + r2 ≤ log2 det Im + H1 Q1 H1 + H2 Q2 H2 ,
2

CMAC = r ∈ R2 : r1 ≤
+

n
n
Q1 ∈ S+1 , Q2 ∈ S+2 , tr(Q1 ) ≤ P1 , tr(Q2 ) ≤ P2

75

(5.27)

Chapter 5. Conic Optimization and SDPT3

if the available transmit powers at the two users are given by P1 and P2 [3, Chapter 9]. Moreover,
all rate vectors r ∈ CMAC can be achieved by having user 1 and user 2 choose Gaussian inputs
x1 ∼ N (0, Q1 ) and x2 ∼ N (0, Q2 ) with appropriate transmit covariance matrices Q1 and
Q2 that satisfy the power constraints, respectively.
A standard problem in communications engineering is the weighted sum rate (WSR) maximization problem over some rate region R ∈ RK , which in general reads as
+
max wT r
r

s. t.

(5.28)

r∈R

for some w ∈ RK . For the Gaussian MAC with two users, i.e., R = CMAC , it can be shown
+
that this WSR maximization becomes
max

Q1 ,Q2

w2
w1 − w2
T
T
T
log2 det Im + H1 Q1 H1 +
log2 det Im + H1 Q1 H1 + H2 Q2 H2
2
2
s. t.

n
Q1 ∈ S+1 ,

n
Q2 ∈ S+2 ,

tr(Q1 ) = P1 ,

tr(Q2 ) = P2

(5.29)

if w1 ≥ w2 . This is a convex optimization problem satisfying the ruleset of disciplined convex
programming, which can therefore be solved by means of CVX.
PROGRAMMING TASK 5.6
Implement an algorithm that takes the channels H1 , H2 , the available transmit powers
P1 , P2 , and the weight vector w ∈ R2 as inputs, and that uses CVX (with SDPT3 as solver)
+
to compute the optimal solution to problem (5.29).
1 Deliverables (Matlab code ﬁle): wsr_mimo_mac_cvx.m
• Function deﬁnition:
function [Q1,Q2] = wsr_mimo_mac_cvx(H1,H2,P1,P2,w)

2 Input Speciﬁcation:
• H1: channel gain matrix H1
• H2: channel gain matrix H2
• P1: available transmit power at user 1
• P2: available transmit power at user 2
• w: weight vector w
3 Output Speciﬁcation:
⋆
• Q1: optimal transmit covariance matrix Q1 of user 1

• Q2: optimal transmit covariance matrix Q⋆ of user 2
2
4 Hint(s):
• First, determine whether w1 > w2 , w1 < w2 , or w1 = w2 . If w1 < w2 , the roles of
users 1 and 2 must be switched in (5.29). If w1 = w2 = w, the objective function
76

Chapter 5. Conic Optimization and SDPT3

reduces to the sum rate r1 +r2 =
is simply scaled with w.

1
2

T
T
log2 det Im + H1 Q1 H1 + H2 Q2 H2 , which

While the considered WSR maximization problem is not a conic problem, it can be expressed
as a standard SQLP. To see this, we ﬁrst reformulate (5.29) as an equivalent minimization
problem:
T
T
T
min −α1 log2 det Im + H1 Q1 H1 − α2 log2 det Im + H1 Q1 H1 + H2 Q2 H2

Q1 ,Q2

s. t.

n
Q1 ∈ S+1 ,

n
Q2 ∈ S+2 ,

tr(Q1 ) = P1 ,

tr(Q2 ) = P2 ,
(5.30)

where α1 = w1 −w2 ≥ 0 and α2 = w2 ≥ 0 for w1 ≥ w2 . In a next step, we introduce two
2
2
m
T
m
T
auxiliary variables X1 = Im + H1 Q1 H1 ∈ S+ and X2 = Im + H1 Q1 H1 + H2 Q2 ∈ S+
to obtain
min −α1 log2 det (X1 ) − α2 log2 det (X2 )

Q1 ,Q2

s. t.

n
Q1 ∈ S+1 ,

n
Q2 ∈ S+2 ,

tr(Q1 ) = P1 ,

m
X1 ∈ S + ,

tr(Q2 ) = P2 ,

T
X1 − H 1 Q 1 H 1 = I m ,

m
X2 ∈ S + ,

(5.31)

T
T
X2 − H 1 Q 1 H 1 − H 2 Q 2 H 2 = I m .

Observe that this is almost an SQLP in standard form. All we need to do now to actually obtain
one is to reformulate the equality constraints in an appropriate manner. To this end, let us ﬁrst
consider the power constraints. Obviously, we have
tr(Q1 ) = tr(In1 Q1 ) = P1 ,

tr(Q2 ) = tr(In2 Q2 ) = P2 ,

(5.32)

and since In1 ∈ S n1 and In2 ∈ S n2 , the two scalar power constraints already match the required
form. However, rewriting the matrix equalities to match the standard SQLP form is more comT
plicated. The constraint X1 − H1 Q1 H1 = Im means that, for all i, j ∈ {1, . . . , m},
T
[X1 ]i,j − [H1 Q1 H1 ]i,j = δi,j =

1

if i = j,

0

otherwise.

(5.33)

This can equivalently be written as
T
T
tr(eT X1 ej ) − tr(eT H1 Q1 H1 ej ) = tr(ej eT X1 ) − tr(H1 ej eT H1 Q1 ) = δi,j ,
i
i
i
i

(5.34)

T
where ei denotes the i-th canonical unit vector. Since ej eT and H1 ej eT H1 are not symmetric
i
i
except for the case i = j, we need to formulate the equality constraints in a diﬀerent way. For
T
T
this purpose, note that [X1 ]i,j = [X1 ]j,i and [H1 Q1 H1 ]i,j = [H1 Q1 H1 ]j,i . Consequently,
we can equivalently express (5.33) as
T
T
[X1 ]i,j + [X1 ]j,i − [H1 Q1 H1 ]i,j − [H1 Q1 H1 ]j,i = 2δi,j ,

(5.35)

T
tr((ej eT + ei eT ) X1 ) + tr(−H1 (ej eT + ei eT )H1 Q1 ) = 2δi,j ,
i
j
i
j

(5.36)

or

A1 (i,j)

A2 (i,j)

77

Chapter 5. Conic Optimization and SDPT3

where A1 (i, j) ∈ S m and A2 (i, j) ∈ S n1 for all i, j ∈ {1, . . . , m}. Moreover, note that
we need to specify above constraints only for i ∈ {1, . . . , m} and j ∈ {i, . . . , m} since only
redundant constraints would be obtained by switching i and j. As a result, m(m + 1)/2 scalar
equality constraints in the form of (5.36) are required to express the matrix equality constraint
T
T
T
X1 −H1 Q1 H1 = Im , and the same obviously applies for X2 −H1 Q1 H1 −H2 Q2 H2 = Im .
Together with the two power constraints, m(m + 1) + 2 scalar equality constraints are hence
necessary to express all equality constraints of problem (5.31). If all these constraints are
stacked in a vector of dimension m(m + 1) + 2, an equivalent reformulation of the WSR
maximization problem (5.29) in standard SQLP form is obtained.
PROGRAMMING TASK 5.7
Implement an algorithm that takes the channels H1 , H2 , the available transmit powers
P1 , P2 , and the weight vector w ∈ R2 as inputs, and that uses SDPT3 to compute the
+
optimal solution to problem (5.29). To this end, use the reformulation of the WSR maximization problem in standard SQLP form.
1 Deliverables (Matlab code ﬁle): wsr_mimo_mac.m
• Function deﬁnition:
function [Q1,Q2] = wsr_mimo_mac(H1,H2,P1,P2,w)

2 Input Speciﬁcation:
• H1: channel gain matrix H1
• H2: channel gain matrix H2
• P1: available transmit power at user 1
• P2: available transmit power at user 2
• w: weight vector w
3 Output Speciﬁcation:
⋆
• Q1: optimal transmit covariance matrix Q1 of user 1

• Q2: optimal transmit covariance matrix Q⋆ of user 2
2
4 Hint(s):
• First, determine whether w1 > w2 , w1 < w2 , or w1 = w2 again.

TASK 5.8
Measure and compare the execution times of your two functions wsr_mimo_mac and
wsr_mimo_mac_cvx for diﬀerent input parameters. Which of the two solutions is more
eﬃcient? Try to explain the results.
Note that if we solve problem (5.29) for given channels H1 , H2 , transmit powers P1 , P2 , and
78

Chapter 5. Conic Optimization and SDPT3

one particular weight vector, we obtain a point on the boundary of CMAC . Therefore, we can
evaluate the boundary of the capacity region of the two-user MIMO MAC by solving WSR
maximization problems over CMAC for diﬀerent weight vectors w ∈ R2 . In, particular, the
+
boundary of CMAC can be determined with arbitrary precision by varying the ratio of the weights
w1
w2 from zero to inﬁnity.
PROGRAMMING TASK 5.9
Implement an algorithm that takes the channels H1 , H2 , the available transmit powers
P1 , P2 , and a collection of weight vectors w1 , . . . , wL ∈ R2 as inputs, and that determines
+
⋆
⋆
L rate vectors r1 , . . . , rL that belong to the boundary of CMAC . To this end, use your func⋆
tion wsr_mimo_mac to obtain rℓ as the optimizer of the WSR maximization problem with
weight vector wℓ , ℓ ∈ {1, . . . , L}.
1 Deliverables (Matlab code ﬁle): c_mimo_mac.m
• Function deﬁnition:
function R = c_mimo_mac(H1,H2,P1,P2,W)

2 Input Speciﬁcation:
• H1: channel gain matrix H1
• H2: channel gain matrix H2
• P1: available transmit power at user 1
• P2: available transmit power at user 2
2×L
• W: matrix of weight vectors W = [w1 , . . . , wL ] ∈ R+

3 Output Speciﬁcation:
2×L
⋆
⋆
• R: matrix of rate vectors R = [r1 , . . . , rL ] ∈ R+

4 Hint(s):
• The function wsr_mimo_mac only determines the optimal covariance matrices Q⋆
1
and Q⋆ . The optimal rate vector r ⋆ is then obtained as
2
r⋆ =

1
2

log2 det Im +

1
⋆
T
2 log2 det Im + H1 Q1 H1
1
T
⋆
T
H1 Q⋆ H1 + H2 Q2 H2 − 2 log2 det
1

T
Im + H 1 Q ⋆ H 1
1

if w1 > w2 , or
r⋆ =

1
2

1
T
⋆
T
T
log2 det Im + H1 Q⋆ H1 + H2 Q2 H2 − 2 log2 det Im + H2 Q⋆ H2
1
2
1
⋆H T
2 log2 det Im + H2 Q2 2

if w1 < w2 . If w1 = w2 , both options yield an optimal rate vector, which hence is
not unique in general.

79

REFERENCES

TASK 5.10
⋆
⋆
Let rk,max = maxℓ=1,...,L eT rℓ , k ∈ {1, 2}. Plot the capacity region CMAC of the twok

⋆
⋆
user MIMO MAC as the convex hull of the rate vectors r1 , . . . , rL ,
for diﬀerent input parameters.

0
0

,

⋆
r1,max
0

,

0
⋆
r2,max

References
[1] A. Ben-Tal and A. Nemirovski, Lectures on Modern Convex Optimization. Analysis,
Algorithms, and Engineering Applications., Society for Industrieal and Applied Mathematics, Philadelphia, PA, USA, 2001.
[2] S. Boyd and L. Vandenberghe, Convex Optimization, Cambridge University Press, New
York, NY, USA, 1st ed., Mar. 2004.
[3] T. M. Cover and J. A. Thomas, Elements of Information Theory, John Wiley & Sons,
2nd ed., 2006.
[4] M. Grant and S. Boyd, CVX: Matlab Software for Disciplined Convex Programming,
Feb. 2009.
[5] R. Hunger and M. Joham, A Complete Description of the QoS Feasibility Region in the
Vector Broadcast Channel, IEEE Transactions on Signal Processing, 57 (2010), pp. 698–
713.
[6] M. S. Lobo, L. Vandenberghe, S. Boyd, and H. Lebret, Applications of Second-Order
Cone Programming, Linear Algebra and its Applications, 284 (1998), pp. 193–228.
[7] Y. Nesterov and A. Nemirovski, Interior Point Polynomial Algorithms in Convex Programming, Studies in Applied Mathematics (SIAM), Philadelphia, PA, USA, 1994.
[8] J. F. Sturm, Using SeDuMi 1.02, a MATLAB Toolbox for Optimization over Symmetric
Cones, Optimization Methods and Software, 11 (1999), pp. 625–653.
[9] K. Toh, R. Tütüncü, and M. Todd, SDPT3—A Matlab software package for semideﬁnite
programming, Optimization Methods and Software, 11 (1999), pp. 545–581.
[10] A. Wiesel, Y. C. Eldar, and S. Shamai, Linear Precoding via Conic Optimization for
Fixed MIMO Receivers, IEEE Transactions on Signal Processing, 54 (2006), pp. 161–176.

80

Chapter 6

Nonconvex Optimization
In Chapter 2, the problem of maximizing the sum rate of a MIMO multiple access channel
(MAC) under a sum power constraint was considered under the assumption that successive
interference cancellation is applied. However, to reduce the complexity of encoding and decoding, practical implementations of communication systems usually rely on so-called linear
transceivers, where nonlinear operations (encoding, detection, . . . ) are only applied to single
data streams while all ﬁltering operations that involve more than one data stream have to be
linear (e.g., [2]).
When the MIMO MAC considered in Chapter 2 is restricted to linear transceivers, the signals
transmitted by all other users cause interference to the signal of user k, and the sum rate can
be written as


−1

K


H
H
Hℓ Qℓ Hℓ  Hk 
(6.1)
log2 det In + Hk Im +
R(Q1 , . . . , QK ) =
ℓ=k

k=1

where we have used the same notations as in Chapter 2. Unfortunately, this sum rate expression
is no longer a concave function of the covariance matrices Qk , so that the sum rate optimization
problem1
K

min

Q1 0,...,QK 0

R(Q1 , . . . , QK )

s. t.
k=1

tr[Qk ] ≤ P

(6.2)

is no longer a convex problem. Consequently, linear transceivers simplify the implementation
of a transmit strategy in a real system, but they make the procedure of optimizing the transmit
strategy more involved.
In this chapter, we study various approaches to ﬁnd optimal and suboptimal solutions of the sum
rate optimization (6.2) with linear transceivers in the special case of n = 1 transmit antenna at
1

We use

0 to denote that a matrix is positive semideﬁnite.

81

Chapter 6. Nonconvex Optimization

each user terminal. In this case, the transmit covariance matrices Qk are reduced to scalars qk ,
H
and the channel matrices Hk become vectors hH . Thus, the sum rate optimization reads as
k




−1

K

min

q1 ≥0,...,qK ≥0

k=1


log2 1 + qk hH Im +
k

ℓ=k

h ℓ qℓ h H 
ℓ

K


hk 

s. t.

k=1

qk ≤ P. (6.3)

6.1 Monotonic Optimization: Branch, Reduce, and Bound
Even though problem (6.3) is a nonconvex problem, it is possible to ﬁnd its globally optimal
solution by means of monotonic optimization. To this end, we introduce a new function deﬁned
as

−1 

K


˜
hℓ yℓ hH  hk  . (6.4)
log2 1 + xk hH Im +
R(x1 , . . . , xK , y1 , . . . , yK ) =
ℓ
k
ℓ=k

k=1

˜
Note that this function satisﬁes R(q1 , . . . , qK , q1 , . . . , qK ) = R(q1 , . . . , qK ).
TASK 6.1

˜
Show that R(x1 , . . . , xK , y1 , . . . , yK ) with xk ≥ 0 and yk ≥ 0 is non-decreasing in all xk
−1
and non-increasing in all yk . Hint: ∂(A(y) ) = −A(y)−1 ∂A(y) A(y)−1 .
∂y
∂y
PROGRAMMING TASK 6.2
˜
Implement a function to compute R(x1 , . . . , xK ) or R(x1 , . . . , xK , y1 , . . . , yK ) for a power
vector x or for a pair of vectors (x, y), respectively.
1 Deliverables (Matlab code ﬁle): sumrate_SIMO.m
• Function deﬁnition: function R = sumrate_SIMO(H,x,y)
2 Input Speciﬁcation:
• H: m × 1 × K set of channel vectors h1 , . . . , hK
• x: column vector [x1 , . . . , xK ]T
• y (optional): column vector [y1 , . . . , yK ]T
3 Output Speciﬁcation:
˜
• R: R(x1 , . . . , xK , y1 , . . . , yK ) if y is provided, R(x1 , . . . , xK ) otherwise
4 Hints:
• You can use exist('y','var') to check whether y is provided.

82

Chapter 6. Nonconvex Optimization

q2

q2

P

q2

P
B0

P
B1

B2

P
B1

q1
P

q2

q1

B3
B2

P

q1
P

B4

B2

q1
P

Figure 6.1: Schematic of the branch-reduce-and-bound method: feasible region (gray), branching (dashed), and reduction (dotted).
˜
• It suﬃces to implement R(x1 , . . . , xK , y1 , . . . , yK ) and to set y=x; if y is not provided.
Problem (6.3) can now be solved using a modiﬁed version of the branch-reduce-and-bound
(BRB) algorithm from [3]. We ﬁrst discuss the three main steps and summarize the algorithm
afterwards.
6.1.1 Branching
Consider a set B = [a, b] = {q | a ≤ q ≤ b} of power vectors q = [q1 , . . . , qK ]T , where
the inequalities have to be understood component-wise. Let us call such a set box, and let
B = {B0 , B1 , . . . } be a set of boxes.
The branch step in the BRB algorithm then consists in cutting a box [a, b] ∈ B along its
longest edge into two subboxes (bisectional rectangular subdivision). To this end, we ﬁrst ﬁnd
the direction of the longest edge
k ⋆ = arg max
k∈{1,...,K}

(6.5)

bk − ak .

and then replace the box by the two new boxes:
B←B∪

a, b −

bk ⋆ − a k ⋆
bk ⋆ − a k ⋆
ek ⋆ , a +
ek ⋆ , b
2
2

\ {[a, b]}

(6.6)

where ek is the kth canonical unit vector, which has a one in the kth element and zeros elsewhere.
A visualization of the branching can be seen in Fig. 6.1.
6.1.2 Reduction
Each box B = [a, b] might contain both feasible and infeasible power vectors q, i.e.,
B = q ∈ B 1T q ≤ P ∪ q ∈ B 1T q > P
83

(6.7)

Chapter 6. Nonconvex Optimization

where 1 is the all-ones vector. The smallest box B ′ ⊆ B which still contains all feasible vectors
q ∈ B, i.e., q ∈ B 1T q ≤ P ⊆ B ′ , is called the reduction of B.
For the problem under consideration a rule to compute the reduction can be obtained from
geometrical considerations. For a box B = [a, b] with a ≥ 0 that contains at least one feasible
power vector, the reduced box B ′ is given by B ′ = [a, b′ ] with
b′ = min a + (P − 1T a)1, b

(6.8)

where the minimum has to be taken element-wise.
A visualization of the reduction step can be seen in Fig. 6.1.
PROGRAMMING TASK 6.3
Implement a function to compute the reduction B ′ of a box B = [a, b].
1 Deliverables (Matlab code ﬁle): reduction.m
• Function deﬁnition: function [a,b] = reduction(P,a,b)
2 Input Speciﬁcation:
• P: maximum sum power P
• a: column vector [a1 , . . . , aK ]T specifying the lower boundary of the box B
• b: column vector [b1 , . . . , bK ]T specifying the upper boundary of the box B
3 Output Speciﬁcation:
• a: column vector [a1 , . . . , aK ]T specifying the lower boundary of the reduced box
B′
• b: column vector [b1 , . . . , bK ]T specifying the upper boundary of the reduced box
B′
4 Hint:
• You may assume that the function is only called for boxes which contain at least one
feasible power vector.

6.1.3 Bounding
Consider a box B = [a, b]. Due to the monotonicity properties shown in Task 6.1, the inequality
˜
˜
R(q1 , . . . , qK ) = R(q1 , . . . , qK , q1 , . . . , qK ) ≤ R(b1 , . . . , bK , a1 , . . . , aK )

(6.9)

˜
holds for all q ∈ [a, b]. Therefore, U ([a, b]) = R(b1 , . . . , bK , a1 , . . . , aK ) is an upper bound
to R(q1 , . . . , qK ), q ∈ [a, b]. Even though this bound is an utopian bound, i.e., there is usually
no q ∈ [a, b] fulﬁlling (6.9) with equality, the bound becomes tight as b − a → 0. This
property is called consistency [3].
84

Chapter 6. Nonconvex Optimization
′
′
On the other hand, it is obvious that evaluating R(q1 , . . . , qK ) for any feasible q ′ ∈ [a, b]
delivers a lower bound to the optimal rate in the box [a, b], i.e.,
′
′
max R(q1 , . . . , qK ) ≥ R(q1 , . . . , qK ).

(6.10)

q∈[a,b]

For instance, we can use L([a, b]) = R(a1 , . . . , aK ) as lower bound since a is feasible whenever there exists at least one feasible q ∈ [a, b].
Note that
U = max U (B)

(6.11)

B∈B

is an upper bound to R(q1 , . . . , qK ) for all q ∈

B∈B B

while

L = max LB

(6.12)

B∈B

is a lower bound to the rate R(qopt,1 , . . . , qopt,K ) at the optimal power vector qopt ∈

B∈B B.

6.1.4 The Algorithm
We initialize the branch-reduce-and-bound algorithm with a set B = {B0 }, where B0 is the
reduction of RK , i.e., the minimal box containing all feasible power vectors. This initial box is
given by B0 = [0, P 1] (cf. Fig. 6.1).
Then, the following steps are repeated until convergence:
1. Find the box with the highest upper bound, i.e.,
[a, b] = arg max U (B)

(6.13)

B∈B

and perform a branching with this box.
2. Replace the new boxes obtained in the branch step by their respective reductions.
3. Compute upper and lower bounds for the new reduced boxes.
4. Break if U − L ≤ ǫ, where ǫ is the desired accuracy, and U and L are deﬁned in (6.11)
and (6.12), respectively.
The solution to problem (6.3) is then given by the vector a corresponding to the lower bound
L in (6.12), i.e.,
qsolution = a with [a, b] = arg max LB .
(6.14)
B∈B

Due to Step 4 of above algorithm, the solution is a so-called ǫ-optimal solution, which means
that the rate achieved with this power vector is guaranteed to be at most ǫ away from the actual
global optimum Ropt , i.e.,
R(qsolution,1 , . . . , qsolution,K ) ∈ [Ropt − ǫ, Ropt ].

(6.15)

Convergence of the method can be shown based on the observation that the bounds become
tight for b − a → 0 [3].
85

Chapter 6. Nonconvex Optimization

PROGRAMMING TASK 6.4
Implement the branch-reduce-and-bound algorithm described above.
1 Deliverables (Matlab code ﬁle): brb.m
• Function deﬁnition:
function [q_opt,optval]=brb(f,red,a_0,b_0,epsilon)

2 Input Speciﬁcation:
˜
• f: handle to a function R=f(x,y) which computes R(x1 , . . . , xK , y1 , . . . , yK )
• red: handle to a function [a b]=red(a,b) which computes a reduction of [a, b]
• a_0: column vector [a1 , . . . , aK ]T specifying the lower boundary of the initial box
B0
• b_0: column vector [b1 , . . . , bK ]T specifying the upper boundary of the initial box
B0
• epsilon: desired accuracy ǫ
3 Output Speciﬁcation:
• q_opt: optimizer qopt corresponding to an ǫ-optimal solution of (6.3)
• optval: R(qopt,1 , . . . , qopt,K )
4 Veriﬁcation:
• You can run an optimization using your brb implementation by calling the provided
helper function [R q] = srmax_brb(H,P) for some set of channels H and some
maximum power P .
• That is, to check your program with the provided veriﬁcation function use
test('srmax_brb').
5 Hints:
• We use the function handles f and red in order to allow a generic implementation, which could also be used to solve other optimization problems. Inside brb.m,
you can use f(x,y) and red(a,b) just like normal functions. The correct deﬁnition of the function handles for the optimization under consideration is done in the
provided helper function [R q] = srmax_brb(H,P), so that you do not have to
worry about how to pass such handles to the brb function.
• Note that the functions f(x,y) and red(a,b) do not require the channels or the
sum power as arguments.

86

Chapter 6. Nonconvex Optimization

6.2 Suboptimal Solution: Gradient Ascent
The disadvantage of the method is that its computational worst-case complexity is exponential
in the number of variables, which is K in our case.
TASK 6.5
Test your brb implementation by calling [R q] = srmax_brb(H,P) after loading a small
and a large scenario by the help of the provided function load_example('small') and
load_example('large'), respectively. What do you observe? Hint: Add some debug
output to your brb implementation (e.g., print U − L after each 100 iterations).
If a solution with less complexity is desired, it might be necessary to resort to a local method,
which does not necessarily ﬁnd the global optimum of the nonconvex problem (6.3). As an
example, let us study a gradient-projection algorithm.
The derivative of R with respect to a power qj is given by
−1
hH C j hj
∂R
j
=
−1
∂qj
ln 2 · 1 + qj hH Cj hj
j

−1
qk |hH Ck hj |2
k

−

k=j

−1
ln 2 · 1 + qk hH Ck hk
k

(6.16)

with
h ℓ qℓ h H .
ℓ

C k = Im +

(6.17)

ℓ=k

PROGRAMMING TASK 6.6
Implement a function to compute the gradient

∂R
∂q

at position q = x.

1 Deliverables (Matlab code ﬁle): gradient_SIMO.m
• Function deﬁnition: function grad = gradient_SIMO(H,x)
2 Input Speciﬁcation:
• H: m × 1 × K set of channel vectors h1 , . . . , hK
• x: column vector [x1 , . . . , xK ]T
3 Output Speciﬁcation:
• grad: the value of

∂R
∂q q=x

Note that the powers qk can be considered as 1 × 1 covariance matrices Q and the constraint
set of problem (6.3) is the same as the one in Section 2.4. Therefore, the projection to the
constraint set implemented in Section 2.4 can be reused.2
2

The eigenvalue decomposition used in Section 2.4 could be skipped since it is trivial for 1 × 1 matrices, but
reusing the implementation with eigenvalue decomposition should work properly, too.

87

Chapter 6. Nonconvex Optimization

PROGRAMMING TASK 6.7
Implement a gradient-projection algorithm to ﬁnd a locally optimal solution of problem (6.3).
1 Deliverables (Matlab code ﬁle): srmax_gradient.m
• Function deﬁnition:
function [R q] = srmax_gradient(H,P,q)

2 Input Speciﬁcation:
• H: m × 1 × K set of channel vectors h1 , . . . , hK
• P: maximum sum power P
• q: column vector [q1 , . . . , qK ]T containing the initialization
3 Output Speciﬁcation:
• R: sum rate achieved at the local optimum
• q: column vector [q1 , . . . , qK ]T containing the powers at the local optimum
4 Veriﬁcation:
• Check your program by looking at the simulation results plotted by
plot_gradient, which are averaged over 100 channel realizations. Your
average achieved rate should always lie below the average of the globally optimal
rate, and it should lie close to the optimal solution for small values of P .
5 Hints:
• Use sumrate_SIMO(H,q) from Programming Task 6.2 to evaluate the sum rate
for given q.
• Use gradient_SIMO(H,x) from Programming Task 6.6 to compute the gradient
at q = x.
• You can use the projected gradient implementation from Chapter 2

6.3 Zero-Forcing Solution
A variation of problem (6.3) is the maximization of the sum rate under so-called zero-forcing
constraints [1, 4], i.e., we enforce that the receiver applies linear receive ﬁlters in a way that no
interference between streams of diﬀerent users is present after the ﬁltering operation. The data
transmission can then be described by
K

xk =
ˆ

√
hℓ qℓ x ℓ + n

H
vk
ℓ=1

88

(6.18)

Chapter 6. Nonconvex Optimization
H
where vk is the receive ﬁlter for the data stream of user k. To cancel out interference for any
H
data symbols xℓ and any trasmit powers qℓ , we need that vk hℓ = 0 for all k and all ℓ = k. For
H
H
ℓ = k, we can choose vk hk = 1 without loss of generality since scaling the receive ﬁlter vk
does not change the signal-to-noise ratio and, thus, has no inﬂuence on the achievable rate.

In matrix notation, the zero-forcing constraints can be written as
 H
v1
 . 
V H =  .  h1 . . . hK = IK .
.

(6.19)

H
vK

This equation can only be fulﬁlled for K ≤ m, and the solution is given by V = H H H
i.e., V has to be the Moore-Penrose pseudo-inverse3 of the joint channel matrix H.

−1

HH

To be able to also handle the case K > m, we have to introduce a set of active users K ⊂
{1, . . . , K} with cardinality |K| ≤ m, where qk = 0 has to hold for all k ∈ K. Let k(i) denote
/
4 in the set K. The zero-forcing constraints can then be written as
the ith user


H
vk(1)


.
VK HK =  .  hk(1) . . . hk(|K|) = I|K|
(6.20)
. 

H
vk(|K|)

which is fulﬁlled by

H
V K = HK HK

−1

H
HK .

(6.21)

With this receive ﬁlters, the eﬀective channel of a user k ∈ K including the receive ﬁlters
H
2
H
H
is vk hk = 1, the variance of the ﬁltered noise is σk = vk Im vk = vk vk , all inter-user
interference is canceled, and the achievable rate is given by
2
rk = log2 1 + qk · 1/σk .

(6.22)

Consequently, for a given set of users K, the sum rate optimization problem becomes
|K|

max

qk(1) ,...,qk(|K|)

|K|

log2 1 +

−2
σk(i) qk(i)

s. t.

i=1

i=1

qk(i) ≤ P, qk(i) ≥ 0, ∀i ∈ {1, . . . , |K|}
(6.23)

which is equivalent to the waterﬁlling problem (1.4) from Chapter 1.
PROGRAMMING TASK 6.8
Implement a function that computes the optimal zero-forcing sum rate for a given set of
active users K.
1 Deliverables (Matlab code ﬁle): sumrate_zf.m
3

Even though there are other possible solutions for the case K < m, the Moore-Penrose pseudo-inverse is the
optimal solution with respect to the sum rate optimization since it is the minimal norm solution and, thus, leads to
the lowest possible noise ampliﬁcation (cf., e.g., [4]).
4
The order of the users within the set can be chosen arbitrary.

89

Chapter 6. Nonconvex Optimization

• Function deﬁnition: function [R q] = sumrate_zf(H,P,a)
2 Input Speciﬁcation:
• H: m × 1 × K set of channel vectors h1 , . . . , hK
• P: maximum sum power P
• a: column vector [a1 , . . . , aK ]T where ak = 1 if k ∈ K and ak = 0 otherwise
3 Output Speciﬁcation:
• R: sum rate achieved at the waterﬁlling solution
• q: column vector [q1 , . . . , qK ]T containing the powers at the waterﬁlling solution
4 Hints:
• Use waterfilling(h,s,P) from Programming Task 1.4 in Chapter 1 to compute
the waterﬁlling solution.
• Return qk = 0 for all k ∈ K.
/
Knowing a method to compute the optimal rate for a given set of active users K, we still have
to ﬁnd the optimal K. This problem is treated in the following subsections.
6.3.1 Optimal Zero-Forcing Solution: Exhaustive Search
Let R(K) denote the optimal value of (6.23) for given K. We then have to solve
max

K⊆{1,...,K}

R(K) s. t. |K| ≤ m

(6.24)

which is a combinatorial problem.
The globally optimal solution can be found with high complexity by testing all possible sets K.
PROGRAMMING TASK 6.9
Implement a function that computes the optimal zero-forcing sum rate by testing all possible
sets K.
1 Deliverables (Matlab code ﬁle): srmax_zf_exhaustive.m
• Function deﬁnition:
function [R q] = srmax_zf_exhaustive(H,P)

2 Input Speciﬁcation:
• H: m × 1 × K set of channel vectors h1 , . . . , hK
• P: maximum sum power P

90

Chapter 6. Nonconvex Optimization

3 Output Speciﬁcation:
• R: sum rate achieved at the globally optimal zero-forcing solution
• q: column vector [q1 , . . . , qK ]T containing the powers at the globally optimal zeroforcing solution
4 Hints:
• Make use of sumrate_zf(H,P,s) from Programming Task 6.8.
• Return qk = 0 for all k ∈ K.
/

6.3.2 Suboptimal Zero-Forcing Solution: Greedy Allocation
To avoid the high computational complexity of an exhaustive search (espcially for large numbers
of user K such as in load_example('large')), we implement a suboptimal solution based
on a so-called greedy allocation [1]. The algorithm performs a successive allocation, i.e., one
user after another is added to the set of active users.
The algorithm is initialized with an empty set K = ∅. Then, a series of allocation steps is
performed where each step works as follows. Given a set K of active users with |K| < m, we
set
k ⋆ = arg max R({k} ∪ K)
(6.25)
k∈{1,...,K}\K

which can be solved by a linear search, i.e., by testing all possible k. If R({k} ∪ K) ≥ R(K),
the algorithm replaces K ← {k} ∪ K and proceeds to the next allocation step. Otherwise, the
algorithm terminates, and K is the obtained suboptimal solution. The algorithm also terminates
if a set of cardinality |K| = m has been found so that no further users can be added.
The number of rates R(K) that have to be computed is quadratic in the number of users for
the greedy algorithm while it is exponential in the case of an exhaustive search. Therefore, the
greedy allocation can be applied for large numbers of users, which is not true for the exhaustive
search.
PROGRAMMING TASK 6.10
Implement a function that computes a suboptimal zero-forcing sum rate by performing a
greedy allocation.
1 Deliverables (Matlab code ﬁle): srmax_zf_greedy.m
• Function deﬁnition:
function [R q] = srmax_zf_greedy(H,P)

2 Input Speciﬁcation:
• H: m × 1 × K set of channel vectors h1 , . . . , hK
• P: maximum sum power P
91

Chapter 6. Nonconvex Optimization

3 Output Speciﬁcation:
• R: sum rate achieved at the suboptimal zero-forcing solution
• q: column vector [q1 , . . . , qK ]T containing the powers at the suboptimal zero-forcing
solution
4 Hints:
• Make use of sumrate_zf(H,P,s) from Programming Task 6.8.
• Return qk = 0 for all k ∈ K.
/

6.4 Comparison
Since the problem with zero-forcing constraints has a more restrictive constraint set, its optimal solution always has to lie below the optimal solution of the problem without zero-forcing
constraints. Moreover, it is clear that the suboptimal algorithm proposed for each of the problems must perform worse than the respective globally optimal solution. This behavior can be
observed by plotting the average sum rate achieved with each of the algorithms.
TASK 6.11
Compare the four algorithms by calling plot_all. Zoom in to see the diﬀerent behavior
at low, intermediate, and high values of P .
It is known that zero-forcing becomes optimal for very low power (where only one stream is
transmitted in the optimal strategy) and very high power (where suppression of interference
becomes crucial), but a performance gap compared to the branch-reduce-and-bound solution
without zero-forcing should be observable at intermediate SNR.
Since problem (6.24) is a discrete optimization problem, the greedy allocation ﬁnds the globally
optimal set K at least in some cases while a suboptimal set is chosen in other cases. Therefore,
the diﬀerence of the achieved rates Rexhaustive − Rgreedy is either zero or positive, yielding a
positive diﬀerence on average.
Similar considerations are true for the comparison of the BRB solution and the gradient solution. Since the gradient-projection method converges to a local optimum, its achieved rate is
equal to the globally optimal rate if the local optimum is also the global one, but it is lower
if the local optimum is not the global one. However, it has to be taken into account that the
BRB algorithm only ﬁnds an ǫ-optimal solution. Therefore, it might happen that the grandient
method delivers a higher sum rate than the BRB algorithm, but in that case, the diﬀerence is
never more than ǫ. Nevertheless, the gradient solution should be worse on average at least for
suﬃciently small ǫ.

92

REFERENCES

References
[1] G. Dimic and N. Sidiropoulos, On downlink beamforming with greedy user selection:
performance analysis and a simple new algorithm, IEEE Transactions on Signal Processing, 53 (2005), pp. 3857–3868.
[2] D. P. Palomar and Y. Jiang, MIMO Transceiver Design via Majorization Theory, Foundations and Trends® in Communications and Information Theory, 3 (2006), pp. 331–551.
[3] H. Tuy, F. Al-Khayyal, and P. Thach, Monotonic Optimization: Branch and Cut Methods, in Essays and Surveys in Global Optimization, Springer, New York, NY, USA, 2005,
ch. 2, pp. 39–78.
[4] A. Wiesel, Y. Eldar, and S. Shamai, Zero-Forcing Precoding and Generalized Inverses,
IEEE Transactions on Signal Processing, 56 (2008), pp. 4409–4418.

93


