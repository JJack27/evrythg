Lecture: Continuous-time linear systems
Automatic Control 1
Continuous-time linear systems
Academic year 2010-2011
Prof. Alberto Bemporad (University of Trento)
Dynamical systems
Dynamical models
A dynamical system is an object (or a set of objects) that evolves over time,
possibly under external excitations.
Examples: a car, a robotic arm, a population of animals, an electrical circuit,
a portfolio of investments, etc.
The way the system evolves is called the dynamics of the system.
A dynamical model of a system is a set of mathematical laws explaining in a
compact form and in quantitative way how the system evolves over time,
usually under the effect of external excitations.
Main questions about a dynamical system:
Understanding the system (“How X and Y inﬂuence each other ?”)
Simulation (“What happens if I apply action Z on the system ?”)
Design (“How to make the system behave the way I want ?”)
Qualitative models only useful in non-technical domains
(examples: politics, advertisement, psychology,...)
Experiments provide an answer, but have limitations:
maybe too expensive (example: launch a space shuttle)
maybe too dangerous (example: a nuclear plant)
maybe impossible (the system doesn’t exist yet!)
In contrast, mathematical models allows us to:
capture the main phenomena that take place in the system
(example: Newton’s law – a force on a mass produces an acceleration)
analyze the system (relations among dynamical variables)
simulate the system (=make predictions) about how the system behaves under
certain conditions and excitations (in analytical form, or on a computer)
Working on a model has almost zero cost compared to real experiments (just
mathematical thinking, paper writing, computer coding)
However, a simulation (or any other inference obtained from the model) is as
better as the dynamical model is closer to the real system
Conﬂicting objectives:
Descriptive enough to capture the main behavior of the system
Simple enough for analyzing the system
“Make everything as simple as possible, but not simpler.”
– Albert Einstein
Albert Einstein
(1879-1955)
Making a good model is an art ! (that you are learning ...)
Differential equations
Ordinary differential equations (ODEs)
First order differential equation (=the simplest dynamical model):
˙(t)
x(0)
a , ˙
ax(t)
Its unique solution is x(t) = eat x0
x(t)
Examples
x(t) = velocity
x(t) = voltage
Kirchhoff’s voltage law:
Newton’s law:
−RC˙(t) − x(t) = 0
−βx(t) = M˙(t)
x(t) = x(0)e
x(t) = x(0)e− M t
First order differential equations with inputs
Introduce the forcing signal $u(t)$
The unique solution x(t) is
![()](140605085822.png)

Linear systems
System of n ﬁrst-order differential equations with inputs
˙1 (t)
˙2 (t)
˙n (t)
x1 (0) = x10 ,
Setting x = [x1 . . . xn ] 
linear system
a11 x1 (t) + . . . + a1n xn (t)
a21 x1 (t) + . . . + a2n xn (t)
an1 x1 (t) + . . . + ann xn (t)
xn (0) = xn0
+b1 u(t)
+b2 u(t)
+bn u(t)
, the equivalent matrix form is the so-called
˙(t) = Ax(t) + Bu(t)
with initial condition
x(0) = x0 = [x10 . . . xn0 ] 
Example: RLC circuit
x"(t)
u(t) − Rx1 (t) − L
x1 (t) =
dx2 (t)
dx1 (t)
x!(t)
− x2 (t) = 0
Kirchhoff’s voltage law
Kirchhoff’s current law
Rewrite as the 2nd order linear system
or in matrix form
˙(t) = 
= − R x1 (t) − 1 x2 (t) + 1 u(t)
= C x1 (t)
 x(t) + 
 u(t)
Example: Mass-spring-damper system
x!(t), x"(t)
˙1 (t) = x2 (t)
M˙2 (t) = u − βx2 (t) − Kx1 (t)
velocity = derivative of traveled distance
Newton’s law
= x2 (t)
= − M x2 (t) −
x (t) + M u(t)
Linear algebra recalls
 a21
square matrix of order n, A 
identity matrix of order n
Characteristic equation of A:
det(λI − A) = 0
Characteristic polynomial of A:
P(λ) = det(λI − A) = λn + an−1 λn−1 + . . . + a1 λ + a0
The eigenvalues of A are the roots λ1 , . . . , λn of its characteristic polynomial
An eigenvector of A is any vector such that for some i = 1, 2, . . . , n.

Linear algebra recall
Example:
Eigenvalues: λ1 =
Complex numbers recall:
Imaginary unit: 
Cartesian form: $c = a + jb$, $c \in \mathbb{C}$ , a, b 
Real part of c: $\mathcal{R} c = a$
Imaginary part of c: Im c = b
Conjugate of c: ¯ = a − jb
Polar form: c = ρejθ , ρ ≥ 0, θ 
Modulus or magnitude: [ ... ]$\rho$
Angle or phase: ∠c = θ
Lagrange’s formula
For the continuous-time linear system ˙ = Ax + Bu with initial condition
x(0) = x0  n , there exists a unique solution x(t)
x(t) =
eAt x0
eA(t−τ) Bu(τ)dτ
The exponential matrix is deﬁned as
E = expm(A*t)
If A is diagonalizable [...]
Eigenvalues and modes
Let u(t) ≡ 0 and assume A diagonalizable

[ _to('140530092708') ]
Differential equations of order n
By setting x1 (t) y(t), x2 (t) ˙(t), . . . , xn (t) yn−1 (t), this is equivalent to the system of n ﬁrst-order equations Linear ordinary differential equations

Examples of state-space realizations
Example 1

Alternative state-space realization method
In the following special case (=no input derivatives)
[ _to('140518222334') ]
we can deﬁne the following states
and therefore set

State vector
Generally speaking, the state of a dynamical system is a set of variables that
completely summarizes the past history of the system, and allows us to
predict its future motion
For the linear system
y(t)
Ax(t) + Bu(t)
Cx(t) + Du(t)
given the initial state x(0) and the input signal u(t), ∀t  [0, T], we already know how to compute the state x(t) and the output y(t) of the system,
If we know the initial state x(0), we can neglect the past history
The dimension n of the state $x(t)$ $n$ is called the order of the system
Some classes of dynamical systems
Causality: a dynamical system is causal if y(t) does not depend on future
inputs u(τ) ∀τ > t (strictly causal if ∀τ ≥ t)
A linear system is always causal, and strictly causal iff D = 0
Linear time-varying (LTV) systems:
A(t)x(t) + B(t)u(t)
C(t)x(t) + D(t)u(t)
When A, B, C, D are constant, the system is said linear time-invariant (LTI)
Multivariable systems: more generally, a system can have m inputs
(u(t)  m ) and p outputs (y(t)  p ). For linear systems, we still have
Nonlinear systems
where f :
f (x(t), u(t))
g(x(t), u(t))
are (rather arbitrary) nonlinear
Time-varying nonlinear systems are very general classes of dynamical systems
f (t, x(t), u(t))
g(t, x(t), u(t))
Stability
Consider the continuous-time nonlinear system
Definition
A state $x_r$  n and an input $u_r$ m are an equilibrium pair if for initial condition x(0) = xr and constant input u(t) ≡ ur the state remains constant: x(t) ≡ xr , ∀t ≥ 0
Equivalent deﬁnition: (xr , ur ) is an equilibrium pair if f (xr , ur ) = 0
$x_r$ is called equilibrium state, $u_r$ equilibrium input
The deﬁnition generalizes to time-varying nonlinear systems
Consider the nonlinear system
and let xr an equilibrium state, f (xr , ur ) = 0
The equilibrium state xr is stable if for each initial conditions x(0) “close
enough” to xr , the corresponding trajectory x(t) remains near xr for all t ≥ 0 a
Analytic deﬁnition: ∀ε > 0 ∃δ > 0 : x(0) − xr < δ ⇒ x(t) − xr < ε, ∀t ≥ 0
The equilibrium point xr is called asymptotically stable if it is stable and
x(t) → xr for t → ∞
Otherwise, the equilibrium point xr is called unstable
Stability of equilibria - Examples
asymptotically stable equilibrium
stable equilibrium
asymptotically stable 
unstable if a < 0

[ _to('140602204357') ]
***
###Stability of continuous-time linear systems
Since the natural response of $\dot{x} = Ax + Bu$ is $x(t) = \exp(A t) x_0$, the stability properties depend only on A. We can therefore talk about system stability of a linear system $(A, B, C, D)$
[ $A \in \mathbb{R}^{n \times n}$ ]
![()](140602204438.png)
The stability properties of a linear system only depend on the real part of the eigenvalues of matrix $A$

The natural response is x(t) = eAt x0 (eAt
If matrix A is diagonalizable , A = TΛT
Take any eigenvalue λ = a + jb:
|eλt | = eat |ejbt | = eat
A is always diagonalizable if algebraic multiplicity = geometric multiplicity
If A is not diagonalizable, it can be transformed to Jordan form. In this case the natural
response x(t) contains modes tj eλt , j = 0, 1, . . . , alg. multiplicity - geom. multiplicity
 ˙(t) =
x(0) =
⇒ eigenvalues of A: {−1, −2}
x1 (t)
x2 (t)
x (t)
asymptotically stable
x10 (2e−t − e−2t ) + x20 (−e−t + e−2t )
x10 (2e−t − 2e−2t ) + x20 (−e−t + 2e−2t )
Example 2
⇒ eigenvalues of A: {+j, −j}
x2(t)
x1(t)
marginally stable
Example 3
⇒ eigenvalues of A: {0, 0}
Note: A is not diagonalizable !
unstable
Example 4
⇒ eigenvalues of A: {−1, 1}
x10 et
x et + (x20 − 2 x10 )e−t
Linearization
Linearization of nonlinear systems
Let (xr , ur ) be an equilibrium, f (xr , ur ) = 0
Objective: investigate the dynamic behaviour of the system for small
perturbations ∆u(t) u(t) − ur and ∆x(0) x(0) − xr .
The evolution of ∆x(t)
x(t) − xr is given by
∆x(t) = ˙(t) − ˙r = f (x(t), u(t))
= f (∆x(t) + xr , ∆u(t) + ur )
(xr , ur ) ∆x(t) +
(xr , ur ) ∆u(t)
Similarly
∆y(t) ≈
where ∆y(t)
equilibrium
y(t) − g(xr , ur ) is the perturbation of the output from its
The perturbations ∆x(t), ∆y(t), and ∆u(t) are (approximately) ruled by the
linearized system
∆x(t) = A∆x(t) + B∆u(t)
∆y(t) = C∆x(t) + D∆u(t)
Lyapunov’s indirect method
Consider the nonlinear system ˙ = f (x), with f differentiable, and assume
x = 0 is equilibrium point (f (0) = 0)
Consider the linearized system ˙ = Ax, with A =
If ˙ = Ax is asymptotically stable, then the origin x = 0 is also an
asymptotically stable equilibrium for the nonlinear system (locally)
If ˙ = Ax is unstable, then the origin x = 0 is an unstable equilibrium for the
nonlinear system
If A is marginally stable, nothing can be said about the stability of the origin
x = 0 for the nonlinear system
Aleksandr Mikhailovich Lyapunov
(1857-1918)
Example: Pendulum
y(t) = angular displacement
˙(t) = angular velocity
¨(t) = angular acceleration
u(t) = mg gravity force
h˙(t) = viscous friction torque
l = pendulum length
ml2 = pendulum rotational inertia
u(t) = mg
mathematical model
ml2 ¨(t) = −lmg sin y(t) − h˙(t)
in state-space form (x1 = y, x2 = ˙)
Look for equilibrium states:
Linearize the system around x1r = 0, x2r = 0
∆˙(t) =
∆x(t)
ﬁnd the eigenvalues of A
det(λI − A) = λ2 + Hλ +
by Lyapunov’s indirect method
xr = 0 is also an asymptotically
stable equilibrium for the
pendulum
Linearize the system around x1r = π, x2r = 0
det(λI − A) = λ2 + Hλ −
λ1 < 0, λ2 > 0 ⇒ ˙ = Ax unstable
xr = 0 is also an unstable
equilibrium for the pendulum
English-Italian Vocabulary
dynamics
eigenvalue
eigenvector
modulus or magnitude
angle or phase
nonlinear systems
controllable canonical form
observable canonical form
dinamica
risposta libera
autovalore
autovettore
fase
sistemi non lineari
forma canonica di raggiungibilità
forma canonica di osservabilità
Translation is obvious otherwise.
Diagonalization of A:
_v('140504214018')
(not all matrices A are diagonalizable, see Jordan normal form)

[ _to('140603192155') ]
Complex exponential: $\exp(c) = ... $
![()](140603192132.png)
[ $| \exp(j b) = 1$ ]

The state trajectory is the natural response
_v('140504233114')
where $v_i$ =eigenvector of A, $\lambda_i$ eigenvalue of A, $\alpha = $
The evolution of the system depends on the eigenvalues λi of A, called modes of the system (sometimes we also refer to eλi t as the i-th mode)
A mode λi is called excited if αi = 0

>Linear ordinary differential equations
$n$th-order linear ODE with input
![](140504215652.png)
[ by setting 
![](140518223843.png) ]
One can verify by inspection that the given $n$th-order ODE is equivalent to the following $1$st-order linear system of ODEs:
![](140518223618.png)
[ Note the *ordering* and *sign* of the coefficients $a_{(n-1)}, b_{(n-1)}$ ]

The operation of transforming a nth -order ODE into a linear system of 1st -order ODEs is called state-space realization. There are inﬁnitely many realizations.

### Other state-space realization methods
The following state-space realization is called controllable canonical form
![()](140504220319.png)

The following state-space realization is called observable canonical form 2
We will see later in the course that the pair (A, B) is completely reachable.
We will see later in the course that the pair (A, B) is completely observable.
Let λ1 , . . ., λm , m ≤ n be the eigenvalues of A 
. The system ˙ = Ax + Bu is
asymptotically stable iff ℜλi < 0, ∀i = 1, . . . , m
