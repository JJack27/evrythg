Computer-Controlled
Systems
Theory and Design
THIRD EDITION

Karl J. Astrom

Bjorn Witten mark

Tsinghua University Press

Prentice Hall

Computer-Controlled Systems-Theory and Design, Third Edition
Copyright

© 1997 by Prentice

Hall

Original English language Edition Published by Prentice Hall.
For sales in Mainland China only.

*=t:513 Ep .~ EE ffl-1:~~ ttl ~~IW~~~m$**-:Jj Jl&t±;(-F. t.p ~!Jl1*J (;f'-EJ.f&wm, 1m f1 *f
JJiH:r ~ ~ fit it ~ jt! I~J ~!k itHl& ,:& IT

*

0

*~ttl~~~oo~m.~meMh~~M.~.*~~ffM$~o

~

t:

1'1:

~: K. J. Astrom , B. Wittenmark

ttllt&;f:

it.fJU~ffitl~HJt---·JI~~t'tit(m 3 Jl&)

~$*~ ill If&U(:ltJr~m$*~~IiJf*J!(' W~~ 100084)

http:/ /www.tup.tsinghua.edu.cn
~Jijjll~: ~t* rn* W
fi1$Jr
~IT~: f@f$:j:$Jit~J~ jt /~ ~J:r JiJf

]f

*: 787X9601/16

fi1*:

36.25

Jl& 7jz: 2002 1f 1 j:j ~ 1 Ji& 2002 ~ 1 fJ ~ 1 7jzEjl jjj~
~ %: ISBN 7-302-0S008-2 jTP • 2828
Ep

fl:

0001---3000

JE if\': 49.00 JG

Preface
A consequence of the revolutionary advances in microelectronics is that prac, tically all control systems constructed today are based on microprocessors and
sophisticated microcontrollers. By using computer-controlled systems it is possible to obtain higher performance than with analog systems, as well as new
functionality. New software tools havealsodrastically improved the engineering
efficiency in analysis and design of control systems.
Goal of the book

This book provides the necessary insight, knowledge, and
understanding required to effectively analyze and design computer-controlled
systems.

The newedition This third edition is a majorrevision basedon the advances
in technology and the experiences from teaching to academic and industrial
audiences. The material has been drastically reorganized with more than half
the text rewritten. The advances in theory and practice ofcomputer-controlled
systems and a desire to put more focus on design issues have provided the
motivation for the changes in the third edition. Many new results have been
incorporated. By ruthless trimming and rewriting we are now able to include
new material without increasing the size of the book. Experiences of teaching
from a draft version have shown the advantages of the changes. We have been
very pleased to note that students can indeed deal with design at a much earlier
stage. This has also made it possible to go much more deeply into design and
implementation.
Another major change in the third edition is that the computational tools
MATLAJ3® and SIMULINK® have been used extensively. This changes the pedagog}' in teaching substantially. All major results are formulated in such a way
that the computational tools can be applied directly. This makes it easy to deal
with complicated problems. It is thus possible to dealwith manyrealisticdesign
issues in the courses. The use of computational tools has been balanced by a
strong emphasis of principles and ideas. Most key results have also been illustrated by simplepencil and paper calculations BO that the st~dent8 understand
the workings of the computational tools.
vii

vIII

Preface

Outline of the Book

Background Material A broad outline of computer-controlled systems is
presented in the first chapter. This gives a historical perspective on the development ofcomputers. control systems, and relevant theory. Some key points of
the theoryand the behavior ofcomputer-control systems are also given, together
with many examples.
Analysis and Design of Discrete-Time Systems It is possible to makedrastic simplifications in analysis and design by considering only the behavior ofthe
system at the sampling instants. We call this the computer-oriented view. It is
the view of the systemobtained by observing its behavior through the numbers
in the computer. The reason for the simplicity is that the system can be described by linear difference equations with constant coefficients. This approach
is covered in Chapters 2, 3.4 and 5. Chapter 2 describes how the discrets-time
systems are obtained by sampling continuous-time systems. Both state-space
models and input-output models are given. Basic properties of the models are
also given together with mathematicaltools such as the a-transform. Tools for
analysis are presented in Chapter 3.
Chapter 4 deals with the traditional problem of state feedback and observers, but it goes much further than what is normally covered. in similar
textbooks. In particular, the chapter shows how to deal with load disturbances,
feedforward, and command-signal following. Taken together, these features give
the controller a structure that can cope with many of the cases typically found
in applications. An educational advantage is that students are equipped with
tools to deal with real design issues after a very short time.
Chapter 5 deals with the problems of Chapter 4 from the input-output
point of view, thereby giving an alternative view on the design problem. All
issues discussed in Chapter 4 are also treated in Chapter 5. This affords an
excellent way to ensure a good understanding of similarities and differences
between stete-space and polynomial approaches. The polynomial approach also
makes it possible to deal with the problems of modeling errors and robustness,
which cannot he conveniently handled by state-space techniques.
Having dealt with specific design methods, we present general aspects of
the design of control systems in Chapter 6. This covers structuring of large
systems as well as bottom-up and top-down techniques.

Broadening the View Although manyissuesin computer-controlled systems
can be dealt with using the computer-oriented view, there are some questions
that require a detailed study of the behavior of the system between the sampling instants. Suchproblems arise naturally if a computer-controlled system is
investigated through the analog signalsthat appear in the process. We call this
the process-oriented view. It typically leads to linear systems with periodic coefficients. This gives rise to phenomena such as aliasing, which may lead to very
undesirable effects unless special precautions are taken. It is veryimportant to
understand both this and the design of anti-aliasing filters when investigating
computer-controlled. systems. Tools for this are developed in Chapter 7.

Preface

Ix

When upgrading older control equipment, sometimes analog designs of
controllers may be available already. In such cases it may be cost effective to
have methods to translate analog designs to digital control directly. Methods for
this are given in Chapter 8.

Implementation It is not enough to know about methods of analysis and design. A control engineer should also be aware of implementation issues. These
are treated in Chapter g, which covers matters such as prefiltering and computational delays, numerics, programming, and operational aspects. At this stage
the reader is well prepared for all steps in design, from concepts to computer
implementation.
More Advanced Design Methods To make more effective designs of control systems it is necessary to better characterize disturbances. This is done in
Chapter 10. Having such descriptions it is then possihle to design for optimal
performance. This is done using state-space methods in Chapter 11 and by using
polynomial techniques in Chapter 12. So far it has been assumed that models
of the processes and their disturbances are available. Experimental methods to
obtain such models are described in Chapter 13.

Prerequisites

The book is intended for a final-year undergraduate or a first-year graduate
course for engineering majors. It is assumed that the reader has had an introductory course in automatic control. The book should be useful for an industrial
audience.

Course Configurations

The book has been organized 80 that it can be used in different ways. An introductory course in computer-controlled systems could cover Chapters 1, 2~ 3,
4, 5, and 9. A more advanced course might include all chapters in the book A
course for an industrial audience could contain Chapters 1, parts of Chapters
2,3,4, and 5, and Chapters 6, 7,8, and 9. 'Ib get the full henefit of a course, it
is important to supplement lectures with problem-solving sessions, simulation
exercises, and laboratory experiments.
Computetional Tools

Computer tools for analysis, design, and simulation are indispensable tools
when working with computer-controlled systems. The methods for analysis and
design presented in this book can be performed very conveniently using M.\rLAB®. Many of the exercises also cover this. Simulation of the system can similarly be done with Simnon® or SIMULINX®. There are 30 figures that illustrate various aspects of analysis and design that have been performed using
MATLAB®, and 73 fignres from simulations using SrMULTNK®. Macros and mfiles are available from anonymous FrP from ftp. control. 1th. se, directory
Ipub/booksl ecs. Other tools such as Simnon® and Xmath® can be used also.

Preface

x

Supplements

Complete solutions are available from the publisher for instructors who have
adopted our book. Simulation macros, transparencies, and examples ofexaminations are available on the World Wide Web at http://ww.control.lth.se ;
see Education/Computer-Controlled Systems.
Wanted: Feedback
As teachers and researchers in automatic control, we know the importance of
feedback. Therefore, we encourage all readers to write to us about errors, po-

tential miscommunications, suggestions for improvement, and also aboutwhat
may be ofspecial valuable in the material we have presented.
Acknowledgments

During the years that we have done research in computer-controlled systems
and that we havewritten the book, wehave had the pleasure and privilege ofinteractingwith manycolleagues in academia and industrythroughout the world.
Consciously and subconsciously, we have picked up material from the knowledge hase called computer control. It is impossible to mention everyone who
has contributed ideas, suggestions, concepts, and examples, but we owe each
one our deepest thanks. The long-term support of our research by the Swedish
Board oflndustrial and Technical Development (NUTEK) and by the Swedish
Research Council for Engineering Sciences (TFR) are gratefully acknowledged.
Finally, wewant to thank some people who, more than others, havemade it
possible for us towrite thisbook. We wishto thank LeifAndersson, who has been
our'IF.,Xpert. Heand Eva Dagnegard have been invaluable in solving manyofour
'lE}X. problems. EvaDagnegard and Agneta Tuszynski have done an excellent job
of typing many versions of the manuscript. Most of the illustrations have been
done by Britt-Marie M8.rtensson. Without all their patience and understanding
ofour whims, never would there have been a final book. We also want to thank
the staff at Prentice Hall for their support and professionalism in textbook
production.
KARL J. AsTBOM
BJORN WITrENMARK

Department of Automatic Control
Lund Institute ofTechnology
Box 118, 8-221 00 Lund, Sweden
kar Lj ohan. astrolD.(kontrol.lth . Be

bjorn.wittenmarkCcontrol.lth.se

Contents
Pfeface vII
1. COmputer Control 1
1.1
1.2
1.3
1.4
1.5
1.6

Introduction 1
Computer Technology 2
Computer-Control Theory 11
Inherently Sampled Systems 22
How Theory Developed 25
Notes and References 28

2. Discrete-TIme Systems 30
2.1 Introduction 30
2.2 Sampling Continuous-Time Signals 31
2.3 Sampling a Continuous-Time State-Space System 32
2.4 Discrete-Time Systems 42
2.5 ChangingCoordinates in State-Space Models 44
2.6
2.7
2.8
2.9
2.10
2.11

Input-Output Models 46
The z-Transform 53
Poles and Zeros 61
Selection of Sampling Rate 66
Problems 68
Notes and References 75

3. Analysis of Discrete-TIme Systems 77
3.1

3.2
3.3
3.4

3.5
3.6
3.7

Introduction 77
Stability 77
Sensitivity and Robustness 89
Controllability, Reachability, Observability, and Detectebility 93
Analysis of Simple Feedback Loops 103
Problems 114
Notes and References 118

4. Pole-Placement Design: A state-Space Approach 120
4.1 Introduction 120
4.2 Control-System Design 121
xl

xII

Contents

4.3 Regulation by State Feedback 124
4.4 Observers 135
4.5 Output Feedback 141
4.6 The Servo Problem 147
4.7 A Design Example 156
4.8

Conclusions 160

4.9 Problems 161
4.10 Notes and References 164

s.

Pole-Placement Design: A Polynomial Approach 165
5.1 Introduction 165
5.2 A Simple Design Problem 166
5.3 The Diophantine Equation 170
5.4 More Realistic Assumptions 175
5.5 Sensitivity to Modeling Errors 183
5.6 A Design Procedure 186
5.7 Design of a Controller for the Double Integrator 195
5.8 Design of a Controller for the Harmonic Oscillator 203
5.9 Design of a Controller for a Flexible Robot Arm 208
5.10 Relations to Other Design Methods 213
5.11 Conclusions 220
5.12 Problems 220
5.13 Notes and References 223

6. Design: An Overview 224
6.1 Introduction 224
6.2 Operational Aspects 225
6.3 Principles of Structuring 229
6.4 A Top-Down Approach 230
6.5 A Bottom-Up Approach 233
6.6 Design of Simple Loops 237
6.7 Conclusiuns 240
6.8 Problems 241
6.9 Notes and References 241
7. Proeess-Oliented Models 242
7.1 Introduction 242
7.2 A Computer-Controlled System 243
7.3 Sampiing and Reconstruction 244
7.4 Aliasing or FrequencyFolding 249
7.5 Designing Controllers with Predictive First-Order Hold 256
7.6 The Modulation Model 262
7.7 Frequency Response 268
7.8 Pulse-Transfer-Function Formalism 278
7.9 Multirate Sampling 286
7.10 Problems 289
7.11 Notes and References 291

Contents

xiii

8. Approximating Continuous- Time Controllers 293
8.1
8.2
8.3
8.4
8.5
8.6
8.7
8.8

Introduction 293
Approximations Based on Transfer Functions 293
Approximations Based on State Models 301
Frequency-Response Design Methods 305
Digital PID-Controllers 306
Conclusions 320
Problems 320
Notes and References 323

9. Implementation of Digital Controllers 324
9.1 Introduction 324
9.2 An Overview 325
Prefiltering and Computational Delay 328
Nonlinear Actuators 331
Operational Aspects 336
Numerics 340
Realization of Digital Controllers 349
9.8 Programming 360
9.9 Conclusions 363
9.10 Problems 364
9.11 Notes and References 368

9.3

9.4
9.5
9.6
9.7

10. Disturbance Models 370
10.1 Introduction 370
10.2 Reduction of Effects ofDisturbances 371
10.3 Piecewise Deterministic Disturbances 373
10.4 Stochastic Models of Disturbances 376
10.5 Continuous-Time Stochastic Processes 397
10.6 Sampling a Stochastic Differential Equation 402
10.7 Conclusions 403
10.8 Problems 404
10.9 Notes and References 407

11. Optimal Design Methods: A State-Space Approach 408
11.1 Introduction 408
11.2 Linear Quadratic Control 413
11.3 Prediction and Filtering Theory 429
11.4 Linear Quadratic Gaussian Control 436
11.5 Practical Aspects 440
11.6 Conclusions 441
11.7 Problems 441
11.8 Notes and References 446

12. Optimal Design Methods: A Polynomial Approach 447
12.1
12.2
12.3
12.4

Introduction 447
Problem Formulation 448
Optimal Prediction 453
Minimum-Variance Control 460

xtv
12.5 Linear Quadratic Gaussian (LQG) Control 470
12.6 Practical Aspects 487
12.7 Conclusions 495
12.8 Problems 496
12.9 Notes and References 504
13. Identification 505
13.1 Introduction 505
13.2 MathematicalModel Building 506
13.3 System Identification 506
13.4 The Principle of Least Squares 509
13.5 Recursive Computations 514
13.6 Examples 521
13.7 Summary 526
13.8 Problems 526
13.9 Notes and References 527
A. Examples 528
B. Matrices 533
B.l Matrix Functions 533
B.2 Matrix-Inversion Lemma 536
B.3 Notes and References 536
Bibliography 537
Index 549

Contents

1
Computer Control
1.1 Introduction
Practically all control systems that are implemented today are based on computer control. It is therefore important to understand computer-controlled systems well. Such systems can be viewed as approximations of analog-control
systems, but this is a poor approach because the full potential of computer control is not used. At best the results are only as good as those obtained with
analog controL It is much better to master computer-controlled systems, so that
the full potential of computer control can be used. There are also phenomena
that occur in computer-controlled systems that have no correspondence in analog systems. It is important for an engineer to understand this. The main goal
of this book is to provide a solid background for understanding, analyzing, and
designing computer-controlled systems.
Acomputer-controlled system can be described schematically as in Fig. 1.1.
The output from the process y(l) is a continuous-time signal. The output is
converted into digital form by the analog-to-digital (A-D) converter. The A-D
converter can be included in the computer or regarded as a separate unit, according to one's preference. The conversion is done at the sampling times, th'
The computer interprets the converted signal, {y(tk)}, as a sequence of numbers, processes the measurements using an algorithm, and gives a new 5e~
quence of numbers, {U(tk)}. This sequence is converted to an analog signal by
a digital-to-analog (D-A) converter. The events are synchronized. by the realtime clock in the computer. The digital computer operates sequentially in time
and each operation takes some time. The D-A converter must, however, prodace
a continuous-time signal. This is normally done by keeping the control signal
constant between the conversions. In this case the system runs open loop in
the time interval between the sampling instants because the control signal is
constant irrespective of the value of the output.
The computer-controlled system contains both continuous-time signals and
sampled, or discrete-time. signals. Such systems have traditionally been called
1

Chap. 1

Computer Control

2

r----- ---------- --------- -------- ,
Computer
Clock

~
I
I
~
I

A-D

Algorithm

y(t)

u(t)

{u(t /c )}

{y(t k )}

D-A

I
I

Process

______________ ___ ______ _________JI

Figure 1.1 Schematic diagram of a computer-controlled system.

sampled-data systems, and this term will be used here as a synonym for computer-controlled systems.
The mixture of different types of signals sometimes causes difficulties. In
most cases it is, however, sufficient to describe the behavior of the system at
the sampling instants. The signals are then of interest only at discrete times.
Such systems will be called discrete-time systems. Discrete-time systems deal
with sequences of numbers, so a natural way to represent these systems is to
use difference equations.
The purpose of the book is to present the control theory that is relevant to
the analysis and design of computer-controlled systems. This chapter provides
somebackground. Abrief overview ofthe development of computer-control technology is given in Sec. 1.2. The need for a suitable theory is discussedin Sec. 1.3.
Examples are used to demonstrate that computer-controlled systems cannot be
fully understood by the theory oflinear time-invariant continuous-time systems.
An example shows not only that computer-controlled systems can be designed
using continuous-time theory and approximations, but also that substantial improvements can be ohtained by other techniques that use the full potential of
computer control. Section 1.4 gives some examples of inherently sampled systems. The development of the theory of sampled-data systems is outlined in
Sec. 1.5.

1.2 Computer Technology
The idea of using digital computers as components in control systems emerged
around 1950. Applications in missile and aircraft control were investigated first.
Studies showed that there was no potential for using the general-purpose digital
computers that were available at that time. The computers were too big. they
consumed too much power, and they were not sufficiently reliable. For this
reason special-purpose computers--digital differential analyzers (DDAs)-were
developed for the early aerospace applications.

Sec. 1.2

Computer Technology

3

The idea of using digital computers for process control emerged in the
mid-1950s. Serious work started in March 1956 when the aerospace company
Thomson Ramo Woodridge (TRW) contacted Texaco to set up a feasibility study.
After preliminary discussions it was decided to investigate a polymerization
unit at the Port Arthur, Texas, refinery. A group of engineers from TRW and
Texaco made a thorough feasibility study,which required about 30 people-years.
A computer-controlled system for the polymerization unit was designed based
on the RW-300 computer, The control systemwent on-line March 12, 1959. The
system controlled 26 flows, 72 temperatures, 3 pressures, and 3 compositiens,
The essential functions were to minimize the reactor pressure, to determine
an optimal distribution among the feeds of 5 reactors, to control the hot-water
inflow based on measurement ofcatalyst activity, and to determine the optimal
recirculation.
The pioneering work done by TRW was noticed by many computer manufacturers, who saw a large potential market for tbeir products. Many different
feasibility studies were initiated and vigorous development was started. To discuss the dramatic developments, it is useful to introduce six periods:
Pioneering period

~

1955

Direct-digital-control period
Minicomputer period

~

~

1962

1967

Microcomputer period ;:;;; 1972
General use of digital control
Distributed control

~

~

1980

1990

It is difficult to give precise dates, because the development was highly diversified. There was a wide difference between different application areas and
different industries; there was also considerable overlap. The dates given refer
to the emergence of new approaches.

Pioneering Period
The work done by TRW and Texaco evoked substantial interest in process industries, among computer manufacturers, and in research organizations. The
industries saw a potential tool for increased automation, the computer industries saw new markets, and universities saw a new research field. Many feasibility studies were initiated by the computer manufacturers because they were
eager to learn the new technology and were very interested in knowing what a
proper process-control computer should look like. Feasibility studies continued
throughout the sixties.
Thecomputer systemsthat were usedwere slow, expensive, and unreliable.
The earlier systems used vacuum tubes. Typical data for a computer around
1958 were an addition time of 1 rns, a multiplication time of 20 rns, and a mean
time between failures (MTBF) for a central processing unit of50-100h. To make
full use ofthe expensive computers, it was necessary to havethem perform many

4

Computer Control

Chap. 1

tasks. Because the computers were so unreliable, they controlled the process by
printing instructions to the process operator or by changing the set points of
analog regulators . These supervisory modes of operation were referred to as an
operator guide and a set-point control.
The major tasks of the computer were to find the optimal operating conditions, to perform scheduling and production planning, and to give reports about
production and raw-material consumption. The problem of finding the best operating conditions was viewed as a static optimization problem. Mathematical
models of the processes were necessary in order to perform the optimization.
The models used-whicb were quite complicated-were derived from physical
models and from regression analysis of process data. Attempts were also made
to carry out on-line optimization.
Progress was often hampered by lack of process knowledge. It also became
clear that it was not sufficient to view the problems simply as static optimization
problems; dynamic models were needed. A significant proportion of the effort
in many of the feasibility studies was devoted to modeling, which was quite
time-consuming because there was a lack of good modeling methodology. This
stimulated research into system-identification methods.
A lot of experience was gained during the feasibility studies. It became
clear that process control puts special demands on computers. The need to respond quickly to demands from the process led to development of the interrupt
feature , which is a special hardware device that allows an external event to
interrupt the computer in its current work so that it can respond to more urgent process tasks. Many sensors that were needed were not available. There
were also several difficulties in trying to introduce a new technology into old
industries.
The progress made was closely monitored at conferences and meetings
and in journals. A series of articles describing the use of computers in process
control was published in the journal Control Engineering. By March 1961, 37
systems had been installed. A year later the number of systems bad grown to
159. The applications involved controlof steel mills and chemical industries and
generation of electric power. The development progressed at different rates in
different industries. Feasibility studies continued through the 19608 and the
19708.
Direct-Digital-Control Period
The early installations of control computers operated in a supervisory mode, either as an operator guide or as a set-point control. The ordinary analog-control
equipment was needed in both cases. A drastic departure from this approacb
was made by Imperial ChemicalIndustries (leI) in England in 1962.A complete
analog instrumentation for process control was replaced by one computer, a Ferranti Argus. The computer measured 224 variables and controlled 129 valves
directly. This was the beginning of a new era in process control: Analog technology was simply replaced by digital technology; the function of the system was
the same. The name direct digital control (DDC) was coined to emphasize that

Sec. 1.2

Computer Technology

5

the computer-controlled the process directly. In 1962 a typical process-control
computer could add two numbers in 100 /is and multiply them in 1 ms. The
MTBF was around 1000h.
Cost was the major argument for changingthe technology. The cost of an
analog system increased linearly with the number of control loops; the initial
cost of a digital system was large, but the cost of adding an additional loop
was small. The digital system was thus cheaper for large installations. Another
advantage was that operator communication could be changed drastically; an
operator communication panel could replace a large wall ofanaloginstruments.
The panel used in the ICI system was very simpl~a digital display and a few
buttons.
Flexibility was another advantage of the DDC systems. Analog systems
were changedby rewiring; computer-controlled systems were changed-by reprogramming. Digital technology alsooffered other advantages. It was easy to have
interaction amongseveral control loops. The parameters of a control loop could
be made functions of operating conditions. The programming was simplified by
introducing special DDe languages. A user of such a language did not need
to know anything about programming, but simply introduced inputs, outputs,
regulator types) scale factors, and regulator parameters into tables. To the user
the systems thus looked like a connection of ordinary regulators. A drawback
ofthe systems was that it was difficult to do unconventional control strategies.
This certainly hampered development of control for many years.
DDC was a major change of direction in the development of computercontrolled systems. Interest was focused on the basic control functions instead
of the supervisory functions of the earlier systems. Considerable progress was
made in the years 1963-1965. Specifications for DDC systems were worked out
jointlybetween users and vendors. Problema related to choice ofsamplingperiod
and control algorithms? as well as the key problem of reliahility, were discussed
extensively. The DDC concept was quickly accepted althoughDDC systemsoften
turned out to be more expensive than corresponding analog systems.

Minicomputer Period
There was substantial development ofdigitel computer technology in the 1960s.
The requirements on a process-control computer were neatly matched with
progress in integrated-circuittechnology. The computers became smaller, faster,
more reliable, and cheaper. The term minicomputer was coined for the new oomputers that emerged. It was possible to design efficient process-control systems
by using minicomputers.
The development of minicomputer technology combined with the increasing knowledge gained about process control with computers during the pioneering and DDC periods caused a rapid increase in applications of computer
control. Special process-control computers were announced by several manufacturers. A typical process computer of the period had a word length of 16 bits.
The primary memory was 8-124 k words. A disk drive was commonly used as a
secondary memory. The CDC 1700 was a typical computer of this period. with

6

Computer Control

cnap.t

an addition time of 2 JlS and a multiplication time of 7 p». The MTBF for a
central processing unit was about 20,000 h.
An important factor in the rapid increaseofcomputer control in this period
was that digital computer control now came in a smaller "unit." It was thus
possible to use computer control for smaller projects and for smaller problems.
Because of minicomputers, the number of process computers grew from about
5000 in 1970 to about 50,000 in 1975.

Microcomputer Period and General Use of Computer Control

The early use of computer control was restricted to large industrial systems
because digital computing was only available in expensive, large, slow, and
unreliable machines. The minicomputer was still a fairly large system. Even
as performance continued to increase and prices to decrease, the price of a
minicomputer mainframe in 1975 was still about $10,000. This meant that a
small system rarely cost less than $100,000. Computer control was still out
of reach for a large number of control problems. But with the development of
the microcomputer in 1972, the price of a card computer with the performance
of a 1975 minicomputer dropped to $500 in 1980. Another consequence was
that digital computing power in 1980 came in quanta as small as $50. The
development ofmicroelectronics has continued with advances in very large-scale
integration (VLSI) technology; in the 1990s microprocessors became available
for a few dollars. Thishas had a profound impact on the use of computer control.
As a result practically all controllers are now computer-based. Mass markets
suchas automotive electronics has alsoled tothe development ofspecial-purpose
computers, called microcontrollers, in which a standard computer chip has been
augmented with A-D and D-A converters, registers, and other features that
make it easy to interface with physical equipment.
Practically all control systems developed today are based on computer
control. Applications span all areas of control, generation, and distribution
of electricity; process control; manufacturing; transportation; and entertainment. Mass-market applications such as automotive electronics, CD players,
and videos are particularly interesting hecause they have motivated computer
manufacturers to make chips that can be used in a wide variety of applications.
As an illustration Fig. 1.2 shows an example of a single-loop controller for
process control. Such systems were traditionally implemented using pneumatic
or electronic techniques, but they are now always computer-based. The controller has the traditional proportional, integral, and derivative actions (PID),
which are implemented in a microprocessor. With digital control it is also possible to obtain added functionality. In this particular case, the regulator is provided with automatic tuning, gain scheduling, and continuous adaptetion of
feedforward and feedback gains.These functions are difficult to implement with
analog techniques. The system is a typical case that shows how the functionality of a traditional product can be improved substantially by use of computer
control.

Sec. 1.2

Computer Technology

7

Figure 1.2 A standard single-loop controller for process control. (By courtesy of Alfa Laval Automation, Stockholm, Sweden.)

logic, Sequencing, and Control
Industrial automation systems have traditionally had two components) controllers and relay logic. Relays were used to sequence operations such as startup
and shutdown and they were also used to ensure safety ofthe operations by providing interlocks. Relays and controllers were handled by different categories
of personnel at the plant. Instrument engineers were responsible for the controllers and electricians were responsible for the relay systems. We have already
discussed how the controllers were influenced by microcomputers. The relay systems went through a similar change with the advent of microelectronics. The
so-called programmable logic controller (PLCj emerged in the beginning of the
1970s as replacements for relays. They could be programmed by electricians
and in familiar notations, that is, as rungs of relay contact logic or as logic
(AND/OR) statements. Americans were the first to bring this novelty to the
market, relying primarily on relay contact logic, but the Europeans were hard
on their heels, preferring logic statements. The technology becamea big success,
primarily in the discrete parts manufacturing industry (for obvious reasons).
However, in time, it evolved to include regulatory control and data-handling
capabilities as well, a development that has broadened the range of applications for it. The attraction was, and is, the ease with which controls, including
intraloop dependencies, can be implemented and changed, without any impact.
on hardware.

Computer Control

8

Chap. 1

Distributed Control
'The microprocessor has also had a profound impact on the way computers were
applied to control entire production plants. It became economically feasible to
develop systems consisting of several interacting microcomputers sharing the
overall workload. Such systems generally consist of process stations, controlling
the process; operator stations, where process operators monitor activities; and
various auxiliary stations, for example, for system configuration and programming, data storage, and so on, all interacting by means of some kind of communications network. The allure was to boost performance by facilitating parallel
multitasking, to improve overall availahility by not putting Hall the eggs in one
basket," to further expandability and to reduce the amount of control cabling.
The first system of this kind to see the light of day was Honeywell's TDC 2000
(the year was 1975), but it was soon followed by others. The term "distributed
control" was coined. The first systems were oriented toward regulatory control,
but over the years distributed control systems have adopted more and more of
the capabilities of programmable (logic) controllers, making today's distributed
control systems able to control all aspects of production and enabling operators
to monitor and control activities from a single computer console.

Plantwide Supervision and Control
The next development phase in industrial process-control systems was facilitated by the emergence of common standards in computing, making it possible
to integrate virtually all computers and computer systems in industrial plants
into a monolithic whole to achieve real-time exchange of data across what used
to he closed system borders. Such interaction enables
• top managers to investigate all aspects of operations
• production managers to plan and schedule production on the basis of current information
• order handlers and liaison officers to provide instant and current information to inquiring customers
• process operators to look up the cost accounts and the quality records of
the previous production run to do better next time
all from the computer screens in front of them, all in real time. An example of
such a system is shown in Fig. 1.3. ABB's Advant OCS (open control system)
seems to be a good exponent of this phase. It consists of process controllers with
local and/or remote I/O, operator stations, information management stations,
and engineering stations that are interconnected by high-speed communications buses at the field, process-sectional, and plantwide levels. By supporting
industry standards in computing such as Unix, Windows, and SQL, it makes
interfacing with the surrounding world of computers easy. The system features
a real-time process database that is distributed among the process controllers
of the system to avoid redundancy in data storage, data inconsistency, and to

.... - - .. ,..

,..",

....

. Jrr. _

_

---'0

T __ L. __ 1-. _ .

Plant

mana er

financIal
manager

Purchaser

Computer Control

10

Chap. 1

Information-Handling Capabi Iities
Advant Des offers basic ready-to-use information management functions such
as historical data storage and playback, a versatile report generator, and a
supplementary calculation package. It also offers open interfaces to third-party
applications and to other computers in the plant. The historical data-storage
and -retrieval service enables users to collect data from any system station at
specified intervals, on command or on occurrence of specified events, performs
a wide range of calculations on this data, and stores the results in so-called
logs. Such logs can be accessed for presentation on any operator station or
be used by applications on information stations or on external stations for a
wide range of purposes. A report generator makes it possible to collect data for
reports from the process datahase, from other reports, or the historical database.
Output can be generated at specified times, un occurrence of specified events,
or on request by an operator or software application. Unix- or Windows-based
application programming interfaces offer a wide range of system services that
give programmers a head start and safeguard engineering quality. Applications
developed on this basis can be installed on the information management stations
of the system, that is, close enough to the process to offer real-time performance.

The Future
Based on the dramatic developments in the past, it is tempting to speculate
about the future. There are four areas that are important for the development
of computer process control.
• Process knowledge
• Measurement technology
• Computer technology
• Control theory
Knowledge about process control and process dynamics is increasing slowly but
steadily. The possibilities of learning about process characteristics are increasing substantially with the installation of process-control systems because it is
then easy to collect data, perform experiments, and analyze the results. Progress
in system identification and data analysis has also provided valuable information.
Progress in measurement technology is hard to predict. Many things can be
done using existing techniques. The possibility of combining outputs of several
different sensors with mathematical models is interesting. It is also possible to
obtain automatic calibration with a computer. The advent of new sensors will,
however, always offer new possibilities.
Spectacular- developments are expected in computer technology with the
introduction of VLSI. The ratio of price to performance will continue to drop
substantially. The future microcomputers are expected to have computing power
greater than the large mainframes of today. Substantial improvements are also
expected in display techniques and in communications.

Sec. 1.3

11

Computer-Control Theory

Programming has so far been one of the bottlenecks. There were only
marginal improvements in productivity in programming from 1950 to 1970. At
the end of the 1970s, many computer-controlled systems were still programmed
in assembler code. In the computer-control field, it has been customary to overcome some of the programming problems by providing table-driven software.
A user of a DDC, system is thus provided with a so-called DDC package that
allows the user to generate a DDC system simply by filling in a table, so very
little effort is needed to generate a system. The widespread use of packages
but it is a
hampers development, however, because it is very easy to use
major effort to do something else. So only the well-proven methods are tried.
Control theory has made substantial progress since 1955. Only some ofthis
theory, however, has made its way into existing computer-controlled systems,
even though feasibility studies have indicated that significant improvements
can be made. Model predictive control and adaptive control are some of the theoretical areas that are being applied in the industry today. To use these theories,
it is necessary to fully understand the basic concepts of computer control. One
reason for not using more complex digital controllers is the cost of programming. As already mentioned, it requires little effort to use a package provided
by a vendor. It is, however, a major effort to try to do something else. Several
signs show that this situation can he expected to change. Personal computers
with interactive high-level languages are starting to be used for process controL
With an interactive language, it is very easy to try new things. It is, however,
unfortunately very difficult to write safe real-time control systems. This will
change as hetter interactive systems hecome available.
Thus, there are many signs that point to interesting developments in the
field of computer-controlled systems. A good way to be prepared is to learn the
theory presented in this book.

nne,

1.3 Computer-Control Theory
Using computers to implement controllers has substantial advantages. Many of
the difficulties with analog implementation can be avoided. For example, there
are no problems with accuracy or drift of the components. It is very easy to
have sophisticated calculations in the control law, and it is easy to include logic
and nonlinear functions. Tahles can be used to store data in order to accumulate
knowledge about the properties of the system. It is also possible to bave effective
user interfaces.
A schematic diagram of a computer-controlled system is shown in Fig. 1.1.
The system contains essentially five parts: the process, the A-D and D·A converters, the control algorithm, and the clock. Its operation is controlled by the
clock. The times when the measured signals are converted to digital form are
called the sampling instants; the time between successive samplings is called
the sampling period and is denoted by h. Periodic sampling is normally used,
but there are, of course, many other possibilities. For example, it is possible to
sample when the output signals have changed by a certain amount. It is also

12

Chap. 1

Computer Control

possible to use different sampling periods for different loops in a system. This
is called multirate sampling.
In this section we will give examples that illustrate the differences and the
similarities of analog and computer-controlled systems. It will be shown that
essential new phenomena that require theoretical attention do indeed occur.

Time Dependence
The presence of the the clock in Fig. 1.1 makes computer-controlled systems
time-varying. Such systems can exhibit behavior that does not occur in linear
time-invariant systems.

Example 1.1 Time dependence in digital filtering
A digital filter iR a simple example of a computer-controlled system. Suppose that
we want to implement 8 compensator that is simply a first-order lag. Such a compensator can be implemented using A-D conversion, a digital computer, and D-A
(a)

--u

A-D

y~

D-A

Computer

t

t
Clock

r-----~-~-~

1

I
I

I
O~I-----------J

o

1

10

.................

,..-----~

0...-............_------.-.1
o
10
Time

o
o

~1I"_1I----~~............J

1

10

...........,.

r-----~

O.........~~------..l

o

10
Time

Figure 1.4 (a) Block diagram of a digital filter. (b] Step responses (dots)

of a digital computer implementation of a first-order lag for different delays
in the input step (dashed) compared with the first sampling instant. For
comparison the response of the corresponding continuous-time system (solid)
is also shown.

Sec. 1.3

13

Computer-Control Theory

conversion. The first-order differential equation is approximated by a first-order
difference equation. The step response of such a system is shown in Fig. 1.4. Tho
figure clearly shows that the sampled system is not time-invariant because the
response depends on the time when the step occurs. If the input is delayed, then
the output is delayed by the same amount only if the delay is a multiple of the
_
sampling period.

The phenomenon illustrated in Fig. 1.4 depends on the fact that the system is
controlled by a clock (compare with Fig. 1.1). The response of the system to an
external stimulus will then depend on how the external event is synchronized
with the internal clock of the computer system.
Because sampling is often periodic, computer-controlled systems will often
result in closed-loop systems that are linear periodic systems. The phenomenon
shown in Fig. 1.4 is typical for such systems. Later we will illustrate other
consequences of periodic sampling.

ANaive Approach to Compuler-ControUed Systems
We may expect that a computer-controlled system behaves as a continuoustime system if the sampling period is sufficiently small. This is true under very
reasonable assumptions. We will illustrate this with an example.
Example 1.2 Controlling the ann of a disk drive
A schematic diagram of a disk-drive assembly is shown in Fig. Hi. Let J be the
moment of inertia of the arm assembly. The dynamics relating the position y of
the arm to the voltage u of the drive amplifier is approximately described by the
transfer function
G(s)

k

= J s2

(1.1}

where k is a constant. The purpose of the control system is to control the position of the arm so that the head follows a given track and that it ran be rapidly
moved to a different track. It is easy to find the benefits ofimproved control. Better
trackkeeping allows narrower tracks and higher packing density. A faster control
system reduces the search Lime. In this example We will focus on the search problem, which is a typical servo problem. Let U,o be the command signal and denote
Laplace transforms with capital letters. A simple servo controller can be described
by

(1.2)

U. C

II

Controller "------ Amplifier
r-----

Arm

Y
,......,.........

Figure 1.5 A system for controlling the position of the arm of a disk drive.

Computer Control

14

...

."

1

"

Chap. 1

...

;:l

0..
....
;J

0

0

0

10

5

0.5

1

.....
;:l

0

0.

~
o-t

-0 .5
0

5
Time (w
ot)

10

Figure 1.6 Simulation of the disk arm servo with analog (dashed) and
computer control (solid). The sampling period is h .: O.2/lIJo.

This controller is a two-degree-of-freedom controller where the feedback from the
measured signal is simply a lead-lag filter. If the controller parameters are chosen
as

a "" 2wo
b := wo/2

K = 2 J(f)~

.. k
a closed system with the characteristic polynomial

is obtained. This system has a reasonable behavior with a settling time to 5% of
5.52/wo. See Fig. 1.6. To obtain an algorithm for a computer-controlled system, the
control law given by (1.2) is first written as

bK
a
U(s} := - - U, (s) - KY(s) + K - - b Y(s) "" K (b Uc{s) - Y(s) + X(s) )
a
s+a
a
This control law can be written as

I~\t) = K (~Uf{t) dx
dt

y(t)+X(t))

(1.3)

= -ax + (a - b}y

To obtain an algorithm fora control computer, the derivative dxldt is approximated
with a difference. This gives

x(t + h) - x(t)

h

= - ax(t) + (0 - b)y(t)

Sec. 1.3

15

Computer-Control Theory

Clock

Algorithm

Figure 1.7 Scheduling a computer program.

The following approximation ofthe continuous algorithm (1.3) is then obtained:

u(t~) = K (~UC[tk) -

y(tk) + x{t/:))

(lA)

x(t~ + h) ;; X(tk) + h( (a - b)y(t/r) - ax(tk))
This control law should be executed at each sampling instant. This can be accomplished with the following computer program.
y: ~ adin(in2)
u:=K*(a/b*uc-y+x).

{read process value}

dout (u)

{output control signal}

newx;~x+h.(a-b)*y-a*x)

Ann position y is read from an analog input. Its desired value u; is assumed to he
given digitally. The algorithm has one state, variable .I, which is updated at each
sampling instant. The control law is computed and the value is converted to an
analog signal. The program is executed periodically with period h by a scheduling
program, as illustrated in Fig. 1.7. Because the approximation of the derivative by
a difference is good if the interval h is small, we can expect the behavior of the
computer-controlled system to be close to the continuous-time system, This is illustrated in Fig. 1.6, which shows the ann positions and the control signals for the
systems with h ;:;- 0.2/ wo . Notice that the control signal for the computer-controlled
system is constant between the sampling instants. Also notice that the difference
between the outputs ofthe systems is very small. The computer-controlled system
has slightly higher overshoot and the settling time to 5% is a little longer, 5.7/0)0
instead of5.5( l/}o- Thedifference hetween the systems decreases when the sampling
period decreases. When the sampling period increases the computer-controlled systern will, however, deteriorate. This is illustrated in Fig. l.B, which shows the behavior of the system for the sampling periods h = 0.5/0)0 and h = lOB/We.. The
response is quite reasonable for short sampling periods, but the system becomes
unstable for long sampling periods.
I

We have thus shown that it is straightforward to obtain an algorithm for computer control simply by writing the continuous-time control law as a differential
equation and approximating the derivatives by differences. The example indi-

Computer Control

16

Chap. 1

tb)

(a)

10

0.5

0.5

o

o
-0.5

- 0.5 ~---~-~---'-'

'-----~

o

5
10
Time (wo!;)

15

o

15

Figure 1.8 Simulation of the disk arm servo with computer control having
sampling rates (a ) h = O.5/wo and (b) h ~ l.OB/wo. For comparison, the
signals for analog control are shown with dashed lines.

cated that the procedure seemed to work well if the sampling period was sufficiently small. The overshoot and the settling time are, however, a little larger for
the computer-controlled system. This approach to design ofcomputer-controlled
systems will be discussed fully in the following chapters.

Deadbeat Control
Example 1.2 seems to indicate that a computer-controlled systemwill be inferior
to a continuous-time example. We will now show that this is not necessarily the
case. The periodic nature of the control actions can be actually used to obtain
control strategies with superior performance.
Example 1.3 Disk drive with deadbeat control
Consider the disk drive in the previous example. Figure 1.9 shows the behavior of
a computer-controlled system with a very long sampling interval h = l.4/wo. For
comparison we have also shown the arm position, its velocity, and the control signal
for the continuous controller used in Example 1.2. Notice the excellent behavior of
the computer-controlled system. It settles much quicker than the continuous-time
system even if control signals of the same magnitude are used. The 5%settling time

is 2.34/wo, which is much shorter than the settling time 5.5/wo of the continuous
system. The output also reaches the desired position without overshoot and it

remains constant when it has achieved its desired value, which happens in finite
time. This behavior cannot be obtained with continuous-time systems because the
solutions to such systems are sums of functions that are products of polynomials
and exponential functions. The behavior obtained can be also described in the
following way: The ann aecelerates with constant acceleration until is is halfway to
the desired position and it then decelerates with constant retardation. The control

1 .. . . - . - ...... - .

c
0
.....

~

.~

/

rtJ

a

//

~

0

.0
....

17

Computer-Control Theory

Sec. 1.3

/

"

... ".

-- - -

0

-

10

5

0.5

(,,)

o
.....

~

--- - --- ....

o
o
0.5 ....

-0.5

o

to

5

"

"" r-

..... .....

-

--

-

--

10

Figure 1.9 Simulation of the disk arm servo with deadbeat control (solid).
The sampling period is h == L4/Wij. The analog controller from Example 1.2
is also shown (dashed).
strategy used has the same farm as the control strategy in Example 1.2, that is,

The parameter values are different. When controlling the disk drive, the system can
be implemented in such a way that sampling is initiated when the command signal
is changed . In this way it is possible to avoid the extra time delay that occurs due
to the lack of synchronization of sampling and command signal changes illustrated
in Fig. 1.4.
•

The example shows that control strategies with different behavior can be obtained with computer control. In the particular example the response time can
be reduced by a factor 0£2. The control strategy in Example 1.3 is called deadbeat control because the system is at rest when the desired position is reached.
Such a control scheme cannot he obtained with a continuous-time controller.
Aliasing

One property of the time-varying nature of computer-controlled systems was
illustrated in Fig. 1.4. We will now illustrate another property that has farreaching consequences. Stable linear time-invariant systems have the property

Chap. 1

Computer Control

18
(b)

(a)

.....

....

0.2

:l

.fr
~

f-----------i

0

o

0.2

.fr

0

:::I

~

c
-0.2

-0.2

o

....
;;

10

20

.....

o

10

20

:::I

~ 0.2

,fr 0.2
;:;
e

~

al

a

~

-0.2

o

0

I-<
~
'JJ

:l
rI:i

~

~

-0.2

~

L -_ _~ ~_ _~_---J

o

10

20

o

10

20

o

10
Time

20

o

10

20

Time

Figure 1.10 Simulation of the disk ann servo with analog and computer
control. The frequency (rJo is 1, the sampling period is h ::: 0.5, and there
is a. measurement noise n ::: 0.1 sin 12t. (a) Continuous-time system; (b)
sampled-data system.

that the steady-state response to sinusoidal excitations is sinusoidal with the
frequency of the excitation signal. It will be shown that computer-controlled
systems behave in a much marc complicated way because sampling will create
signals with new frequencies. This can drastically deteriorate performance if
proper precautions are not taken.
Example 1.4 Sampling creates new frequencies

Consider the systems for control of the disk drive arm discussed in Example 1.2.
Assume that the frequency Wo IS 1 rad/s, let the sampling period be h = 0.5/(lJo.
and assume that there is a sinusoidal measurement noise with amplitude 0.1 and
frequency 12 rad/s . Figure 1.10 shows interesting varia.bles for the continuous-time
system and the computer-controlled system. There is clearly a drastic difference
between the systems. For the continuous-time system, the measurement noise has
very little influence on the arm position. It does. however, create substantial control action with the frequency of the measurement noise. The high-frequency measurement noise is not noticeable in the control signal for the computer-controlled
system, but there is also a substantial low-frequency component.
To understand what happens, we can consider Fig. 1.11, which shows the
control signal and the measured signal on an expanded scale. The figure shows

19

Computer-Control Theory

Sec. 1.3

....
:l
fr 0.2
;:l
o

1l

0

:l
""'
UJ

~

-0.2

l--

~

--'-

o

---'

5

10

5

10

0.2

-0.2

o

Time

Figure 1.11 Simulation of the disk arm servo with computer control. The
frequency Wo is 1, the sampling period is h = 0.5, and there is a measurement
noise n = O.lsin 12t.

that there is a considerable variation of the measured signal over the sampling
period and the low-frequency variation is obtained hy sampling the high-frequency
signal at a slow rate .
_

We have thus made the striking observation that sampling creates signals with
new frequencies, This is clearly a phenomenon that we must understand in
order to deal with computer-controlled systems. At this stage we do not wish
to go into the details of the theory; let it suffice to mention that sampling of a
signal with frequency co creates signal components with frequencies
W~ampled

= no, ± (J)

(1.6)

where (J). ::: 2Tr j h is the sampling frequency, and n is an arbitrary integer.
Sampling thus creates new frequencies . This is further discussed in Sec. 7.4.
In the particular example we have to, = 4Jr ;:: 12.57, and the measurement
signal has the frequency 12 rad/s. In this case we find that sampling creates a
signal component with the frequency 0.57 rad/s. The period ofthis signal is thus
11 s. This is the low-frequency component that is clearly visihle in Fig. 1.11.
Example 1.4 illustrated that lowerfrequencies can be created hy sampling.
It follows from (1.6) that sampling also can givefrequencies that are higher than
the excitation frequency. This is illustrated in the following example.
Example 1.5 Creation of higher frequencies hy sampling
Figure 1.12 shows what can happen when a sinusoidal signal of frequency 4.9 Hz
is applied to the system in Example 1.1, which has a sampling period of 10 Hz. It
follows from Eq, (1.6) that a signal component with frequency 5.1 Hz is created by
sampling. This signal interacts with the original signal with frequency 4.9 Hz to

give the beating of 0.1 Hz shown in the figure,

_

Computer Control

20
(u)

Chap. 1

1

....,
:l
0.
~

0

H

-1
(b ) ....
::l

0
1

5

10

5

10

Ii

10

0.
....
;:I
0

-0
e
Q.
~

u:
(c)

-1

0

1
+-'

::l

0.
.....,
;:l
0

...;

0

s::;

0

o
-1

0

Time
Figure 1.12 Sinusoidal excitation of the sampled system in Example 1.5.

(a) Input sinusoidal with frequency 4.9 Hz. (b) Sampled-system output. The
sampling period is 0.1 s. (c) Output of the corresponding continuous-time
system.

There are many aspects of sampled systems that indeed can be understood by
linear time-invariant theory. The examples given indicate, however, that the
sampled systems cannot be fully understood within that framework. It is thus
useful to have other tools for analysis.
The phenomenon that the sampling process creates new frequency components is called aliasing. A consequence of Eq. (1.6) is that there will be lowfrequency components created whenever the sampled signal contains frequencies that are larger than half the sampling frequency. The frequency {/)N = {()s/2
is called the Nyquist frequency and is an important parameter of a sampled system.

Presampling Filters or Antialiasing Filters
To avoid the difficulties illustrated in Fig. 1.10,it is essential that all signal components with frequencies higher than the Nyquist frequency are removed before
a signal is sampled. By doing this the signals sampled will not change much
over a sampling interval and the difficulties illustrated in the previous examples are avoided. The filters that reduce the high-frequency components of the

Sec. 1.3

21

Oornputer-Control Theory

signals are called antialiasing filters. These filters are an important component
of computer-controlled systems. The proper selection of sampling periods and
antialiasing filters are important aspects of the design of computer-controlled
systems .

Difference Equations
Although a computer-controlled system may have a quite complex behavior, it
is very easy to describe the behavior ofthe system at the sampling instants. We
will illustrate this by analyzing the disk drive with a deadbeat controller.
Example 1.6 Difference equations

The input-output properties of the process Eq. (1.1) can be described by

This equation is exact if the control signal is constant over the sampling intervals.
The deadbeat control strategy is given by Eq. (1.5) and the closed-loop system thus
can be described by the equations.
:l'(t. ) -

2)'(t~-d + y(t"-2) ~ a (Il(tk-.) + ll(t.._Z))
u(t~_d

+ rl u(tk -2) = t{)Uc(t~-l) -

(1.8)

soy(tk ~Il- sl)'(fk-2)

where a ; ; : kh2 /2J. Elimination of the control signal u between these equations
gives

The parameters of the deadbeat controller are given by
0.75
1.25

rl

.=.

So

==

81

= -a
-

a

=

0.75

2.5J
khz
1.5J
=-2

kh

1
1
;;;;: 4a
2

to;;;;;: -

With these parameters the closed-loop system becomes

It follows from this equation that the output is the average value of the past two
values of the command signal. Compare with Fig. 1.9.
•

22

Computer Control

Chap. 1

The example illustrates that the behavior of the computer-controlled system at
the sampling instants is described by a linear difference equation. This observation is true for general linear systems. Difference equations, therefore, will
he a key element of the theory of computer-controlled systems, they play the
same role as differential equations for continuous systems, and they will give
the values of the important system variables at the sampling instants. If we
are satisfied by this knowledge, it is possible to develop a simple theory for
analysis and design of sampled systems. To have a more complete knowledge
of the behavior of the systems, we must also analyse the behavior between the
sampling instants and make sure that the system variables do not change too
much over a sampling period.

Is There a Need for a Theory for Computer"ControUed Systems?
The examples in this section have demonstrated that computer-controlled systems can be designed simply by using continuous-time theory and approximating the differential equations describing the controllers bydifference equations.
The examples also have shown that computer-controlled systems have the potential of givingcontrol schemes, such as the deadbeat strategy, with behaviorthat
cannot he obtained by continuous-time systems. It also has been demonstrated
that sampling can create phenomenathat are not found in linear time-invariant
systems. It also has heen demonstrated that the selection of the sampling period is important and that it is necessary to use antialiasing filters. These issues
clearly indicate the need for a theory for computer-controlled systems.

1.4 Inherently Sampled Systems
Sampled models are natural descriptions for many phenomena. The theory of
sampled-data systems, therefore, has many applicationsoutside the field ofcomputer control.

Sampling due to the Measurement System
In many cases, sampling will occur naturally in connection with the measurement procedure. A few examples follow.
Example 1.7 Radar
When a radar antenna rotates, information about range and direction is naturally
obtained once per revolution of the antenna. A sampled model is thus the natural
way to describe a radar system. Attempts to describe radar systems were, in fact,
one of the starting points of the theory of sampled systems.
•
Example 1.8 Analytical instruments
In process-control systems, there are many variables that cannot be measured online, so a sample of the product is analyzed off
-line in an analytical instrument
such as a mass spectrograph or a chromatograph.
I

Sec. 1.4

Inherently Sampled Systems

23

Figure 1.13 Thyristor control circuit.
Example 1.9 Economic systems
Accounting procedures in economic systems are often tied to the calendar. Although
transactions may occur at any time, information about important variables is accumulated only at certain times-for example, daily, weekly, monthly, quarterly, or
yearl~

_

Example 1.10 Magnetic Bow meters

A magnetic flow meter is based on the principle that current that moves in a.
magnetic field generates a voltage. In a typical meter a magnetic field is generated
across the pipe and the voltage is measured in a direction orthogonal to the field.
To compensate for electrolytic voltages that often are present, it is common to
use a pulsed operation in which the field is switched on and off periodically. This
switching causes an inherent sampling.
_

Sampling due to Pulsed Operation
Many systems are inherently sampled because information is transmitted using
pulsed information. Electronic circuits are a prototype example. They were also
one source of inspiration for the development of sampled-data theory. Other
examples follow.
Example 1.11 Thyristor control
Power electronics using thyristors are sampled systems. Consider the circuit in
Fig. 1.13. The current can be switched on only when the voltage is positive. When
the current is switched on, it remains on until the current has a zero crossing. The
current is thus synchronised to the periodicity of the power supply. The variation
of the ingition time will cause the sampling period to vary, which must be taken
care of when making models for thyristor circuits.
_

Example 1.12 Biological systems
Biological systems are fundamentally sampled because the signal transmission in

the nervous system is in the form of pulses.

•

Ex:ample 1.13 Intemal-combustion engines

An internal-combustion engine is a sampled system. The ignition can be viewed as
clock that synchronizes the operation of the engine. A torque pulse is generated
at each ignition.
_

8.

24

Computer Control

Chap. 1

Injector

D·A I~---t Processing

I.....~

A.D

'-----------4l----------ilI--f =10 MHz
Figure 1.14 Particle accelerator with stochastic cooling.

Example 1.14 Particle accelerators
Particle accelerators are the key experimental tool in particle physics. The Dutch
engineer Simnon van der Meer made a major improvement in accelerators by
introducing feedback te control particle paths, which made it possible to increase
the beam intensity and to improve the beam quality substantially. The method,
which is called stochastic cooling, was a key factor in the successful experiments
at CERN. As a result van der Meer shared the 1984 Nobel Prize in Physics with
Carlo Rubbia.
A schematic diagram ofthe system is shown in Fig. 1.14. The particles enter
into a circular orbit via the injector. The particles are picked up by a detector at a
fixed position and the energy of the particles is increased by the kicker, which is
located at a fixed position. The system is inherently sampled because the particles
are only observed when they pass the detector and control only acts when they
pass the kicker.
From the point ofview ofsampled systems, it is interesting to observe that
there is inherent sampling both in sensing and actuation.
_
The systems in these examples are periodic because of their pulsed operation.
Periodic systems are quite difficult to handle, hut they can be considerably
simplified by studying the systems at instants synchronized with the pulsesthat is, by using sampled-data models . The processes then can he described as
time-invariant discrete-time systems at the sampling instants. Examples 1.11
and L13 are of this type,

Sec. 1.5

How Theory Developed

25

1.5 How Theory Developed
Although the major applicationsofthe theory of sampledsystems are currently
in computer control, many of the problems were encountered earlier. In this
section some of the main ideas in the development of the theory are discussed.
Many of the ideas are extensions of the ideas for continuous-time systems.

The Sampling Theorem
Because all computer-controlled systems operate on values of the process variables at discrete times only, it is very important to know the conditions under
which a signal can be recovered from its values in discrete points only. The
key issue was explored by Nyquist, who showed that to recover 8 sinusoidal
signal from its samples, it is necessary to sample at least twice per period. A
complete solution was given in an important work by Shannon in 1949. This is
very fundamental for the understanding of some of the phenomena occuring in
discrete-time systems.
Difference Equations

The first germs of a theory for sampled systems appeared in connection with
analyses ofspecific control systems.The behaviorofthe chopper-bar galvanometer, investigated in Oldenburg and Sartorius (1948), was oneof the earliest contributions to the theory. It was shown that many properties could be understood
by analyzing a linear time-invariant difference equation. The difference equation replaced the differential equations in continuous-time theory. For example,
stability could be investigated by the Schur-Cohn method, which is equivalent
to the Routh-Hurwitz criterion,
I

Numerical Analysis
The theory of sampled-data analysis is closely related to numerical analysis.
Integrals are evaluated numerically by approximating them with sums. Many
optimization problems can be described in terms of difference equations. Ordinary differential equations are integrated by approximating them by difference
equations. For instance, step-length adjustment in integration routines can be
regarded as a sampled-data control problem. A large body of theory is availablethat is related to computer-controlled systems. Difference equations are an
important element of this theory, too.

Transform Methods
During and after World War II, a lot of activity was devoted to analysis of
radar systems. These systems are naturally sampled because a position measurement is obtained once per antenna revolution. One prohlem was to find
ways to describe these new systems, Because transform theory had been so
useful for continuous-time systems, it was natural to try to develop a similar

Computer Control

26

Chap. 1

theory for sampled systems. The first steps in this direction were taken by
Hurewiez (1947). He introduced the transform of a sequence f(kh), defined by

Z{f(kh)} :; Lz-kf(kh)
k",O

This transform is similar to the generating function, which had been used so
successfully in many branches of applied mathematics. The transform was later
defined as the z-tronsform by Ragazzini and Zadeh (1952). Transform theory
was developed independently in the Soviet Union, in the United States, and in
Great Britain. Tsypkin (1949) and Tsypkin (1950) called the transform the discrete Laplace transform and developed a systematic theory for pulse-controlled
systems based on the transform. The transform method was also independently
developed by Barker (1952) in England.
In the United States the transform was further developed in a Ph.D. dissertation by Jury at Columbia University. Jury developed tools both for analysis
and design. He also showed that sampled systems could be better than their
continuous-time equivalents. (See Example 1.3 in Sec. 1.3.) Jury also emphasized that it was possible to obtain a closed-loop system that exactly achieved
steady state in finite time. In later works he also showed that sampling can
cause cancellation of poles and zeros. A closer investigation of this property
later gave rise to the notions of observability and reachability.
The a-transform theory leads to comparatively simple results. A limitation
of the theory, however, is that it tells what happens to the system only at the
sampling instants. The behavior between the sampling instants is not just an
academic question, because it was found that systemscould exhibi t hiddenoscillations . These oscillations are zero at the samplinginstants, but very noticeable
in between.
Another approach to the theory of sampled system was taken by Linvill
(1951). Following ideas due to MacColl (1945), he viewed the sampling as an
amplitude modulation. Using a describing-function approach, Linvill effectively
described intersample behavior. Yet another approach to the analysis of the
problem was the delayed z-transiorm, which was developed by Tsypkin in 1950,
Barker in 1951,and Jury in 1956. It is also known as the rrwdified z-transform.
Much of the development of the theory was done by a group at Columbia
University led by John Ragazzini. Jury, Kalman, Bertram, Zadeh, Franklin,
Friedland, Krane, Freeman, Sarachik, and Sklansky all did their Ph.D. work
for Ragazzini,
Toward the end of the 19508, the z-transform approach to sampled systems had matured, and several textbooks appeared almost simultaneously: Jury
(1958), Ragazziui and Franklin (1958), Tsypkin (1958), and 'Ibu (1959). This
theory, which was patterned after the theoryoflinear time-invariantcontinuoustime systems, gave good tools for analysis and synthesis of sampled systems. A
few modifications had to be made because ofthe time-varying nature ofsampled
systems. For example, all operations in a block-diagram representation do not
commute!

Sec. 1.5

HowTheory Developed

27

State-Space Theory
A very important event in the late 1950s was the development of state-space
theory. The major inspiration came from mathematics and the theory of ordinary
differential equations and from mathematicians such as Lefschetz, Pontryagin,
and Bellman. Kalman deserves major credit for the state-space approach to
control theory. He formulated many of the basic concepts and solved many of
the important problems.
Several of the fundamental concepts grew out of an analysis ofthe problem
ofwhether it would be pcssible to get systems in which the variables achieved
steady state in finite time. The analysis of this problem led to the notions of
reachability and obaervability.Kalman's work alsoled to a much simpler formulation of the analysis of sampled systems: The basic equations could be derived
simply by starting with the differential equations and integrating them under
the assumption that the control signal is constant over the sampling period. The
discrete-time representation is then obtained by only considering the system at
the sampling points. This leads to a very simple state-space representation of
sampled-data systems.

Optimal and Stochastic Control
There were also several other important developments in the late 1950s. Bellman (1957) and Pontryagin et al. (1962) showed that many design problems
could be formulated as optimizationproblems. For nonlinear systems this led to
nonclassical calculus of variations. An explicit solution was given for linear systerns with quadratic loss functions by Bellman, Glicksberg, and Gross (1958).
Kalman (1960a) showed in a celehrated paper that the linear quadratic problem
could be reduced to a solution of a Riccati equation. Kalman also showed that
the classical Wiener filtering problem could be reformulated in the state-space
framework. This permitted a "solution" in terms of recursive equations, which
were very well suited to computer calculation.
In the beginning of the 19605, a stochastic variational problem was formulated by assuming that disturbances were random processes. The optimal
control problem for linear systems could be formulated and solved for the case
of quadratic loss functions. This led to the development of stochastic control
theory. The work resulted in the so-called Linear Quadratic Gaussian (LQG)
theory, This is now a major design tool for multivariahle linear systems.

Algebraic System Theory
The fundamental problems of linear system theory were reconsidered at the
end of the 19608 and the beginningof the 1970s. The algebraic character (If the
problems was reestablished, which resulted in a better understanding of the
foundations of linear system theory. Techniques to solve specific problems using
polynomial methods were another result [see Kalman, Falb, and Arbib (1969),
Rosenhrock (1970), Wonham (1974), Kucera (1979, 1991), and Blomberg and
Ylinen (1983) I.

28

Computer Control

Chap. 1

System Identification
All techniques for analysis and design of control systemsare basedon the availability of appropriate models for process dynamics. The success of classical control theory that almost exclusively builds on Laplace transforms was largely
due to the fact that the transfer function of a process can be determined experimentally using frequency response. The development of digital control was
accompanied by a similar development of system identification methods. These
allow experimental determination of the pulse-transfer function or the difference equations that are the starting point of analysis and design of digital
control systems. Good sources of information on these techniques are Astrom
and Eykhoff (1971) , Norton (1986), Ljung (1987), Soderstrom and Stoica (1989),
and Johansson (1993 ).

Adaptive Control
When digital computers are used to implement a controller, it is possible to implement more complicated control algorithms. A natural step is to include both
parameter estimation methods and control design algorithms. In this way it is
possible to obtain adaptivecontrol algorithms that determine the mathematical
models and perform control system design on-line. Research on adaptive control
began in the mid-1950s. Significant progress was made in the 19708 when feasibility was demonstrated in industrial applications. The advent of the microprocessor made the algorithms cost-effective, and commercial adaptive regulators
appeared in the early 1980s. This has stimulated vigorous research on theoretical issues and significant product development. See, for instance, Astrom and
Wittenmark (1973, 1980, 1995), Astrom (1983b, 1987), and Goodwin and Sin
(1984).

Automatic Tuning
Controller parameters are often tuned manually. Experience has shown that it
is difficult to adjust more than two parameters manually. From the user point of
view it is therefore helpful to have tuning tools built into the controllers. Such
systems are similar to adaptive controllers. They are, however, easier to design
and use. With computer-based controllers it is easy to incorporate tuning tools.
Such systems also started to appear industrially in the mid-1980s. See Astrom
and Hagglund (1995).

1.6 Notes and References
To acquire mature knowledge about a field it is useful to know its history and
to read some of the original papers. Jury and Tsypkin (1971), and Jury (1980),
written by two of the originators of sampled-data theory, give a useful perspective. Early work on sampledsystems is found in MacCon (1945), Hurewicz

Sec. 1.6

Notes and Reierences

29

(1947), and Oldenburg and Sartorius (1948). The sampling theorem was given
in Kotelnikov (1933) and Shannon (1949).
Major contributions to the early theory of sampled-data systems were obtained in England by Lawden (1951) and Barker (1952); in the United States by
Linvill (1951), Ragazzini and Zadeh (1952), and Jury (1956); and in the Soviet
Union by Tsypkin (1949) and Tsypkin {1950).The first textbooks on sampleddata theory appeared toward the end of the 19508. They were Jury (1958),
Ragazzini and Franklin (1958), Tsypkin (1958), and 'Iou (1959). A large number of textbooks have appeared since then. Among the more common ones we
can mention Ackermann (1972, 1996), Kuo (1980), Franklin and Powell (1989),
and Isermann (1989. 1991).
The idea of formulating control problems in the state space also resulted
in a reformulation of sampled-data theory. Kalman (1961) is seminal.
Some fundamental references on optimal and stochastic control are Bellman (1957}, Bellman, Glicksberg, and Gross (1958), Kalman (1960a),Pontryagin et a1. (1962), and AstroID (1970). The algebraicsystem approach is discussed
in Kalman, Falb, and Arbib (1969), Rosenbrock (1970), Wonham (1974), Kucera
(1979, 1991, 1993), and Blomberg and Ylinen (1983).
System identificationis surveyed in Astrom and Eykhoff (1971), Ljung and
Soderstrom (1983), Norton (1986), Ljung (1987), SOderstrom and Stoiea (1989),
and Johansson (1993). Adaptive control is discussed in Bellman (1961),Astrom
and Wittenmark (1973, 1980, 1995), Astrom (1983b, 1987), Goodwin and Sin
(1984). Gupta (1986), and Astrom and Hagglund (1995).
A survey of distributed computer systems is found in Lucas (1986). In
Gustafsson, Lundh, and Soderlind (1988), it is shown how step-length control
in numerical integration can be regarded as a control problem. This is also
discussed in Hairor and Wanner (1991).
Many additional references are given in the following sections. We also
recommend the proceedings of the !FAC Symposia on Digital Computer Applications to Process Control and on Identificationand System Parameter Estimation, which are published by Pergamon Press.

2
Discrete-Time Systems
2.1 Introduction
Mathematical models for computer-controlled systems are introduced in this
chapter. Akey idea is to showhow a continuous-timesystem can be transformed
into a discrete-time system by considering the behavior of the signals at the
sampling instants.
In this chapter the system is studied as Been from the computer. The computer receives measurements from the process at discrete times and transmits
new control signals at discrete times. The goal then is to describe the change in
the signals from sample to sample and disregard the behavior between the samples. The use of difference equations then becomes a natural tool. It should be
emphasized that computer-oriented mathematical models onlygivethe behavior
at the sampling points-the physical process is still a continuous-time system.
Looking at the problem this way, however, will greatly simplify the treatment.
We will give formulas that allow a computation of inters ample behavior, but a
fun treatment of process-oriented models, which takes continuous-time behavior
into account, is given Chapter 7.
One point that must be treated with some caution is that the sampleddata system is time-varying (see Example 1.1). This problem is also discussed
in Chapter 7. In this chapter the problem of time variation is avoided by studying the signals at time instances that are synchronized with the clock in the
computer. This gives models described by difference equations in state-space
and input-output forms. Section 2.2 gives a description of the sampling mechanism. Section 2.3 treats the problem of finding the discrete-time representation
of a continuous-time state-space model by using zero-order-hold devices. The inverse problem offinding the continuous-time system that corresponds to a given
discrete-time system is also treated in Sec. 2.3. The general solution of forced
difference equations is given in Sec. 2.4. Sections 2.5 and 2.6 deal with transformation of state-space models and the connection between state-space and
input-output models. Shift operators are used to describe input-output mod-

in

30

Sec. 2.2

Sampling Continuous-Time Signals

31

els, Shift-operator calculus is equivalent to the use of differential operators for
continuous-time systems. The discrete-time equivalentofthe Laplace transform
is the a-transform, which is covered in Sec. 2.7.
The treatment of state-space models in Sec. 2.3 covers the multivariable
case. The discussion of input-output models is, however, restricted to singleinput-single-output systems. Extensions to the multivariable case are possible,
but are not used in this book because they require the mathematics of polynomial matrices.
In order to design computer-eontrolled systems, it is important to understand how poles and zeros of continuous-time and discrete-time models are
related. This is treated in Sec. 2.8. The selection ofsamplingperiod is discussed
in Sec. 2.9. Rules ofthumb based on the appearances oftransient responses are
given in terms of samples per rise time.

2.2 Sampling Continuous-Time Signals
According to dictionaries, sampling means "the act or process oftaking a small
part or quantity ofsomethingas a sample for testing or analysis."In the context
ofcontrol and communication, sampling means that a continuous-time signal is
replaced by a sequence of numbers, which represents the values ofthe signal at
certain times.
Sampling is a fundamental property of computer-controlled systems because ofthe discreta-time nature ofthe digital computer. Consider) for example,
the system shown in Fig. 1.1. The process variables are sampled in connection with the analogconversion and then converted to digital representation for
processing. The continuous-time signal that represents the process variables
is thus converted to a sequence of numbers, which is processed by the digital
computer. The processing gives a new sequence ofnumbers, which is converted
to a continuous-time signal and applied to the process. In the system shown in
Fig. 1.1, this is handled by the D·A converter. The process of converting a sequenceof numbers into a continuous-time signal is called signal reconstruction.
For the purposeofanalysis, it is useful to have a mathematicaldescription
of sampling. Sampling a continuous-time signal simply means to replace the
signal by its values in a discrete set ofpointe. Let Z be the positive and negative
integers Z -::;: {... •-1,0,1. ... } and let {th; : k E Z} be a subset of the real
numbers called the sampling instants. The sampled version of the signal f is
then the sequence (f(tk) : k E Z}. Sampling is a linear operation. The sampling
instants are often equally spaced in time, that is, tk :::: k .h. This case is called
periodic sampling and h is called the sampling period, or the sampling time.
The corresponding frequency fs .:= I/h (Hz) or to, = 2trlh (rad/s) is called the
sampling frequency. It is also convenient to introduce a notation for half the
samplingfrequency i» :;;: lj(2h) (Hz) or (J)N :::: Trlh (rad/s), which is called the
Nyquist frequency.
More complicated. sampling schemes can also be used. For instance, different sampling periods can be used for different control loops. This is called

32

Discrete-TIme Systems

Chap. 2

multirate sampling and can be considered to be the superposition of several
periodic sampling schemes.
The case of periodic sampling is well understood. Most theory is devoted
to this case, but systems with multirate sampling are becoming more important
because of the increased use of multiprocessor systems. With modem software
for concurrent processes, it is also possible to design a system as if it were
composed of many different processes running asynchronously. There are also
technical advantages in using different sampling rates for different variables.

2.3 Sampling a Continuous-Time State-Space System
A fundamental problem is how to describe a continuous-time system connected
to a computer via A-D and D-A converters. Consider the system shown in
Fig. 2.1. The signals in the computer are the sequences {U(tk)} and {y(ti)}'
The key problem is to find the relationship between these sequences. To find
the discrete-time equivalent of a continuous-time system is called sampling a
continuous-time system. The model obtained is also called a stroboscopic model
because it gives a relationship between the system variables at the sampling
instants only. To obtain the desired descriptions, it is necessary to describe the
converters and the system. Assume that the continuous-time system is given in
the following state-space form:

dx

dt :::: Ax(t) + Bu(t)

(2.1)

y(t) ::;: Cx(t) + Du(t)

The system has r inputs, p outputs, and is of order n.
Zero-Order-Hold Sampling of a System

A common situation in computer control is that the D-A converter is so constructed that it holds the analog signal constant until a new conversion is
commanded. This is often called a zero-order-hold circuit. It is then natural

Clock

{U(tk }}

~
D·A

I
utt )

y(t)

System

•

{y(t.. )}

A-D

Figure 2.1 Block diagram of a continuous-time system connected to A-D

and D-A converters.

Sec. 2.3

Sampling a Continuous-TIme State-Space System

33

to choose the sampling instants, [h, 3S the times when the control changes . Because the control signal is discontinuous , it is necessary to specify its behavior
at the discontinuities. The convention that the signal is continuous from the
right is adopted. The control signal is thus represented by the sampled signal
{tl (tk} : h = . . . , - 1,0, 1, ... }. The relationship between the system variahles at
the sampling instants will now be determined. Given the state at the sampling
time tk, the state at some future time t is obtained by solving (2.1). The state
at time t, where tk ~ t ~ thl> is thus given by

(2.2)

The second equality follows because u iii constant between the sampling instants.
The state vector at time t is thus a linear function of x(tJr ) and U(tk )' If
the A-D and D-A converters in Fig. 2.1 are perfectly synchronized and if the
conversion times are negligible, the input u and the output y can be regarded as
being sampled at the same instants. The system equation ofthe sampled system
at the sampling instants is then
X(tk.. d = £1>(tl/+l . tk)X(tk)

y(tl11

= CX(tk)

+ f(tktl. tk)U(th)

+ DU{tk)

(2.3)

where

The relationship between the sampled signals thus can be expressed by the
linear difference equation , (2.3). Notice that Equation (2.3) does not involve
any approximations. It gives the exact values of the state variables and the
output at the sampling instants because the control signal is constant between
the sampling instants. The model in (2.3) is therefore called a zero-order-bold
sampling of the system in (2.1). The system in (2.3) can also be called the
zero-order-hold equivalent of (2.1).
In most cases D = O. One reason for this is because in computer-controlled
systems, the output y is first measured and the control signal U(tk) is then
generated as a function of yUk). In practice it often happens that there is a
significant delay between the A·D and D-A conversions. However, it is easy to

Discrete-Time Systems

34

Chap,2

make the necessary modifications. The state vector at times between sampling
points is given by (2.2). This makes it possible to investigate the intersample
behavior ofthe system. Notice that the responses between the sampling points
are parts ofstep responses) with initial conditions, for the system. This implies
that the system is running in open loop between the sampling points.
For periodic sampling with period h, we have til = k · h and the model of
(2.3) simplifies to the time-invariant system
x(kh + h) = 4lx(kh) + fu(kh)
y(kh) = Cx(kh) + Du(kh)

(2.4)

where
<D

=eAh

r =!.A eA. dsB

(2.5)

It follows from (2.5) that
d<1>(t)
= A<1>(t)
dt
dr(t) = <D(t)B

= 4l(t)A

dt
The matrices <D and r therefore satisfy the equation

where I is a unit matrix ofthe same dimension as the number ofinputs. The
matrices 4l(h) and r(h) for the sampling period h therefore can he obtained
from the block matrix
(2.6)

How toCompute <!l and r
Thecalculations required tosample a continuous-time system are the evaluation
of a matrix exponential and the integration of a matrix exponential. Thesecan
be done in many different ways, for instance, by usingthe following:
• Numerical calculation in MATLAB@ or MATRIXX®
• Series expansion of the matrix exponential
• The Laplace transform-the Laplace transform of exp(At) is (81 - At!

Sec. 2.3

Sampling a Continuous·Time staie-space System

35

• Cayley-Hamilton's theorem (see Appendix B)
• Transformation to diagonal or Jordan forms
• Symbolic computer algebra, using programs such as Maple® and Mathematica®.
Calculations by hand are feasible for low-order systems, n :5 2, and for
high-order systems with special structures. One way to simplify the computations is to compute

The matrices <1> and r are given by

Computer evaluation can be done usingseveral different numerical algorithms
in MATLAB® or MATRIXX~'
Example 2.1 First·order &ystem

Consider the system
dx

dt ;;: ax+pu

with a -:F O. Applying Eqs. (2.5) we get
4> ::: eah

r::: 1/1 ea~ dsp :::: l!. (t lth -1)
a

o

The sampled system thus becomes

x(kh +h) = eQhx(kh) + ~ (e ah -l)u(kh)
a

Example 2.2 Double integrator
The double integrator (see Example A.I in Appendix A) is described by

dz

dt =

(0 0 x+ (0) u
1) 1
0

Y= (1 o)x

•

Chap. 2

Discrete-Time Systems

36
Hence

$

= eAIi = I + Ah + A2h 2(2 + ... =

(~ ~) + (~ ~) = (~ ~)

r~ l(~ldp [~]
'I'he discrete-time model of the double integrator is

!l

(~ ~ 1x(kh) + [

x(kh + h) -

y(kh) =

u(kh)

(2.7)

(1 0) x{kh)

•

Example 2.3 Motor
A simple normalized model of an electrical DC motor (see Example A.2 in Appendix A) is given by
dx
- = (-1
dt
1

y=(o

0) :r+ (1)
0
0

u

1):r

'I'he Laplace transform method gives

(sf _ At1 =

(S + 1 o
-1

s)

-lIS

0

;:: s(s + 1) (1 s + 1 )

_1
S +1

0]

= ( .1
!
s{s + 1) s

Hence

and

where £-1 is the inverse of the Laplace transform.

•

The Inverse ofSampling
Sampling a system defines a map from continuous-time systems, as in (2.1),
to discrete-time systems, as in {2.4). A natural question is if and when it is
possible to get the corresponding continuous-time system from a discrete-time
descri ption.

Sec. 2.3

Sampling a Continuous-Time State-Space System

37

Example 2.4 Inverse sampling
Consider the first-order difference equation
x(kh +h) = ax(kh) + bu(kh)

From Example 2.1 we find that the corresponding continuous-time system is obtained from

This gives
1
h
1
b
= -lna ' -

a = - ina

,8

h

a~l

This example shows that a continuous-time systemwith teal coefficients is obtained

only when a is positive.

•

1b investigate the process ofsampling in the general case we note that it follows
from (2.6) that
[

A

B) =! In [<I>

o a

r)

hOI

where In (.) is the matrix logarithmic function. The continuous-time system
is thus obtained by taking the matrix logarithm function of a block matrix.
Computation ofmatrix logarithm is discussed in Appendix B. From the CayleyHamilton theorem it must he assumed that the logarithm exists only when the
matrix <I> does not have any eigenvalues on the negative real axis. There is also
a nonuniqueness in the matrix logarithmic function for complex arguments
which is illustrated by the following example.
I

Example 2.5 Harmonic oscillator
The discrete-time system
x(kh +h) :::: (

CO~ ah Sinah) x(kh) + ( 1-. cos ah ) u(kh)
-smah cosah
smah

can be obtained by sampling a continuous-time system with

where
2Jr

w == a + h . n

n = 0, 1,,..

In this case the inverse problem has many solutions (compare Examples A.3 and
B.l). This is generally the case if the matrix <I> has complex eigenvalues. Notice that
there always exists a unique (JJ in the interval -(tJN $ (l) ~ (tJN, where WN =: fr(h

is the Nyquist frequency associated with the sampling period h.

•

Discrete-Time Systems

38

Chap. 2

Sampling a System with Time Detay
Time delays are common in mathematical models of industrial processes. The
theory of continuous-time systems with time delays is complicated because the
systems are infinite-dimensional.
It is, however, easy to samplesystems with time delays becausethe control
signal is constant between sampling instants, which makes the sampled-data
system finite-dimensional. Let the system he described by
dx(t)

dt

:;=

(2.8)

Ax(t) + Bu(t - r)

It is assumed initially that the time delay r is less than or equalto the sampling
period. The zero-order-hold samplingof the system (2.8) will now be calculated.
Integration of (2.8) over one sampling period gives

x(kh + h)

=eAhx(kh ) +

l

Jr. h+1t

eA(lth+h-5~Bu(8' -

r)ds'

(2.9)

kh

Because the signal u (t) is piecewise constant over the samplinginterval, the delayedsignal u(t - r) is also piecewise constant. The delayed signal will, however,
change between the sampling instants (see Fig. 2.2). Th evaluate the integral
of (2.9), it is then convenient to split the integration interval into two parts 50

u(t)

•

,

..

j

I
I

I
I

I
I
;

t

I

I
I
I
I

t

I

Delayed

:~

signal

I

I

I

f

f

I
I
I
I
I
I
I

r

kh-h

•

•

•
•

f

I
I

I
I

t

kh

kh+h

kh+2h

t

Figure 2.2 The relationship among u(t), the delayed signal u(t - r), and
the sampling instants.

39

Sampling a Continuous-Time State-Space System

Sec. 2.3

that u(t - r) is constant in each part. Hence
kh+h

l

eA(hh+h-s~ Bu(st -

-r) dsr

kh

=

l

kh+r

eA(kk+h-si

B ds' u(kh - h) +

kh

lkh+h A
e (ilh+h- s1B ds'
kh+f

u(kh)

= r1u(kh - h) + rou(kh)
Sampling the continuous-time system (2.8) thus gives

x(kh + h) ~ 4>x(kh) + rou(kh) + rlu(kh - h)

(2.10)

where

J.'-' eA'ds B
r, :;:;:
J.1 e ds B

fa =

(2.11)

As

eA(h-r )

A state-space model of (2.10) is given by
(

X + h) ) :::: (<I>
(kh
u(kh}
0

r

1)

0

(

X(kh))
u(kh -h)

(r
+ I

o ) u(kh)

Notice that r extra state variables u(kh ~ h)) which represent the past values
of the control signal, are introduced. The continuous-time system of (2.8) is
infinite dimensional; the corresponding sampled system, however, is a finitedimensional system. Thus time delays are considerably simpler to handle if the
system is sampled, for the following reason: 'Ib specify the state of the system.
it is necessary to store the input over a time interval equal to the time delay.
With zero-order-hold reconstruction, the input signal can be represented always
by a finite number of values.

Example 2.6 First-order system with time delay
Consider the system
dx(t}

Cit = ax(t) +fJu(t -1)
with C/ ¥= O Assume that the system is sampled with period h. where 0 ::;
.
Equation (2.11) gives

t

S; h.

Chap. 2

Discrete-Time Systems

40
The sampled system is thus

x(kh + h) = ax(kh) + bou(kh) + b1u(kh - h)

•

Example 2.7 Double integrator with delay
The double integrator in Example 2.2 with a time delay 0 S r :5 h gives

•
Longer Time Delays
If the time delay is longer than h, then the previous analysis has to be modified
a little. If
r ~ (d -l)h + t'

0 < t' :5 h

where d is an integer, the following equation is obtained:

x(kh + h) ;:: ¢lx(kh) + fou(kh - (d -l),h) + rlu(kh - dh)
where To and I'i are given by (2.11) with t replaced by t'. The corresponding
state-space description is

x(kh + h)
u(kh - (d -l)h)

¢l

f

0

0

l

rl}

0

x(kh)

0

I

0

u(kh-dh)

0

+

u(kh - h)
u{kh)

0
0

0
0

0
0

I
0

ll(kh -2h)
u(kh - h)

ll(kh)
0
1

(2.12)
Notice that if t > 0, then d . r extra state variables are used to describe the
delay, where r is the number of inputs. The characteristic polynomial of the
state-space description is ;.. dr A(A), where A(A) is the characteristic polynomial
of «!l.
An example illustrates use ofthe general formula.

Sec, 2.3

41

Sampling a Continuous-nme State-Space System

Example 2.8 Simple paper-machine model
Determine the zero-order-hold sampling of the system (see Example A.4).
dx(t)

& =-xU) + u(t - 2.6)
with sampling interval h '= 1. In this case d

= 3 and r' =0.6, and (2.12) becomes

x(k + I} =fJ>r(k) + rou(k - 2) + r1u(k - 3)

where

•
System with Internaillme Delay

In the previous derivation it is assumed that the time delay of the system is
at the input (or the output) of the system. Many physical systems have the
structure shown in Fig. 2.3. that is, the time delay is internal. Let the system
be described by the equations
dXl (t)
81 ; ----;It = A1% + Btu(t)
1(1)

YI(t) = C.Xl(t) + n1u(t)

82:

dX2(t)

"dt
U2(t)

(2.13)

U
= A2X2 (t) + B2 2(t)

=Yl(t- r)

It is assumed that u(t) is piecewise constant over the sampling interval h. We
now want to find the recursive equations for xl(kh) and x2(kh).
Sampling (2.13) when r = 0 using the sampling period h gives the partitioned system

We have the following theorem.
Y

Figure 2.3 System with inner time delay.

Discrete·Time Systems

42

Chap. 2

2.1 INNER TIME DELAY Periodic samplingof the system (2.13)
with the sampling interval h and with 0 < r ::;; h gives the sampled-data
representation
THEOREM

xI(kh + h) = 4>t{h)X1(kh) + rl(h)u(kh)
x2(kh + h) = l1>21Xl(kh - h) + $2(h)X2(kh)

(2.14)

+ f 2u(kh - h) + r2 (h - r)u(kh)
where

(f}i(t)

= eA1r

<1>21(1) =
f 1(t) =

f,(t)

=

l"'"

i = 1. 2
B,CleA,(t-'l ds

teA lS B1 ds

.10

l

(2.15)

eA"B2C,f,(t -s)ds

4>21 = 4>21(h)l1>1(h - r)
f

2 = $21 (h) r 1( h - r) + 4>21 (h - r)r 1(r) + 1)2(h - r) I'2(r)

Reference to proof of the theorem is given at the end of the chapter.

•

Remark. The sampled-data system (2.14)for the time delay 'r is obtained
by sampling (2.13) without any time delay for the samplingintervals h, h - r,
and r . This gives $lt t1>2 , l1>21, f l t and Ts for the needed sampling intervals.
This implies that standard software for samplingsystemscan be used to obtain

(2.14) .
Intersample Behavior
The discrete-time models (2.8) and (2.4) give the values of the state variables
and the outputs at the sampling instants tk. The values of the variables between the sampling pointe are also of interest. These values are given by (2.2).
Other ways of obtainingthe intersample behaviorare discussed in Sec. 2.7 and
Chapter 7.

2~4

Discrete-nme Systems
The previous section showed how to transform a continuous-time system into
discrete-time form. In most of the remaining part of this chapter we will disregard how the difference equation representing the discrete-time system has

43

Discrete-TIme Systems

Sec. 2.4

been obtained. Instead we will concentrate on the properties of difference equations. Time-invariant discrete-time systems can be described hy the difference
equation

x(k + 1) == ¢x(k) + fu(k)
y(k) == Cx(k) + Du(k)

(2.16)

For simplicity the sampling time is used as the time unit, h ;:; 1.

Solution of the System Equation

To analyze discrete-time systems it is necessary to solve the system equation
(2.16). Assume that the initial condition x(k o) and the input signals u(k o), u(ko +
1), ... are given. How is the state then evolving? It is possible to solve (2.16) by
simple iterations.
x(ko + I} = q>x(ko) + fu(k o)
x{ko + 2) == 4lx(ko + 1) + fu(k o + 1)
:=

lI>2 x(ko) + ¢fu(k o) + fu(k o + 1)

(2 .17)

x(k} := q>k-kI1X(ko) + q>k-ko-1fu(k o) +... + ru(k -1)
k-l

== q>k-koX(k o) +

L: lflk-j-1ruU)
j=ko

The solution consists of two parts: One depends on the initial condition, and
the other is a weighted sum of the input signals. Equation (2.17) clearly shows
that the eigenvalues of 4l will determine the properties of the solution. The
eigenvalues are obtained from the characteristic equation
det( AI

-

<1» ;::

0

Example 2.9 Solution of the difference equation
Consider the discrete-time system

x(k + 1)

= (.1.\

1

0) x(k)

,tz

with x(O) ::: (1 1) T. It is easily verified that

and

Chap. 2

Discrete-Time Systems

44

If jld < Iii:: 1,2, then x(k) will converge to the origin. If one ofthe eigenvalues
of 4> has an absolute value larger than 1, then one or both of the states will diverge.

•

2.5 Changing Coordinates In State-Space Models
Consider the discrete-time system (2.16). We will now discuss how new ceordinates can be introduced. Assume that T is a nonsingular matrix and define a
new state vector z(k) = Tx{k). Then
z(k + 1)

=Tx(k + 1) = T<P:r(k) + Tru(k) :; T~T-10!:(k) + Tfu(k)
== d>z(k)

+ ru(k)

and
y(k) = Cx(k) + Du(k) =CT-1z(k) + Du(k) = Cz(k) + lJu(k)

The state-space representation thus depends on the coordinate system chosen
to represent the state. The invariants under the transformation are of interest.
THEOREM 2.2 INVARIANCE OF THE CHARACTERISTIC EQUATION

The char-

acteristic equation
det(AI -~)

=0

is invariant when new states are introduced through the nonsingular transformation matrix T.
Prool
det{ll - <1» ::: det(J. TT-l - T~T-l) :;; det T det(tll - ~) det T- 1
:;:: det(J.] -tl»

•
To find a transformation matrix is the same as solving for the n'l elements of T
from the linear set of equations
T4> = <PT

Coordinates can be chosen to give simple forms ofthe system equations.

Sec. 2.5

45

Changing Coordinates inState-Space Models

Diagonal Form
Assume that 41 has distinct eigenvalues. Then there exists a T such that

where Ai are the eigenvalues of41. The computation ofT is discussed in Sec. 3.4.
In this case a set of decoupled first-order difference equations is obtained.

zll(k + 1) = Anzn(k) + f3nu(k)

y(k) = YIZl(k) + ... +Ynzn(k)
The solution to the system of equations is now simple. Each mode will have the
solution
k-l

zl(k)

= A~Zi(O} + LA.~ -}-1.81UU)

(2.18)

j=O

EIaDlple 2.10 Diagonal form

Consider the motor in Example 2.3 with h = 1. Using the transformation

. T-

1
1)
[ 1.4142 0

gives
41;;: ( 1.0000

o

0)

c = (1

0.3679

- 0.7071 )

•

Jordan Form
If 41 has multiple eigenvalues, then it is generally not possible to diagonalize
<J>. Let ¢l be a n x n matrix and introduce the notation

;.

1

0

A

0

0
i

0

Lk(A) =

0,
0

0

A

1

0

0

A

Discre1e-Time Systems

45

Chap. 2

where L, is a k x k matrix. Then there exists a matrix T such that

o
(2.19)

o
with k I + k'2 + .. ' + k; = n. The A.i are the eigenvalues of (J), not necessarily
distinct. Equation (2.19) is called the Jordan form. See Appendix B. In this
form the transformed matrix, cil, has the eigenvalues in the diagonal and some
I's in the superdiagonal.

2.6 Input..Output Models
A dynamic system can be described using either internal models or external models. Internal models-for instance, the state-space models discussed
in Sec. 2.3-describe all internal couplings among the system variables. The
external models give onlythe relationship between the input and the output of
the system. In this section, it is first shown that the input-output relationship
for a general linear system can be expressed by a pulse-response function. It is
then shown that shift-operatorcalculus can be used to derive input-output relationships directly, which leads to characterization of the input-output behavior
in terms of pulse-transfer operators.
The Pulse Response
Consider a discrete-time system with one input and one output. The input and
output signals over a finite interval can be represented as finite-dimensional
vectors
U = ( u(O)

u(N _ 1) )

Y:: (y(O)

y(N -1) ) T

T

The general linear model that relates Y to U can then be expressed as

y = HU + Yp
where H is an N x N matrix. Yp accounts for the initial conditions. If the
relation between U and Y is causal, the matrix H must be lower triangular.
The element h(k,m) of H is thus zero if m > k. The input-output relationship
for a general linear system can be written as
k

y(k) ;;;;

L h(k, m)u(m) + Yp(k)
rn",O

47

Input·Output Models

Sec, 2.6

where the term Yp is introduced to account for initial conditions in the system.
Thefunction h( k. m) is called the pulse-response function, or the weighting function, of the system. The pulse-response function is a convenient representation,
because it can easilybe measureddirectlyby injectinga pulseofunit magnitude
and the width of the sampling interval and recording the output. For zero initial conditions, the value h(k, m) ofthe pulse response gives the output at time
k for a unit pulse at time m. For systems with many inputs and outputs, the
pulse response is simply a matrix-valued function. For time-invariant systems,
the pulse response is a function of h - m only, that is,
h(k,m):;;; h(k - m)
It is easy to compute the pulse response ofthe system defined by the state-space
model in {2.16}. It follows from (2.17) that
k-l

y(k) =

C41 k - kll x(ko) +

L C<I>k-J-1ruU) + Du(k)
j::ko

The pulse-response function for the discrete-time system is thus

o
D

h(k) =

k <0

k=O

(2.20)

The pulse response is a sum of functions of the form

Re{P(k)Af}
where P is a polynomial in k; and A are the eigenvalues ofthe matrix <f).
i
The pulse response has the following property.

2.3 INvARIANCE OF PULSE RESPONSE Thepulse response (2,20)
is invariant with respect to coordinate transformations ofthe state-space model.
THEOREM

Introduce new coordinates z = Tx. The pulse response of the
transformed system is then, for k ~ 1,

Proof.

h{k)

= C<i>k-'lf =CT-l(T<I>T-1)k-1Tr
::: CT-1T<f)k-1T-1Tr'=

iJ :: D has to be added for k = o.
If h(k)

c¢>~-lr

;:: h(k)

•

f:. 0 for only a finite number of k, then the system is called a finite

impulse-response (FIR) system. This implies that the output only will be influenced hy a fiuite number of inputs.

Discrete-Time Systems

48

Chap. 2

Shift-Operator Calculus
Differential-operator calculus is a convenienttool for manipulating linear differential equations with constant coefficients. An analogous operator calculus can
be developed for systems described by linear difference equations with constant
coefficients. In the development of operator calculus, the systems are viewed as
operators that map input signals to output signals. Th specify an operator it
is necessary to give its range-that is, to define the class of input signals and
to describe how the operator acts on the signals. In shift-operator calculus, all
signals are considered as doubly infinite sequences {f(k) : k =.,.- 1. 0, 1,... }.
For convenience the sampling period is chosen as tbe time unit.
The forward-shift operator is denoted by q. It has the property

qf(k) = f(k+ 1)
If the norm of a signal is defined as

II f II ~ sup lf(Il)1
k

or
II

f

2
1
1

~

[

f 2(k)

k.. - oo

it follows that tbe shift operator has unit norm. This means that the calculus
of shift operators is simpler than differential-operator calculus, because the
differential operator is unbounded. The inverse of the forward-shift operator is
called tbe backward-shift operator or the delay operator and is denoted by q-l.
Hence
"

Notice that it is important for the range of the operator to be doubly infinite
sequences: 'otherwise, the inverse of the forward-shift operator may not exist.
In discussions of problems related to the characteristic equation of a system,
such as stahility and system order. it is more convenientto use the forward-shift
operator. In discussions ofproblems related to causality,it is more convenientto
use the backward-shift operator. Operator calculus gives compact descriptions
of systems and makes it 'easy to derive relationships among system variables.
hecause manipulation of difference equations is reduced to a purely algebraic
problem.
The shift operator is used to simplify the manipulation of higher-order
difference equations. Consider the equation
y(k +na) +aly{k+na-.1) + ... +anay{Jl)
== bQu(k + nb) + ... + bnbu(k)

(2.21)

Sec. 2.6

49

Input-Output Models

where na ~ nb. Use of the shift operator gives

With the introduction of the polynomials

A()
,z

= Z no + alZ na-l + .. ' + a

TlCl

and

the difference equation can be written as

A(q)y(k)

::0

B{q)u(k)

(2.22)

'When necessary, the degree of a polynomial can be indicated by a subscript,
for example, Ana (q). Equation (2.22) can be also expressed in terms of the
backward-shift operator. Notice that (2.21) can be written as

y(k) + aly(k - 1) + ... + anay(k - na) '" bou(k - d) + ... + bnbu(k - d - nb)

where d

= na -

nb is the pole excess of the system. The polynomial

which is obtained from the polynomial A by reversing tbe order of the coefficients, is called the reciprocal polynomial. Introduction of the reciprocal polynomials allows the system in (2.22) to be written as

Some care must be exercised when operating with reciprocal polynomials because A" is not necessarily the same as A. The polynomial A(z) = z has the
reciprocal A* (z) :: z - Z-l = 1. The reciprocal of A* is N· (z) ::: I, which is
different from A. A polynomial A(z} is called selfreciprocal if

At (z)

=A(z)

ADifficulty
The goal of algebraic system theory is to convert manipulations of difference
equations to purely algebraic problems. It follows from tbe definition of the
shift operator that the difference equation of (2.22) can be multiplied by powers
of q, which simply means a forward shift of time. Equations for shifted times can

50

Discrete-Time Systems

Chap. 2

alsobe multiplied by real numbersand added, which corresponds to multiplying
Eq. (2.22) by a polynomial in q. If (2.22) holds, it is thus also true that
C(q)A(q)y(k) = C(q)B(q)u(k)
'Ib obtain a convenient algebra, it is also useful to be able to divide an equation
like (2.22) with a polynomial in q. For example, if

A(q)y(k) = 0

it would then possible to conclude that

y(k)

=0

If division is possible, an equation like (2.22) canbe solved withrespect to y(k).
A simple example shows that it is not possible to divide by a polynomial in q
unless special assumptions are made.
Example 2.11 Role of initial conditions
Consider the difference equation

y(k + 1) - ay(k)

= u(k)

where lal < 1. In operator notation the equation can be written as

(q- a)y(k) = u(k)

(2.23)

If y(ko) =Yo it follows from (2.17) that the solution can be written as
~-l

y(k)

= aA!-kO yo + L ak-j-1u(j)
j=k o

.11-.0

(2.24)

=ak-~Oyo + L a'-1u(k - i)
i=l

A formal solution of the operator equation (2.23) can be obtained as follows:

1
q-l
y(k) =- - a u(k) = 1 - aq--1 u(k)
q

Because q-l has unit norm, the right-hand side can be expressed as a convergent
series.

o:

==

L

ai-1 u (k

- i)

(2.25)

j,'1

It is clear that solutions in (2.24) and (2.25) are the same only if it is assumed
that Yo ;;:: 0 or that k - ko ~ 00.
•

Sec. 2.6

51

Input-Output Models

It is possible to develop an operator algebra that allows division by an arbitrary
polynomial in q if it is assumed that there is some ko such that all sequences
are zero for k s k o• This algebra then allows the normal manipulations of
multiplication and division of equations by polynomials in the shift operator as
well as addition and subtraction of equations. However, the assumption does
imply that all initial conditions for the difference equation are zero, which is
the convention used in this book. (Compare with Example 2.11.)
If no assumptions on the input sequencesare made, it is possible to develop
a slightly different shift-operator algebra that allows division only by polynomials with zeros inside the unit disc. This corresponds to the fact that effects of
initial conditions on stable modes will eventually vanish, This algebra is slightly
more complicated because it does not allow normal division.

The Pulse-Transfer Operator
Use of operator calculus allows the input-output relationship to be conveniently
expressed as a rational function in either the forward- or the backward-shift operator. This function is called the pulse-transfer operator and is easily obtained
from any system description by eliminating internal variables using purely algebraic manipulations .
.
Consider, for example, the state-space model of (2.16). To obtain the inputoutput relationship, the state vector must be eliminated. It follows from (2.16)
that
x(k + 1)

=qx(k} :;: l1>x(k) + ru(k)

Hence
(qI - CI»x(k)

= ru(k)

This gives

y(kl = Cx(k) + D[k(k) :;: (C(qI -

<1lt 1r + D)u(k)

The pulse-transfer operator for the system (2.16) is thus given by

H(q) = C(qI - <t>r1r + D
The pulse-transfer operator can be also expressed in terms ofthe backward-shift
operator.

H*(q-l)

= C(I - q-1<t>t1q-1r + D = H(q)

The pulse-transfer operator for the system of (2.16) is thus a matrix whose
elements are rational functions in q. For a system with one input and one
output,

H(q) :: C(qI

~ Cllt1r + D = B(q)
A(q)

(2.26)

52

Discrete-Time Systems

Chap. 2

If the state vector is of dimension n and if the polynomials A(q) and B(q) do
not have common factors, then the polynomial A is of degree n. It follows from
(2.26} that the polynomial A is also the characteristic polynomial of the matrix
<fl, which means that the input-output model can be written as

= bou{k) + ... + bnu(k - n)

y{k) + aly(k - 1) + ., . + any(k - n)

where ai are the coefficients of the characteristic polynomial of «t>. The most common case in computer-control systems is that bo = 0, that is, there is no direct
term in the discrete-time model. Usually j'(k) is measured first, and then u(k} is
determined. Then y(k) cannot he influenced by u(k) even if the continuous-time
system has a direct term.
Example 2.12 Double integrator

Consider the double integrator in Example 2.2 when h ::: 1. From (2.26)
H(q) "" (1 0) {q - 1

o

-1) (0.5)
-1

q- 1

= O.5{q + 1)

1

(q - 1)2

"" O
.5(q-l + q-2)
. 1 - 2q~1 + q~2

•

Example 2.13 Double integrator with time delay

Use h = 1 for the double integrator and introduce a time delay of0.5 s. Then from
(2.10) and Example 2.7,
H(q)

=

C(qI -

= (1

4lr 1{f o + r1q-l)

0)

r:'

-1)

0
q- 1
(q - 1)2

= 0.125(q2 + 6q + 1) : :
q(q2 - 2q + 1)

( 0.125 + O
.375q-1 )
+ O.5q-l

05
.

O.125(q 1 + 6q-2 + q-3)
1 - 2q-l + q: 2

---=-=--_...:..----.,;:.........:..

•

Section 2.5 shows that different state-space representations can be used. Of
course, this does not change the input-output model.
THEOREM 2.4 INVARIANCE OF THE pmSE-TRANSFER OPERATOR The pulsetransfer operator H(q) for the state-space model (2.16) is independent of the
state-space represen ta tion.

Prool

Given the pulse-transfer operator

and a transformation matrix T. In the new coordinates

fJ(q) ~ C(qI- ~)-lf + b = G-T- 1{qTT- 1 - Tqlr-1t1Tr + D
==

CT- 1 (T (q/

-<I»T-1f1Tr + D ::: CT-1T(qI - «t>r1T-1Tr + D

::: C(qI - «t»-lr + D = H(q)

•

Sec. 2.7

The z·Transform

53

The input-output models of a system with a zero-order hold can be obtained
by using (2.5) and (2.26). In order to simplify the computation of the pulsetransfer operator H(q), it is convenient to use Table 2.1, which gives H(q) for
some standard systems.
.
.
Programs for computer algebra such as Maple® and Mathematica® are
very convenient for performing sampling because the result is obtained in algebraic form and it can easily be converted to computer code. This approach
makes tables ohsolete and it also reduces the potential sources of mistakes in
manual calculations.

Poles and Zeros
The poles of a system are the zeros of the denominator of H(q ), the characteristic
polynomial A(q). The zeros are obtained from B (q) == 0, the poles of the inverse
system. For instance, the system in Example 2.12 has one zero in -1; the system
has two poles in 1.
Time delay in 11 system gives rise to poles at the origin. The system in
Example 2.13 has three poles: two in 1, and one at the origin. There are two
zeros: -3 ±
The interpretations of poles and zeros are discussed in Sec. 2.8.

..;s.

The Order ofa System
The order of a system is the same as the dimension of a state-space representation or, equivalently, the number of poles of the system. Notice that it is
important to use the forward-shift form to determine the order because of the
time delays. The determination of the,.poles, zeros, and order of a system are
occasions when it is important to use the forward-shift form.

2.7 The z-Transform
In the analysis of continuous-time systems the Laplace transform plays an important role. The transformation makes it possible to introduce the transfer
function and the frequency interpretation of a system. The combination of timedomain and frequency-domain aspects gives an increasing understanding ofsystems. The discrete-time analogy of the Laplace transform is the z-transfonn-a
convenient tool to study linear difference equations with or without initial conditions.
The z-transform maps a semi-infinite time sequence into a function of a
complex variable. Notice the difference in range for the z-transform and the
operator calculus. In the operator calcnlus we consider double-infinite time sew
quences. The main difference is because the z-transform also takes the initial
values into consideration. The variable z is a complex variable and should be
distinguished from the operator q.

Discrete-Time Systems

54

Chap. 2

Table 2.1 Zero-order hold sampling ofa continuous-time system, G(s). The table gives the zero-order-hold equivalent ofthe continuous-time system, G(s), preceded by a zero-order hold. The sampled system is described by its pulse-transfer
operator. The pulse-transfer operator is given in terms ofthe coefficients of

G(s)

H (q) or the coeffieients in H (q)

1

h
q-l

s

1
s2

1

q - 1.

(_1)m 8m (

-hm~~

q

a

__

I

s+a

a

s(s + a)

m!

Q-4Q

8a m

q )
q - e- ah

1- exp(-ah)
q - exp(-ah)

b1 ;:

! (ah - 1 t e-'lIh )
a
+ e- oh )

al;:

-(1

bI

1 - e-Clh(l t ah)

;;::

1 (1- e -Ilh - ahe -ah )

b2';: -

a

a2

= e- ah

b2 = e-ah(e- ah + ah. - 1)
.

:".

al ;: _2e- ah

s
(8 + a)2

(q ~ l)he- ah

(q _ e- ah)2
b1 =

ab
(sta)(st b)
af.b

b2

~

b(l - e-ah ) - a(1 - e- M )
b-a
a(l - e-bh)e-ah - b(l- e-ah)e bh
-.:.---.....;..,...-:---:..-_ _...:...-~---:--~.:.-.---.-,;,.

b-a

a1 = _(e- ah + e- bll)
02 ;;:: e-(n+bjh

55

The z-Transform

Sec. 2.7

Table 2.1 continued

G(s)

H(q) or the coefficients in H{q)

(8 + c)
(s+a)(s+b)

e- bh - e- nh + (1- Cbh)c jb - {l- e-ah)c/a
b1 = --~-"";"""_--':"----'---_":"-_---'-"":"a-b
b- C
'. C - a
b2- --=- e-(a+b)h +b{a-b)e -ah +a(a_b)e -bh
ab

a#-b

al

=

_e- ah - e- bh

a2 = e-(G+b)h

( +W r
{Wo)

b1 = 1 - a fJ
(.02
0

S2

+

2'

(Oos

+ 0)5

bF a' +€X (

(J) ':;:

{;o r - fl)

(.00-/ 1 - '2

a ;:; ; e-~6)oh

al =

-2afJ

fJ

CZ2 =

a2

r;:;;;; sin(wh)

1 .
b1 ;:;;;; W e-(mo h s~(OJh)
S

S2

+ 2{WOB +to5

al

=:

cos (wh)

b2 ;:;;;;
a2 =

= ~2e-,wuh cos (wh)

-b«
e- 2' Woh

OJ = roOyl-{2

b1 ;:;;;; 1- cos ak
at;:;;;; -2 cos

b1 ==

ah

! sin ah
a

at:;:: -2 cos ah

a

bz ;:; ; 1- cos ah
a2 =:

b2 =

1

-~ sin ah
a

«1

Discrete-Time Systems

56

Chap. 2

DEFINITION 2.1 z-TRANSFORM Consider the discrete-time signal {f(kh) :
k "" 0.1. ... }. The z-transform of f (kh) is defined as
oo

Z {f(kh)} = F(z)

= L f(kh)z -k

(2.27)

k=O

where z is a complex variable. The a-transform of f is denoted by Zf or F. The
inverse transform is given by

f(kh) =

2~i

f

(2.28)

F(z)l-ldz

where the contour of integration encloses all singularities of F(z).
Example 2.14 Transform of a ramp
Consider a ramp signal defined by y{kh) = kh for k
Y(z) ;;: 0 + hz-I + 2hz- 2 + .. '

•

2: O. Then

= h(Z-l + 2z -2 +

hz
.. .) ;;: (~_ 1)2

•

Some properties of the z-transform are collected. in Table 2.2. Notice that the
formulas for forward and backward time shifts are not the same. Tbis is a
consequence of the assumption that the time sequences are semi-infinite.
The a-transform can be used to solve difference equations; for instance,

x(k + 1) = <1>x(k) + ru(k)

y(k) "" Cx(k) + Du(k)
If the z-tranaform of both sides is taken,

Hence

z(X(Z)-x(O))

==

4lX(z) + ru(z)

X(z ) ::: (zI -

<l>r l (z.t(O) + rU(z))

and

Y(z) = C(zl - tllt1zx(Q) + (C(zI ..,. <1>r 1r + D) U(z}
The pulse-transfer function can now he introduced.
(2.29)

which is the same as (2.26) with q replaced by z. The time sequence y(k) can now
be obtained using the inverse transform. The following theorem is analogous to
that of continuous-time systems.

Sec. 2.7

57

The a-Trans'orm
Table 2.2 Some properties of th e a-transform.

1. Definition.
oo

F (z)

= L f(kh)z ·k
k :::; O

2. Inversion.

f F(z)~-ld2

1

f (kh) = -2.

1ft .

3. Linearity.

Z{af + fig} :: aZ[ + fJZg
4. Time shift.

Z{q-llf} '= z -rlF
Z{qJlf} ~ zll(F - Ft) where F1(z) = E;~~ fUh)z-J ,
5. Initial-value theorem.
f(O) = lim F{z )
1;-.00

6. Final-value theorem.
If (1- z-l )F(z) does not have any poles on or outside the unit circle, then
lim f(kh ) ::: lim(l- z-l)F (z) .
z-e l

k-+ r::c

7. Convolution.

Z{f' g}

=Z

{t.

f(n)g(k - n)}

= (Zf)(Zg)

response of (2.20) and the pulse-transfer function (2.29) are a z-transform pair, that is, Z{h(k)} ::; H(z).
•
THEOREM 2.5

The pulse

Computation of the Pulse-Transf~r Function
The pulse-transfer function can be determined directly from the continuoustime transfer function. Let the system be described by the transfer function
G(s) preceded by a zero-order hold (see Fig. 2.4). The pulse-transfer function is

{u(kh)}

Zero-order

hold

I"

u(t)

-

G(s)

-

-yet)

{Y(kh )}

H(z)

Fjgure 2.4 Sampling a continuous-time system.

"I

Discrete-Time Systems

58

Chap. 2

uniquely determined by the response to a given signal. Consider, for instance, a
unit-step input. The sequence {u(kh)} is then a sequence of ones and the signal
u(t) is then also a unit step. Let Y(s) denote the Laplace transform of y(t), that
Y(s)

= G{s)
s

Let the sampled output b(kh)} have the z-transform Y ;;:; Z{L-1y}. Division
ofY by the pulse-transfer function of the input, which is Z/(2 -1)) gives

The pulse-transfer function is now obtained as follows:

1. Determinethe step response ofthe systemwith the transfer function G(s).

2. Determine the corresponding z-transform'ef the step response.
3. Divide by the z-transform of the step function.

By using this procedure the following formula can he derived:
z - 1 1 Jy-t-iOC esh G(s)
H(z):;; - - ds
z 2Jri y-I.'X! z ~ esh s

(2.30)

If the transfer function G(s) goes to zero at least as fast as \51- 1 for a large s
and has distinct poles, none of which are at the origin, we get

H{z) =,

~

s=s,

1
z-e
S

h

Res

{e

Sh
-

s

1} G(s)

(2.31)

where Si are the poles of G(s) and Res denotes the residue. A proof of this formula is given in Sec. 7.8. If G(s) has multiplepoles or a pole in the origin, (2.31)
must be modified to take multiple poles into consideration when calculatingthe
residues. Table 2.3 shows some time functions and the corresponding Laplace
and a-transforms. The tahle can thus be used to combine steps 1 and 2. Tables
in textbooks are usually found in this form.
Warning. Notice that Zf in Table 2.3 does not give the zero-order-hold
sampling of a system with the transfer function Lj, ExamineTable 2.1. It is a
very common mistake to believe that it does. The desired pulse-transferfunction
is obtained through the procedure given.

Shift-Operator Calculus and z..transforms
There are strong formal relations between shift-operator calculus and calculations with z-transforms. When manipulating difference equations we can use
either. The expressions obtained look formally very similar. In many textbooks
the same notation is in fact used for both. The situation is very similar to the

Sec. 2.7

59

The a-Transform

Table 2.3 Some time functions and corresponding Laplace and z-transforms. Warning: Use the table only as prescribed!

f

Zf

Lf

o(k) (pulse)
1 k ~ 0 (step)

kh

1

z
z-l
hz
(z - 1)2

1

s
1
s2

1
82

T
l+sT

z - e- h/ T

1
s(1 + sT)

z{l- e- h/ T )
(z - 1Hz - e-h / T )

z

zsinmh

sinwkh
Z2 -

2z cos wh + 1

difference between the differential operator p :: d/dt and the Laplace transform ~ for continuous-time systems. First, we may notice that q is an operator
that acts on sequences and z is a complex variable.From a purelymathematical
point of view, it clearly makes sense to make a distinction between such different objects. There is, however, also a good system-theoretic reason for making
a distinction. We illustrate this by an example.
Example 2.15 Pole-zero cancellations

Consider the difference equation
y(k + 1) + u)'(k)

=u(k + 1) + au(k)

(2.32)

If (2.32) is considered as a dynamical system its pulse-transfer function is obtained
as
H(z)=z+a=1
z +a
The last equality is obtained because z is a complex variable. We may be thus

misled to believe that the system (2.32) is identical to
y(k) ;;; u(k)

(2.33)

Discrete-Time Systems

60

Chap. 2

This is clearly not true because the difference equation (2.32) has the solution
y(k) ~ (-a)ky(O) + u{k) ,

k ~ 1

which is identical to (2 .33) only it'the initial condition y(O) is zero. It may be reasonable to neglect the initial conditions if laJ < 1, but not reasonable if lal ~ 1, We
thus have the situation that from a system-theoretic point of view, the expression .
z+a

z+a

can 1xJ considered equal to one if lal < 1 but not otherwise. If equation (2.32) 18
solved using shift-operator calculus we obtain formally
(q + a)y(k) = (q + a)u{k)

Notice that we cannot divide hy q + a because q is an operator.

I

The conclusion that we can draw from the simple example is that the algebras
of z-transforms and shift operators are different. In a-transforms calculus we
can divide with an arbitrary expression, but this is not allowed in shift-operator
calculus. The system-theoretic interpretation is that we may throwaway some
modes in the system with a-transform calculusby cancellationfactors. This may
make sense if the canceled factors correspond to stable modes, but it may be
strongly misleading if the canceled factors are unstahle. Another manifestation
of this effect will be given in the discussions of the notions of observabilityand
controllability in Chapter 3.
Modified z-transform

The behavior between sampling points can be investigated using the modified
z-transform. This is the ordinary z-transform, but a time delay mh, which is
a fraction of the sampling period is introduced. The modified e-transform is
defined as follows.
DEFINITION 2.2

THE MODIFIED z-TRANSFORM
of a continuous-time function is given by

The modified z-transform

x

F(z,m)

= Lz-kf(kh-h+mh)

O::;m::;l

(2.34)

h=O

The inverse transform is given by
1

r

f(nh - II + mh} = -2. F(z,m}zn-1dz
m ir
where the contour r encloses all singularities of the integrand.

_

The modified z-transform is useful for many purposes-for example, the intersample behavior can easily be investigated using these transforms. There are
extensive tahles ofmodified z-transforms and many theorems about their properties (see the References}.

Sec. 2.8

61

Poles and Zeros

2.8 Poles and Zeros
For single-input-single-output finite-dimensional systems, poles and zeros can
be conveniently obtained from the denominator and numerator of the pulsetransfer function. Poles and zeros have good system-theoretic interpretation. A
pole z =. a corresponds to a free mode of tlie system associated with the time
function z(k) == ak • Poles are also the eigenvalues of the system matrix <1>. The
zeros are related to how the inputs and outputs are coupled to the states.
Zeros can also be characterized by their signal blocking properties. Azero
z = a means that the transmission of the input signal u{k) == Uk is blocked
by the system. This interpretation can be used to define zeros in terms of the
state-space equation. It follows from (2.16) that the input u(k} = uQU k gives the
state x(k) = xoah and zero output if z =. a such that
det (

z1 - tV
C

-r]
D

:=

0

Poles

Consider a continuous-time system described by the nth-order state-space model
dx
-d
t

= Ax+ Bu
.

Y =

(2,35)

ex

The poles of the system are the eigenvalues ofA. which we denote hy Aj(A). i ==
1, ... ,11. TIle zero-order-hold sampling of (2.35) gives the discrete-time system
x(kh + h) ::: <1>x(kh) + ru(kh)
y{kh) ::: Cx(kh)

.

.

,

Its poles are the eigenvalues of <1>, Ad c), !";;} ~ ,r:! n. Because 4> : : ; exp(Ah} it
,
:
follows from the properties of matrix funetiQDB. (se;e Appendix B) that
"

I

,

.•

l-

(2.36)

Equation (2,36) gives the mapping from ~. continuous-time poles to the discrete-time poles. Figure2.5 illustrates a mapPing ofthe complex s-plane intothe
a-plane, when z = exp(sh)t For instance, ~fi!lleft}tali of the s-plane is mapped
into the unit discof the z-plane, The map isnot bijective-several points in the
s-plane are mapped into the same point in the a-plane (see Fig. 2.6). This is
an illustration of the aliasing effect discussed in Example 1.4. For poles inside
the fundamental strip So in Fig. 2.6, there is a simple relationship between
continuous- and discrete-time poles. (Also compare with Example 2.5.)

62

Discrete-Time Systems

Figure 2.5 The conformal map z

Chap. 2

= exp(sh).

3rr 1h

rr lh

- TC Jh

- 3rr I h
Figure 2.6 Each strip in the left half ofthe s-plane is mapped into the unit
disc. This means that the ·pair of poles, Ps and P2 , are both mapped
into the
pair p.

63

Poles and Zeros

Sec. 2.8
(a)

(b)

•

•
••

1

1

•

•
•
•

oQ•

0
5

•
•
•
Q

5

(d)

{c)

•

1

••

• •

••• • • • •

•

1

• •

•

•
•
Qi--------------

o

5

0'--------""'--------'
Q
5

Time

Time

Figure 2.7 Step responses ofthe discrete-time system in Example 2.16 for
different values of h when' = 0.5 and {J)o :::: 1.83, which gives the rise time
T, ;;;; 1: (a) h :: 0.125, (b) h ;;;; 0.25, (c) h "" 0.5, and (d) h = 1.0,
Emmple 2.16 Complex poles

Consider the continuous-time system
(2.37)

The poles ofthe corresponding discrete-time system are given by the characteristic
equation

where
UI

= _2e-'~oh C05 ( J1- '2 (doh)

Q2

== e- 2( li1Jh

(Compare with Table 2.1.) Figure 2.7 shows the step responses ofthe discrete-time
system for different values ofthe sampling interval when llJo ';;;; 1.83 and , ;;;; 0.5,
Figure 2.8 gives a more detailed picture ofhow the continuous-time poles of (2.37)
are mapped into the unit circle for different values. of' and (j)oh when the system
is sampled.
_

Zeros
It is not possible to give a simple formula for the mapping of zeros. If a continuous-time transfer function is viewed as a rational function. it has zeros at the
zeros of the numerator polynomial and d zeros at infinity, where d is the pole

Discrete-Time Systems

64

-1

o

-0.5

0.5

Chap. 2

1

Real axis

Figure 2.8 Loci of constant ( (solid) and wok (dashed) when (2.37) is
sampled.

excessfor.the continuous-timetransfer function-that is, the difference between
the number of poles and the number of zeros. The discrete-time system has, in
general, n - 1 zeros; compare Examples 2.12 and 2.13. The sampling procedure
thus gives extra zeros.
For short sampling periods, a discrete-time system will have zeros in

where the s/s are the zeros of the continuous-time system. The r = d - 1 zeros
introduced by the samplingwill go to the zeros ofthe polynomials Zd in Table 2.4
as the sampling interval goes to zero, because for large s, the transfer function
of the continuous-time system is approximately given by G(s) ~ s:",
Example 2.17 Second-order system

Consider the continuous-time transfer function
2
(8 + 1)(8 + 2)

Using Table 2.1 gives the zero ofthe pulse-transfer function

z :;;

(1- e- 2h)e· h - 2(1 - e-h)e-2h
2(1- e-h ) - (1- e-2h )

~ -'-~~---:-c,.--:'----='":--

When h is small
z ~ -1 + 3h

Sec. 2.8

65

Poles and Zeros

Numerator polynomials ,
Zd . when sampling «" .

Table 2.4

1

1

2
3

z+1

4

zJ

+ llz2 + Hz + 1

5

Z4

+ 26z::l + 66z2 + 26z + 1

z'2 + 4z + 1

and when h approaches zero, the zero moves to -1. The zero moves toward the
origin when h is increased. The zerofor small values of h also can be obtained from
Table 2.4. The pole excess of the continuous-time system is d = 2. The discretetime system will have a zero at z = -1 when h goes to zero.
_

Systems with Unstable Inverses
A continuous-time system with a rational transfer function is nonminimumphase if it has right half-plane zeros or time delays . Analogously, a discretetime system is often defined to be nonminimum-phase if it has zeros outside the
unit disc. That definition implies that a time delay does not make the system
nonminimum-phase. On the other hand, time delays do not pose the same severe
problems as they do for continuous-time systems. For discrete-systems it is
therefore more relevant to talk about systems with or without stable inverses,
which are defined as follows.
DEFlNITlON

2.3 UNSTABLE fNVER..l;JF.

A discrete-time system has an un-

stable inverse if it has zeros outside the unit disc.

•

A continuous-time system with a stable inverse may become a discrete-time
system with an unstahle inverse when it is sampled. It follows from Table 2.4
that the inverse system is always unstable if the pole excess of the continuouslime system is larger than 2, and if the sampling period is sufficiently short.
Further, a continuous-time nonminimum-phase system will not always become
a discrete-time system with an unstable inverse, as shown in the following
example.
Example 2.18 Stability of inverse system changes with sampling
The transfer function
G
_ 6(1- s)
(s) - (s + 2)(8 + 3)

66

Discrete-Time Systems

Chap. 2

has an unstable zero s = 1. Sampling the system gives a discrete-time pulse.
transfer function with a zero:
&-211 _ ge-:lh

+ e-5h

1 _ ge-21r + Be .11r

Zl ;;; -

For h ~ 1.25,Z1 ~ -1; for larger h, the zero is always inside the unit circle and
the sampled system has a stable inverse.
_

2.9 Selection of Sampling Rate
Proper selection of the sampling rate is a very important issue in computercontrolled systems. Too long a sampling period will make it impossible to reconstruct the continuous-time signal. Tho short a sampling period will increase
the load on the computer. The problem of sample-rate selection was touched
in Sec. 1.3. The choice of the sampling period strongly depends on the purpose
of the system. We will return to this question many times in the book. This
section only relates the sampling-rate selection to the poles of the open-loop
continuous-time system.
It is useful to characterize the sampling period with a variable that is
dimension-free and that has a good physical interpretation. For oscillatory systems, it is natural to normalize with respect to the period of oscillation; for
nonoscillatory systems, the rise time is a natural normalization factor.
We now introduce N, as the number of sampling periods per rise time,

N _ Tr
r

h

-

where T, is the rise time. For first-order systems, the rise time is equal to
the time constant. It is then reasonable to choose N, between 4 and 10. For
a second-order system with damping , and natural frequency (tJOI rise time is
given by

where'

= cos qJ. For a damping around ,
woh

~

~ 0.7, this gives

0.2 - 0.6

where [00 is in radians per second.
Figures 2,7 and 2.9 illustrate the choice of the sampling interval for different signals. It is thus reasonable to choose tbe sampling period so that

N, =

T

hr

~

4 to 10

1

(a )

67

Selection of Sampling Rate

Sec . 2.9

•

-

o

1

0

o
o

-1

'-----~--""---------'

0

5

(b) 1

•••

•

•

5
• • •••••••••

1

0

.,

-1 '---

o
(c)

1

"•

...... •

•

•

••

•

•

.'

'

.

•

(d ) l'

0".

5

,-....

.'.

.

I •• . . .
I

i

-1_
;

.

5

1

•

"t •• <.-..._----------'

o

o~----_..........------'

o

5

. ...
of
-1

•
__'

~

t'

,0'-

• •••• •••••••••••••••••

o~--------~

o

5
."

1

~

··....I'l
'-'

'.

o

.0

5

-----.J

o

--'-_ _

_~

o

-.-J

5

Time

Time

Figure 2.9 Illustration of the sample and hold of a sinusoidal and an exponential signal. The rise times of the signals are T; = 1. The number of
samples per rise time is (a) N, ;;;: I, (b) N, = 2, (c) N, ~ 4, and (d) N, =8.

Example 2.19 Pole-zero variation with sampling interval
Consider the system
1

G(s I "" -(8-+-1-)(-52 + 8 +-1)
--

(2.38)

Figure 2.10 shows the step response of the system. Assume that the system is
sampled with period h. Figure 2.11 shows how the poles and zeros ofthe sampleddata system vary with the sampling period, Sampling intervals close to zero give
three poles close to 1. Further, the continuous time system has a poie excess of 3.
This implies that the zeros for short sampling intervals are close to the roots of
/'+4z+1",0

See 'fable 2.4. The poles and zeros approach the origin when the sampling interval
is increased. The sampled-data system has a stable inverse if h > 2.24. The rules

C~ap.2

Discrete-Time Systems

68

1

O........::....--_~-~_....J...._----_-J._~~-~_-------J

o

15

10

5
Time

Figure 2.10 Step response of the system (2.38).

of thumb for the choice of the sampling interval give that a reasonable choice is
h == 0.5. Compare with Figure 2.10.
•

2.10 Problems
2.1 Consider the system

dx
dt
y

~ ==

-ax + bu

= ex

Let the input be constant over periods oflength h. Sample the system and discuss
how the poles of the discrete-time system vary with the sampling interval h.
2.2 Derive the discrete-time system corresponding to the following continuous-time
systems when a zero-order-hold circuit is used:
(a)

~~ = (~1 ~) x + (~) u
y= (1 O)x
(b)
d 2y
2

dt
(c)

of-

dy
du
3 - + 2y ;:;; -d + 3u

dt

t

69

Problems

Sec. 2.10

1
Q:l

.~

~
e

_*
x

0

·0

O· ..

0

O·

·0

'So
~

o

x
x

x

oS

)(

x

x

-1

-4

-2

-3

-1

o

1

Real axis
Figure 2.11 Poles (x) and zeros (c) when the system (2.38) is sampled
with h "" 0, 0.2, 0.5, 1, 2, and 3.
2.3 The following difference equations are assumed to describe continuous-time systems sampled usinga zero-order-hold circuit and the sampling period h. Determine.
if possible, the corresponding continuous-time systems.
(a)

y(kh) - O
.5y{kh - h) ;;: 6u(kh - h)
(b)
x{kh + h) ~ ( -0.5
o
y(kh) ""

1 ) x(kh) + ( 0.5 ) u(kh)

-0.3

0.7

(1 1) ~(kh)

(c)
y(kh) + O.5y(kh - h) ::: 6u(kh - h)
2.4 Consider the harmonic oscillator [see Example A.3 or Problem 2.2(a)]. Compute
the step response at 0, h, 2h, .. . when the sampling period is (a) h '" 1r/2. (b)
h "" ,,/4. Compare with the continuous-time stepresponse.

2.5 Sample the system
G(s) -

1

~~-,-----':"":""
8 2(8 + 2)(8 + 3)

using a zero-order-hold circuit and h '" 1.

Discrete-Time Systems

70

Chap. 2

2.6 Consider the system in (2.1). Assume that the input is a sum of impulses at the
sampling instants, that is,
u(t) ;

L 8(t - kh)u(kh)

Determine the discrete-time representation.
2.7 Find the transformation matrix, T. that transforms the state-space representation

of the double integrator (2.7) into diagonal or Jordan form.
2.8 Determine the pulse-transfer function of the systam

0.5
x(kh + h) ;;; ( 0
y(kh) ==

-0.2)
(2)
0
x(kh) + 1 Il(kh)

(1 0) x(kh)

2.9 Many physical systams can be described by the form

dx = (-a -d x+ (f) u
b) g
dt
c
where at b, C, and d are nonnegative. Derive a formula for the sampled-data system
when using a zero-order hold. (Hint: Show first that the poles of the systam are
real.)
2.10 Figure 2.12 shows a system of two tanks, where the input signal is the flow to the
first tank and the output is the level in the second tank. Use of the levels as state
variables gives the system

o )

dx ;;:: (-0.0197
dt

0.0178

- 0.0129

x+

(0.0263 )
0

U

y;(o l)x
(a) Sample the system with the sampling period h '" 12.
(h) Verify that the pulse-transfer operator for the system is
H ( )
oq

=

O.030q + 0.026
q2 - 1.65q + 0.68

2.11 The normalized motoris described in Example A.2. Show that the sampled system
is described hy (A.6). Determine the following:
(a) The pulse-transfer function.
(b) The pulse response.

(c) A difference equation relating the input and the output.
(d) The variation of the poles and zeros of the pulse-transfer function with the
sampling period.

Sec. 2.10

71

Problems

Figure 2.12 The two-tank process.

2.12 A continuous-time system with the transfer function
1
G(s) ::;: - c- sr
s
is sampled with h = 1 when r "" 0.5.

(a) Determine a state-space representation of the sampled system. What is the
order of the sampled system?

(h) Determine the pulse-transfer function and the pulse response ofthe sampled
system.
(c) Determine the poles and zeros of the sampled system.
2.13 Solve Problem 2.12 with
G(s) = _l~ e-!lt
s+l

and h = 1 and r = 1.5.
2.14 Consider the sampled system

y(k + 1) =ay(k) + bau(k - 3) + b4 u(k - 4)

where the sampling interval is 1 s. Show that the system may be obtained by
sampling the system

d~~t) ~ -ay(t) +bui; -1)
where

Discrete-Tlme Systems

Chap. 2

2.15 Consider the system
y(k) - O.5y(k - 1) :; u(k - 9) + O.2u(k - 10 )

Determine the polynomials A(q)l B(q), A'(q-J), and B' (q '11 in the representations
A(q)y(k) = B (q)u(k)
and

What are d and the order of the system?
2.16 A filter with the pulse-transfer operator

H' (- 1)
q

= b[) + blq - 1 + .. . + bnq

f1

is called a finite impulse-response (FIR) filter.
(a) Determine the order of the system.
(b) Determine the poles of the filter and make a state-space representation of the
filter.
2.17 Use the z-transform to determine the output sequence of the difference equation
y(k + 2) -1.5y(k + 1) + O
.5y(k)
when u{k) is a step at k

= 0 and when

y(O)

= u(k + 1)

= 0.5 and y( - 1) = l.

2.18 Verify that

Compare with Table 2.3 and use that to determine the pulse-transfer function of
the double integrator (see Example Al).
2.19 Use (2.30) to determine the pulse-transfer function of(a) the system in Problem 2.1
and (b) the normalized motor (see Example A.2).
2.20 Show that a curve of constant damping' in the s-plane is a logarithmic spiral in
the z-plane when using the mapping 2 ~ exp(sh). That is, the distance to the origin
can be written as r =aem lp , where ffJ is the angle.
2.21 If {3 < a, then
s+fJ

8+a
is called a lead network (i.e., it gives a phase advance) . Consider the discrete-time
system
z+b
Z+a

Sec. 2.10

Problems

73

(a) Determine when it is a lead network.
(b) Simulate the step response for different pole and zero locations.
2.22 Consider the system

z+b
(1 + b)(Z2 - LIz + 0.4)
The pole location corresponds to a continuous-time system with damping' =0.7.
Simulate the system and determine the overshoot for different values of b in the
interval (-1.1).
2.23 Consider the stable continuous-time system
G(s) = s + b

sta

where a t= b. Sample the system with the sampling period h. Derive conditions for
when the sampled system will have a stable inverse.
2.24 Consider the discrete-time system

This system is obtained hy sampling a continuous-time system with the transfer
function

O(s)

= Ke-

sr

1 + sT

using the sampling interval h. Show that

= -h/lna
K = hI + b2
T

I-a

ab, + b2

h

r = nh - Ina In a(bl + b2 )
2.25 Use (2.30) to determine the pulse-transfer function associated with

G(8)

1
=-;;s·>

2.26 Use Eq. (2.30) to show that the pulse-transfer function obtained with zero-order-

hold samplings of the transfer function
1

G(s) ::; sn

is given by

Discrete-Time Systems

74

Chap. 2

where

B()
II Z

::;:

bll Zlt - l + bnn -2 +. .. +
1
22

v:

Jl

and
k

~

1,2, . .. , n

Furthermore show that
B1(z} == 1
B~lz) == z + 1

8 3 (z) :=; Z2 +4z + 1
8 4 (z) =' zS + 1122 + 11z + 1
Bs{z) ==
B£(z)

:=:

+ 66z 2 + 26z2 + 1
i + 57z 4 + 3022 3 + 302z2 + 572 + 1

Z4

+ 26z3

2.27 Derive Eq. (2.31) from (2.30).
2.28 Solve the difference equation
y(k) == y(k -1) + y(k- 2)

when y{O) ::;: y(l)

k

~

2.3•...

= 1. [The numbers y(k) are called Fibonacci numbers.]

2.29 Detennine the poles and zeros (with multiplicity) of the system
j'(k) - O.5y(k - 1) + y(k -

2) ;;; 2u(k -

10) + u(k - 11)

2.30 Which of the following discrete-time systems can be obtained by sampling a causal
continuous-time system using a zero-order hold?
1

H1(q) ;;; q _ 0.8

q-l
Hs(q)

==

(q + 0.8)2

1

H2 {q) " ' - q+O.8
H (q) ::; 2q2 - O.7q - 0.8
4
q(q - O.B)

2.31 Determine the pulse-transfer operater obtained by sampling
G
with h

8 _
2(s + 2)
( ) - (8 + 1)(8 + 3)

= 0.02.

2.32 Sample the continuous-time system

d~~t) == (~ ~)

x(t) +

(~) u(t - 0.2)

using the sampling interval h ::; 0.3. Determine the pulse-transfer operator.

Sec.2.11

75

Notes and References

2.33 Consider a linear system with the transfer function

Sampling the system gives the pulse-transfer function

Letting a --. DO, we get

Ooo(s)

= lim Gn{s) = 1
U '00

and

Notice that H.:..,(z) is not the pulse-transfer function obtained by sampling the
system with the pulse-transfer function Ooo{s) = 1. Determine conditions on the
transfer function On (s) such that sampling commutes with limit operations.

2.11 Notes and References
The early texts on sampled-data systems dealt exclusively with input-output
models and transform theory Jury (1958), Ragazzini and Franklin (1958), and
Tsypkin (1958). The state-space approach used in this chapter offers significant simplifications. With a zero-order hold, the control signal is constant over
the sampling period and the discrete-time model is obtained simply by integrating the state equations over one sampling period. This problem formulation
was introduced in Kalman and Bertram (1958). It took some time before this
approach found its way into textbooks. Because of its simplicity it is now the
predominant approach.
Transformation of state variables and canonical forms is standard material in state-space theory. These results are very similar to the corresponding results for continuous-time systems. A more detailed treatment is given in
Kailath (1980). Historically, the input-output approach preceded the state-space
approach. A direct treatment from this point of view is given in the classic texts
just mentioned. The multivariable case is discussed in Rosenbrock (1970) and
Kucera (1979, 1991).
The a-transform is extensively discussed in Jury (1958, 1982) and Doetsch
(1971). These references contain large tables of a-transform pairs. A table of
zero-order-hold equivalent transfer functions (compare with Table 2.1) is given
in Neuman and Baradello (1979).
The relationship between the zeros of continuous and sampled systems
is discussed in Astrom, Hagandsr, and Sternby (1984). The theorems for the
limiting zeros for large and small sampling periods are given in this paper.

76

Dlscrete·Time Systems

Chap. 2

Theorem 2.1 is proved in Wittenmark {1985b). A generalization to the sampling
ofa system with several time delays is found in Bernhardsson (1993).
Programs for computer algebra such as Maple® and MBthematie;P) are
discussed, for instance, in Char (1992) and Wolfram (1988). For MATue® and
MATRIXX® we refer to the manuals for the programs.
Properties of matrices and transformations are found, for instance, in
Gantmacher (1960), Bellman {1970), and Golub and Van Loan (1989).

3
Analysis of
Discrete-Time Systems
3.1 Introduction
Previous chapters have shown how continuous-time systems are transformed
when sampled. In this chapter we will develop the key tools for analyzing
discrete-time systems. Stability, sensitivity, and robustness are introduced in
Sees. 3.2 and 3.3. The concepts of controllahility, reachability, and obssrvability, which are useful for understanding discrete-time systems, are discussed in
Sec. 3.4.Simple feedback loops and their properties are treated in Sec. 3.5. Simulation is used throughout the text because it is a very important tool for the
analysis of sampled-data systems-for instance, in investigating intersample
behavior.

3.2 Stability
The concept of stability is very important when analyzing dynamic systems.
It is assumed that the notion of stability is known from basic texts in control
theory. Only the basic definitions are given here.

Definitions
Stability is first defined with respect to changes in the initial conditions. Consider the discrete-time state-space equation (possibly nonlinear and time-varying)

x(k + 1) ~ f(x(k),k)

(3.1)
rt

78

Analysis of Discrete-Time Systems

Chap. 3

Let xO(k) and x(k) he solutions of (3.1) when the initial conditions are xO(k o)
and x(k o) . respectively. Further, let 1 11 denute a vector norm,
1·

3.1 STABILITY The solution xO(k) of (3.1) is stable if for a
given e > 0, there exists a 0(£,k o} > 0 such that all solutions with lIx(kol xO(k o) II < 0 are such that II x(k ) - xo(k) II < E for all k 2: ko.
•
DEFINITION

3.2 ASYMYTOTIC STABILITI The solution xO(k) (3.1) is asymptotically stable if it is stable and if 5 can he chosensuch that Ilx(kol - xO(ko)11 <
5 implies that 1\x(k) - XO (k)ll-4 0 when k ~ 00.
•
DEFINITION

From the definitions, it follows that stability in general is defined for a particular
solution and not for the system. The definitions also imply that stability, in
general, is a local concept. The interpretation of Definitions 3.1 and 3.2 is that
the system is (asymptotically) stable if the trajectories do not change much if
the initial condition is changed by a small amount.
Stability of linear Discrete-Time Systems

Consider the linear system

(3.2)
To investigate the stability ofthe solution of (3.2)) the initial value is perturbed.
Hence
x(k + 1)

= C1>x(k)

x(O) ::: a

The difference .i: ::: x - xlJ satisfies the equation
x(k + 1}

=:

<1>x(k)

itO)

'=

a·· aO

(3.3)

This implies that if the solution XO is stable, then every other solution is also
stahle. For linear, time-invariant systems, stability is thus a property of the
system and not of a special solution.
The system (3.3) has the solution
x(k) ;;;; C1> k.i(O
)

See (2.17). If it is possible to diagonalize <1>, then the solution is a combination
of terms A7, where Ai,i =: 1,.. . .n are the eigenvalues of¢l; see (2.18). In the
general case, when C1> cannot be diagonalized, the solution is instead a linear
combination of the terms pi(k)A7, where Pi(k) are polynomials in k of order one
less than the multiplicity of the corresponding eigenvalue. To get asymptotic
stability,all solutions must go to zero as k increases to infinity. The eigenvalues
of <1> then have the property

IAil

<1

i ::: 1.... . n

which is formulated as the following theorem.

Sec. 3.2

79

Stability

3.1 AsYMPTOTIC STABILITY OF LINEAR SYSTEMS A discrete-time
linear time-invariant system (3.2) is asymptotically stable if and only if all
eigenvalues of CI> are strictly inside the unit disk.
•
THEOREM

Stability with respect to disturbances in the initial value has already been defined. Other types of stability concepts are also of interest.
Input..Output Stability
DEFlNITION 3.3

BOUNDED-INPtrr BOUNDED-OUTPUT STABILITY

A linear

time-invariant system is defined as bounded-input-bounded-output (BIBO) sta_
ble if a bounded input gives a bounded output for every initial value.
From the definition it follows that asymptotic stability is the strongest concept.
The following theorem is a result.

3.2 RELATION BETWEEN STABILITY CONCEPTS
bility implies stability and BIBO stability.
THEOREM

Asymptotic sta-

•

When the word stable is used without further qualification in this text, it normally means asymptotic stability.
It is easy to give examples showing that stability does not imply BillO
stability, and vice versa.
EJ::Hmple 3.1 Harmonic o8cillator
Consider the sampled harmonic oscillator (see Example A.3)
x(kh + h}

=(

y(kh);;

cos wh

sin

- sin (ol!

(1 0)

Wh)

cos wh

x(kh) + ( 1- OOSmh) u(kh)
sin (J)h

x(kh)

The magnitude of the eigenvalues is one. The system is stable because Ilx(kh) II =
IIx(O)1l if u(kh) = O. Let the input be a square wave with the frequency (J) rad/s.
By using the z-transform, it is easily seen that the output contains a sinusoidal
function with growing amplitude and the system is not BIBO stable. Figure 3.1
shows the input and output ofthe system. The input signal is exciting the system
I
at its undamped frequency and the output amplitude is growing.

Stabi lity Tests

It follows from Theorem 3.1 that a straightforward way to test the stability of
a given system is to calculate the eigenvalues of the matrix ~. There are good
numerical algorithms fOT doing this. WelI-established methods are available,
for instance, in the package LAPACK, which is easily accessible in most computing centers. The routines are also included in packages like MATI..AB®. The
eigenvalues of a matrix then can be calculated with a single command.

Analysis of Discrete-Time Systems

80

Chap. 3

0.5

'--

~O.5

....
;:l
Q,
.iJ

0

~

•

o.

.., ...... •

0

-5

30

20

10

0
5

.00

•

0 .' 0 0

0

••••

0

• ••

.

•

•
t

o·

0

o.

0

0

0

•

20

10

30

Time
Figure 3.1 Input and output of the system in Example 3.1 when {() = 1,
h

=;

0.5, and the initial state is zero.

It is, however, also important to have algebraic or graphical methods for
investigating stability. These methods make it possible to understand how parameters in the system or the controller will influence the stability.The following
are some of the ways of determining the stability of a discrete-time system:
• Direct numerical or algebraic computation of the eigenvalues of lI>
• Methods based on properties of characteristic polynomials
• The root locus method
• The Nyquist criterion
• Lyapunov's method
Explicit calculation of the eigenvalues of a matrix cannot be done conveniently by hand for systems of order higher than 2. In some cases it is easy to
calculate the characteristic equation

(3.4)
and investigate its roots. Recall from Sec. 2.6 that the characteristic polynomial
is the denominator polynomial of the pulse-transfer function. Stability tests can
be obtained by investigating conditions for the zeros of a polynomial to be inside
the unit disc.
It is also useful to have algebraic or graphical conditions that tell directly if
a polynomial has all its zeros inside the unit disc. Such a criterion, which is the
equivalent of the Routh-Hurwitz criterion, was developed by Schur, Cohn, and
Jury. This test will be describedin detail in the following section. The calculation
ofthe coefficients of the characteristic polynomial from the elements of a matrix

Sec.3.2

81

Stability

is poorly conditioned. If a matrix is given, it is therefore preferable to calculate
the eigenvalues directly instead of calculatingthe characteristic equation,
The well-known rootlocus method for continuous-time systemscan be used
for discrete-time systems also. The stability boundary is changedonly from the
imaginary axis to the unit circle. The rules of thumb for drawing the root locus
are otherwise the same. The root locus method and the Nyquist criterion are
used to determine the stability of the closed-loop system when the open-loop
system is known.

JUry's Stability Criterion
The following test is useful for determining if Eq. (3.4) has all its zeros inside
the unit disc. Fonn the table
aD

al

On-l

an

an

an-l

al

ao

a 11-1 a n-l
l
o

a,,-1

at>

an-l
n- 1

/l-I
11-1
a n - l an _ 2

an

an = -

al\-1

an-l

0

11-1
= a11-1

o

where
k-l
ai
~

k

aj -

k
akak_i

kj It
ak :: a k ao
The first and second rows are the coefficients in (3.4) in forward and reverse order, respectively. The third row is obtained by multiplying the second
row by an ;::; all/ao and subtracting this from the first row. The last element in
the third row is thus zero. The fourth row is the third row in reverse order. The
scheme is then repeated until there are 2n + 1 rOW5. The last row consists of
only one element. The following theorem results.

If ao > 0 1 then Eq. (3.4) has all
roots inside the unit disc if and only if all a~, k = 0, 1,... , n - 1 are positive. If
no a~ is zero then the number of negative a~ is equal to the number of roots
•
outside the unit disc.
THEOREM 3.3

JURY'S STABILITY TEST

I

Remark. If all a~ are positive for k = I, 2" .. , n - 1, then the condition
a~ > 0 can be shown to be equivalentto the conditions

>0
(-lrA(-1) > 0
A(l)

These conditions constitute necessary conditions for stability and hence can be
used before forming the table.

82

Analysis of Discrete-TIme Systems

Chap. 3

Figure 3.2 The stability area for the second-order equation (3.5) as a function of the coefficients a1 and 02.

Example 3.2 Stability of a second-order system
Let the characteristic equation be
(3.5)
Jury's scheme is
1
1

All the roots of Eq. (3.5) are inside the unit circle if

This gives the conditions

a2 < 1
02

> -1 + a1

02

> -1-

a1

The stability area for the second-order equation is shown in Fig. 3.2.

•

Sec. 3.2

83

Stability

Nyquist and Bode Diagrams for Discrete-Time Systems
Consider the continuous-time system G(s ). The Nyquist curve or frequency response curve of the system is the map G(ico) for W E [0,00). This curve is drawn
in polar coordinates (Nyquist diagram) or as amplitude and phase curves as a
function of the frequency (Bode diagram). In the discrete-time case we have a
similar situation. Consider a system with the pulse-transfer function H(z). The
Nyquist or frequency curve is given by the map H(e1W h ) for wh E [O,R], that is,
up to the Nyquist frequency. Notice that it is sufficient to consider the map in
the interval OJh E [ -Ir,n] because the function H(eifJJh ) is periodic with period
2n/h .
In the continuous-time case, the Nyquist curve G(iw) can be interpreted
as the stationary amplitude and phase when a sinusoidal signal with frequency
w is applied to the system. In the discrete-time case, higher harmonics are
generated; see Example 1.4. This will make the interpretation of H(e iWh ) more
complex as is further discussed in Chapter 7.
Example 3.3 Frequency responses
Consider the continuous-time system
G(s):::; 2

1
14

s + .

S

+1

(3.6)

Zero-order-hold sampling ofthe systemwith h = 0.4 gives the discrete-time system
H(z);;::
z2

O.066z + 0.055
-1.4502 + 0.571

The frequency curve is given by H(eiwh ) . Figure 3.3 shows the Nyquist diagram
and Fig 3.4 shows the Bode diagram for the continuous-time system and for the
discrete-time system. The difference between the continuous-time and discretetime frequency curves will decrease when the sampling period is decreased. The
connection between the frequency curves of the discrete-time and continuous-time
systems is further discussed in Sec. 7.7.
•

The Nyquist Criterion

The Nyquist criterion is a well-known stability test for continuous-time systems.
It is based on the principle of arguments. The Nyquist criterion is especially
useful for determining the stability of the dosed-loop system when the openloop system is given. The test can easily be reformulated to handle discrete-time
systems.
Consider the discrete-time system in Fig, 3.5. The closed-loop system has
the pulse-transfer function

84

Chap. 3

Analysis of Discrete-Time Systems

,

o
/

I
I

,
r

\

\

-1 '--_.L.-.
-0.5

____'__

~____I.

o

0.5

~_....J.__-----'

1

Real axis
Figure 3.3 The frequency curve of (3.6) (dashed) and for (3.6) sampled
with zero-order hold when h -= 0.4 (solid).

1 ~---------...__

....
0.01

1

0.1

0r-----

.....

10

1

10

__

-180
0.1

Frequency, rad/s
Figure 3.4 The Bode diagram of (3.6) (dashed) and of (3.6) sampled with
zero-order hold when h == 0.4 (solid).

Sec. 3.2

85

Stability

y

-1
Figure 3.5 A simple unit-feedback

system .

The characteristic equation of the closed-loop system is

1 + H(z)

=;

(3.7)

0

The stability of the closed-loop system can be investigated from the Nyquist
plot of H(z). For discrete-time systems, the stability area in the a-plane is the
unit disc instead of the left half-plane. Figure 3.6 shows the path r c encircling
the area outside the unit disc. The small indentation at z = 1 is to exclude the
integrators in the open-loop system. The mapping ofthe infinitesimal semicircle
at z = 1 with decreasing arguments from n /2 to -Jr /2 is mapped into the H(z)plane as an infinitely large circle from -n7r /2 to nt: /2~ where n is the number
of integrators in the open-loop system. If there are poles on the unit circle other
than for z = 1, those have to be excluded with small semicircles in the same
way as for z = 1. The map of the unit circle is H(e iWh ) for mh E (O,2n).
The stability of the closed-loop system now can be determined by investigating how the path T, is mapped by H(z). The principle of arguments states
that the number of encirclements N in the positive direction around (-1,0) by
the map of f c is equal to

N=Z-P
where Z and P are the number of zeros and poles, respectively, of 1 + H(z)
outside the unit disc. Notice that if the open-loop system is stable, then P = 0
1m

Re

Figul'e 3.6 The path F, encircling the area outside the unit disc.

Analysis of Discrete-Time Systems

86

Chap. 3

1m

Re

-1

Figure 3.7 Themap of r c into the H(2 )-plane ofthe systemin Example 3.4,
when K :::: 1. The solid line is the Nyquist curve.

and thus N ;:;: Z. The stability of the closed-loop system is then ensured if the
map of I', does not encircle the point (-1, 0). If H('1(z) ~ 0 when z --) 00, the
parallel lines III and V do not influence the stability test, and it is sufficient to
find the map of the unit circle and the small semicircle at z :::: 1. The Nyquist
criterion can be simplified further if the open-loop system and its inverse are
stable. Stability ofthe closed-loop system is then ensured if the point (-1,0) in
the H (zj-plane is to the left of the map of H (e iwh ) for toh. :::: 0 to IT-that is, to
the left of the Nyquist curve.
E:rr::mnple 3.4 A second-order system
Consider a system with sampling period h = 1 and the pulse-transfer function
H(z) =

O.25K
(z - l)(z - 0.5)

then
H(e"~ ) "" O
.25K 1.5(1-

2m

2sin - isincu(2CQtlCtJ - 1.5)
(2 - 2COSlV){1.25 + cosw)

COSltJ) -

The map of F, is shown in Fig. 3.7. The solid line is the Nyquist curve, that is,
the map of H(e'li)) for (() :; ; ; 0 to It . Notice that the sampled-data system has a
phase shift that is larger than 1800 for some frequencies. From the figure it can be
found that the Nyquist curve crosses the negative real axis at - 0.5. Theclosed-loop
system is thus stable if K < 2.
•

Relative Stability

Amplitude and phase margins can be defined for discrete-time systems analogously to continuous-time syatems.

Sec. 3.2

87

Stability

3.4 AMPLITUDE MARGIN Let the open-loop system have the
pulse-transfer function H(z) and let (i)o be tbe smallest frequency such that
DEFINITION

arg H {eilouh) ;:: - Jr
and such that H (e lfll• h ) is decreasing for
is then defined as

OJ :::: to.;

The amplitude or gain margin

•
DEFiNITION 3.5 PHASE MARCIN

Let the open-loop systemhave the pulsetransfer function H(z) and further let the crossover frequency (Oc be the smallest
frequency such that

The phase margin ¢ marg is then defined as
tPmarg ;:: 1C

+ arg H(eiOJrh )

•

In words, the amplitude margin is how much the gain can be increased before
the closed-loop system becomes unstable. The phase margin is how much extra
phase lag is allowed before the closed-loop system becomes unstable.
The amplitude and phase margins are easily determined from the Nyquist
and Bode diagrams.
Example 3.5 Amplitude margins
Consider the system in Example 3.3. The continuous-time system has an infinite
amplitude margin. The closed-loop sampled-data systam will, however, be unstable
with a proportional controller if the gain is larger than 7.82. 1}e finite-amplitude
margin for the discrete-time system is due to the phase lag introduced by the zeroorder hold. The difference between the discrete-time system and the continuoustime system will decrease when the sampling interval is decreased.
I

The phase margin can be used to select the samplingperiod. Allowing the phase
margin to decrease by 5 to 15° compared with the continuous-time system at
the crossover frequency gives one rule of thumb.

Lyapunov's Second Method
Lyapunov's second methodis a useful tool for determining the stabilityof nonlinear dynamic systems. Lyapunov developed the theory for differential equations,
but a corresponding theory also can be derived for difference equations. The
main idea is to introduce a generalized energy function called the Lyapunov
function, which is zero at the equilibrium and positive elsewhere. The equilibrium will be stable if we can show that the Lyapunov function decreases along
the trajectories ofthe system.

Analysis of Discrete-Time Systems

88

V(x(k

+ l)J

Chap . 3

___~ x ( k )

Figure 3.8 Geometric illustration ofIyapunov's theorem.

The first step to show stability is to find the Lyapunov function, which is
defined as follows:
DEFrNITION 3.6

LYAPUNOV FUNCTION

V (x) is a Lyapunou function for the

system
x{k + 1) = f(x(k))

((0) = 0

(3.8)

if:
1. V(x) is continuous in x and V(O)

= O.

2. V(x) is positive definite.

3. aV(x) = V(f(x)) -V(x) is negative definite.

•
A simple geometric illustration of the definition is given in Fig. 3.8. The level
curves of a positive definite continuous function V are closed curves in the
neighborhood ofthe origin.Let each curve be labeled by the value ofthe function.
Condition 3 implies that the dynamics of the system is such tbat the solution
always moves toward curves with lower values. All level curves encircle the
origin and do not intersect any other level curve.
From the geometric interpretation it thus seems reasonable that the existence of a Lyapunov function ensures asymptotic stability. The following theorem is a precise statement of this fact.
THEOREM 3.4 STABILITY THEOREM OF LYAPUNOV
The solution x(k) = 0
is asymptotically stable if there exists a Lyapunov function to the system (3.8).
Further, if

o < cp(llxll) < V(x)

as

where fP(llxlD -+ 00 (\Ix!\)
all initial conditions.

-7 00,

then the solution is asymptotically stable for
_

Sec. 3,3

89

Sensitivity and Robustness

The main obstacle to using the Lyapunov theory is finding a suitable Lyapunov
function. This is in general a difficult problem; however, for the linear system
of (3.2L it is straightforward to determine quadratic Lyapunov functions . Take
V(x) = xT Px as a candidate for a Lyapunov function. The increment of V is
then given by
~ V(x)

= V(<1>x) - V (x) ;:: xT <1>TP<1lx - xT Px
;:: x T ((}>T P()> _ P)x

= _x T Qx

For V to be a Lyapunov function, it is thus necessary and sufficient that there
exists a positive definite matrix P that satisfies the equation

<1>TP<1> - P = - Q

(3.9)

where Q is positive definite. Equation (3.9) is called the Lyapunov equation. It
can be shown that there is always a solution to the Lyapunov equation when
the linear system is stable. The matrix P is positive definite if Q is positive
definite. One way of determining a Lyapunov function for a linear system is
to choose a positive definite matrix Q and solve the Lyapunov equation. If the
solution P is positive definite then the system is asymptotically stable.
Example 3.6 Lyapunov function
Consider the discrete-time system

x(k + 1) = ( 0.4 0) x(k)
- 0.4 0.6
Using

Q=

(~ ~)

gives the solution of the Lyapunov equation

p

= (1.19
-0.25

- 0.25 )
2.05

Figure 3.9 shows the level curves of V(x ) = xT Px and trajectories for some starting

values of x. The trajectories are such that for each step, the state is reaching a
value of V with a lower value.
_

3.3 Sensitivity and Robustness
It is of interest to investigate the sensitivity of a system to perturbations, which
may be introduced because of component tolerances. Because the designs of control systems are based on simplified models, it is also interesting to know how
accurate the model has to be for the design to be successful. The Nyquist theorem can give good insight into these problems. In this section we will investigate
the sensitivity of the closed-loop system to disturbances and perturbations in
the components of the system.

Analysis of Discrete-Time Systems

90

~'"

2 0

Chap. 3

.

....
~

00.

o

-2

2

State Xl
Figure 3.9 Level curves of V(x} and trajectories for different initial values
of the system in Example 3.6. The sampling points are indicated by dots.

Sensitivity
We will first determine the sensitivity of a closed-loop system with respect
to changes in the open-loop pulse-transfer function. Consider the system in
Fig. 3.10. The closed-loop system has a feedforward filter Hrr from the reference
signal and a feedback controller H {h' There are also an input load disturbance
v and measurement noise e. The primary process output is x, and the measured
signal is y. The pulse-transfer operator from the inputs to y is given by

HffH
y;;;; 1 + L

1

H

Ur

+ 1 +L v + 1 + L e

where the loop-transfer function is defined as L

= HrbH. The closed-loop pulse-

v

e

H

-HfQ
Figure 3.10 Closed-loop system withfeedback and feedforward controllers.

Sec . 3.3

91

Sensitivity and Robus1nes5

transfer function from the reference signal Ur to the output y is
HffH
H cl = 1 + £

The sensitivity of HcI with respect to variations in H is given by

an;

Hr
= (1 +f£)'2
dH

The relative sensitivity of Bel with respect to H thus can be written as

1 dH _ SdH
HcJ - 1 + £ H - H

dBeI _

The pulse-transfer function S is called the sensitivity function and also can be
written as

s = _1_ = dlogHcl
1+ L

dlogH

(3.10)

The transfer function

£

t[=l-S=-

1+£

(3.11)

is called the complementary sensitivity function.
The different transfer functions from the inputs uc , V, and e to the signals Y
X, and u show how the different signals are influenced by the input signals. The
sensitivity function can be interpreted as the pulse-transfer function from e to
y or as the ratio of the closed-loop and open-loop pulse-transfer functions from
l! to y. The complementary sensitivity function is the pulse-transfer function
with opposite sign from e to x.
I

Robustness

We will now consider the situation when the design of the controlleris based on
the nominal model H, but the true open-loop pulse-transfer function is UO(z).
The closeness of B to If1 needed to make the closed-loop system stable is of
concern. Consider the simple closed-loop system in Fig. 3.10with H(z) replaced
by HO(z}. The pulse-transfer function of the closed-loop system is
HrrHO (z)
Hcl(Z) = 1 + £O(z)

(3.12)

The poles of the closed-loop system are thus the zeros of the function
f(z)

= 1 + Hfb(z)Ho(z)

= 1 + Hfb(z)H(z} + Hrb(z)Ho(z) - Hf/){z)H(z)
= 1 + Hfb(z)H(z) + Hfb(Z)[Ho(z) - H (z)]

92

Analysis of Discrete-Time Systems

Chap. 3

If

on the unit circle, then it follows from the principle ofvariation ofthe argument
that the differences between the number ofpoles and zeros outsidethe unit disc
for the functions 1 + L and 1 + £0 are the same.
The relative precision needed for stability robustness is obtained by dividing (3.13) by L
' HO(z)
l

- H(z) < 1 + L ;;; ~I
H
L
'T

r

where the last equality is obtained from (3.11). The complementary sensitive
function thus makes it possible to determine bounds for stability robustness.
The following theorem results.
Consider the closed-loop systems S and SO
obtained by applyingunit negative feedback aroundsystemswith pulse-transfer
functions Hand HO respectively. The system SO is stable if the following conditions are true:
THEOREM 3.5 ROBUSTNESS 1
I

1. S is stable.

2. Hand HO have the same number ofpoles outside the unit disc.
3. The inequality (3.13) is fulfilled for

'zl == 1.

•

The result shows that it is important to know the number ofunstable modes in
order to design a regulator for the system. The theorem is, however, conservative. The inequality also gives the frequency range in which it is important to
have a good description of the process. Notice in particular that the precision
requirements are very modest for the frequencies where the loop gain is large.
Good precision is needed for frequencies where HO{z) ~ -1.
A closely related result that gives additional insight is obtainedas follows.
The pulse-transfer function ofthe closed-loop system given in (3.12) can also be
written as
H _
cl -

1
1 + 1/£0

The poles ofthe closed-loop system are thus given by the zeros of the function

sec. 3.4

Controllability, Reachabllity, Observability, and Detectability

93

It follows from the principle of variation of the argument that the differences
between the zeros and poles outside the unit disc of the functions 1 + 1/ LO and

1 + 1/L are the same if
(3.14)
on the unit circle. The following result is thus obtained.
THEOREM 3.6 ROBUSTNESS 2

Consider the closed-loop systems Sand
SO obtained by applying unit negative feedback around systems with the pulsetransfer functions Hand HO , respectively. The system SO is stable if the following conditions are true:

1. S is stable.

2. H and HO have the same number of zeros outside the unit disc.
3. The inequality (3.14) is fulfilled for Izi = 1.

•
The theorem indicates the importance of knowing the number of zeros
outside the unit disc. The theorem shows that stability can be maintained in
spite of large differences between Hand HO provided that the loop gain is large.
From the conclusions of Theorems 3.5 and 3.6, the following rules are
obtained for design of a feedback system based on approximate or uncertain
models.
It is important to know the number of unstable poles and zeros.
It is not important to know the model precisely for those frequencies for
which the loop gain can be made large.
It is necessary to make the loopgain small for those frequencie s for which
the relative error Sli / H is large.

It is necessary to have a model tbat describes the system precisely for
those frequencies for which HO(z) ~ -1.

3.4 Controllability, Reachability, Observability, and Detectability
In this section, two fundamental questions for dynamic systems are discussed.
The first is whether it is possible to steer a system from a given initial state
to any other state. The second is how to determine the state of a dynamic
system from observations of inputs and outputs , These questions were posed
and answered by Kalman, who also introduced the concepts of controllahility
and observability.The systems are allowed to he multiple-input-multiple-output
systems.

Analysis of Discrete-Time Systems

94

Chap. 3

Controllability and Reachability
Consider the system
x(k + 1) = <J)x{k) + ru(k)
y(k) ::; Cx(k)

(3.15)

Assume that the initial state x(O) is given. The state at time n, where n is the
order of the system, is given by
x(n) = <J)nx(O) + $n-1ru(O) + . .. + ru(n - 1)
= <J)llx (O) + WcU

(3.16)

where

We =

u=

(r <fir ...
(uT(n-l) ...

<J)n-lr)

UT(O))T

[Compare with Eq. (2.17).] If We has rank n, then it is possible to find n equations from which the control signals can be found such that the initial state is
transferred to the desired final state x(n). Notice that the solution is not unique
if there is more than one input signal. In the literature. controllability is defined
in different ways; the following definition will be used in this text.

3.7 CONTROLLABILITY The system (3.15) is controllable if it
is possible to find a control sequence such that the origin can be reached from
any initial state in finite time.
_
DEFINITION

A concept related to controllability is reachability, which is defined as follows.
DEFINITION 3.8 REACHABILITY
The system (3.15) is reachable if it is
possible to find a control sequence such that an arbitrary state can be reached

from any initial state in finite time.

_

The two concepts, however, are equivalent if <J) is invertible. Reachability will
be discussed here primarily. Controllability does not imply reachability, which
is seen from (3.16) . If <J)nx(O) = 0, then the origin will be reached with zero
input but the system is not necessarily reachable.
The following theorem follows from the preceding definition and calculations.
THEOREM 3.7 REACHABILITY
if the matrix We has rank n.

The system (3.15) is reachable if and only

-

Remark. The matrix We is usually referred to as the controllability matrix because of its analogy with continuous-time systems.

Controllability, Reachability, Observability, and Delectability

Sec.3.4

95

Example 3.7 A controllable system which is not reachable

The system
x(k + 1)

= <f>x(k) t

ru(k)

where

r=

(~)

is reachable because

has full rank.. Assume that

r is changed to )"""1' = (0 1); then

and the system is not reachable. The system is, however, controllable because
<1>2 ; 0, The origin is reached in two steps for any initial condition by using
u(O) = u(l) O.
•

=

By the Cayley-Hamilton theorem it is found from (3.16) that all states that can
be reached from the origin are spanned by the columns of the controllability

matrix We. This implies that the reachable states belong to the linear subspace
spanned by the columns of We'
E1BID.ple 3.8 Reachable subspaces
Given the system
x(k +

1) = (-:'25

~)

x(k) + [ .

~.5 )u(k)

x(O)

is it possible to find a control sequence such that xT (2)

(3.16),
x(2) ;;:

q,2 X (O
)

+ cbru(O) + fu(l)

or

which gives the condition
O.5u(O) + u(l) = -4

= (~)

= (-0.5

i)? From

Analysis of Discrete-Time Systems

96

Chap. 3

One possible sequence of controls is u(O) == -2 and u(l) -3. Assume instead
that xT (2) "" (0.5 1). This gives the system of equations
.::0

)
(-3
2

= (

1) (0.5u(O) + u(l))'

-0.5

which does not have a solution. The reason, of course, is that the system is not

reachable. The controllability matrix is
We ""

1 0
.5)
(-0.5 -0.25

By starting at the origin, it is possible to reach only those points of the state space
that belong to the subspace spanned by the vector [1 - O.5]T. In the example. it

is possihle to reach other points due to the effect of the initial value.

_

Assume that new coordinates are introduced by a nonsingular transformation
matrix T (compare with Sec. 2.5) . In the new coordinates,

We = (r &f ... tiJ n 1f'

)

T~T-1Tr ...

= (Tr
=TWc

Tq,n-1 T - I Tr )

(3.17)

If We has rank n, then We also has rank n. This means that the reachability of
a system is independent of the coordinates.

Controllable Canonical Form
Assume that t1J has the characteristic equation
det( AI - e)

=An + a 1A. 11-1 + ." + an

=::

0

(3.18)

and that We is nonsingular. Then there exists a transformation such that the
transformed system is

- an- l

-an

1

1

-a2
0

0

0

0

0

1

0

0

-a1

z(k + 1) =

z(k) +

a

u(k)

(3.19)
0

y(k) =

(b

I

1

0
...

bn

)

0

0

z(k)

which is called the controllable canonical form. The advantage of this form
is that it is easy to compute the input-output model and to compute a statefeedback-eontrol law. There are simple ways of finding the transformation to
controllable canonical form.

Sec. 3.4

Controllability, Reachability. Observability, and Delectability

97

For a single-input system it follows from (3.17) that the transformation
matrix to the controllable canonical form is T ::: We W;l, where We is the controllability matrix for the representation (3.19). The following example shows
that the inverse of the controllability matrix has a simple form.
Example 3.9 The inverse of the controllability matrix
Consider the third-order system
-al

x(k +l)=

[

~

-a2 -a

~

~

J
]

x(k} +

[1 u(k)
]
~

which is in controllable form. The controllability matrix is

w = (r er
,

<1>'

r) = ( ~

1

o

The inverse is given by

The example can be generalized to the nth-order case, where
1 al

a~

1

al

0 0

0

0 0

0

0

W-1 t
-

•
Trajectory Following

From the preceding definitions and calculations, it is possible to determine a
control sequence such that a desired state can be reached after at most n steps of
time. Does reachability alsoimply that it is possible to follow a given trajectory
in the state space? Assume that any x(k) is given and that it is necessary to
get to X(Jl + 1). From (3.16) it can be seen that this is possible only if r has
rank n, that is, it is necessary but not sufficient to have n input signals, For
a single-input-single-output system it is, in general, possible to reach desired
states onlyat each nth sample point, provided that the desired pointe are known
11 steps ahead.

98

Chap. 3

Analysis of Discrete-Time Systems

It is easier to make the output follow a given trajectory. Assume that the
trajectory is given by ur(k}. The control signal u then should satisfy

y(k)

B(q)

= A(q) u(k):::

uc(k)

or

(3.20)
Assume that there are d steps of delay in the system. The generation of u (k) is
then causal only if the desired trajectory is known d steps ahead. The control
signal then can he generated in real time. The control signal thus is obtained by
sending the desired output trajectory through the inverse system AIB . Equation
(3.20) has a unique solution ifthe signal uc(k) is such that there exists a ko such
that u(k) ~ 0 for all k < ko (compare with Sec. 2.6). The signal u is bounded if
u{' is bounded and if the system has a stable inverse.

ObservabUityand Detectabillty
Th solve the problem of finding the state of a system from observations of the
output, the concept of unobservable states is introduced.
DEFINITION 3.9

UNOBSERVABLE STATES

The state x O f. 0 is unobservable

if there exists a finite k 1 ~ n - 1 such that y(k)
x(O) = xO and u(k) ~ 0 for 0 5 k ~ kt •

~

0 for 0

~

k

'$

k I when
•

The system in (3.15) is observable if there is a finite k such that knowledge of
the inputs u(O) , ... ,u(k - 1) and the outputs y(OL ... ,y(k -1) is sufficient to
determine the initial state of the system. Consider the system in (3.15). The
effect of the known input signal always can be determined, and there is no loss
of generality to assume that u(k) .;. O. Assume that y(O),y(l) , ... ,y(n - 1) are
given. This gives the following set of equations:
y(O) = Cx(O)

y(l ) = Cx(l) = C<t>x(O)

Using vector notation gives

y(O)

C
C<t>

y(l)
x(O)

C<t>n-l

=

(3.21)

y(n - 1)

Sec, 3.4

Controllability, Aeachability, Observability, and Detectability

99

The state x{O} can be obtained from (3.21) if and only if the observability matrix

C
C¢:

(3.22)

has rank n. The state x(O) is unobservable if x(O) is in the null space of WOo If
two states are unobservable, then any linear combination is also unobservable;
that is, the unobservable states form a linear subspace.
THEOREM

3.8 OnSERVADILlTY

The system (3.15) is observableifand only

if Wn has rank n..

_

A system is detectable if the only unobservable states are such that they decay to the origin. That is, the corresponding
eigenvalues are stable.
_
DEFINITION 3.10 DETECTABILITY

The test of observahility given by Theorem 3.8 is equivalent to that of observability for continuous-time systems. It is straightforward to show that the observability matrix. is independent of the coordinates in the same way as in the
controllability matrix.
Example 3.10 A system with unobservable states
Consider the system
1.1
x(k + 1) '" ( 1

y(k) =

-0.3)
0
x(k}

(1 -0.5)

x(k)

The observability matrix is

w_(
(} -

C ) _ (1 -0.5 )
Gel> - 0.6 -0.3

The rank of W is I, and the unobservable states belong to the null space ofW ,
ll
o
that is, [0.5 1]. Figure 3.11 sbows the output for four different initial states.
All initial states that lie on a line parallel to [0.5 1] give the same output [see
Fig. 3.11(b) and (d)\.
_

Observable Canon~cal Form
Assumethat the characteristic equation of <I> is (3.18) and that the observability
matrix Wf) is nonsingular. Then there exists a transformation matrix such that

100

Analysis of Discrete-Time Systems
(a)

(b)

2

o4ol

2

='
Q.
"'5 1

0

o

10

0
(c)

....

(d)
•

::l

+>

•

<3

•

•

•

.... 2
Q.

+>

0

10

0

2

Po.
=1

.

•

•
'
0 .. ...... .. ~ . .

.

Chap. 3

0

•

6

• • •

0

.

10

0

1
•

•
o ...,.... , ,' 0..' , , . 0.• .•. ' •. •
o
10

Time

Time

Figure 3.11 The output ofthe systemin Example 3.10 for the initial states
(a) 10.5 IV I {b} i1.5 O.5}T, {c) 12.5 0IT, and (d) [1 - 0.5I T •

the transformed system is
1 0

-a201

0

z{k + 1) =:

z(k) +
-Un-l

0 0

1

-an
y(k)

bi
b2

0

-al

0 0

0

= (1

u(k)

bn- 1
bn

(3.23)

0 .. . 0) z(k)

which is called the observable canonical form. This form has the advantage that
it is easy to find the input-output model and to determine a suitable observer.
The transformation in this case is given by

T=
where

w;-1 w,

W is the observability matrix for the representation (3.23).
o

Remark.

The observable and controllable forms are also called compan-

ion forms .
Example 3.11 A second-order system
Consider the following system, which is written in observable canonical form:

x(k + I} ==
y{k) =

t;
-Uz

1) r(k) + (bz
0
b

(I 0) x{k)

t

)

u(k}

Sec. 3.4

Controllability, Reachability, ObselVability, and Delectability

101

The pulse-transfer operator is

Thus the OJ'S and bl's in the canonical form are defining the polynomials A and
B I respectively. This is true for nth-order systems also, in both observable and

controllable form.

I

Kalman's Decomposition

The reachable and the unobservable parts ofa system are two linear subspaces
of the state space. Both subspaces are independent of the coordinates in the
state space. Kalman showed that it is possible to introduce coordinates such
that a system can be partitioned in the following way:

x(k + 1)

=

<1l n
0

<1>12
<1>22

<I>:u <Il 32
0 <D 42

r1

0
0

0
0

<1>33

<1>34

fa

0

<1>44

0

x(k) +

0

u(k)

y(k) == ( C1 C2 0 0) x(k)

where <1lib fi. and C; are matrices of suitable orders. The state space is partitioned intofour parts!which correspond to states that are reachable and observable! not reachable but observable, reachable and not observable! and neither
reachable nor observable.
By simple algebraic manipulations, the pulse-transfer operator is given by

The pulse-transfer operator is thus determined by the reachable and observable
part of the system. The following theorem summarizes these results.
3.9 KALMAN'S DECOMPOSlTION A linear system can be partitioned into four subsystems with the following properties:
THEOREM

Sor Observable and reachable subsystem
Sor Observable but not reachable subsystem

Sor Not observable but reachable subsystem

So; Neither observable nor reachable subsystem

Analysis of Discrete-Time Systems

102

Chap. 3

ul-~---------I)'

Sor

I)=:~~)

I

I

G

I
L

I
I

:

--l

Figure 3.12 Block diagram of the Kalman decomposition when the system
is diagonalizable.

Further, the pulse-transfer function of the system is uniquely determined hy
the subsystem that is both observable and reachable.
A block diagram for the decomposition is given in Fig. 3.12, which shows how
the subsystems are interconnected. The figure also shows that the input-output
relationship is given only by the subsystem S~, .

Loss of Reachablllty and Observabllity Through Sampling
Sampling of a continuous-time system gives a discrete-time system with system
matrices that depend on the sampling period. How will that influence the reachability and observability of the sampled system? To get a reachable discrete-time
system, it is necessary that the continuous-time system also be reachable, because the allowable control siguals for the sampled system-c-piecewise-conatant
signals-are a subset of the allowable control signals for the continuous-time

system.
However, it may happen that the reachability is lost for some sampling periods. The conditions for unohservability are more restricted in the continuoustime case because the output has to he zero over a time interval, whereas the
sampled-data output has to be zero only at the sampling instants. This means
that the continuous output may oscillate between the sampling times and reo
main zero at the sampling instants. This condition is sometimes called hidden
oscillation. The sampled-data system thus can he unobservable even if the corresponding continuous-time system is observable.
The harmonic oscillator can be used to illustrate the preceding discussion.

Example 3.12 Loss of reachability and observability
The discrete-time model of the harmonic oscillator is given by (see Example A.3)
x(kh + h) '"

y{kh)::;

(

COS wh
sin wh )
) ( 1 - coswh )
x(kh +
u(k)
- sin wh cos wh
sin wh

(1 0) x(kh)

Sec. 3.5

Analysis of Simple Feedback Loops

103

The determinants of the controllability and observability matrices are

det W == -2sinwh(1- c05wh)
(.
and

det Wo

= sinwh

Both reachability and observability are lost for wh =nx, although the corresponding continuous-time system given by (A.7) is both controllable and observable. _

The example shows one obvious way to lose observability and/or reachability, If
the sampling period is half the period time (or a multiple thereof) ofthe natural
frequency of the system, then this frequency will not be seen in the output.
The rules ofthumb for the choice of the sampling period given in Chapter 2
are such that this situation should not occur. The rules imply about 20 samples
per period, not 2.
Observability and/or reachability are lost when the pulse-transferoperator
has common poles and zeros. The poles and zeros are functions of the sampling
interval. This implies that there will be common factors only for isolated values
of the sampling period. A change in sampling period will make the system
observable andlor reachable again.

3.5 Analysis of Simple Feedback loops
In this section the effect of feedback on stability, transient, and steady-state
behavior is discussed. Simple feedback systems, as in Fig. 3.10, are primarily
considered. Several advantages are obtained by using feedback in continuoustime as well as in discrete-time systems. Feedback, for instance, can do the
following:
• Improve the transient behavior of the system
• Decrease the sensitivity to parameter changes in the open-loop system
• Eliminate steady-state errors if there are enough integrators in the openloop system
• Decrease the influence of load disturbances and measurement errors
The stability of closed-loop systems can be investigated using the tools
given in Sec. 3.2. The root locus method is a suitable tool for analyzing simple feedback loops. Because feedback will change the poles of the system, it is
important to understand the coupling between the discrete-time poles and the
transient behavior of the system. This is treated in Sec. 2.8.
Character of Disturbances
It is customary to distinguish among different types of disturbances, such as

load disturbances, measurement errors, and parameter variations.

Analysis of Discrete-Time Systems

104

Load disturbances. Load disturbances influence the process variables.
They may represent disturbance forces in a mechanical system-for example,
wind gusts on a stabilized antenna, waves on a ship, load on a motor. In process
control, load disturbances may be quality variations in a feed flow or variations
in demanded flow. In thermal systems, the load disturbances may be variations
in surrounding temperature. Load disturbances typicallyvary slowly. They may
also be periodic-for example, waves in ship-control systems.
Measurement errors. Measurement errors enter in the sensors. There
may be a steady-state error in some sensors due to errors in calibration. However, measurement errors typicallyhave high-frequency components. There may
also be dynamic errors because of sensor dynamics. There may also be complicated dynamic interaction between sensors and the process. Typical examples
are gyroscopic measuremente and measurement of liquid level in nuclear reactors. The character of the measurement errors often depends on the filtering in
the instruments. It is often a good idea to look at the instrument and modify
the filtering so that it fits the particular problem.
Parameter variations. Linear theory is used throughout this book. The
load disturbance and the measurement noise then appear additively. Real systems are, however, often nonlinear. This means that disturbances can enter in
a more complicated way. Because the linear models are obtained by linearizing
the nonlinear models, some disturbances then also appear as variations in the
parameters of the linear model.

Stmple Disturbance Models
There are four different types of disturbances-impulse, step, ramp, and sinusoid-that are commonly used in analyzing controlsystems. These disturbances
are illustrated in Fig. 3.13 and a discussion of their properties follows.

The Impu1se and the pulse. The impulse and the pulse are simple idealizations of sudden disturbances of short duration. They can represent load
disturbances as well as measurement errors. For continuous systems, the disturbance is an impulse (a delta function) ; for sampled systems, the disturbance
is modeled as a pulse with unit amplitude and a duration ofone sampling period.

Pulse

Step

Ramp

Sinusoid

Figure 3.13 Idealized models of simple disturbances.

Sec. 3.5

105

Analysis of Simple Feedback Loops

Jl

u('

Hrlq)

L

y

e
H(q)

-1

r--

Figure 3.14 Generation of the reference value using a dynamic system
with a pulse input.

The pulse and the impulse are also important for theoretical reasons because the response of a linear continuous-time system is completely specified by
its impulse response and a linear discrete-time system by its pulse response.

The step.

The step signal is another prototype for a disturbance (see
Fig. 3.13). It is typically used to represent a load disturbance or an offset in a
measurement.

The ramp.

The ramp is a signal that is zero for negative time and increases linearly for positive time (see Fig. 3.13). It is used to represent drifting measurement errors and disturbances that suddenly start to drift away.
In practice. the disturbances are often bounded; however, the ramp is a useful
idealization.

The sinusoid.

The sine wave is the prototype for a periodic disturbance.
Choice of the frequency makes it possible to represent low-frequency load disturbances, as well as high-frequency measurement noise.

Generation of disturbances.

It is convenient to view disturbances as
being generated by dynamic systems (see Fig. 3.14). It is assumed that the
input to the dynamic system is a unit pulse ok, that is,

In order to generate a step, use Hr(q) = q/(q - 1); to generate a ramp, use
Hr(q) :::: qj(q - 1)2, and a sinusoid from a harmonic oscillator (compare Exampies A.l and A.3 in Appendix A). From an input-output viewpoint, disturbances
may be described as impulse responses. Disturbances also may be regarded as
the responses of dynamic systems with zero inputs but nonzero initial conditions. In both cases the major characteristics of the disturbances are descrihed
by the dynamic systems that generate them. The approach, of course, can be
applied to continuous-time, as well as discrete-time, systems.

Analysis of Discrete-TIme Systems

106

Chap. 3

Steady-State Values
When analyzing control systems, it is important to calculate steady-state values
of the output and of the error of the system. Assume a simple feedback system,
as shown in Fig. 3.5. To generalize, it can be assumed that -1 in the feedback
path is replaced by - H fb (q). The error e (k) is then given by
e(k)

=

1
1
1 + H(q)Hfb(q) uc(k) :: 1 + L(q) uc(k)

(3 .24)

The final-value theorem (Sec. 2.7, Table 2.2) can be used to calculate the
steady-state value of e (k). Notice, however, that the stability of the system must
be tested before the final-value theorem can be used. If the input signal is a
step, the steady-state error can be calculated simply by putting q :: 1 in (3.24).
The number of integrators in the open-loop system determines the class of
reference values that can be followed without steady-state errors. If the openloop system has p integrators, then the error will be zero in steady state (provided that the closed-loop system is asymptotically stable) for reference signals
that are polynomials in k of order tess than or equal to p - 1.
Example 3.13 Steady-state errors for step and ramp inputs
Consider the system

~~)~: _ 1) u(k)

y(k) ::: H{q)u(k} ;;; (q _
Closing the system , as in Fig. 3.5, gives

e(k)

:0'

(q - 0.8)(q - 1)
(q _ 0.8)(q _ 1) + q _ 0.5 uc(k)

Assume that Uc is a unit step, Because the dosed-loop system is stable, the finalvalue theorem can be used to show that the steady-state error is zero. This can be
seen simply by putting q '" 1. Another way is to observe that the open-loop system
contains one integrator, that is, a pole in + 1. If Ur is a unit ramp, use Table 2.3 in
Sec. 2.7 to find the a-transform of tbe ramp, The steady-state error is then given

by
·
Inn C(k)

k .... x

:;

I'

im

z-.. 1

(z - O.8)(z - 1)
z{l- Z-I)
~
.
'" 0 4
(z - O
.8)(z - L) + z - 0.5 (z - 1)2
.

•

Simulation
Simulation is a good way to investigate the behavior of dynamic systems-for
example, the intersample behavior of computer-controlled systems. Computer
simulation is a very good tool, but it should be remembered that simulation and
analysis have to be used together. When making simulations, it is not always
possible to investigate all combinations that are unfavorable, for instance, from

Sec. 3.5

107

Analysis of Simple Feedback Loops

the point of view of stability, observability, or reachability. These cases can be
found through analysis.
It is important that the simulation program be so simple to use that the
person primarily interested in the results can he involved in the simulation and
in the evaluation of the simulation results.
In the beginning of the 1960s, several digital simulation packages were developed. These packages were basically a digital implementation of analog simp
ulation. The programming was done using block diagrams and fixed-operation
modules. Later programs were developed in which the models were given directly as equations.
It is important to have good user-machine communication for simulations;
the user should be able to change parameters and modify the model easily. Most
simulation programs are interactive, which means that the user interacts with
the computer and decides the next step based on the results obtained so far.
One way to implement interaction is to let the computer ask questions and the
user select from predefined answers. This is called menu-driven interaction.
Another possibility is command-driven interaction, which is like a high-level
problem-solving language in which the user can choose freely from all commands
available in the system. This is also a more flexible way of communicatingwith
the computer, and it is very efficient for the experienced user, whereas a menudriven program is easier to use for an inexperienced user.
In a simulation package, it is also important to have a flexible way of
presenting the results , whicb are often curves. Finally, to be able to solve the
type of problems of interest in this book, it is important to be able to mix
continuous- and discrete-time systems.
Examples ofsimulation packages are MATLAB® with SlMULINl\..@, MATRIXX®'
and Simnon®. Becausetbese packages are readily available we will not describe
any of them in detail. However, we urge the reader to use simulation to get a
good feel for the behavior of the computer-controlled systems that are described
in the text. For the figures in the book we have used MATLAB® with SrM1JLIN~.
Macros for these figures are available through anonymous ftp; see the Preface
of the book.

Control of the Double Integrator
The double integrator (Example A.l) will be used as the main example to show
how the closed-loop behavior is changed with different controllers. The pulsetransfer operator of the double integrator for the sampling period h = 1 is

H ( ) := 0.5(q + 1)
oq
(q _ 1)2

(3.25)

Assume that the purpose of the control is to make the output follow changes in
the reference value. Also assume that the process is controlled by a computer
using proportional feedback, that is,

u(k) = K(uc(k) - Y(k))

= Ke(k)

K> 0

Analysis of Discrete~Time Systems

108

Chap. 3

2

lJl

.~

e:
~
s=

0 ~--t------+--"""""'--£)

'bn
td

e

~

-2

-6

-4

-2
Real axis

o

Figure 3.15 The root locus of(3.26) when K

2

;>

O.

where U c is the reference value. The characteristic equation of the closed-loop
system is
(q - 1)2 + O.5K (q + 1) = q2 + (O.5K - 2)q + 1 + O.5K

=0

(3.26)

Jury's stability test (compare with Example 3.2) gives the following conditions for stability:

1+ O < 1
.5K
1 + O > -1 + O - 2
.5K
.5K
1 + O.5K > -1- O
.5K + 2
The closed-loop system is unstable for all values ofthe gain K. The root locus
is shown in Fig. 3.15.
To get a stable system, the controller must be modified. It is known from
continuous-time synthesis that derivative action improves stability, so proportional and derivative feedback can be tried also for the discrete-time system.
We now assume that it is possible to measure and sample the velocity y and
use that for feedback; that is,

(3.27)
(see Fig. 3.16). To find the input-output model of the closed-loop system with

Sec. 3.5

109

Analysis of Simple Feedback Loops

uc

~ A-D
.....

f----

Com-

puter

--

D-A

u
t-

1

s

y
~r-

1
s

Y

~....-

Figure 3.16 Discrete-time controller with feedback from position and velocity of the double integrator.
the controller (3.27), observe that

dy

- =u
dt

Because u is constant over the sampling intervals,

y(k + 1) - y(k)

=u(k)

or

j(k) =

~1 u(k)
q-

(3.28)

Equations (3.25) , (3.27), and (3.28) give the closed-loop system

O.5K(q + 1)
y(k) = (q _ l)(q _ 1 + TdK) + O.5K(q + 1) uc(k)

(3.29)

The system is of second order, and there are two free parameters, K and Td ,
that can be used to select the closed-loop poles. The closed-loop system is stable
if K > 0, Td > 0.5, and TdK < 2. The root locus with respect to K of the
characteristic equation of (3 .29) is shown in Fig. 3.17 when Td = 1.5.
Let the reference signal be a step. Figure 3.18 shows the continuous-time
output for four different values of K . The behavior of the closed-loop system
varies from an oscillatory to a well-damped response. Wh.en K = 1, the poles
are in the origin and the output is equal to the reference value after two samples.
This is called deadbeat control and is discussed further in Chapters 4 and 5.
When K > It the output and the control signal oscillate hecause of the discretetime pole on the negative real axis. The poles are inside the unit circle if K <
4/3.
Th determine the closed-loop response, it is important to understand the
connection between the discrete-time poles and the response of the system. This
is discussed in Sec. 2.8. From Fig. 2.8 it can be seen that K = 0.75 corresponds
to a damping of ~ = 0.4. The distance to the origin is a measure of the speed
of the system.
The behavior of the double integrator with some simple controllers has
been discussed; the results can be generalized to more complex systems. Also,
the importance of analysis and simulation has been illustrated.

Analysis of Discrete-Time Systems

110

Chap. 3

1

..:<
.

III

ell

t

~
C

"

.

O~--------+-""""'--~~"""---8

'6'0
1,';\
...
l::

-1

-2

o

-1

1

Real axis
Figure 3.17 The root locus of the characteristic equation of the system in
(3.29) with respect to the parameter K when T,i '" 1.5.

Practical Aspects of the Choice of the Sampling Per;od
Selection of the sampling period in sampled systems is a fundamental problem
that will be discussed several times in this book. The proper choice depends on
the properties of the signal, the reconstruction method, and the purpose of the
system. In a pure signal-processing problem, the purpose is simply to record a
signal digitally and to recover it from its samples. A reasonable criterion for
selection may then be the size of the error between the original signal and the
reconstructed signal. In signal-processing applications it can be justified to have
sampling rates of several hundred samples per period.
A rational choice of the sampling rate in a closed-loop control system
should be based on an understanding of its influence on the performance of
the control system. It seems reasonable that the highest frequency of interest
should ho closely related to the bandwidth of the dosed-loop system. The selection of sampling rates then can be based on the bandwidth Oft equivalently, on
the rise time of the closed-loop system. Reasonable sampling rates are 10 to 30
times the bandwidth, or 4 to 10 per rise time, which may seem slow in relation
to the typical signal-processing problem. Comparatively low sampling rates can
be used in control problems because the dynamics of many controlled systems
are of low-pass character and their time constants are typically larger than the
closed-loop response times. The contribution to the output from one sampling
period then depends on the pulse area; it is comparatively insensitive to the
pulse shape.

111

Analysis of Simple Feedback Loops

Sec. 3.5

(b)

(a)

,.::l

1

~

::I

a.
....

....

<5

0

1

~

~

0

0

10

0

10

0

1

...,

.;.a

~

::l

a.

0.

0

~ -1

~ -1

-2

-2
10

0
(c)
~

~

.e::l

0

(d)

:j

~

::l

1

o.
....
::l

0

0

0

11--

1
~ 0

U

0.

oS -1

10

0

10

.... 0
::I

10

0

Po

~ -1

-2

-2

10

0

Time

10

0

Time

Figure 3.18 The continuous-time output of the system in Fig. 3.16 when
Td = 1.5 and (a) K '" 0.5, (b) K ;;;; 0.75, (c) K ;;;; 1, and (d) K == 1.25.

Hidden OscUlations

Figure 3.18 shows that the continuous-time output of the process may have
oscillations that are not seen at the sampling points. These are called hidden
oscillations or intersample ripple. Simulation is an effective tool for finding hidden oscillations. The modified a-transform or (2.34) also can be used to calculate
the continuous-time output between the sampling instants; however, it is also
enlightening to do some analysis.
The intersample ripple is essentially determined by the open-loop dynamice because the system operates in open loop hetween the sampling points. 1\\'0
cases can be distinguished.
I

• Oscillation in the continuous-time output of an open- or closed-loop system
when there is no oscillation in the control signal

112

Analysis of Discrete-Time Systems

Chap. 3

• Oscillations between the sampling points caused by an oscillation in the
control signal
The first case of intersample ripple may occur if observability of the openloop system is lost due to sampling. The pulse-transfer function then has canceled poles and zeros. The effect of the canceled modes is then not seen at the
sampling instants. There may then be hidden oscillations if the continuous-time
open-loop system has oscillatory modes and if the sampling period matches the
frequency of these modes. This type of hidden oscillation occurs only for certain
values of the sampling period. A change in the sampling interval makes the
system observable and the oscillation can be seen in the sampled output. The
oscillation frequency is often lowerin the sampledsignal than in the continuoustime signaL Th detect this type of inters ample ripple, it is necessary to check
the observability of the sampled-data system (compare with Example 3.12).
Example 3.14 Hidden oscillation in an open-loop system
Consider a continuous-time system with the transfer function

1

1r

G(s) ;::; -s + -(8-+-0-.0-2--=)2""-+-Jr--=-2
+-1
Sampling this system with h ;;;;; 2 gives the pulse-transfer function

Hlz) ;;; 1- a + 0.0125
z a

z ex

where a =- e- 2 and a ;;; e-0 04 .
The oscillatory part of the continuous-time system has the frequency If and
damping of 0.02. The sampling frequency is If, which implies that the oscillation
1S sampled only once per period .
The discrete-time system is of second order and the continuous-time system
is of third order. The cancellation of poles and zeros that are oscillatory is an
indication that hidden oscillation may occur. Figure 3.19 shows the step response
of the continuous-time system. The sampling points are indicated by dots. The
system behaves like a second-order system at the sampling points. Figure 3.19
also shows the sampled output when h = 1.8. The oscillation is now clearly seen
_
in the sampled output although it now appears at a lower frequency.

The second type of hidden oscillation occurs if there are poorly damped zeros
in the open-loop system that are canceled by the controller. In this case, the
oscillation can be seen in the control signal. This type of hidden oscillation will
not be detected if the sampling period is changed, provided that the design is
still such that the process zeros are canceled.
Example 3.15 Contreller- induced hidden oscillation
The double integrator previously used in this section can be used to show how a
controller may introduce hidden oscillations. The model of (3.25) can be written as
the difference equation

y(k) ; ; ; 2,)'{k - 1) - y(k - 2) + O.5u(k - 1) + O
.5u(k - 2)

SeC. 3.5
(a)

113

Analysis of Simple Feedback Loops

2.---------------r----------,

O'--------------'----~-------'

(b)

40
o
20
2 ,...----------~------~-

04------------.....I...-~-----------J

o

20

40

Time
Figure 3.19 Step response of the system in Example 3.14. (a) Continu-

ous-time (solid line) and sampled output (dots) when (a) h '" 2; (b) h ;;;; 1.8.

Let the purpose of the control be to follow the reference trajectory ur(k). If the
control signal is chosen such 'that the right-hand side is equal to the reference
value at time k - 1, the following causal controller is obtained:
u(k)

= ~ u,(k) _ 2(2q q+l

1) y(k)

q+l

(3.30)

The closed-loop system is given by
q(q - 1)
uc(k)
(k}
Y = (q + 1)(q2 - 2q + 1 - (-2q + 1))
q(q + 1)

= q2(q + 1) u, (k) == uc(k-1)
The output is equal to the reference value after one step. By using the controller in
(3.27) with K = 1 and Td == 1.5, it took two steps. The step response and the control
signal when using the control law (3.30) are shown in Fig. 3.20. At the sampling
points, the system has the desired performance, but there is an oscillation in the
continuous-time output. This hidden oscillation is caused by the oscillation in the
control signal. It is thus important to simulate a system in order to investigate the
behavior between the sampling points.
The closed-loop system is of third order, the process has two modes. and the
controller has one mode. The zero on the stability boundary is canceled hy a pole.
This mode is not observable in the closed-loop discrete-time system. This means
that observability of the closed-loop system has been lost by an improper choice of
the controller.
_

To summarize, there are no hidden oscillations if the unobservable open-loop
modes are not oscillatory and if unstable or poorly damped process zeros are
not canceled by the regulator.

Analysis of Discrete-Time Systems

114

Chap. 3

...
=1
.....
0;:l

0

0
0

...
::3

10

5
Time

10

5

C.

C
.....

5

0

-5
0

Figure 3.20 The step response and the control signal of the double integrator when the controller of (3.30) is used.

3.6 Problems
3.1 Determine if the following equations have all their roots inside the unit disc:
(a)

Z2 -

(b)

Z3 -

(c)

z3 -

1.5z + 0.9 :;: 0
3z2 + 2z - 0.5 = 0
2z2 + 2z - 0.5 ;:; 0

+ 5z2 - O - 1.25 =0
.25z
(e) z3 -1.7z2 + 1.7z - 0.7 = 0

(d)

Z3

3.2 Consider the system in Fig. 3.5 and let

K
K >0

H(z) == z(z _ O.2)(z _ 0.4)

Determine the values of K for which the closed-loop system is stable.
3.3 Consider the system in Fig. 3.21. Assume that the sampling is done periodically
with the period h and that the D-A converter holds the control signal constantover
y
H(q}

-1

Figure 3.21 Closed-loop system for Problem 3.3.

Sec. 3.6

115

Problems

the sampling interval. 'The control algorithm is assumed to be
u(kh) ::;:

where K
is

> 0 and r

K(U~(kh -

r ) - y(kh -

r))

is the computation time. The transfer function of the process

O(s)

1

=-

s

(a) How large are the values of the regulator gain, K, for which the closed-loop
system is stable if t = 0 and r :;;; h?

(b) Compare this system with the corresponding continuous-time systems, that
is, wben there is a continuous-time proportional controller and a time delay
in the process.
3.4

Determine the Nyquist curve for the system
1

H(z) = - z-O.5
3.5

From the system
x{k + 1} =

y(k) =

(~ ~)

(~)

x(k) +

u(k)

(0 1) x(k)

the following values are obtained

=1

y(1) ;;;; 0

u(1)

y(2) :;;; 1

u(2) "" ~l

Determine the value ofthe state at k = 3.
3.6 Is the following system (a) observable, (b) reachable?
x(k + 1) = ( 0.5 -0.5) x(k) + ( 6 ) ll(k)
o 0.25
4

y{k)

= (2

-4) x(k)

3.7 Is the following system reachable?
x{k + 1) =

(~ 0~5)

x(k) +

(~ ~)

Assume that a scalar input u/{k) such that
u(k) =

(~1)

u'{k)

is introduced. Is the system reachable from ul(k)?

u{k)

Analysis of Discrete-Time Systems

116

Chap. 3

3.8 Given the system

i

X(k+l)=[~ ~lX(k)+mU(kJ
(a) Determine a control sequence such that the system is taken from the initial
stata xT (0) ""
to the origin.

(1 1 1)

{b) Which is the minimum number ofsteps that solve the problem in (a)?
(c) Explain why it is not possible to find a sequence of control signals such that
the state

(1 1 1)

T

is reached from the origin.

3.9 Verify the formula for Wc l given in Example 3.9 for an nth-order systam.
3.10 The system

x(k + 1) = «t>x(k)

+ ru(k)

has been obtained from the system
z(k + 1) = Fl(k) + Gu(k)

by a linear transformation

z =Tx
(a) Use the result in Sec. 3.4 to derive a formula for T when dim(u) :: 1 and
dim(u) = r.
(b) Use the result to solve Problem 2.7.
3.11 Determine the stability and the stationary value of the output for the system de-

scribed by Fig. 3.21 with

H(q) _ ......,.....-_1_
- q(q -0.5)
when Uc is a step function and (a) Hc(q) : : : K (proportional controller), K
(b) H~ (q) = Kqj(q - 1) (intagral controller), K > O.

> 0; and

3.12 Consider the system in Problem 3.11. Determine the steady-stata error hetween
the command signal, UC I and the output when u, is a unit ramp, that is, uc(k) ;:: k.
Assume that He is (a) a proportional controller and (b) an integral controller.
3.L3 Sample the system
G(s) ~
-

s+ 1

s2

+0.2s + 1

and determine the sampling intervals for which the response of the system will
have hidden oscillations. Verify by simulations.

Sec. 3.6

Problems

117

3.14 Consider the t ank system with the pulse-transfer operator given in Problem 2.10(b),
that is, when the system is sampled with h = 12.
(a) Introduce a controller as in Fig. 3.21. Let the command input be a step and
determine the stead y-state error when using a proportional controller K and
an integral controller KIP - q- l).
(b) Simulate the system using the controllers in (a) . Investigate the influence
of the controller gain K. Determine K such that the poles of the closed-loop
system correspond to a damping of ~ := 0.7.

3.15 Consider the system in Fig. 3.5. Derive a formula for the velocity error coefficient .
That is an expression for the steady-state error when the reference signal u,- is a
unit ramp.
3.16 Determine the values of K > 0 for which the system

y (k)

=K

4q-1 +

-2

q

1 t q' 1 + O.16q-2

u(k)

is stable under simple feedback.
3.17 Determine a coordinate transformation z

x(k + l} =
y(k);;

Tx that transfers the system

=

(~ ~)

x(k) + (:) u(k)

(5 6)

X(ll )

to controllable canonical form and to observable canonical form.
3.18 Assume that the continuous-time system (CT)

dx

dt == .4.xt Bu
y:::

ex

is sampled and gives the discrete-time system (IYr)

x(kh + h)

= lfJx{kh ) + ru (kh)

y(kh) -= Cx(kh)
Consider the following statements:

(a) CT stable
(b)
(c)
(d)
(e)

(fj
(g)

DT stable
CT unstable => DT unstable
CT stable inverse es DT stable inverse
CT unstable inverse es DT unstable inverse
CT controllable :::) DT controllable
CT observable ~ DT observable
CT pole excess r => DT pole excess r
=)

Analysis of Discrete-Time Systems

118

Chap. 3

Which statements are true for the following cases:
(i) All sampling intervals h > O.
(ii) All h > 0 except for isolated values.
(iii) Neither (i) nor (iil.
3.19 Consider the system

x(k+ 1) = [:

=:~ ~

l m
x(k) +

u(k)

Determine whether
(a) the system is reachable.
(b) the system is controllable.

3.20 Given the system
(q2 + O.4q)y(k)

=:;

u(k)

(a) Forwhich values of K in the proportional controller
u(k)

=K(uc (k) - y(k))

is the closed-loop system stable?

(b) Determine the stationary error u, - y when u; is a step and when K :::: 0.5 in
the controller in (a).
3.21 Assume that the system
y(k) -1.2y(k - 1) + O.5y(k - 2) "" OAu{k -1) + O.8u(k - 2)
is controlled by

u(k) :;:: -Ky(k)

(a) Determine for which values of K the closed-loop system is stable.
(b) Assume that there is a computational delay in the controller, that is,
u(k) ;::: - Ky(k -1)
For which values of K is the closed-loop system now stable?

3.7 Notes and References
Original papers on tests for checking if a polynomial has all its poles inside
the unit circle are Schur (1918) and Cohn (1922). Jury's test is a simplification
of the Schur-Cohn test and is found in Jury and Blanchard (1961). A simple

Sec. 3.7

Notes and References

119

proof of Jury's test is found in Astrom (1970). The use of the Lyapunov theory
tor discrete-time control systems is introduced in Kalman and Bertram (1960).
Controllability and observability are concepts introduced by Kalman in connection with analysis of optimal control systems. See Kalman (1961) and Kalman,
Ho, and Narendra (1963). The hidden oscillations and their causeare discussed
in Jury (1957) and Sanchis and Albertos (1995).
General aspects of simulation are discussed in Gordon (1969), Astrom
(1983a), Kheir (1988), Cellier (1991), and Mattsson, Andersson, and Astrom
(1993).

4
Pole-Placement Design:

A State-Space Approach
4.1 IntroductIon
This chapter presents design methods based on internal models of the system.
The methods developed in this chapter can be viewed as solutions to specific,
idealized control problems. The solutions give insight into the nature of control
problems. They also show that many of the concepts introduced earlier are useful. Control design involves compromises between conflicting goals. We capture
this by introducing so-called design parameters that have to be chosen by the
designer. See Sec. 4.2. In this chapter we will develop a collection of design
methods that are called pole placement from the point of view of state feedback. The name pole placement refers to the fact that the design is formulated
in terms of obtaining a closed-loop system with specified poles. The methods
will be developed gradually. In Sec. 4.3 we will discuss an idealized regulation
problem. It is assumed that all state variables are measured and the disturbances are widely spaced impulses. In Sec. 4.4 we will discuss the problem of
reconstructing the states from measured outputs. This leads to the introduction
of observers. By combining the observers with the state feedback obtained in
Sec. 4.3, we obtain a solution to the regulation problem for the case of output
feedback in Sec. 4.5. We will also generalize the disturbances by considering
disturbances that are obtained as outputs of dynamic systems whose inputs are
impulses. In this way we can deal with the classical cases of disturbances that
are steps and sinusoids as well as many other cases. This also gives a very
natural way to introduce integral action. So far we have only dealt with the
regulation problem. In Sec. 4.6 we will discuss the servo problem, that is, how
to obtain a system that can also follow command signals. This problem can also
be well captured in the state-space formulation. By combining tbe result with

120

Sec. 4.2

Control-System Design

121

the previous results we obtain a controller that can follow command signals
and reject disturbances acting on the system. The controller structure obtained
is very interesting because the different tasks of the controller are naturally
separated. The design procedure is illustrated in Sec. 4.7 with an application to
control of simple robotics system.

4.2 Control-System Design
Many different factors have to be considered in the design of a control system,
for example:
• Attenuation of load disturbances
• Reduction of the effect of measurement noise
• Command signal following
• Variations and uncertainties in process behavior
Loaddisturbances are disturbances that drive the process away from its desired
behavior. Measurement noise is a disturhance that corrupts the information
about the process obtained from the sensors. Process disturbances can enter
the system in many different ways. It is convenient to consider them as if they
enter the system in the same way as the control signal; in this way they will
excite all modes of the system. For linear systems it also follows from the superposition principle that the assumption is not very critical. The measurement
noise will be injected into the process through the control law. The command
signal following expresses the property of the system to respond to command
signals in a specified way.
Control prohlems can broadly speaking be classified into regulation problems and servo problems. The major issue in the regulation problem is to compromise between reduction of load disturbances and the fluctuations created
by the measurement noise that is injected in the system due to the feedback.
The command signal following is the major issue in servo problems. The major
ingredients of a design problem are
• Purpose of the system
• Process model
• Model for disturbances
• Model variations and uncertainties
• Admissible control strategies
• Design parameters
It is difficult to find design methods that consider all the preceding issues mentioned. Most design methods focus on one or two aspects of the prohlem and the
control-system designer then has to check that the other requirements are also

122

Pole-Placement Design: A State-Space Approach

u

Cnap.4

e

u

-1
Figure 4.1 Block diagram of a typical control system.

satisfied. To do this it is necessary to consider the signal transmission from command signals, load disturbances , and measurement noise to process variables,
measured signals, and control signals. This is illustrated in the block diagram
of Fig. 4.1. Compare with Fig. 3.10. In this chapter we vr.ill develop a design
method based on state models whose purpose is to obtain a specified closed-loop
characteristic polynomial ofthe system. At first sight it may seem unnatural to

specify the problem in this way. It will lead, however, to simple design methods
that will give considerable insight into the structure of good control systems.
The design method is very easy to apply for low-order systems, but it may be
difficult to choose the poles properly for systems of high order. The structure
of the controller is also the same as the one obtained with more sophisticated
design methods, which will be discussed later.
We will start with a simple design prohlem and gradually make it more
and more realistic. The problem is specified as follows.

The process. It is assumed that the process to be controlled can be
described by the model
dx
- = AxtBu

dt

(4.1)

where u represents the control variables, x represents the state vector, and A
and B are constant matrices. Further, only the single-input-single-output case
will be discussed. Because computer control is considered, the control signals
willbe constant over sampling periods ofconstant length. Sampling the system
in Eq. (4.1) by the methods described in Sec. 2.3 gives the discrete-time system

x(kk + h)

=Cl>x(kh) + ru(kh)

where the matrices CI> and r are given by

r ~ /.. eA'dsB
To simplify we will write the system as
x(k + 1) ;:: <ttx(k) t fu(k)

(4.2)

Sec. 4.2

123

Control-System Design

The argument of a signal is thus not real time but instead the number of sampling intervals. We call this the sampling-time convention. We will use real time
whenever there are possibilities for confusion.

Disturbances. Initially it will be assumed that the disturbances acting
on the process are impulses that occur irregularly, and that the impulses are
so widely spread that the system settles between the impulses. Because the
impulses are far apart and the effect of an impulse is simply to change the
process state, the disturbance can be represented hy an initial state. Later we
will extend the results to much more general disturbances that are generated
from dynamic systems whose inputs are impulses. Typical examples are steps,
ramps, and sinusoidal signals.
Process uncertainty. Uncertainties in the elements of the matrices A
and B can be dealt with in the state-space formulation, but it is not easy to deal
with other forms of unmodeled dynamics. A discussion of process uncertainties
therefore will be given later when more appropriate tools have been developed.

The criterion.

When discussing regulation problems it will be assumed
that the criterion is to hring the state to zero after perturbations in the initial
condition. In the pole-placement formulation, the rate of decay of the state is
given indirectly by specifying the poles of the closed-loop system. Servo problems
will be dealt with by requiring that the signal transmission from command
signal to process variables is close to a behavior specified by a model.

Admissible centrois.

Because feedback solutions are desired, it is necessary to specify the information available for generating the control signal.
When the properties of the system are specified by its closed-loop poles, it is
natural to require that the feedback is linear. Several different versions will be
discussed. We will start with the case when all state variables are measured
directly without error. The admissible controls are then a linear feedback of the
form

u(k) ;;: -Lx(k)

(4.3)

This assumption will be relaxed later in Sec. 4.5, where it will be assumed that
only outputs are available for control. For discrete-time systems it is also of
interest to consider the case when there are delays in the measurements.

Design parameters.

In the formal specification of the problem, the design parameters are the sampling period and the desired closed-loop poles. It
is rare that a user of a control system can give specifications in terms of these
parameters. Therefore, the designer must be able to relate the design parameters to quantities that are more meaningful to the user. For this purpose, it is
often useful to consider the time histories of the state variables and the control
variables. It is particularly useful to discuss the trade-off between the magnitude of the control signals and the speed at which the system recovers from a
disturbance.

124

Pole-Placement Design: A State-Space Approach

Chap. 4

4.3 Regulation by State Feedback
A simple regulation problem is discussed in this section. It is assumed that the
system is described hy Eq. (4.1). Initially we also assume that the sampling
period is given so that the process can be described by the discrete-time system
(4.2}. The disturbances are assumed perturbations in the initial state of the
system. The purpose is to find a linear feedback law ofthe form (4.3) so that the
closed-loop system has a specified characteristic equation, This will guarantee
that the disturbances decay in a specified way.
This problem may seem overly simplistic as a representation of a controlsystem design problem. The solution is, however, very simple and the problem
can be generalized successively to make assumptions more and more realistic.
An Example

To introduce the design method and to illustrate the influence of the design
parameters, a special case is first discussed.
Example 4.1 Pole placement for the double-integrator plant
By using the sampling-time convention, the sampled double-integrator plant is
described by
2j2

1 1
x(k + 1} "" ( 0 h) r (k) + ( h h ) u(k}

A general linear feedback can be described by

Witb this feedback, the closed-loop system becomes

The characteristic equation of the dosed-loop system is

Assume that the desired characteristic equation is
z~ + P12 + P2 ::: 0

This leads to the following linear equations for II and l2:

Sec. 4.3

125

Regulation by State Feedback

These equations have the solution
1

II == h2 (1 + Pl + P2)

(4.4)

1

l2 == 2h (3 + Pi - P2)
In this example it is always possible to find controller parameters that give an
arbitrary characteristic equation of the closed-loop system. The linear system of
equations for i 1 and 1 has a solution for all values of Pi and pz.
•
2

The General Case
The solution of the pole-placement problem now will be given for systemswith
oneinput signal. Let the system be described by (4.2) and let the characteristic
polynomial of the matrix ep be

Assume that the system (4.2) is reachable. It then can be transformed to reachable canonical form by changing state variables through the transformation
z :: T'x, and the transformed state equation becomes

(4.5)

z(k + 1) = cPz(k) + tu(k)
where
1

o
o
o

o

0
0

1

o

o

f=

0

(4.6)

o

The coefficients of the characteristic polynomial that determines the closed-loop
poles appear explicitly in this representation. It is also easy to see how the
characteristic polynomial is modified by state feedback. It follows from (4.6)
that the feedback law
u

= -t: =-

(Pi - al P2 - az ... Pn - an ) z

(4.7)

gives a closed-loop system with the characteristic polynomial
P()
Z

=Zn + P1Z n-l + ... + Pn

(4.8)

'Ib find the solution to the original problem we simply have to transform back
to the original coordinates. This gives

u = -iz = -LTx :: -Lx

(4.9)

Pole-Placement Design: A State-Space Approach

126

Chap. 4

It remains to determine the transformation matrix T. A simple way of determining this matrix is based on a property of the reachabiltty matrices. Let We
be the reachability matrix of the system (4.2), that is,
W =
c

(r er ... d>1l-1r)

(4.10)

and let We be the reachability matrix of the system (4.5). The matrices are
related through W, = TWc • The reachability matrix thus transforms in the
same way as the coordinates. It thus follows that

(4.11)
and a straightforward calculation gives
1

Wc-1

-

al

o

1

(4.12)

-

001

Compare with Example 3.9. Summarizing, we find that the solution to the design problem is given by a linear state feedback with the gain

(4.13)
This equation can be expressed in a slightly different way by the following
result.
THEOREM 4.1 POLE-PLACEMENT USING STATE FEEDBACK Consider the system of (4.2). Assume that there is only one input signal. If the system is reachable there exists a linear feedback that gives a closed-loop system with the
characteristic P(z). The feedback is given by

u(k) = -Lx(k)
with

L:= (PI-at P2- a2
=

where We and
respectively.

We

. ..

Pn-an) 'Wcwe- I

(0 ... 0 1) W(;-lP(d»

(4.14)

are the reachability matrices of the systems (4.2) and (4.5),

127

Regulation byState Feedback

Sec. 4.3

To prove the result we first observe that
1
1
P(<1l) ::; cIl n +PI <1l n- + ... + PrJ =:: (PI - al)cIl n- + .,. + (Pn - an)!

Proof.

~

where q) is the system matrix of the transformed system (4.5). The second
equality is obtained by using the Cayley-Hamilton theorem. Introduce el as the
row vector that has all elements equal to zero except the ith element, which
is 1. We have

It then follows from Eq. (4.7) that

L

L ::: enP(<f»

and we get

=Lr = en p (T<1lT - 1)T = e T P(<1l ) = enWcW;lp(<f»
lt

It follows from (4.12) that ellWr- 1 = en and Eq. (4.14) is obtained.

Remark 1.

Equation (4.14) is called Ackermann's formula.

Remark 2. Notice that the pole-placement problem can be formulated as
the following abstract problem. Given matrices <1l and r, find a matrix L such
that the matrix <1l - r L has prescribed eigenvalues.

Remark 3. Notice that it follows from (4.11) and (4.12) that
T- 1

=

(r

<1lr + air .., <1l n - 1r + al<1l n - 2 + . .. + an-l r )

(4.15)

•
The theorem is illustrated by an example.
Example 4.2 Double integrator
Consider the double-integrator plant in Example 4.1. Assume that the desired
characteristic polynomial is given by P(z) =Z2 + Ptl + P2. We have

W= (r er ] ~ (h'

l:2

r

3h:/2)

and
2

w- l

-

(-1/h

r

-

1/h2

1.5!h)
-O.5/h

The characteristic polynomial of the matrix ~ is

P(<I»

Z2 -

=~2+Pl~+P21 = (1+ P1 +P2

o

2z + 1. Hence

2h+ P t h )
1 + PI + P'l,

Ackermann's formula (4.14) now gives

L

= (0 1) Wf-lp(~) = (1/h2 -O.5/h) P(<1l)
= (1 +PI + P2 3+PI - P2 )

h2
2h
which is the same result obtained by the direct calculation in Example 4.1.

•

To solve the pole-placement problem it was assumed that the system is reachable. The following example illustrates what happens when this is not the case.

Pole-Placement Design: A State-Space Approach

128

Chap. 4

Ex.ample 4.3 An unreachable system
The system
1)
1
x{k + 1) ;;;; ( 0.5 0.3 x(k) + ( 0 ) u(k)
0

is not reachable because
0
[1 0.5)

det We '" det 0
The control law u ;;;;
equation

=0

-ltXl -l'}.x~ gives a closed-loop system with the characteristic
(z - 0.5 + lil(z - 0.3) '" 0

The open-loop pole in 0.5 can be changed to an arbitrary value by changing the
parameter l l' The second pole 0.3, which corresponds to the nonreachable state,
cannot be changed.
-

Practical Aspects
It is easy to solve the pole-placement design problem explicitly. Notice that
reachability is a necessary and sufficient condition for solving the problem. To
apply the pole-placement design method in practice, it is necessary to understand how the properties of the closed-loop system are influenced by the design
parameters-that is, the closed-loop poles and the sampling period. This is illustrated by an example,
Example 4.4 Choice of design parameten
Consider the double-integrator plant. Instead of using the parameters PI and
P2 of the characteristic equation we will introduce two other parameters, which
have a more direct physical interpretation. If the desired discrete-time system is
obtained by sampling a second-order system with the characteristic polynomial
2
8 + 2' (J)S + (J)2 we find that
Pl ::: _2e-(wh COB
P2

(Wh~)

= e- 2'wh

where Cd is the natural frequency and' is the damping (compare with Exam.
ple 2.16). The parameter' influences the relative damping of the response and m
influences the response speed. To discuss the magnitude of the control signal, it is
assumed that the system has an initial position %0 and an initial velocity Vo . The
initial value of the control signal is then

If the sampling period is short, then the expressions for PI and P2 can be approximated using series expansion. The following approximation is then obteined:

u(O) ::::::

_ d/ 2XO +

2' (J}lJo

129

Regulation by State Feedback

Sec. 4.3

(b)

(a)

2

.....
.3'1 ~.,

.....

.....

:t

, '

::l

0

0

-

-

•

_

.

-

I

_

•

_

+ _

, _

J'

~

c

.....

"

0

•

0

::l

-5

10

5

15

0

10

15

10

5

15

(d)

(c)

,

.... 0
::l
c..

J--..---- -

--

0-

01

C
.....

r-:

.... 0
::l
I:l

-5

-5
0

5

10

Time

15

0

5
Time

Figure 4.2 Responses of the closed-loop system in Example 4.4. The initial
condition is xT(O) = [1 1], and the parameter values are wh =0.44 and
S ;:; 0.707. Theoutputs for sampling periods fJJ = 0.5 (dashed-dotted), ta = 1
(dashed), and w =2 (solid) are shown in (a). and the corresponding control
signals are shown in (b), (c), and (d), respectively.

The expression shows that the magnitude of the control signal increases with
increasing fJJ. Thus an increase in the speed of the response of the system will
require an increase in the control signals. If the bounds on the control signal and
typical disturbances are known, it is possible to determine reasonable valuesof OJ.
The consequences of different choices of (J) when Xo = 1 and Vo = 1 are illustrated
in Fig. 4.2, A larger OJ gives a faster system but also larger control signals.
The selection of sampling periods for open-loop systems was discussed in
Sec. 2.9. It was suggested that the sampling period can be chosen such that

where N, is the number ofsamples per rise time. Applying the same rule to closed-

loop systems we find that the sampling period should be related to the desired
behavior of the closed-loop system. It is convenient to introduce the parameter N
defined by
(4.16)
This parameter gives the number of samples per period of dominating mode of
the closed-loop system. Figure 4.3 shows the transient of the system for different
values of N. There are small differences between the responses for N > 10. The
responses obtained for N > 20 are indistinguishable in the graph.

Figure4.3 shows the response to an initial condition when an impulse disturhance has entered the system just before the sampling. In reality the disturbances
of course may enter the system at any time. With a long sampling period it will

Pole-Placement Design: AState-Space Approach

130

Chap. 4

(b)

(a)

..

:;2
::l

r' -.

.... 0
;:I
d
....

~

,_·-

0..

0

-2

0

10

5

0
(e)

~

~_I_

~

10

5
Time

10

0

::1

I

0-

C

P-

~
......

~l

I-'

5

(d)

,- ......... _---

0

0

-2

-2
0

5
Time

10

0

Figure 4.3 Responses of the closed-loop system in Example 4.4. The initial condition is xT(O) = 11 II. and the parameter values are (J) = 1 and
, = 0.707. The outputs obtained for N = 5 (dashed-dotted), N = 10
(dashed), and N = 20 (solid) are shown in (a), and the corresponding control
signals are shown in (b), (e), and (d), respectively.

then take a long time before the disturbance is detected. To illustrate this we will
repeat the simulation in Fig. 4.3 but it win be assumed that the disturbance comes
just after a sampling. This implies that the disturbance acts for a full sampling
period before it is detected, Figure 4.4shows the response ofthe system when the
system is disturbed immediately after the sampling, that is, when x(0+) ;; II 1JT .
Notice the significant difference compared with Fig. 4.3. In this casethe results for
N = 20 are much better than the results for N = 10. It is reasonable to choose N
in the range N ~ 25 to 75. This corresponds to wh = 0.12 to 0.36 for' =0.707. •

Theseexamples show that evenif we take a discrete-system point ofview by only
considering what happens at the sampling instants, it is necessary to keep the
time-varying nature ofsampledsystems in mind to make the correct assessment
ofthe results. Particular care shouldbe given to simulations used to assess the
performance ofthe systems. To investigatethe effect ofthe samplingperiod it is
useful to consider cases in which disturbances are introduced both immediately
before and immediately after the sampling instants. The differences can be quite
noticeable, as is indicated by a comparison of Figs. 4.3 and 4.4. Based on the
simulations performed we suggest that the sampling period be chosen as
wh = 0.1 to 0.6

(4.17)

where m is the desired natural frequency of the closed-loop system. Longer
samplingperiods can be used in those rare cases in which the sampling can be
synchronized to the disturbances.

Sec. 4.3

Regulation by State Feedback

(a)

~ 2
~
.....

\

I ..
\

0

-,

0

0
O~

:::l

I

=:
......

c

\

"-

0

-_.

-2

10

0

5

10

5

10

(d)

......... --

0

~

::l

l:l.
Q

H

I

-2

_._ ..

I

1-'1

I

Q.

l.._

::l

,. - , ..,
r~

._-,

0.

5

(c)

....

..., 0
\

\

;j

(b)

....

/

131

-2
10

5
Time

0

Time

Figure 4.4 Responses of the closed-Ioop system in Example 4.4. The initial condition is x r{O+) = 11 I]. and the parameter values are (U = 1
and' = 0.707. The outputs obtained for N "" 5 (dashed-dotted), N "" 10
(dashed), and N = 20 (solid) are shown in (a), and the control signals are

shown in (b), {c), and (d), respectively. The disturbance is immediately after
the first sampling. Notice the significant difference compared to Fig. 4.3.

Deadbeat Control

If the desired poles are all chosen to be at the origin, the characteristic polynomial of the closed-loop system becomes

P(z) = z"
The Cayley-Hamilton theorem then implies that the system matrix «%lc
ofthe closed-loop system satisfies

= ~- r L

This strategy has the property that it will drive all the states to zero in at most
n steps after an impulse disturbance in the process state. The control strategy
is called deadbeat control. Compare with Example 1.3 in Chapter 1.
It follows from Ackermann's formula, Eq. (4.14), that the deadbeat strategy
is given by

(4.18)
If the matrix «%l is invertible we get

Pole·Placement Design: A State-Space Approach

132

Table 4.1 Control signals for deadbeat control of a double
grator with x(O) ;:: col [1,

h

Chap. 4

inte-

11 and different sampling periods.

100

10

1

0.1

0.01

u(O)

-0.0151

-0.16

-2.5

-115

-10,150

u(h)

0.0051

0.06

1.5

105

10,050

•

In deadbeat control there is only one design parameter-the sampling period. Because the error goes to zero in at most r1 samplingperiods, the settling
time is at most nh. The settling time is thus proportional to the sampling period h. The sampling period also influences the magnitude ofthe control signal,
which increases drasticallywith decreasing sampling period. This fact has given
the deadbeat control an undeservedly bad reputation. It is thus important to
choose the sampling period carefully when using deadbeat control. The deadbeat strategy is unique to sampled-data systems. There is no corresponding
feature for continuous-time systems. The following example demonstrates some
propertiesof deadbeat control.
Bxample 4.5 Deadbeat control of a double integrator
Consider a double-integrator plant. It follows from Eq. (4.19) that the deadbeat
control strategy is given by u = -llXl -l2XZ with

3
l2 =2h
If the process has the initial state x(O);;;; collxo,vo]' it follows that

u(O)

= -Xo -3uo
- 2
h

2h

Notice that the magnitude of the control signal increases rapidly with decreasing
sampling period. Also notice that for small h, the control signals u(O) and u(h)
have opposite signs and approximately equal magnitude. The desired effect is thus
obtained as a result of subtracting two large numbers. This is further illustrated
in Table 4.1, which gives the control signals for Xo ;;; 1 and VQ ::: 1. It therefore
can be expected that the deadbeat strategy is quite sensitive for small sampling
periods. The output and the conti-ol signals are shown in Fig. 4.5. In this case the
first sampling is at t :::; 0+. The disturbance thus occurs immediately before the
sampling.
_

More General Disturbances
It is highly desirableto handle other disturbancesthan impulses or equivalently
perturbed initial states. One way to do this is to consider disturbances that are
generated by sending impulses to dynamic systems. In this way it is possible

Sec. 4.3

Regulation by State Feedback

(a)

133
(b)

5

2
+)

+)

::3

Q,

.....
:;l
0

K, '"
"
\

0

\

(c)

l::

~

-5
5

0

J' - . ., , - . - . - . - , -

0

::3

~

10

0

5

10

5
Time

10

Cd) 5

5

,. .,

~ 0
~

=-5 r-

I

...:.

--------

6.
Q

-

H

0

-5
~

0

10

5

0

Time

Figure 4.5 Responses ofthe closed-loop system in Example 4.5 with a deadbeat controller. The initial condition is xT (0) = [1 I], and the parameter
values are (}) = 1 and' = 0.707. The outputs obtained for sampling periods
h =2 (dashed-dotted), h == 1 (dashed), and h =0.5 (solid) are shown in (a),
and the control signals obtained in the different cases are shown in (b), (e),
and (d), respectively.

to capture many different types of disturbances such as steps and sinusoids. To
be specific, assume that the system is described by
dx

-

dt

==

AxtBu tv

where v is a disturbance described by

dw
dt

-=A w
W

v = Cww
with giveninitial conditions. The matrixA; typicallyhas zeros on the imaginary
axis or in the right half plane. A common case is that the disturbance u is a
constant. This is captured hy Aw ::: 0; another case is sinusoidal disturbances,
which correspond to

Aw=(

0
-roo

(00]
0

It is assumed that w can be measured. This assumption will be relaxed later.
We introduce the augmented state vector

Pole·Placement Design: AStale-Space Approach

134

Chap. 4

and we find that the system can be described by

d

dt

(X]
w

::;:

( A A w ] (X]
C
0
W
w

+

(B ] U
0

(4.20)

Thus we have a problem ofthe same form as the basic pole-placement problem.
There is, however, one important difference: The system of (4.20) is not completely reachable. The poles associated with the description of the disturbancethat is, the eigenvalues of Aw-cannot be influenced by the feedback. This is
very natural because the disturbances are exogenous variables that are not influenced by the control. Compare with Example 4.3. Sampling the system gives
the following discrete-time system:
x(k + 1)
( w(k + 1)

1= (€I>
0

<Il X lU
<Il w

1 (x(k) 1+ (r0 1u(k)
w{k)

The general linear-state feedback is given by
u(k)

='

-Lx(k) ,- Lww(k)

(4.21)

This control law gives the following closed-loop system:
x(k + 1) = (€I> - rL)x(k) + (<1>xw -

r Lw)w(k)

(4.22)

w(k + 1) = €l>ww(k)

which tells how the closed-loop system is influenced by the control. Notice that
the control law in (4.21) can be interpreted as a combination of a feedback term
Lx and a feedforward term Lww from the measured disturbances. If the pair
(<Il, f) is reachable, the matrix L can be chosen so that the matrix €I> - r L has
prescribed eigenvalues. This would ensure that the term ofthe solution that is
caused by the initial values decays properly. The matrix €l>w cannotbe influenced
by feedback. The effect of the disturbance on the vector x can, however, be
reduced by a proper choice of the vector Lw , which should be chosen 80 that
the matrix <Il xw - r Lw is small. In some cases it is possible to make this matrix
zero. We illustrate this by an example.
Example 4.6 Constant input disturbance
Consider the situation with a constant disturbance that acts on the process input.
The matrix CPw then becomes the identity and we have CPxw :;; r. The system is
described by
x(k + h) :;:; (¢I - rL)x{k) + [(1- Lw}w(h)

w(k + h)

The effect of the disturbance

=w(k}
!J

on x is thus eliminated by choosing Lu.

;;;:

1.

•

Sec. 4.4

135

Observers

Computational Aspects
The state feedback can be determined by the method used in Example 4.1 for
low-order systems. The procedure is simply to introduce a general state feedback
with unknown coefficients, determine the characteristic polynomial, and equate
it with the desired characteristic polynomial. A set of linear equations for the
feedback coefficients is then obtained. The equations can be always solved if the
system is reachable. It is also possible to use Ackermann's formula, Eq. (4.14),
to calculate the state feedback. This formula is, however, not well suited for
very precise numerical calculations. As a rule, any method using computation
of powers of matrices should be avoided. There are other ways to compute the
feedback matrix L that are better for numerical calculations. These methods
also work for rnultivariable systems. In MATLAB® there is a command place for
solving the problem that is based on sound numerical methods.

4.4 Observers
It is unrealistic to assume that all states of a system can be measured, particularly if disturbances are part of the state as in Eq. (4.20). It is therefore of
interest to determine the states of a system from available measurements and
a model. It is assumed that the system is described by the sampled model

X(ll + 1) = <l>x(k) + ru (k)
y(k) = CX(ll)

(4.23)

The problem is thus to calculate or reconstruct the state x(k) from input and
output sequences y{k), y(k - 1), .. . I u(k), u(k -I) , . .. is considered next. In
Sec. 3.4 it was shown that this is possible if the system is observable.

Direct Calculation of the State Variables
The problem was solved in Sec. 3.4 for the special case when there are rioinputs.
We will now extend this solution slightly and it will be shown that the state can
be computed directly from past inputs and outputs. For simplicity it is assumed
that there is only one output. The output y(k) ;;;; Cx(h) obtained at sampling
instant k gives one linear equation for determining the state variable. Using
information from n different sampling instants h, k - I, . .. I k - n + 1 gives the
following linear equations.

y{k - n + 1) = Cx(k - n + 1)
y(k - n + 2) ;;;; C<I>x(k - n + 1) + Cru(h - n + 1)

y(k) = C<Iln-1x(k - n + 1) + C<I>n-2 r u(k - n + 1) +... + Cru(k - 1)
(4.24)

Pole-Placement Design: AState-Space Approach

136

Chap. 4

By introducing the vectors Uk - 1 and Yk
y(k - n + 1)

y{k-n+2)

u(h-n+l)
u(k -n+2)

y(k)

u(k -1)

whose components are past inputs and outputs} Eq. (4.24) can be written as

where the matrices Wo and Wu are given by

c
Wo =

0

0

c<t>
C<t>2

cr
C«1>r

0

cr

o
o
o

C<t>"-2 r

C<t>n- 3r

cr

C4>I'I-1

Wu =

The matrix Wo is invertible if the system is observable; we can then solve for

x(k - n + 1) and ohtain

The state has thus been obtained in terms offuture outputs and measurements.
Repeated use ofEq. (4.23) gives
x(k) = <l>n-lx(k ~ n + 1) +«1>A-2 r u(k - n +1) +... + ruth -1)

and we find that
(4.25)
where

The state vector x(k) is thus a linear combination of y(k), y(k-l), .. . ,y(k-n+l)
and u(h -I}) u(k - 2L ... , u(h - n + 1). We illustrate by an example.

Sec. 4.4

137

Observers

Example 4.7 Double integrator
For the double integrator we have

Hence
y(k) '" xdk)

y(k) ==

h2

Xl

(k -1) + hX2(k - 1) + 2 u(k - I]

= y(k -1) +

h(X2(k) -

Solving these equations with respect to

Xl

h2

hu(k)) + "2 u(k -I}

and X2 we get

Xt(k) ",y(k)
x'2(k)

= y(k) -

y(k - 1) + ~ u(k _ 1)
h
2

The first component Xl is equal to the measured value and the second component
X2 is obtained by taking differences of the output and adding a fraction of the

control signal.

-

ReconatlUetion Usinga Oynamlc System

Let n be the order of the system. The direct calculation we have just performed
gives the state after at most n measurements of input-output pairs. The disadvantage of the method is that it may be sensitive to disturbances; the operations
done on the data are typically to form differences, as illustrated in Example 4.7.
It is therefore useful to have other alternatives that are less sensitive to noise.
Consider the system (4.23) . Assumethat the state x is to he approximated
by the state x of the model

x(k + I} = ~x{k) + ru(k)

(4.27)

which has the same input as the system of (4.23). If the model is perfect in the
sense that the elements of the matrices (J> and r are identical to those of the
system (4.23) and if the initial conditions are the same, then the state of the
model of (4.27) will he identical to the state x of the true system in (4.23). If
the initial conditions are different, then xwill converge to x only if the system
(4.27) is asymptotically stable.
Reconstruction by Eq. (4.27) gives the state as a function of past inputs.
The reconstruction can be improved by also using the measured outputs. This
can he done by introducing a feedback from the difference between the measured
and estimated outputs, y - Cx. Hence

x

x(k + 1[ k) = <1li(k I k -1) + fu(k) + K (Y(k) - Ci(k I k -

1))

(4.28)

138

Pole-Placement Design: A State-Space Approach

Chap. 4

where K is a gain matrix. The notation x(k + 1 I k) is used to indicate that it
is an estimate of x(k + 1) based on measurements available at time k, that is,
a one-step prediction. Notice that the feedback term K[y(k) - Cx(k I k - l)J
gives no contribution if the output predicted by the model agrees exactly with
the measurements. To determine the matrix K we introduce the reconstruction
error

x;;; x - x
~

(4.29)

Subtraction of (4.28) from (4.23) gives

.i(k +

11 k) == <Dx{k 1 k -1) -

K(Y{k) - Cx(k I k -

1)) = (~- KC).i(k

1

k -1)
(4.30)

Hence if K is chosen so that the system (4.30) is asymptotically stable, the error
i will always converge to zero. By introducing a feedback from the measurements in the reconstruction, it is thus possible to make the error go to zero even
if the system of (4.23) is unstable. The system in (4.28) is called an observer for
the system of (4.23) because it produces the state of the system from measurements of inputs and outputs. It now remains to find a suitable way to choose
the matrix K so that the system (4.28) is stable. Given the matrices <D and C ~
the problem is to find a matrix K such that the matrix ~ - K C has prescrihed
eigenvalues. Because a matrix and its transpose havethe same eigenvalues,
the problem is the same as finding a matrix K T such that cll T - CT K T has
prescribed eigenvalues. However, this problem was solved in Sec. 4.3 in connection with the pole-placement problem; see Theorem 4.1. If those results are
translated, we find then that the problemcan be solved if the matrix

has full rank . Notice that Wo is the observabilitymatrix for the system of (4.23).
The result can be expressed by the following.
4.2 OBSERVER DYNAMICS Consider the discrete system given
by Eq. (4.23). Let P(z) be a polynomial of degree n, where n is the order of
the system. Assuming that the system is completely observable, then there
exists a matrix K such that the matrix <D - K C of the observer (4.28) has tbe
characteristic polynomial P(z).
•
THEOREM

Computing the Observer Gain
The determination of the matrix K in the observer (4.28) is the same mathematical problem as the problem of determining the feedback matrix L in the
pole-placement problem. The practical aspects are alsoclosely related. The selection of the observer poles is a compromise between sensitivity to measurement

Sec. 4.4

139

Observers

errors and rapid recovery of initial errors. A fast observer will converge quickly,
but it will also be sensitive to measurement errors.
Determining the matrix K is the dual of finding the gain matrix L for pole
placement by state feedback. This problem is solved by Ackermann's formula,
Theorem 4.1. By using the relations

it follows from Equation (4.13) that K is given by

or
(4.31 )
The characteristic polynomial of cD - KC is then P(z). The duality with pole
placement also implies that K is especially simple to determine if the system
is in observable form.
Notice, however, that Ackermann's formula is poorly conditioned numerically. The MATLAB® procedure place is based on better numerical methods. This
procedure will also give the observer gain for systems with many measurements.

A Deadbeat Observer
If the observer gain K is chosen so that the matrix <I> - K C has all eigenvalues
zero, the observer is called a deadbeat observer. This observer has the property
that the observer error goes to zero in finite time) actually in at most n steps,
where n is the order of the system. The deadbeat observer is equivalent to the
observer given by Eq. (4.25), which was obtained by a direct calculation of the
state variables .
We illustrate design of an observer by determining an observer for the
double integrator.
Example 4.8 Full-order observer for the double integrator
Consider a double-integrator plant. The matrix <1> - KC is given by

~n = cD - KC = (~ ~) - (~:) (1 0) ~ (1 ~k~l ~)
Thus the characteristic equation is given by

Let the desired characteristic equation he
Z

2

+ P1Z + P2 = 0

140

Pole-Placement Design: A State-Space Approach

Chap. 4

The following equations are obtained:
2 - kl

= -Pl

1 - k 1 + k2h = P2

These linear equations give
hi = 2 + PI
kz = (1 +PI +P2)/h
The deadbeat observer is obtained by setting PI

=P2 .:::. 0, This gives

and the observer becomes
il(k + 1) ;:: xI(k) + hXz(k) +2(y(k) - XI(k))

x2(k + 1)

~ xz(k) + ~ (y(k) -

I\(k))

Straightforward calculations give
.i 1 (k + 1)

= 2y(k) -

y(k -1 )

i:~(k+l):= y(k)-y(k-1)
h

•

An Alternative Observer
There are many variations of the observer given byEq. (4.28). The observer has
a delay, because x(k I k - 1} depends only on measurements up to time k - 1.
The following observer can be used to avoid the delay:

x(k I k) = <1>x(k -11 k -1) + fu(k - 1)
+K[y{k )-C(<t>x(k-1 Ik-l)+fu(k-l})]
= (I - K C) (4l£(k -1 I k -1)

(4.32)

+ fu(k -1)) + Ky(k)

The reconstruction error when using this observer is given by

i(k I k) = x(k) -x(k I k) ~ (<1> -KC<fl)i(k-ll k -1)
This equation is similar to (4.30), and from the definition of the observability
matrix W0 1 it is found that the pair (CPI G¢l) is observable if the pair (4l, C) is
observable. This implies that ¢l - KG <t> can be given arbitrary eigenvalues by
selecting K. Furtber,

y(k) - Cx(k I k) = Ci(k I k) == (1- CK)C<bi(k -1/ k -1)

Sec. 4.5

Output

141

Feedback

If the system has p outputs, then I - C K is a p x p matrix; K may be chosen
such that C K = I if rank (C) = p. This implies that Cx(k I k) = y(k), which
means that the output ofthe system is estimated without error. This will make
it possible to eliminate p equations from (4.32) , and the order of the observer
will be reduced. Reduced-order observers of this type are called Luenberger

obseroers.
Example 4.9 Reduced-order observer for the double integrator
The observer (4.32) applied to the double integrator gives the equations

l - ki h{l-kI})

x(klk)= (
-k2

1 - hk 2
2

+

If I - CK

x(k-llk-l)

/2) u(k - 1) + (kI)
k

(1 - k 1 )h
( h{1 _ hk2 /2)

2

y(k)

=O-that is, if ki = l-then the first equation is reduced to

xI(k I k) = y(k)
The reduced-order observer is now given by the second equation. which can be
simplified to
x2(k I k) :;: (1 - hkZ )X 2(k

11 k -

1)

+ k2 (y(k) - y(k - 1)) + h(1 - hk2!2)u(k - 1)
By choosing k2 , the reduced-order observer can be given an arbitrary eigenvalue.
Fur instance, if k 2 = 11h, the deadbeat response, then the same result is obtained
as when making the direct calculation in Example 4.7.
•

4.5 Output Feedback
In Sec. 4.3 the pole-placement problem was solved in the special case when all
state variables are measured directly. In Sec. 4.4 the problem of finding the
states from the system output was solved. It is now natural to combine the
results of these sections to obtain a solution to the pole-placement problem for
the case of output feedback. Let the system be described by
x(k + 1)

= <lJxlk) + ru(k)

y(k) ;::: Cx(k)

(4.33)

A linear feedback law relating u to y such that the closed-loop system has
given poles is desired. The disturbances are first assumed to he impulses or
equivalently unknown initial states.

Pole-Placement Design: A State-Space Approach

142

.

x

u

-L

Observer

Chap. 4

y
Process

..-

Figure 4.6 Block diagram of a controller obtained by combining state feedback with an observer,

The admissible control law is such that u(k) is a function of y(k - 1),
ylk - 2), .. " u{k - 1), u(k - 2), ... . If all state variables are measured. it is
shown in Sec. 4.3 that the feedback
u(k) == -Lx(k)

gives the desired poles. When the state cannot be measured, it seems intuitively
reasonahle to use the control law
u(k} :;; -L.~(k I k - 1)

(4.34)

where x is obtained from the observer
x(k + 11
k)

= <Px(k I k -1) + fu(k) + K(YUli ~ Ci(k I k -

1))

(4.35)

Thus the feedback is a dynamicsystem of order n. Notice that the dynamicsare
due to the dynamics of the observer. A block diagram of the feedback is shown
in Fig. 4.6.

Analysis of the Closed-Loop System
The closed-loop system has desirable properties. To show this, introduce

i = x-x
It follows from Eqs. (4.33) and (4.34) that the closed-loop system can be described by the equations
x(k + 1) = (~- rL)x(k) + rLx(k I k -1)
x(k + 11 k) = (<P - K C).i(k I k - 1)

(4.36)

The closed-loop system has order 2n. The eigenvalues of the closed-loop system are the eigenvalues of the matrices <P - r Land <P - K C. Notice that the
eigenvalues of <P - fLare the desired closed-loop poles obtained by solving the
pole-placement problem in Sec. 4.3 and the eigenvalues of ~ - K C are the poles
of the observer given in Sec. 4.4.

143

Output Feedback

Sec. 4.5
(8)

c
0

2

;>,
...,
...

....
....
&:0

g

~

(f.l

III

>0

0
(b)

2

5

10

2

0

a
.tj

l::

....
...,
....
0

5

10

5

10

2

- •
>0
Q
III

00
0

~o

0

Figure 4.7

5
Time

10

0

Time

Control of the double-integrator plant using estimated states.

The states and the estimated states are sbown for a (a) second-order observer; (b) reduced-order observer.

This solution to the pole-placement problem has many nice symmetries.
The solution to the state feedback and the observer are dual problems. The
same numerical algorithm can be used to find the feedback gain L and the
observer gain K. It is also attractive that the solution ofthe full problem canbe
split into two smaller problems. The separation of the problem is very useful.
It also justifies that the closed-loop poles are separated into two groups, one is
associated with the state feedback and the other with the observer.
Notice that the observer contains a model oftbe process internally. This is
a special case of the internal-model principle, which says that a good controller
contains a model of the controlled system.
The controller can also be viewed as a hlack box that generates the control
signal from the process output. The controller described by (4.34) and (4.35) can
be represented by the nth-order pulse-transfer function from measured output
y to control signal u:
(4.37)
EKample 4.10 Output feedback of tbe double integrator
Consider the double-integrator plant. Assume that the feedback vector L is determined. as in Examples 4.2 and 4A with the closed-loop natural frequency w :; ;: 1,
the damping h :; ;: 0.7, and h == 0.44. This gives L :; ;: [0.73, 1.21]. First assume
that the observer is designed as in Example 4.8 with the poles of the observer in
z :; ;: 0.75. Figure 4.7(a) shows the true and the estimated states when the estimated states are used in the control law. Figure 4.7(b) shows the states in full
lines and the estimate of the second state in dots when the reduced-order observer
in Example 4.9 is used. The observer pole is in z = 0.75.
•

144

Pole-Placement Design: A State-Space Approach

Chap. 4

Extensions

The problem discussed can be extended in many different directions. The controller given by Eq. (4.34) has a time delay of one sampling period. The reason
for this is that the feedback is based on an observer that gives x(k I k - 1). It is
possible to obtain a controller without extra delays by using instead the control
law
u(k) = -Li(k I k)

(4.38)

where i(k ! k) is obtained from the observer given by Eq. (4.32). The properties
of the system obtained is analogous to the case that has just heen investigated, so the details are left as exercises. See the problem section at the end of
this chapter. Notice, however, that the feedback matrix L does not have to be
changed when we change the observer. This is a very nice consequence of the
separation of the problem into a state feedback and an observer.

More Realistic Disturbance Models
The controller based on a state feedback and an observer is interesting but it
is still not very useful in practice. The reason is that the assumption aboutthe
disturbances made in Sec. 4.3 has heen too simplistic. To generalize the problem
it is therefore assumed that the systemis described by

dx

-

dt
y

:=

Ax + Bu + u

= ex

where IJ is a disturbance acting on the process. The disturbance I), which typically has much energy at low frequencies, is modeled as
dw

di ;;: Aww
v = Cww
Thematrix A w typically has eigenvalues at the origin or on the imaginary axis.
We now introduce the augmented state vector

The augmented system can be described by

(4.39)

145

Output Feedback

Sec. 4.5

Compare with (4.20) . Sampling this system gives the following discrete-time
system:

1») = (4)

x(k +
( w(k + 1)

0

y

= (C

[r]

4>xw] (X(k)] +
u(k)
4>w
w(k)
0
0

Il :~~~ ]

The disturbance states ware not reachable from the control signal but the
complete state is observable from the output if the system (4.33) is observable.
The control law is a linear feedback from all state variables, that is,

u(k) = -Li(k) - Lww(k)
where

(4.40)

x and LV are obtained from the observer

~(k +

1)) = (4)
0

[ w(k + 1)

4>%w) [~(k))
w(k)

4>w

+

[r)
0

u(k) + ( K ) e{k)
Kw

(4.41)

and
r(k)

~

y(k) - Cx(k)

(4.42)

Notice that the state of the observer is composed of estimates of the states of
the process and the disturbances and that the control signalcontains a feedback
from the estimated disturbance state w.
The closed-loop system is described by

x(k + 1) =

(4) - fL)x(k) + (4):cw -

rLw)w - r Li(k) ~ fLww

w(k + 1) = 41 ww(k)
i(k + 1) = (41- KC)i(k) + 4>.uuw(k)
w(k + 1) := 4> w w(k)- KwCi(k)

(4.43)

Notice that the disturbance state w is observable but not reachable. The equations for the closed-loop system give useful insight into the behavior of the
system. The matrix L ensures tbat the state x goes to zero at the desired rate
after a disturbance. A proper choice of the gain Lw reduces the effect of the
disturbance v on the system by feedforward from the estimated disturbances w.
This feedforward control action is particularly effective if the matrix 4>.uv - r Lw
can be made equal to zero. The observer gains K and Ku; influence the rate at
which the estimation errors go to zero. A block diagram ofthe system is shown
in Fig. 4.8.

Integral Action
The special case of a constant but unknown disturbance acting on the process
input is very common. It leads to a solution wbere the controller has integral

Pole-Placement Design: A State-Space Approach

146

x

·L
w
~

-

-L w

~u

Chap. 4

y
Process -....-

Observer

Figure 4.8 Block diagram of a controller with state feedback from estimated disturbance states.

action . To see th is consider the case of a system with a single input and a
constant disturbance at the process input. In this case we have w = v and
~w := 1. In addition if the disturbance acts on the process input we get <1l xw = r.
It then follows from Eq. (4.43) that Lw = 1 gives perfect cancellation of the load
disturbance. Assuming that there are no measurement errors the controller
described by Eqs. (4.40) to (4.42) becomes

u(k) = -Li(k) - Lwv(k)

= - Lx(k )-

v(k)

x(k + 1) == ~x(k) + r(u(k) + u(k)) + Ke(k)

(4.44)

v(k + 1) = v(k) +Kwe(k)
e(k) = y(k) - C.i(k)
Notice that the estimation of the disturbance is obtained simply by integrating
the error of the state estimate. A block diagram of this controller is shown in
Fig. 4.9. The diagram shows clearly how the disturbance u is reduced by its
estimate V, which is obtained by integrating the observer error. There is an
integrator in the disturbance observer. In Fig. 4.9 there is, however, feedback
around the integrator. To see more clearly that the controller has integral action
Eq. (4.44) is rewritten as

u(k) = -Lx(k) - O(k)

i(k + 1) = ($ -

r L)£(k) + K (Y(k) -

Cx(k))

u(k + 1) = v(k) + Kw (Y(k) - Cx(k))
Notice that tbe estimate i of the process state is the same as in the case when
there are no disturbances; compare with Eq. (4.28). We now introduce

(4.45)

Sec. 4.6

147

The Servo Problem
lJ

~

oX

Process

L

y

v

e

Disturbance
Observer

State
Observer
Figure 4.9 Block diagram of a controller with state feedback and an observer with integral action. The pulse-transfer function of the disturbance
observer is K".f(z -1) .

LH:r (z) is the transfer function of the controller for a system with state feedback
given by Eq. (4.37). The input-output relation of the controller (4.44) is then

The expression shows that the controller has integral action. Notice that integral
action is obtained through the observer that estimates a constant disturbance
acting on the process input. We will illustrate by an example.

Example 4.11 Output feedback with integral action of the double integrator
Consider the double-integrator plant. Assume that the feedback vector L is determined as in Examples 4.2 and 4.4 with the closed-loop natural frequency (JJ = 1,
the damping' =0.7, and h = 0.44. This gives L"" \0.73, 1.21\. The initial value
of the state is %(0) = \1 IJT. The controller and the observer are implemented
as in (4.44). The three observer poles are placed in z = 0.75. Figure 4.10 shows
the behavior ofthe system. The response is now slower and more oscillatory than
without the estimated disturbance as in Fig. 4.7. It is, however, clearly seen that
the controller now has integral action and can eliminate constant input-load disturbances.
_

4.6 The Servo Problem
Only the regulator problem has been discussed so far. The criteria have been
to eliminate impulse disturbances and to drive the states of the system to zero.
The servo problem is another important prototype problem. For that problem
the objective is to make the states and the outputs of the system respond to
command signals in a specified way.

Pole-Placement Design: A State-Space Approach

148
(a)

..::l

Chap. 4

2

.So

6
50

0
1

(b)
.....

~

0

Q.

Q

~

-1

-2
(c)

50

0

8 0.2

g

of

.a

0

~ ~O.2

o

50

Fipre 4.10 Simulation of the system in Example 4.11. (a) Output y, (b)
input (l, and (c) disturbance v (dashed) and estimated disturbance u(solid).

A Naive Approach

A simple way to obtain the desired response to command signals is to replace
the regularstate feedback u(k) = -Li(k) by
u(k) = -Lx(k) + Lcuc(k)

(4.47)

where U c is the command signal. 1b investigate the response ofsuch a controller
we consider the closed-loop system that is described by
x(k + 1) =<bx(k) + ru(k)
y(k) = Cx(k)

x(k + 1) = 4lx(k) + ru(k) + K (Y(k) - C.i(k))
u(k)

(4.48)

=- Li(k) + Lcuc(k)

A block diagram of the system is shown in Fig. 4.11. Eliminating u and introducing the estimation error x = x - x we :find that the closed-loop system can

Sec. 4.6

149

The Servo Problem
Uc

x

Lr

-L

I

u

Process

y
~~

Observer
Figure 4.11 Block diagram that shows a simple way of introducing command signals in a controller with state feedback and an observer.

be described by

x(k + 1):::; (~- fL)x(k) + fLi(k)
x(k + 1) = (ct> - KC)x(k)
y(k) = Cx(k)

+ fLcu c(k)
(4.49)

Notice that the observer error is not reachable from uc• This makes sense hecause it would be highly undesirable to introduce command signals in such a
way that they will cause observer errors.
It follows from Eq. (4.49) that the pulse transfer from the command signal
to the process output is given by
-1

Hcl(z) :::; C(zI - ct> + fL) rLc

:::;

B(z)
L, Am(z)

(4.50)

This can be compared with the pulse-transfer function of the process

H(z) = C(zI -~rlf = B(z)
A(z)

(4.51)

The fact that the polynomial B(z) appears in the numerator of both transfer
functions can be seen by transforming both systems to reachable canonical form.
Compare with the derivation of Ackermann's formula given by Eq. (4.14).
The closed-loop system obtained with the control law given by Eq. (4.47)
has the same zeros as the plant and its poles are the eigenvalues of the ma trix <f> - r L. From the previous discussion we have found that the rejection
of disturbances are also influenced oy L. Sometimes it is desirable to have a
controller where disturbance rejection and command signal response are totally
independent. To obtain this we will use a more general controller structure that
is discussed later. Before doing this we will show how to introduce integral
action in the controller {4.47).

Pole-Placement Design: A State-Space Approach

150

Chap. 4

Integral Action

To obtain a controller with integral action we use the same idea as in Sec. 4.5
and introduce a constant disturbance v at the process input. The controllerthen
becomes
u(k) = -Li(k) - ir(k) + Lcur(k)

x(k + 1}

= <1>i(k) + r(u(k) + u(k)) + K (Y(k) -

v(k + 1)

~ v(k ) + Kw (y(k) - C.i(k))

C.i(k))

(4.52)

These equations can also be written as

u(k) = -L.i (k) - O + Lr (k)
(k)
'llc

x(k + 1)

= (<1> - rL).i(k) + r Lcuc(k) T K (Y(k) - Ci(k))

(4.53)

iJ(k + 1) = v(k) + Kw(Y(k) - C.i(k})
A comparison with Eq. (4.44) shows that command signal following is obtained
by a very simple modification of the systems discussed previously.

ATwo-Degree-of-Freedom Controller
Practical control systems often have specifications that involve botb servo and
regulation properties. This is traditionally solved using a two-degree-of-freedom
structure, as shown in Fig. 4.12. Compare with Fig. 3.10. This configuration
has the advantage that the servo and regulation problems are separated. The
feedback controller H f b is designed to obtain a closed-loop system that is insensitive to process disturbances, measurement noise, and process uncertainties.
The feedforward compensator Hfr is l.hen designed to obtain the desired servo
properties. We will now show how to solve the servo problem in the context of
state feedback.
Uc

:-

Hff

-Hfb

uff

u ,fb

L

u

Y
Process ,.........-

Figure 4.12 Block diagram of a feedback system with a two-degree-

of-freedom structure.

Sec. 4.6
Uc

151

The Servo Problem

Model and

- ..... Feedforward
Generator

y

L

x

L.....---I

Process

I--r--

Observer

Figure 4.13 A two-degree-of-freedom controller based on state feedback

and an observer.

AController Structure

In a state-space design it is natural to assume that servo performance is specified in terms of a model that gives the desired response of the output or the
state variables to changes in the command signal. This can be specified with
the model

xm(k + 1) = <l>mxm(k) + r muc(k)
Jm (k) = Cmxm(k)

(4.54)

It is then natural to use the control law

(4.55)
where Xm is the desired state, and urr is a control signal that gives the desired
output when applied to the open-loop system. The coordinates must be chosen
so that the states of the system and the model are compatible. In actual applications it is often useful to choose them so that the components of the state
have good physical interpretations.
The term Ufb == L(xm - i) represents the feedback and v« represents
the feedforward signal. Equation (4.55) has a good physical interpretation. The
feedforward signal U If will ideally produce the desired time variation in the
process state. If the estimated process state x equals the desired state Xm, the
feedback signal L(x m - x) is zero. If there is a difference between x and Xm ,
the feedback will generate corrective actions. The feedback term can be viewed
as a generalization of error feedback in ordinary control systems, because the
error represents deviations of all state variables and not just the output errors.
A block diagram of the system is shown in Fig. 4.13.

Generation of the Feedforward Signal
Given the model (4.54) it is straightforward to generate the desired states. It
remains to discuss generation of the signal urr. Let the pulse-transfer functions

Pole~Placement

152

Design: A State~Space Approach

Chap. 4

ofthe process and the model be H(z) and Hm(z), respectively. If the signal
(4.56)

could be generated it would give the desired result, several conditions are required for this. Themodel Hm must be stable,the pole excess ofthe model must
not be less than the pole excess ofthe process, and unstable process zeros must
also be zeros of the model.
'
In the single-input-single-output casethe generation of U ff is particularly
simple if the order and the zeros of the model and the process are the same.
Assume that H(z) = B(z)/A(z) and Hm(z) = AB(z)jAm(z) then Eq, (4.56)
becomes
u (k) = A. A(q) uc(k) = A
If
Am(q)

(1 + (Ul - af)qll-l + .+,....(ana~- a~)) uc(k)
+
+ aiqll-l
+
qll

(4.57)

The signal urr then can be generated from the states of the reference model.
Generation of feedforward signals is simplified even further if the reference
model (4.54) has reachable canonical form, that is,

eJ>m =

am
1

-a~

-4 71 - 1

-am
n

,t

1
0

a

'0

0

0

1

0

0

a

-

0

1

0

m

rm

=

0

(4.58)

0

It then follows from Eq. (4.57) that
(4.59)

where
(4.60)

Having obtained the closed-form solution we can obtain other representations
by transfonning the state variables.
Afull discussion ofdesign offeedforward compensation is outside the scope
of this book. Let it suffice to mention that it is often useful to introduce nonlinearities in the feedforward path so that the system ~.s not driven too hard in
response to command signals. Because the signal ufr is used mostly to get the
system to move rapidly in the right way it is also possible to use approximate
process models; small deviations are easilyhandled by the feedback.

Sec. 4.6

153

The Servo Problem

Putting It All Together

By combining the solutions to the regulation and servo problems we have a
powerful controller, which is described by
u(k) = tlff(k) + llfb(k)
uff{k)

= A(uc(k) + CffXm(k))

Ufb(k) ;:; L (xm(k) - i(k)) - L~lV(k)
x(k + 1) = <l>i(k) + <l>;tww(k) + ruCk) + Kc(k)

(4.61)

w(k + 1) = l1>ww(k) + Ku)c(k)
e(k) = y(k) - C.i(k)

xm(k + 1) :;; <l>mxm(k) + r muc(k)

This controller captures many aspects of a control problem such as load-disturbance attenuation, reduction of effects of measurement noise, and command
signal following. The responses to load disturbances, command signals, and
measurement noise are completely separated. The command signal response
is determined by the reference model. The response to load disturbances and
measurement noise is influenced by the observer and the state feedback. It can
be adjusted by the matrices L, LIIH K 1 and Kw . The fact that all estimated
states are compared with their desired behavior gives a good possibility to exercise accurate control. A block diagram of the closed-loop system is shown in
Fig. 4.14.
The controller given by Eq. (4.61) can be represented in many different
ways. All representations are equivalent hecause the system is linear and timeinvariant. In practice it is useful to use nonlinear reference models. actuators
and converters may be nonlinear, and there may be nonlinear effects in the

Uc

Model and
Feedforward
Generator

L

Process

-L w
x

Observer

Figure 4.14 Block diagram of a general controller tbat combines model
following with feedback from estimated states, and disturbance states. Compare with Figs. 4.8 and 4.13.

y

Pole-Placement Design: A staie-space Approach

154

Chap. 4

computations such as roundoff. In such cases the different structures may have
drastically different properties.
Useful insight is obtained by introducing the difference between the estimated state xand tbe state ofthe model X m• Assume that the systems are given
in reachable canonical forms and that the model and the process havethe same
zeros. We can then choose Cm :::: C and rill = AT . We now introduce

e = Xm -

i

(4.62)

It follows from Eqs. (4.23) and (4.61) that

e(k + 1) = tllmxm(k) + r muc(k) - <t>i(k) - <t>xww(k) - fu(k) - Kf(k)

=t1>e(k) -

<t>xww(k} + (tllm

-

<t»xm(k) + Aruc(k) - ruCk) - K e(k)

Only the first element of the vector (J>m - d»xm(k) + ..lrur(k) is different from
zero, This elementis given by

Furthermore we have
£(k) :;: y(k) - Ci(k)
= y(k) - Cx(k) +CXm(k) - Cxm(k)

= y(k) - Ym(k) + Ci(k)
We now introduce
u(k)

=Ufb(k) + Uff(k)

where
ufr(k) ==

A.( Cffxm{k) + uc(k))

and the controller (4.61) becomes
u(k) = Ufb(k) + uff{k)
uff(k)

= 1 ( c.,»; (k) + uc(k))

u{b(k)

= Le(k) -

Lww{k)

e(k + 1) = tlle(k) - 4>xww(k) - fUfb(k) + K (Ym(k) - y(k) - Ce(k))

(4.63)

w(k + 1) z: tllww(k) - KW(Ym(k) - y(k) - C€(k))
xm(k + 1) .:: <t>mxm(k) + fmuc(k)
In the special case of a constant input disturbance we have w ;;;: v~ <t>w = 1,
tllxw ~ f. In this casethe controller will haveintegral action. To see this clearly

we will reqrite Eq. (4.63) for the controller.

Sec. 4.6

u,

155

The Servo Problem

Model and
Feedforward . . . . . - - - - - - - - - - - - - - - - ,
Generator

Ym

y

Observer I--r__....

Process
-t!

Figure 4.15 Another representation of the general controller structure
with feedback from estimated states, disturbance states, and model following. Compare with Fig. 4.14

After straightforward algebraic manipulations we obtain

u(k) ;:;; Ufb(k) + ufr(k)
uff(k) =

A( Cffxm(k) +uc(k))

ufb(k) = Li(k) - u(k)

e(k+ 1) = (ct>- rL - KC)e(k) +K(Ym(k)-Y(k))

(4.64)

v(k + 1) ;::; v(k) - Kw (Ym(k) - y(k) - Ci{k))

xm(k + 1) ;;;; <l>mxm(k) + r muc(k)
The transfer function from y - Ym to e is given by Eq. (4.45). A block diagram of
the controller is shown in Fig. 4.15. We will illustrate the ideas by controlling
the double integrator.

Example 4.12 Control of the double integrator
Consider the double-integrator plant and assume that there is a process disturbance in the form of an unknown constant that is acting on the process input. Let
the feedhack vector L is detennined as in Examples 4.2 and 4.4 with the closedloop natural frequency w -::;:; 1, the damping' = 0.7, and h = 0.44. Figure 4.16
shows the control of the double integrator when using the controller (4.64). There
is first an input load disturbance at time t =5, and then a change in the reference
value to the model at t = 30. The model is designed to be twice as fast as when L
is designed. The simulation shows that the regulation and servo problems can be
separated and given different dynamics,
_

Pole-Placement Design: A State-Space Approacn

156

Chap. 4

1 r-------~-~:;;;;;;;=;;;;;;;;;:;;;;~

(a)

O~~~~~~~~~_-_ _-.-J

o

50

2 .----------------~-~-~----,

(b)

o

50

(c)
(l)

tJ

~

..c
::l
""'
+"

tfJ
......

Cl

r- -

0.2

~

-

--:~-~-------------___t

I
I

0 r---""'--

o

50

Figure 4.16 Control of the double integrator usingthe controller (4.64). (a)
Output (solid) and model output Ym (dots), (b) control signal, (c) disturbance
l) (dashed) and estimated disturbance u(solid).

4.7 A Design Example
To illustrate the design method we will consider control of an elastic joint in a
robot. Consider a motor with current constant hI that drives a load consisting
of two masses coupled with a spring with spring constant k (see Fig. 4.17). It
is assumed that friction and and damping can be neglected. The input signal is
the motor current I. The angular velocities and the angles ofthe masses are alI,
W2, lI'l, and lI'2; the moments of inertia are J 1 and J2. It is assumed that there
is a relative damping, d, in the spring and that the first mass may be disturbed
by a torque v. Finally the output of the process is the angular velocity {O2.

Sec.4.7

157

A Design Example

We now introduce the states
Xl :: lfJ1 -

'Pz

X2

=

X3

~ 0)2/ (JJo

(01/(00

where

The process is then described by
dx
-

dt

a
~

(00

y= (0

1

[ a -1 -PI
a

a

/32

!;J

X+

[~) [~)
U+

v

(4.65)

lUo ) x

where

a

:=

Jl/(J 1+ J 2)

PI :: d!J1(JJO
Ih = d/ J2wo
r ::: kIfJ l(J)Q
b

=:

1/J1wo

Thefollowing values have been used in the example: J 1 = 10/9, J 2 :;; 10, k = 1,
d = 0.1, and hI :: 1, which gives lOo ::: 1. With these values the process (4.65)
has three poles, PI =: 0 and P2S = -0.05 ±O.999i, and one zero, Zl :: -10. Notice
that the system contains a pure integrator. The complex poles have a damping
of {p = 0.05 and a natural frequency (JJp = 1 rad/s. The Bode plot ofthe process
is shown in Fig. 4.18 and the impulse response in Fig. 4.19.

Specifications. It is desired that the closed-loop system has a response
from the reference signal such that the dominating modes have a natural frequency tUm = 0.5 rad/s and a damping 'm = 0.7.
Choice of sampling Interval. Thedesired model has a natural frequency
({)m. = 0.5 rad/s. Using the rule ofthumb given by Eq. (4.17) gives h = 0.5 s as
a reasonable choice for the sampling interval. This gives a Nyquist frequency
of lUN = Jr/ h =:: 6 rad/s.
In practice an antialiasing filter is necessary to avoid frequency folding
of disturbances. In this first design the disturbances are disregarded and the
design is done for the plant only.

Pole-Placement Design: A State-Space Approach

158

Chap. 4

10

0.1

o
-180 . . " . " ."", . " . . ". " , . " . " .. " . . .. " . . ,' . . '". _''_'-'--,

10

0.1
Frequency, radls

Fi(Ul"e 4.18 Bode plot of the flexible-robot-arm process.

Ststs feedback design.

It is assumed that all the states are measured.
The system is of third order, which implies that three poles can be placed using
the controller
u(k) : -Lx(k) + Lcuc(k)
(4.66)

Let the desired poles be specified by
(s2 + 2{mcoms + w~) {s + UIOJm }

::

0

(4.67)

This characteristic equation is transferred to sampled form with h =: 0.5. The
parameter L, is determined such that the steady-state gain from Uc to y is

--l..

O
L
.
.
.
.
.
.
~
~
~
~
_
I
_
-

o

25

50

Time
Figure 4.19 Impulse response of the flexible-robot-ann process

---.J

75

+"

:l

0.
....
::s

0

159

A DesIgn Example

Sec. 4.7

17
0

20

0

40

60

80

40

60

80

2
~

1

1--1

0

:l
00

-1

0

20

Time

Figure 4.20 Output and input when the reference signal u; is a step and
the disturbance u a short pulse.

unity, that is, no integrator is introduced in the controller. Figure 4.20 shows
the behavior of the closed-loop system when the state-feedback controller (4.66)
is used when at = 2. The reference signal is a step at t = 0 and the disturbance
v is a pulse at t ::: 25 of height -LO and a duration of 0.1 time unit.

Observer design.

It is now assumed that only the output can be measured. The other states are reconstructed using a full-state observer of the form
(4.28). The eigenvalues of <I> - K C are chosen in the same pattern as the closedloop poles but a factor ao farther away from the origin, that is, in continuous
time we assume that we have
(S2 T

2(mao£Oms + (a olOm)2)(s + aOallOm) = 0

This characteristic equation is transferred to sampled-data form using h ;;: 0.5.
Figure 4.21 shows the same as Fig. 4.20 when an observer is used. The output
is shown for ao = 2. The continuous-time equivalence of the fastest pole of the
closed-loop system when using the observer is -aOatW m . For ao = 2, at = 2,
and OJm = 0.5, we get the pole -2. This implies that the used sampling interval
(h ~ 0.5) is a little too long. There is, however, no significant difference in the
response when h is decreased to 0.25.

Summary.

The example shows the design using state feedback and the
observer. The response to the reference value change is the same, because the
system and the observer have the same initial values. The response to the
disturbance deteriorates slightly when the observer is used compared to directstate feedback. The observer is twice as fast as the desired closed-loop response.
One important aspect of the control problem that has not been captured is the

Pole-Placement Design: A State-Space Approach

160

+>
;I

.fr
;::I
0

17
0

..='

Chap. 4

0
2

20

40

60

80

20

40
Time

60

80

1

c.
s::

'""' 0
-1

0

Figure 4.21 The same as Fig. 4.20, but using state feedback from observed
states when ao ~ 2.

effect of model uncertainty. This will be discussed in the next chapter. Notice
that there is no integrator in the controller. The steady-state error will be zero
even in the presence of a disturbance because the process dynamics has an
integrator.

4.8 Conclusions
The chapter shows how the regulator and servo design problems can be solved
using pole placement and observers. The solution has three major components:
the feedback matrix L, the observer, and the response model. The feedback
matrix L is chosen in such a way that load disturbances decay properly using
the techniques discussed in Sec. 4.3. The observer is designed by considering
the load disturbances and the measurement noise, as discussed in Sec. 4.5. The
major trade-off is between quick convergence and sensitivity to measurement
errors. The regulation properties are taken care of by the matrix L and the
observer. The response model and the inverse process model are then chosen to
obtain the desired servo performance in response to command signals.
The pole-placement design is done here for the single-input-single-output
case. With n parameters in the state-feedback vector, it is possible to place n
poles arbitrarily, if the system is reachable. In the multivariable case, tbere
are more degrees of freedom. This makes it possible to determine not only the
poles, but also some eigenvectors of the closed-loop system. Further details can
be found in the references.

Sec. 4.9

Problems

161

4.9 Problems
4.1 A general second-order discrete-time system can be written as
x(k + 1)
y(k)

=(

7. )

a ll

al

a21

( 61 )

a 22

= (CI

c2

x(k) +

bz

u(k)

x(k}

)

Determine a state-feedback controller ofthe form
u(k) ::; -Lx(k)

such that the characteristic equation of the closed-loop system is
2,2.

+ PI! +P2

;

0

Use the result to verify the deadbeat controller for the double integrator given in
Example 4.5.

4.2 Given the system

0.1) x(k) + (1 ) u{k)

x(k + 1) == ( 1.0
0.5 0.1
y(k) ==

0

(1 1) x(k)

Determine a linear state-feedback controller
u(k) ;;;; -Lx(k)

such that the closed-loop poles are in 0.1 and 0.25.
4..
1

Determine the deadbeat controller for the normalized motor in Example A.2. AB·
surne that x(O) = (1 lV. Determine the sample interval such that the control
signal is less than one in magnitude. It can be assumed that the maximum value
of u(k) is at k ::; O
.

4.4 Consider the continuous system.

~~ ::;

3
(-0 _1 x +
2)

(~) u

(1 o)x
Sampling the system with h ::::: 0.2 gives
x(k + 1) == (0.55 0.12) x(k) + (0.01)
)'==

o

0.67

u(k)

0.16

(a) Detennine a state-feedback control law suchthat the closed-loop characteristic
polynomial is
Z2 -

0.63" + 0.21

Pole-Placement Design: A State-Space Approach

162

Chap. 4

(b) Determine the corresponding continuous-time characteristic polynomial and
discuss the choice of the sampling period.
(c) Simulate the closed-loop system when x(O)

11 Of·

:=

4.5 The system
0.78 0)

x(k+l)= (
0.22 1
y(k):::

x(k}+

( 0.22 )
00
u(k)
. 3

(0 1) x(k)

represents the normalized motor for the sampling interval h = 0.25. Determine
observers for the state based on the output by using each ofthe following.
(a) Direct calculation using (4.25) ,

(b) A dynamic system that gives i(k + 1 [ k) using (4.28).
(c) The reduced-order observer.

Let the observer be of the deadbeat type; that is, the poles ofthe observer should
be in the origin.
4.6 Determine the full-state observer hased on (4.28) for the tank system in Problem 2.10. Choose the observer gain such that the observer is twice as fast as the
open-loop system.
4.7 Consider the observer of (4.32) and let the control law be given by

u(k)

=::

-Li{k I k)

Show that the resulting controller can be written as

w(k + 1) = <J)ow(k) + foy(k)

u(k) = Cow(k) + Doy(k)
where
ifJo == (1 - KC)(CI> - rL)

fa = (1 - KC)(lI> - fL)K

C =-L

Do

Q

= -LK

4.8 Given the discrete-time system
x(k + 1) ~ ( 0.5 1) ~(k) + ( 0,2 ) u{k) + ( 1 ) v(k)
0.5 0.7
0.1
0

y(k) ~

(I 0) x(k)

where v is B constant disturbance. Determine controllers such that the influence of
can be eliminated in steady state in each case.

v

(a) The state and v can be measured.

{b} The state can he measured.

Sec. 4.9

Problems

163

(c) Only the output can be measured.

4.9 Consider the two-tank system in Problem 2.10 for h :::: 12 s.
(a) Determine a state-feedback controller such that the dosed-loop poles are given
by the characteristic equation
Z2 -

This corresponds to ( ::: 0.7 and

1.55z + 0.64
(j) ::;;

z:

0

0.027 rad/s.

(b) Introduce a command signal and determine a controller such that the steadystate error between the command signal and the output is zeroin steady state;
that is, introduce an integrator in the system.
(c) Simulate tbe system using the regulators in (a) and (b).

4.10 Consider the double integrator with a load disturbance acting on the process input. The disturbance can be described as a sinusoid with frequency lOo, but with
unknown amplitude and phase. Design a state-feedback controller and an observer
such that there is no steady-state error due to the sinusoidal perturbation.
4.11 Consider the discrete-time process
x(k + 1)

=

y(k) "

0.9 0)
( 1)
( 1 0.7 x(k) + 0 u(k)

(0 1)

x(k)

(a) Determine a state deadbeat controller that gives unit static gain, that is,
determine L~ and L in the controller

(b) Determine the stability range for the parameters in L, that is, use the controller from (a) and determine how mucb the other parameters may change
before the closed-loop system becomes unstable.

4.12 Consider the system
0.25 0.5)
( 1)
x(k + 1) ;;;; ( 1, 2
x(k) + 4 u(k}
y

=

(1 0) x(k)

(a) Determine the state-feedback controller u(k) = Lcuc(k) - Lx(k) such that the
states are brought to tbe origin in two sampling intervals.
(b) Is it possible to determine a state-feedback controller that can take the system
from the origin to x(k) ;;;; [2 Sf?
(c) Detennine an observer that estimates the state suchthat the estimation error
decreases as p(k)· 0.2k •

164

Pole-Placement Design: A State-Space Approach

Chap,4

4.10 Notes and References
Pole placement was one of the first applications of the state-space approach.
One of the first to solve the problem was J. Bertram in 1959. The first published
solution is given in Rissanen (1960). Treatment ofthe multivariable case ofpole
placementcan be found, for instance, in Rosenbrock (1970), Wolowich (1974),
and Kailath (1980). Observers are also described in the preceding books. The
reduced-order observer was first described in a Ph.D. thesis by Luenberger.
Easier available references are Luenberger (1964,1971).
The servo problem and introduction of reference values are discussed in
Wittenmark (1985a). Numerical aspects of computing the state feedback and
the observer gain are discussed in Miminis and Paige (1982). Petkov, Christov,
and Konstantinov (1984), and Mirninis and Paige (1988).

5
Pole-Placement Design:
A Polynomial Approach

5.1 Introduction
In this chapter we will discuss the same design problems as in Chapter 4 but
we will use polynomial calculations instead of matrix calculations. This gives
new insights and new computational methods. In addition we will be able to
investigate consequences of errors in the model used to design the controller.
The idea of pole placement is to find a controller that gives a closed-loop system
with a specified characteristic polynomial. It is natural to explore if this can be
done directly by polynomial calculations.
We start by describing a process model and a controller as input-output
systems characterized by rational transfer functions. The design problem is then
solved in a simple setting in Sec. 5.2. The design problem is identical to the one
posed in Sees. 4.2 and 4.5. A polynomial equation is a crucial part ofthe solution.
This equation is investigated in Sec. 5.3, where we give conditions for solvability
and algorithms. In Sec. 5.4 we solve more realistic design problems. We consider
cancellation of poles and zeros, separation of command signal responses and
disturbance responses, and improved responses to disturbances. In Sec. 5.5 we
consider the problem of modeling errors , which is much more convenient to
deal with in the input-output formulation than in the state-space formulation.
In Sec. 5.6 we summarize results and obtain a general design procedure. Some
practical aspects are also discussed in that section.
The chapter ends with several design examples that illustrate the procedure. Control of a double integrator is discussed in Sec. 5.7, an harmonic
oscillator in Sec. 5.8, and a flexible robot arm in Sec. 5.9. Many other design
procedures can be expressed in terms of pole placement. This gives insight and
gives a unified view, as is illustrated in Sec. 5.10.
165

166

Pole-Placement Design: A Polynomial Approach

Chap. 5

5.2 A Simp'e Design Problem
We will now discuss the same simple design problem that was solved by statespace methods in Sec. 4.6. namely, to find a two-degree-of-freedom controller for
a linear system with output feedback. The design problem is stated, and the
solution is given and illustrated by two examples. It turns out that an algebraic
equation plays a key role in the solution. The properties of this equation will
be explored in the next section, where we also will resolve some technicalities.
A general discussion of the design problem was given in Sec. 4.2. It is
recommended to review that section before proceeding. In this case we will
consider command signalfollowing, attenuation of load disturbances, and effects
of measurement noise.
It is assumed that the system has one control variable, u, and one measured output. y, which are related by the following input-output model:

A(q)y{k) = B (q)u(k)

(5.1)

where A{q) and B (q) nrc polynomials in the forward-shift operator q. It is assumed that the degree of B{q) is less than the degree of A(q), that the polynomials A(q) and B(q) do not have any common factors, and that the polynomial
A(q) is normalized so that the coefficient of the term with the highest power in
q is one. Such a polynomial is called monic.
The dynamics of the process has the pulse-transfer function B(z)jA(z),
which includes a hold circuit, an actuator, a sensor, and antialiasingfilter. Recall
from Sec. 2.3 that the model of (5.1) may represent a discrete-time model of a
continuous-time system with a rational transfer function and an arbitrary time
delay.
As in Sec. 4.5 we will assume that the disturbances are widely spaced
impulses. The response of the closed-loop system can thus be judged by how
well it will respond to perturbations in initial conditions of the process.
In pole-placement design it is assumed that specifications are primarily
given by the closed-loop characteristic polynomial. In addition it may be specified that the controller should have certain properties, for example, integral
action. The design variables are the closed-loop characteristic polynomial and
the sampling period. Notice that the sampling per iod appears implicitly in the
model (5.1).
The controller has one output, u, and two inputs: the command signal, u.,
and the measured output, y . A general linear controller can be represented by

R(q)u(k)

= T(q)uc(k) -

S(q)y(k)

(5.2)

where R(q), S (q) t and T (q) are polynomials in the forward-shift operator. The
polynomial R(q) can be chosen 80 that the coefficient of the term of highest
power in q is unity.
The control law (5.2) represents a combination of a feedforward with the
pulse-transfer function Hjf(z) := T(z)jR (z} and a feedback with the pulsetransfer function Hfb(z) ~ S(z)jR{z). To have a causal controller it must be

.Sec. 5.2

A Simple Design Problem

167

required that the degree of R(z) is larger than or equal to the degrees of S(z)
and T (z).

Solving the Design Problem
The solution of the design problem is straightforward. We will simply determine
the characteristic equation of the closed-loop system and explore the conditions
that it has to satisfy.
Eliminating u(k) between the process model (5.1) and the controller (5.2)
gives

(A(q)R(q) + B(q)S(q))Y(k):= B(q}T{q)uc(k)

(5.3)

The characteristic polynomial of the closed-loop system is

Acl(z) :::: A{z )R(z) + B(z)S(z)

(5.4)

Pole-placement design thus reduces to the algebraic problem of finding polynomials R{z) and S(z) that satisfy Eq. (5.4) for given A(z), B(z), and Ad(z}.
Equation (5.4), which plays a central role in the polynomial approach, is called
the Diophantine equation. A general discussion of this equation will be given
later. Let it suffice for now that the problem always can be solved if the polynomials A(z) and B(z) do not have common factors.
Additional insight is obtained by comparing with the state-space solution
to the design problem in Sec. 4.5. There we found that the characteristic polynomial Ad{z) could be factored as

(5.5)

=

where A,(z) det(zI - <t> + rL) and Ao(z} = det{zI - <fl + KC}. This factorization corresponds to the separation of the controller into a state feedback and
an observer. For this reason we call Ac(z) the controller polynomial and A(J(z)
as tbe observer polynomial. Recall that it was found in Sec. 4.3 that the arbitrary eigenvalues could be assigned to Ae (z) if the system is reachahle and that
arbitrary eigenvalues could be assigned to Ae(z) if the system is observable.
To complete the design it remains to determine the polynomial T(z). To
do this we consider Eq . (5.3), which tells how the system reacts to command
signals. The pulse-transfer function from command signal to output is given by

Y(z) ::: B(z)T{z) Uc(z) = B (z )T(z) Uc(z)
Acr(z}
Ac(z)Ao(z)

(5.6)

This equation shows that the zeros of the open-loop system are also zeros of
the closed-loop system, unless the polynomials B(z) and AcJ(z) have common
factors. By referring to the solution of the design problem in Sec. 4.6 it is natural
to choose the polynomial T(z) so that it cancels the observer polynomial Ao(z).

Pole-Placement Design: A Polynomial Approach

168

Chap. 5

This implies that command signals are introduced in such a way that they do
not generate observer errors. Hence

T(z ) :;: toAo(z)

(5.7)

The response to command signals is then given by
(5.8)

where the parameter to is chosen to obtain the desired static gain ofthe system.
For example, to have unit gain we have 'to:: ~(l)1 B (1).

Summary
We have thus obtained the following design procedure.
ALGORITHM 5.1 SIMPLE POLE-PLACEMENT DESIGN

Data: A process model is specified by the pulse-transfer function B (z)/A(z),
where A(z) and B(z) do not have any common factors. Specifications are given
in terms of a desired closed-loop characteristic polynomial Acdz).

Step 1_ Find polynomials R(z) and S(z), such that dog S(z) :::; deg R(z), which
satisfy the equation

A(z)R(z) + B (z)S(z) = Acdz)

Step 2. Factor the closed-loop characteristic polynomial as Ad (z)
where degAo(.z) ~ degR(z), and choose
T(z) =

=Ac(z)Ao{z),

t~Q(z)

where to ::: A c (l)/B (1). The control law is

R(q)u(k) :0 T(q)uc(k) - S(q)y(k)
and the response to command signals is given by

Ac(q)y(k) = toB(q)uc(k)

•
There are several details that have to be investigated. The most important is the
solution of the Diophantine equation (5.4). Before doing this we will, however,
consider an example.

Sec. 5.2

A Simple Design Problem

169

Example 5.1 Control of a double integrator
For the double integrator we have

A{z) '" (z _1)2
8 (z)

h2
2

= -(z + 1)

and the Diophantine equation (5.4) becomes

h2
(Z2 - 2z + l )R(z) + 2 (z + 1)8(z) "" Ac/(z)
The closed-loop characteristic polynomial Ad is a design parameter. Both its degree
and its parameters will be selected to achieve the design goals. It is natural to look
for as simple controllers as possible. This means that we will search forpolynomials
R(z) and 8(z) of the lowest order that satisfies the Diophantine equation. The
simplest case is R(z) 1 and 8(z) = So, that is, a proportional controller. This
gives the equation
;;0

which cannot be solved for an arbitrary Ad (z) of second order. With a first-order
controller we have R(zl '" Z + ' 1 and S(z) SOZ + 511 which gives

=

h2

(z2 - 2z + l)(z + ril + 2 (z + 1)(80Z + sd

;;: Acdz)

Hence
2

Z3

2

h2
h
h
+ ( rl + ""2 So - 2) z2 + ( 1 - 2r1 + 2 (so + sd ) z + r1 + 51 "2 = Acdz)

and we find that it is possible to select the controller coefficients
obtain an arbitrary polynomial Act(z) of third degree. Choosing

and identifying coefficients of powers of equal degree we find that
ft +

h2

2: 80 =Pt

+2

h~

- 2rl + 2" {so + stl -;;: P2 - 1
h2

fl

+ 81"2

'"

P3

This equation has the solution

3 + PI + P2 - P3

' 1 = ---=----4-:...;;.--=.....:.

5 + 3Pt + P2 - P3
2h2

So

.=

51

-= -

3 + Pt - P2 - 3P3
2h2

rl ,

So, and 81 to

Pole-Placement Design: A Polynomial Approach

170

Chap.S

It now remains to determine the polynomial T(z). For this purpose we will factor
the dosed-loop characteristic polynomial as ArI(Z) : : ; ~(z}Ac(z). The closed-loop
characteristic polynomial Ad (z) is of third order. Because a third-order polynomial
always has a real root we will select this tocorrespond with the observer polynomial
A(J(z) and we have T(z) ~ toA~(z), where to ;;: A(l)/ B(l) ,
_

The example shows that to solve the prohlem, the specified closed-loop characteristic polynomial and consequently the controller must be of sufficiently
high orders . This can also be seen easily by simply counting equations and unknowns. Increasing the order of the controller with one gives an increase of
two parameters, but the number of equations only increases by one. The problem will thus be overdetermined when the closed-loop characteristic polynomial
has sufficiently high order. The increased degrees of freedom can be used to
introduce auxiliary constraints. This is illustrated by the next example .

Example 5.2 Controller with on integral action for the double integrator
Consider control of the double integrator where it is desired to have a controller
with integral action, This means that the polynomial R(z) must have z - 1 as a
factor. Using the same arguments as in Example 5.1 we find that the simplest
controller of second order with an integrator is
R(z} == (z-l}(z + rd
S{z)

= S()Z2 + SlZ + s~

Inserting this into the Diophantine equation (5.4) we obtain

The closed-loop system is of fourth order and we have four parameters
and

82

to determine,

rl'

So,

S11

_

5.3 The Diophantine Equation
The discussion in the previous section gave some insight into the design problem. In particular we found that the Diophantine equation (5.4) played a central
role, We will now analyze this equation. The fundamental mathematical problem is to understand the properties ofthe polynomial equation

AX +BY::: C

(5.9)

where A, B, and C are known polynomials, and X and Yare unknown polynomials. This is a well-known problem in elementary algebra. Equation (5.9) is
named after Diophantus (~ A.D. 300), who was one of the original inventors of
algebra. It has also many other names in literature, the Aryabhatta's identity
or the Bezout identity.

Sec. 5.3

171

The Dlopharnne Equation

A Digression

Equation (5.9) looks strange at first because two unknowns have to be determined from one equation. A simpler, but related, problem from high school
algebra gives insight.
Example 5.3 The Diophantine equation
Consider the equation
(5. lO)

3x + 2y " 5

where x and y are integers. When does this equation have a solution? A clue is
obtained by first considering x and y as real variables. The equation has infinitely
many solutions, which can be represented as points on the straight line defined
by the equation. By returning to integers it is obvious that x :;;; 1 and y :::; 1 is a
solution. Another solution may be found by increasing x by 2 and decreasing y by
3. Hence, if XQ and Yo satisfy (5.10), then another solution is given by
x = Xo + 2n

(5.U)

y ;;; Yo - 3n

where n is an arbitrary integer. A few solutions follow:
x:

-5

-3

-1

1

y:

10

7

4

1

357
-2

-5

-8

We thus find that if the equation has one solution there are infinitely many other
solutions. It follows from (5.11) that if a solution .ro, Yo is known, it is possible to
add or subtract 2 from Xo until a unique solution with
05:r<2
is obtained. Similarly, there is also a unique solution such that

Os )/<3

•

Another example shows that there may not be a solution to an equation such
as (5.10).
Example 5.4 The Diophantine equation without II solution
Consider tbe equation
4x + 6y

=1

where x and y are integers. Because the left-band side is an even number and
the right-hand side an odd number it is clear that the equation does not have a
,
solution. The difficulty in finding a solution is because numbers 4 and 6 have 2 as
I
a common factor, whereas the right-hand side does not.

Equation (5.10) is closely related to Eq. (5.9) because the integers and the
polynomials with real coefficients obey the same algebraic rules. Both may be
multiplied and added with the usual rules. However, division of two integers
(or polynomials) does not necessarily result in an integer (or a polynomial). In
algebraicterminology this is expressed by saying that integers and polynomials
with real coefficients are rings.

Pole-Placement Design: A Polynomial Approach

172

Chap.S

Euclid's Algorithm

Examples 5.3 and 5.4 essentially reveal the important issues about Eq. (5.9). It
is now simply a matter of giving a formal analysis of the equation. We will first
develop a classical result in algebra. This algorithm finds the greatest common
divisor G of two polynomials A and B . The algorithm is recursive. If one of the
polynomials is zero then the other polynomial is defined as the greatest common
divisor G. If this is not the case the algorithm proceeds recursively as follows.
Assume that the degree of A is greater or equal to the degree of B. Put Ao ;:: A
and Bo == B. Iterate the equations
A n+ 1 = Bn

8 11+1 = An mod Bn
until BIl +1 = O The greatest common divisor is then G := B,I' Backtracking we
.
find that G satisfies the equation

AX + BY = G

(5.12)

where the polynomials X and Y can be found by keeping track of the quotients
and the remainders in the iterations. The link between Euclid's algorithm and
the Diophantine equation is thus established and we have the following result.
THEOREM 5.1

EXISTENCE OF SOLUTIONS TO THE DIOPHANTINE EQUATION

Let A, B, and C be polynomials with real coefficients. Then Eq. (5.9) has a
solution if and only if the greatest common factor of A and B divides C. If one
solution Xo, Yo exists there are X == X o + QB and Y = Yo - QA, where Q is
an arbitrary polynomial and is also a solution.
I

Proof.

The proof follows directly from Euclid's algorithm. If A and B do
not have a common factor we have G ;;;;; 1. Multiplying Eq. (5.12) by C now
gives (5.9).
•
Solv'ng the Diophantine Equation

1b solve the Diophantine equation we simply have to keep track of the intermediate steps in Euclid's algorithm. This can be done conveniently as follows.
At the same time we also obtain the minimum-degree solutions U and V to the
equation

AU +BV =0

(5.13)

Equations (5.12) and (5.13) can be written as

(~ ~) [~) = [~]

(5.14)

Sec. 5.3

The Diophantine Equation

173

which implies that

[X Y) [A 1 0) = [G X Y)
UV
BOI
OUV

(5.15)

To determine the matrices X, Y, U, and V we can thus start with the matrix
A
[

1 0)

B 0 1

(5.16)

and perform elementary row operations until a matrix with a zero in the 2,1
position is obtained, that is,

Y)
(GX V
o U

(5.17)

The polynomials X, Y, U, and V are then obtained directly from the elements
ofthis matrix. This algorithm is called the extended Euclidean algorithm. It is
now straightforward to solve the Diophantine equation (5.4) . This can he done
as follows.
ALGORITHM 5.2 THE DIOPHANTINE EQUATION

Step 1. Determine the greatest common divisor G ofA and B and the associated
polynomials X, Y, U, and V using the extended Euclidean algorithm. If G does
not divide C the problem has no solution,
Step 2. If G divides C a particular solution is given by

Xo =XC divG
Yo == YC divG
and the general solution is givenby

X=Xo+QU
Y == Yo - QV

where Q is an arbitrary polynomial.

(5.18)

•

5.1 UNIQUE SOLUTION There are unique solutions to (5.9)
such that degX < deg B or degY < degA.
•
COROLLARY

These solutions with degX < deg B is obtained from the general solution given
by Eq. (5.18) by choosing Q = -Xo div U.

174

Pole-Placement Design: A Polynomial Approach

Chap . 5

Causality Conditions
It follows from the analysis that there may be infinitely many solutions to the
Diophantine equation (5.4) . For the Diophantine equations that appear when
solving the pole-placement problem, it is natural to introduce some constraints
onthe solution. The degrees ofthe polynomials 8(z) and T(z) must be less than
or equal to the degree ofR(z) . If this is not the case the control signal at time k
will depend on values ofthe measured signal and the command signal at times
larger than k. We call this the causality condition .
If the time to calculate the control signal in the computer is only a small
fraction ofthe sampling period, it is natural to neglect the time to compute the
control signal. The causality constraint then becomes

deg R = degT

= degS

(5.19)

If the computation time is one samplingperiod we have
deg R ::: deg T + 1 = deg S + 1
The constraint of (5.19) is normally used as a standard case. Possihle computational delays can be included in the process model instead of in the controller;
compare with Sec, 2.3.
Minimum-Oegree Solution

In the control problem it is natural to select the solution of (5.4) that gives a
causal controller of lowest order. It is natural to assume that the process model
is causal. This means that deg B > deg A. Because the controller is also causal
we have deg S :s deg R. We will thus find the solution where the degree of
8 is as low as possible, According to Corollary 5.1 we have deg8 < deg A. If
degA : :;: It we find that the minimum-degree solution corresponds to deg S =
deg R = deg T = deg An ;; n - 1 and deg A: = n. If we in addition require that
the controller shouldhave integral action we find that the controller must be of
degree n ,

Relations to Linear Matrix Equations

The Diophantine equation can also be solved using matrix calculations. Assuming that the degrees of the polynomials are known, introducing the unknown
coefficients of the polynomials as variables, and identifying coefficients of equal
powers of z, we obtain a linear equation that can be solved in the usual manner.
Consider, for example, Eq. (5.9). Assume that the degrees of the polynomials
are deg A(z) = deg B (z) ~ nand degX(z) =:: deg Y(z) = n - 1. The following

More Realistic Assumptions

Sec, 5.4

175

linear equations are then obtained.
ao

0

0

a1

ao

0

0 bo
0 b1

a2

at

110

0 b2

an
0
0

an-l

a/l-2

an

an-l

0

an

0

0

0

bo
b1

0
bo

0

ao bn bn- 1 blt - 2
al 0 btl bn- 1
U2

0

0

bit

0

bo

bl

Co
Cl

Xo

%,.-1

Yo

C3

=

en.
ClI+l

b2

Cn+2
Yn-l

0

0

0

an

0

0

0

bn.

C2n-l

The matrix on the left-hand side, which is called the Sylvester matrix, occurs
frequently in applied mathematics. It has the property that it is nonsingular if
and only if the polynomials A and B do not have any common factors. Compare
with Theorem 5.1.Notice) however, the nonuniqueness withrespecttothe orders
of X and Y. Different choices of the orders of the polynomials give different
solutions X and Y as discussed before.
The solution to the preceding linear equation can be obtained by Gaussian
elimination. This method does not use the special structure of the Sylvester
matrix. The polynomial methods based on the extended Euclidean algorithm
are faster and more efficient hecause they exploit the structure of the problem.
J

5.4 More Realistic Assumptions
In this section we will gradually remove several ofthe assumptions made when
solving the design problem in Sec. 5.2.

Canceflation of Potes and Zeros
In Sec. 5.2 it was assumed that no process poles or zeros are canceled by the
controller. In some cases it is possible to cancel process poles and zeros that
are well damped. This is done in several design methods. Assume that the
polynomials A and B are factored as
A =A+AB = B+B-

(5.20)

where A + and B + are the factors that can be canceled. To obtain unique factorizations polynomials A+ and B+ are chosen to he monic. In this section we
will drop all arguments indicating the independent variable in the polynomials to simplify the writing. The polynomials A + and B+ must have all their

176

Pole-Placement Design: A Polynomial Approach

Chap. 5

roots inside the unit disc. Because a process pole that is canceled must be a
controller zero and vice versa, it follows that the polynomials R, S, and T have
the following structure:

R

=:

B+R

S = A-S

(5.21)

T = A-t

It follows from Eq. (5.4) that the characteristic polynomial of the closed-loop
system is

The polynomials A+ and B + which are canceled, are thus factors ofthe closedloop characteristic polynomial Acf. It is natural tofactor the characteristic polynomial as Acl = AcAo l where
I

(5.23)

Cancelling the common factors in Eq. (5.22) we find that polynomials Ii and S
satisfy
(5.24)
The minimum-degree causal controller is obtained hy choosing the unique solution with degS < degA", The control (5.2) law can be written as

Hence

Thismeans that we simply cancel the poles and zeros of the process and design
a controller for the reduced system as if the canceled poles were not present.
Because T :: toAOI the pulse-transfer function from the command signal to
process output is

BT
A cl

toB+B- Ao
;;;:;

Ac~

toB-

= Ae

The canceled factors must correspond to stable modes. If this is not the case
the system will have unstable modes that are unreachable or unobservable. In

Sec. 5.4

More Realistic Assumptions

1m

1

Re

Figure 5.1 A region D such that points in the region have a minimum
relative damping and a minimum absolute damping.

practice it is useful to have more stringent requirements on allowable cancellations. Sometimes cancellation may not be desirable at all. In other cases it
may be reasonable to cancel zeros that are sufficiently wen damped. One way
to express this formally is to introduce a region D in the complex plane that
corresponds to modes with sufficient relative and absolute damping. Only zeros
inside D may he canceled. An example of a region is shown in Fig. 5.1. From
Sec. 2.8 we saw that lines with constant relative damping are logarithmic spirals in the a-plane and that lines with constant absolute damping are circles.

Separation of Disturbance and Command Signal Response

In Sec. 4.6 we designed a controllerwhere the response to command signals was
completely separated from the response to disturbances. This is a nice property
hecause it gives the designer much freedom. It is straightforward to obtain a
similar controller using the polynomial approach, Let the factored model be
described by A = A+A-and B ::: B-1- B-, where A+ and B -+- are the dynamics
that will be canceled. Furthermore let the desired response to command signals
be given by
(5.25)

To obtain perfect model following the polynomial B- must be a factor of Bm ~
because B- cannot be canceled. Hence Bm == BmB-. By introducing

R

=AmB+il

S = AmA+S
T ~ Bm.AoAcA+

(5.26)

Pole-Placement Design: APolynomial Approach

178

A
B

Chap. 5

uif

B
A

S
R

y

-1

Figure 5.2 Block diagram ofthe closed-loop system for thecontroller given
by (5.29) that admits complete separation of responses to command signals
and disturbances.

the control law (5.2) can be written as
_ A+

u - B+

(BmAoAc u
AmR

_

c

S )
RY

(5.27)

It follows from the Diophantine equation (5.22) that

.AoAc =A-h +B-8

(5.28)

Hence

The control law (5.27) can thus be written as

BmA
A+S
u = AmB U c + R+R (Ym - Y)

(5.29)

This controller is composed ofa feedforward with the pulse-transfer function

H (z) = Bm(z)A(z) = Bm (z}A(z)
ff
Am(z}B (z) Am(z)B+(z}
and a feedback from the model error e = Ym-

H (z)
fb

=

y

(5.30)

with the pulse-transfer function

At (z)S(z)
B+(z)R(z)

(5.31)

The polynomials Rand S are obtained from (5.28). The controller corresponds
to the general structure ofa two-degree-of-freedom controller shown in Fig. 5.2.
The response to disturbancesis governed by the polynomials lie and All and the
response to command signals is given by the pulse-transfer function Bm/Am.
Notice that the controller cannot be implemented by the separate blocks shown
in the figure, because each separate block is not causal.

Sec. 5.4

179

More Realistic Assumptions

e

v
B

u

y

A

Figure 5.3 Block diagram of a closed-loop system with command signals,
load disturbances, and measurement errors.

Improved Response to Disturbances
We will now modify the controller to improve its response to disturbances. For
this purpose we will assume that there is a process disturbance v that acts at
the process input and measurement noise that acts at the process output e. This
is illustrated in the block diagram of Fig . 5.3. The system in Fig. 5.3 is described
hy the equations.
Ax

:c<;

B(u + v)

y =x +e
Ru :;: : TU e - Sy

(5.32)

Solving for the signals x, y, and u we get

BT
BR
BS
c
x = AR + B S U + AR + B S U - AR + B S e
BT
BR
AR
)':: AR + BS U + AR + BS v + AR + BS e
AT
BS
AS
c - AR + B S v - AR + BS e
U = AR + BS U
C

(5.33)

These equations tell how the closed-loop system responds to command signals
and disturbances. We will assume that the design is performed in such a way
that the closed-loop system is always stable. The characteristic polynomial.L, =
AR + BS then has all its roots inside the unit disc.
First, consider the situation when the load disturbance v is a step. The
steady-state response is then given by the static gain. 1b avoid that there is a
steady-state error we must require that the static gain from the disturbance v
to x is zero. This means that B(l)R(l) ::: O. Iftbe process itself has a nonzero
gain , that is, if B(l) f; 0 then we must require that R(l) = O. This means that
z - 1 is a factor of R (z) or that the controller is required to have integral action.
Periodic signals with period n . h can he eliminated in a similar way by
requiring that z" - 1 is a factor of R (z). This follows from the observation that
a signal with period n· h satisfies the difference equation

u( (k + n)h) -

v(kh) = (qn - l)v(kh) = 0

Pole-Placement Design: A Polynomial Approach

180

Chap.S

In a similar way a sinusoidal load disturbance with frequency (00 will not give
any steady-state deviation if the polynomial R(z) has the factor z2 - 2z cos OJoh+
1. This follows because the sinusoid sin OJot satisfies the difference equation

y(kh) - (2 cos OJoh) y(kh - h) + y(kh - 2h) = 0
which can be verified by a direct calculation.
Measurement noise is typically of high frequency. The Nyquist frequency
is the highest frequency of interest in a sampled system. This corresponds to
z = -1. One way to make sure that measurement noise does not generate large
signals is to require that the polynomial S (z) have the factor z + 1. This means
that measurement signals at the Nyquist frequency do not give any errors in
the process variable. Signals with other frequencies can be suppressed in an
analogous way by requiring that the polynomial 8(z) vanishes at other other
values of z,
To summarize we find that disturbances can be dealt with by introducing
constraints on the polynomials Rand S. Disturbances at the process input (load
disturbances) are dealt with through the polynomial R and disturbances at the
process output (measurement noise) through the polynomial S.

Examples

Two examples will be given to illustrate control-system design with the poleplacement algorithm.
Example 5.5 Motor with cancellation of process zero
The pulse-transfer function of a DC motor can be written as
H(z)

=

K(z - b)
(z-l)(z-a)

(5.34)

(see Example A.2), where

K

~ e- h

1+h

-

a ;;;; e- h
b '= 1 _ h{1 - e-li )
e-h - 1 + h

Notice that b < 0; that is, the zero is on the negative real axis. It is first assumed
that the desired closed-loop system is characterized by the pulse-transfer function
Hm(z) '" z(l + Pl +P2)
2

2

+ P1Z +PZ

{5.35)

The pulse-transfer function H has a zero z = b that is not included in Hm • With
the given specifications, it is necessary to cancel the zero z "" b. Factor B as

=z- b
s :« K

B~

181

More Realistic Assumptions

Sec. 5.4
Then

The observer polynomial can be chosen as
Ao(z)

The degree of the polynomials

~

1

R and S are given by

deg R:: : . degA, + deg Am - degA == 0
degS "'" degA -I = 1

We now introduce R as a zero-order polynomial and S as a first-order polynomial
in the design equation. The following polynomial identity is then obtained.
(z -l)(z - a)ro + K(soz + Sl)

=l' +PIZ +P2

Equating coefficients of equal powers of z gives the equations
TO

=1

-(1 + a)ro + KSQ =PI
aro + KS1 ;::: P2

Hence

ro

:=

So;:::

1
1 +a+ PI

-~-=--

K

P2 -a

51=--

K

Further

The control law can be written as
u(k) = touc(k) - soy(k) - sly(k - 1) + bu [k -1)

(5.36)

A simulation of the step response of the system is shown in Fig. 5.4. Notice the
"ringing," or the "ripple," in the control signal, which is caused by the cancellation
of the zero on the negativereal axis. Theripple is not noticeable in the output signal
at the sampling instants. It is, however, seen as a ripple in the output between
the sampling instants . The amplitude of the ripple in the output depends on the
_
sampling period. It goes down rapidly as the sampling period is decreased.

Pole-Placement Design: A Polynomial Approach

182

Chap. 5

(b)

5

5

2
+'

::l

At
r::l

10

5

10

10

2
~

1

::l

Q,

1

==
-0

~O

0

5
Time

10

0

Time

Figure 5.4 Step response for a motor with pole-placement control. The
specifications are ( =0.7 and fJJ = 1. The sampling periods are (a) h = 0.25

and (b) h = 1.0. The process zero is canceled.

Rumple 5.6 Motor with no cancellation of process zero
Consider the same motor as in Example 5.5, but assume that the desired closedloop transfer function is

(5.37}

Notice that the process zero on the negative real axis is now also a zero of the
desired closed-loop transfer function. This means that the zero does not have to be
canceled by the regulator. Factor B as

Hence,

The degree of the observer polynomial is

Therefore, the observer polynomial should be of at least first degree. A deadbeat
observer ~ Chosen:

Sec. 5.5

183

Sensitivity to Modeling Errors

The minimal degrees of the polynomials Rand S are then given by
deg R ;;;; degAlii + deg Ao - deg A ;;;; 1
deg S = deg A-I = 1
The Diophantine equation can then be written as

To determine rt , put z = b in (5.38). Hence,

which gives

Now put z = 1 and z =. a in (5.38). This gives

K(l-b)(so+sd = l+Pl +P2
:3

K(a - b){soa + sd = a

+Pia 2 +P2 0

from which So and 81 can be determined. Further
1 + Pl + P2
T(z } ~ A"B/Il = Z K(l _ b) = toz

The control law is then
u(k) = touf (k)- soy(k) - sly(k -1) - rlu(k -1)
Notice that this feedback lawis ofthe sameConn as (n.36). However, the coefficients
are different. A simulation ofthe step response ofthe system is shown in Fig. 5.5.
A comparison with Fig. 5,4 shows that the control signal is much smoother; there
is no ringing. The response start is also a little slower, because All is of higher
degree than in Example 5.5.
•

5.5 sensitivity to Modeling Errors
A process model is a key element in control-system design. It is interesting
to investigate how sensitive the closed-loop system is to modeling errors and
also to determine how accurate the model needs to be for a successful control
design. These problems can be approached very naturally in polynomial design.
We refer to the discussion of sensitivity and robustness in Sec. 3.3.

Pole-Placement Design: A Polynomial Approach

184

(a)

Chap. 5

(b)

5

5

10

10

2

2
~

go 111
- 0 l ~"""""-----------1

o

5
Time

10

o

5

10

Time

Figure 5.5 Step response of a motor with pole-placement control. The specifications are w :::: 1 and ( :::: 0.7. The sampling periods are (a) h == 0.25 and
(b) h = 1.0. The process zero is not canceled.

Stability Margins
Phase and amplitude margins are traditional measures that are used to express the sensitivity of a system to modeling errors. The sensitivity function
introduced in Sec. 3.3 is another measure.

AR
5= AR +BS

1
~ 1 +BSjAR

AR
:=-

(5.39)

The inverse value of IS(eiw)1represents the distance from a point of the Nyquist
curve of the loop-transfer function B S / AR to the critical point -1. The maximum value of IS(eiw)j is thus the reciprocal of the smallest distance from the
critical point -1 to the Nyquist curve. To have a reasonable robustness against
instability, the largest value of IS( eiCll ) 1 should therefore not be too large. A typical requirement is that IS I < 2. In all design work it is therefore useful to
(ejl"tl)
investigate IS(e1aJ)1and make sure that it is not too large.
Control-system design is normally an iterative procedure. In a typical
case we start with a nominal design. By calculating the sensitivity function we
may find that the sensitivity is too large for some frequencies. It follows from
Eq. (5.39) that a large sensitivity can be reduced by making R or S small at
some frequencies. Making R small means that the controller gain is increased;
making S small means that the controller gain is decreased. Th avoid the large
sensitivity we can introduce additional constraints on polynomials Rand S in
some frequency ranges and repeat the design.

Sec. 5.5

185

Sensrtivity to Modeling Errors

Alternative Conditions
'lb further investigate the sensitivity of the closed-loop system to changes in the
process model, it is assumed that the design is based on the model H ::: B I A,
and the true model is HO :;: B I Ao. From Theorem 3.5 it follows that the closedloop system is stable if

°

IH (z) - HO(z) I ~ H(z)
Hrr(z)
Hm (z) . H[b(Z)
for

Izi :;:

I= Hm(z)S(z)
H(z)T(z)

(5.40)

I, where it follows from (5.30) and (5.31) that Hm = toB/A c • H[r

T/R, and H fb

::

:=

S /R. The relative accuracy that is needed for stability is
IH(z) - HO(z)1 <
1
Hrr(z) I
IH(z)1
- IHm (z)\ I H [h(Z)

It is easy to use this result. When a design is performed, the right-hand side of
wh
(5.40) can easily be calculated for z :;: e1 • Notice that it does not depend on
the true pulse-transfer function.
The condition given in (5.40) has good physical interpretation. Consider
first the ratio HI Hm. The pulse-transfer function H of the process is typically
large for low frequencies and decreases for high frequencies (see Fig. 5.6) . The
desired pulse-transfer function H m of the closed-loop system is typically unity
for low frequencies. There is a small increase around the crossover frequency
and H m decreases for high frequencies. The frequency response of H m is also
shown in Fig. 5.6. The ratio H / H m is easy to obtain from the figure. It is
clear from the figure that it is sufficient to have good model precision only in
certain frequency ranges. The consequences of changing the desired bandwidth
of the closed-loop system can also be determined. The requirements on the model
accuracy are relaxed if the closed-loop bandwidth is decreased. A more-precise
model will he needed if the desired bandwidth is increased. The requirements

Figure 5.6 Bode diagrams for Hand Hm • The ratio
in (5.40), is easily found in the figure.

H/Hm , which appears

Pole-Placement Design: A Polynomial Approach

186

Chap.S

on model precision are smaller for frequencies where the feedforward gain is
larger than the feedback gain. The ratio of the feedforward- and the feedbackpulse-transfer functions H it I H (6 :: TIS is equal to one for a controller with
error feedback.
Performance

So far we have concentrated on the influence of modeling errors on the stability
of the closed loop. It is also possible to investigate other questions. For example,
it is interesting to see how modeling errors will influence the pulse-transfer
function from the command signals to the output. The controller obtained by
Algorithm 5.1 gives a closed-loop system with the pulse-transfer function

H

el

=H

m

1
1 + (RB jAc/)(l jHO- l lH )

(5.41)

This expression shows how errors in the model arc reflected in errors in the
closed-loop pulse-transfer function. It is clear from the expression that the errors
are small when the open-loop pulse-transfer functions Hand HO are large.

5.6 A Design Procedure
The analysis in Sec. 5.4 bas given insight into the design problem. In particular
we have found that many factors can be taken into account simply by requiring
that the polynomials R and Shave specified factors. Poles and zeros of the
process may be canceled; compare with Eq. (5.21). Attenuation of disturbances
can be improved. For example, steady-state errors are removed by requiring
that z -1 be a factor or R(z). This means that the controller is required to have
integral action. The sensitivity function will be unity at the Nyquist frequency
if we require that z + 1 is a factor ofS (z). A complete separation of the responses
to command sig-nals and disturbances can be obtainedby requiring that Rand
S have certain specified factors, as expressed by Eq. (5.26). Summarizing we
thus have the following general design procedure.
ALGoRITHM

5.3

GENERAL POLE-PLACEMENT DESIGN

Data: A process model is specified by the pulse-transfer function B(z)/ A(z) ~
where A{z) and B(z) do not have any common factors; the closed-loop characteristic polynomial Acl (z); polynomials Rd(z) and Sd(Z), which specify given
factors of R(z) and S (z); and the pulse-transfer function Bm(z)jAm(z), which
gives the desired response to command signals.
Pole excess condition: deg Am (z) - deg Bm(z) 2: degA(z) - deg B (z).
Model following condition: The factor B- of B that is not canceled by the
•
controller then must be a factor of B m that is, Bm= B - Em.

Sec. 5.6

187

A Design Procedure

Degree condition:
deg Ad = 2deg A +degAm+ deg Rd + deg Sd -1

Step 1. Factor the polynomials A and B as A == A+A- and B
A+ and B + are factors that can be canceled by the controller.

=

(5.42)

B + B-, where

Step 2. Solve the Diophantine equation
(5.43)
with respect to Sand R.

Step 3. The controller is then given by

(5.44)
where

R ~ AmB +RdR

S =AmA+SdS
- +T = BmA Ad
s; == BmB and the closed-loop characteristic polynomial is Ad ;:: A +B +Am.Ad •

(5.45)

•

The degree condition is obtained in the following way. Equation (5.43) has a
minimum-degree solution with deg SO ;:: deg A- + deg Rd - 1. It then follows
from Eq. (5.45) that
degS = degA" + degA" + degAm
= degA + degA;

+ deg Rd + degSd-1
+ degR d + degSd-1

Because deg R == degS we obtain the condition (5.42). Comparing with the
simple design procedure in Algorithm 5.1 we find that the order of the closedloop system is increased with deg Am + deg Rd +deg Sd. The requirements are
thus coped witb by increasing the order of the controller.
Calculating the Control Law

TheDiophantine equation (5.43) can be solved by Euclid's algorithm,as was discussed previously. It can, however, also be solved in the following way. Assume
that we have a solution RO and SO to the equation
(5.46)

Pole-Placement Design: A Polynomial Approach

188

Chap. 5

and the minimum-degree solution U and V to the equation
AU +BV;::; 0

{5.47)

Such solutions are typically obtained from the solution of a simple design problem. We introduce the polynomials Rand S defined by

R =XRo+ YU

(5.48)

S:;;:XSo+YV

where X is a stable monic polynomial; then
AR + BS == XA~I

If polynomials A~, and X are chosen so that Ad = A~,X, we thus find that
polynomials Rand S given by (5.48) satisfy (5.43) . To satisfy the compatibility
conditions X should have deg Rd + degSd. Polynomial Y will generically have
degRd + deg Sd -1. To determine polynomial Y we impose the conditions that
Rd divides R and that Sd divides S. This gives the following linear equations
for determining the coefficients ofpolynomial Y.
X(zi)RO(Zl) - Y(z/)U{ziJ ;: 0 for Rd(Zi)= 0
X(ZI)SO{ZI)

+ Y(ZI) U(ZiJ :;;; 0

(5.49)

for Sd(Zl) == 0

We illustrate the procedure by two examples.
Example 5.7 Integral action
Assume that a controller RO, So has been designed and that we want to find
a new controller for the same system that has integral action. Assume that the
rninimum-dagras solution of Eq. (5.47) is U = -B and V ~ A. A new dosed-loop
pole is introduced at -Xl; hence X (2) = Z +XI. The polynomial Y(z) is then simply
a scalar Yo and Eq. (5,49) become

This gives Yo

= (1 + xdR O(l)/ B(1) and the new controller becomes
R(1- ) = (Z + r 1}Ro(Z ) _ {I + xl)R°{l)B (z)
B(l)
S{ ) = (
Z

Z+Xl

)So()
Z

+

(1 +xtlR()(l)A(z)
B(l)

•

189

A Design Procedure

Sec. 5.6

Example 5.8 Integral action and robustness
Considerthe same problem as in Example 5.7 but assume that in addition we would
like to make sure that the sensitivity function is oneat the Nyquist frequency. This
is achieved hy the conditions Rd =: Z - 1 and Sd :;: Z + 1. The polynomial X is thus
of second order and polynomial Y is of first order. The conditions (5.49) become
X(l)RO (l ) - (Yo + ydB (1) = 0

X( -l)SO( -1) - (-YO YI)B{ -1)
+

=0

Solving these equations for Yo and YI gives
_ ~ (X(l)R{)(l) _ X( -l)SO(
Yo - 2
B(1)
B(-l)

_ ~ (X(l)R O(l)
Yl - 2

B(l)

-1))

X(-l)SO(

+

B{-l)

-1))
•

Youla-Kucera Parameterization
The calculations made give an interesting characterization of stabilizing controllers. We have the following result.
5.2 YOULA.KuCERA PARAMETERIZATION Consider a system described by the transfer function B(z)/ A(z) . Let 8 0 (z)/RO(z) be a stabilizing
controller. Then all rational stabilizing controllers are described by
THEOREM

S(z) _ SO(z) + Q(z)A(z)
R(z) - RO(z) - Q(z)B(z)

(5.50)

where Q(z) is stable,

Prool We will first prove that the controller given by (5.50) is stable. To
do so we introduce Q(z) = Y(z)jX(z) , where X(z) and Y{z) are polynomials. It
follows from the assumption that X (z) has all its zeros inside the unit disc. The
controller (5.50) can then be written as

where we have dropped the argument to simplify the writing. This controller
gives a closed-loop system with the characteristic polynomial
AR

+ B S = A(XRO - YB) + B (X SO + YA) ::: X(ARO + B8°)

This polynomial has all its roots inside the unit disc because X is stable and
ARo +B SO is a180 stable. Th prove that all stabilizingcontrollers can be written

Pole-Placement Design: A Polynomial Approach

190

Chap. 5

Q

-A

B

Process
u

B Y
A

t-----~

Figure 5.7 Block diagram that illustrates Youla-Kueera's characterization
of all stabilizing controllers.

as (5.50) with Q stable, consider a stabilizing control SIR that gives a closedloop system with the characteristic polynomial
AR + BS

=C

It follows from (5.50) that
SRo -- QSB == RSo + QRA

Hence
SRO - RSo
SRo - RS o
Q = AR +BS "" C

which is stable because polynomial C has all its zeros inside the unit disc.

•

This theorem is often quite useful in control system design bemuse it gives a
simple way of characterizing all stabilizing controllers. The block diagram in
Fig. 5.7 illustrates the theorem.
Practical Aspects

The design procedure given by Algorithm 5.3 is a solution to a general poleplacement design problem. The solution is specified in terms of the closed-loop
characteristic equation with auxiliary constraints on the controllerpolynomials.
Although the characteristic polynomial in principle can be chosen arbitrarily, it
is necessary to choose it properly in order to obtain a controller that is not too
sensitive to modeling errors. For a practical problem a variety of requirements
must be expressed in terms of conditions on the characteristic equation. This
is straightforward for systems of low order but it may be difficult for a system
of high order. Real control-system design is typically an iterative procedure
consisting of the steps:

Sec. 5.6

A Design Procedure

191

1. Choose a characteristic polynomial and controller constraints Rd and Sd·
2. Determine a controller using Algorithm 5.3.
3. Evaluate the design.
The steps are repeated until a satisfactoryresult is obtained. Steps 2 and 3 are
straightforward. The difficult step is to modify the characteristic polynomial
and the controller constraints if the design is not satisfactory. Some detail of
the procedure will be discussed in the following.
The Characterislic Polynomial

It is convenient to describe the characteristic polynomial in terms of factors of
first and second order, which are described in terms of their continuous-time
equivalents. The discrete-time equivalent of a first-order system characterized
by A{s) = s + a is

where a -:::. e~ah, and a second-order system A(s) = 32 +2( WOS
to

where al = -2e-(Woh cos
then

+wa is equivalent

(woh '1'1- (2), and a2 = e- 2( a>oll. A common choice is

In this case the system has three dominating poles and the remaining poles are
positioned at the origin.
It is practical to use the continuous-time parameters a, (00, and' instead
ofthe equivalent discrete-time parameters a, ci , and a2. The designer can then
use the intuition developed for continuous-time systems and it is a simple task
to compute the discrete-time parameters.
The poles ofthe closed-loop characteristic polynomial are normallychosen
so that the dominating poles are of the same order of magnitude as the openloop poles. It follows from the analysis of sensitivity to modeling errors that the
closed-loop system will be very sensitive to parameter variations if the closedloop bandwidth is chosen much higher than the bandwidth of the open-loop
system. Compare with Fig. 5.6. The observer poles are often chosen to be a
little faster than the controller poles.
Influence of the Observer Polynomial

The effect of the observer polynomial on the transmission of disturbances is
illustrated by two examples in which we use the simple design procedure given
by Algorithm 5.1.

Pole-Placement Design: A Polynomial Approach

192
(a)

(b)

1

",

,

.

11-"--......0...:.

..

...

r::
....
CIS

o

Chap. 5

l::
ell

o

0.1

0.01

0.1
1
Frequency, rad/s

10

0.1

0.01

0.1
1
Frequency, radls

10

Figure 5.8 Bode diagrams (gain curves) for the transmission of (a) load
disturbances and (b) measurement noise for the system in Example 5.9.

Example 5.9 Influence of the observer polynomial 1

Consider a system with the pulse-transfer function

H(z ) ==

~
z-1

Assume that the desired pulse-transfer function from command to output is given

by

n; (z) = z ~·~.8
We have thus Ac(z) ~ z - 0.8. The observer polynomial can be chosen as Ao "'- 1,
which gives the controller
u(k) :: 2(uc (k) - y(k))

and the desired closed-loop transfer function. The process output is then given by
(compare with Fig. 5.3)
X(z)

:>;

z

~·~.8 Uc (z) + z ~·~.8 V(z) - z ~·~.8 E(z)

The Bode diagrams for the transmission of load disturbances and measurement errors are shown in Fig. 5.8. The gain from low-frequency load disturbances
is 0.5 and from low-frequency measurement disturbances is 1. High-frequency load
and measurement disturbances are wen attenuated.
_
Figure 5.8 shows that the proportional feedback gives a closed-loop system that
is sensitive to load disturbances. A less-sensitive system can be obtained by
introducing an observer polynomial of higher degree and constraints on the
polynomial R, as shown in the next example .

193

A Design Procedu re

Sec. 5.6

(b)

(a)

1

1l---........::-:i:t.I~-:< : ~:

" ..

-<:':'.,,,
....

s::

~

~

0.1

~

/

0.1

I
I' .:

0.01

0.1

0.01

10

1

0.1

1

10

Frequency, rad/s

Frequency, radls

Figure 5.9 Bode diagram for the signal transmission from (a) load disturbances and (b) measurement error to process output for the controller
in Example 5.10. The observer polynomial has a ::;. 0.99 (solid) , a "" 0.9
(dashed), a = 0.5 (dashed-dotted), and a = 0 (dotted) .

EJ:am.ple 5.10 Influence of the observer polynomial 2
Consider the same system and the same desired closed-loop response as in Example 5.9. Let the observer polynomial be
Ao(z) = z - a

The Diophantine equation (5.4) becomes
(z - 1)(z + rd + O
.l(soZ + 51) = I:Z- a)(z - 0.8)

Hence the following conditions are obtained.
-1 + rl + O.lso = -a
- rl + 0.181

-

0.8

= 0.8a

Because there are two linear equations and three unknowns, one extra condition
may be introduced. Choose rl ;;; -1 to obtain integral action. This gives
So

= 12 -

Sl

= Ba - 10

lOa

The following expression is obtained for the process output.

X(z)

= ~ Ur(z) +
z - 0.8

O.1(z -1) V(z) _ (1.2 ~a)l-l + O.8a E(z)
(z - a)(z - 0.8)
(z - a}(z - 0.8)

The Bode diagrams for the signal transmission from load disturbances and measurement errors to x are shown in Fig. 5.9; compare this with Fig. 5.8. By changing the observer dynamics the closed-loop system will be less sensitive for lowfrequency load disturbances. The figure shows that the effects ofload disturbances
and measurement noise are strongly influenced by the observer polynomial Ao. A
fast ohserver (a = 0) gives a very good rejection of load disturbances, but much
measurement noise is also injected into the system. With a slow observer (a ;;; 0.9),
much less measurement noise is injected into the system but the attenuation of
•
load disturbances is not so good.

194

Pole-Placement Design: A PcXynomial Approach

Chap. 5

Se'ectlon of Sampling Interval
The choice of samplinginterval was discussed in Sec. 4.3 for the pole-placement
design basedon state feedback. Thesame arguments can be ueed for the method
given in this chapter.This meansthat the sampling interval should be chosen in
relation to the desired closed-loop behavior. Notice, however, that all closed-loop
poles must be taken into conaideration. This is further discuseed in the following
sections. The simple rule ofthumb to have 4 to 10 samples per rise time of the
closed-loop system or 15 to 45 samples per period may be inadequate for highorder systems where the rise time to command signals and disturbances may
be very dift'erent.

Validation
After a controller is obtained it is important to investigate the closed-loop system obtained to determine if it satisfies all requirements. 1b do this we must
investigatethe response to command signals and disturbances and the sensitivity to modeling errors.
In the nominal case when the process model is correct it follows from
Eq. (5.33) and (5.45) that the response of the closed-loop system obtained by
Algorithm 5.3 is given by

BM
x=Am

Uc

+

BRdR
B-SdS
ve
A+AcI
Ac,

s;

BRdR
A-RdR
c + A+ttl V Acl e
y = Am U
+

ABm
BAm

u = - - Uc -

B-SdS
•

AcJ

V-

(5.51)

ASIlS
• e
B+ Act

Notice that these responses are completely characterised by six pulse-transfer
functions. The properties of the system can be illustrated by time or frequency
responses. 'Ib get a properassessmentofthe system it is important to investigate
the responses of all signals to all inputs.
Consider, for example. the response to command signals. H there are no
diaturbances it follows from Eq. (5.51) that

Hlfl
u= H

U(

(5.52)

11lia equation gives the control signals for a desired command signal. Notice
that the ratio Hili / H also appeared in the robustneu analysis. Compare this
with Figure 5.6. The fact that very large eontrol signals are required for a
given command signal is thus a very good indication that the system is highly
sensitive to modeling eJTm'8.
1b judge the sensitivity to modeling eJTm'8 it is useful to compute tha

Sec. 5.7

Design of a Controller for the Double Integrator

t95

loop-transfer function
(5.53)

and to evaluate amplitude and phase margins and crossover frequencies. It is
also useful to investigate the sensitivity function

(5.54)

5.7 Design of a Controller for the Double Integrator
In pole-placement design we are primarily choosing the polynomials ~ and ~,
whose zeros are the closed-loop poles, and the sampling period. 'lb make proper
choices it is important to understand how they influence response to command
signals, load disturbances, measurement noise, and sensitivity to modeling errors. This is illustrated in this section where we consider control of a doubleintegrator plant. The design will be based on Algorithm 5.1.

Process Model
Consider a proceas with the transfer function

k
G(s) =s2
where' =1. This could, for example. be a simplifiod model of the arm servo of
a compact disc player. The sampled pulae-transfer function is

H(z) ;:

h2

"2

Z +1
(z _ 1)2

Specifications
The properties of the closed-loop system are specitiod indirectly by requiring
that the polynomial Ac is the di8C1'ete-time equivalent of
8

2

+ 2(ws + ar

Hence

~ (z) =,2 - 2ze-'· cos ( whJl -

(2) +e-

2( IPA

== %2 +aclZ + ac2

An observer of second order is required if we want a controller with intfgral
action. '!be ob&erver polynomial is chosen 88 the discrete-time equivalentof a
continuous system with two poles at, = -a. Hence
Ao(z) = (z- e- ah)2 ;. + (101% +ad

r

196

Pole-Placement Design: A Polynomial Approach

Chap. 5

Controller Design

The controller design is now straightforward. The Diophantine equation (5.4)
becomes

where it is required that R have a zero at z ~ 1. The minimum-degree solution
with no controller delay is such that both Rand 8 are second-order polynomials,
that is,
8(z)

= soz2 + SIZ + 82

R(z) = Z2 + rlZ + r2

= (z + r)(z ~ 1)

Straightforward calculations give

where A~I{z) and A~l(z) are the first and second derivative of Act with respect
to z. The polynomial T is given by

Nominal Design

The design parameters that the user has to choose are the polynomials Ac
and Ao' which specify the closed-loop poles, and the sampling period h. The
closed-loop poles are parameterized in terms of " W, and a, that is, in terms
of continuous-time equivalents. The nominal parameter values are chosen as
S :; 0.707, W = 0.2, a = 2, and h ~ 1. This choice means that the observer
poles are an order of magnitude faster than the dominant poles. The sampling
rate is chosen so that mh = 0,2, according to the recommendation in Sec. 5,6.
This choice, however, does not take the observer dynamics into account. Withthe
chosen sampling period we have e- a h = 0.135. The sampled observer poles are

Sec. 5.7

197

Design of a Controller forthe Double Integrator

50

100

150

100

150

0.1

o
o

50
Time

Figure 5.10 Simulation of the nominal design, which has parameters
w == 0.2, ( ;::: 0.707, a ~ 2, and h == 1.

thus close to the origin. A simulation experiment is performed to illustrate the
properties of the nominal design. The experiment is chosen to show responses
to command signals, load disturbances, and measurement noise. A unit-step
command signal is first applied to the process. A load disturbance in the form
of a negative step with amplitude 0.05 at the plant input is then applied at time
50. Finally, a high-frequency sinusoidal measurement error e(k) = 0.01sin2t is
introduced at time 100 to show the response to high-frequency measurement
noise. 'Theresults are shown in Fig. 5.10. Notice that frequency folding is clearly
noticeable in the control signal. The Nyquist frequency is 0.5 Hz = ft rad/s and
the measurement noise has a frequency of 2 rad/s. In a practical case it would
thus be important to use a proper prefilter. This is discussed in more detail in
the example in the next section.

Changing wand (
'The polynomial Ac determines the response to command signals. It also influences the response to load disturbances and measurement errors. Figure 5.11
illustrates the consequences of changing w. The results are as we can expect.
'The response time and the error due to load disturbances decrease inversely
proportional to the bandwidth. When the bandwidth is increased, the control
signals also increase. The initial control signal is approximately proportional to
the square of the bandwidth . Saturation of the control signal thus limits the
admissible bandwidth.
Different choices of (J) have only moderate effect on the response to measurement noise. The fluctuations in the control signal are increased a little when
the bandwidth is increased. The effects of changing damping' are also as can
be expected. A command response without overshoot is obtained for ( :::; 1.

Figure 5.11 Simulation of pole-placement controllers when changing t».
(a) Output for OJ == 0.1 (dashed), 0.2 (solid), and 0.4 (dashed-dotted). (b)
Control signal when to ;;; 0.1. (c) Control signal when OJ =: 0.4.

Changing Observer Poles

The observer has two poles at z = e- a h or equivalently at s ::: -a in the
continuous-time representation. Figure 5.12 shows the effect ofchanging a from
its nominal value a :::: 2. The figure shows that the observer poles influence
the response to load disturbances and measurement noise. The response to
command signals is, however, the same for all observer polynomials, as can be
expected. The response to load disturbances is improved when the observer is
made faster (a = 10). The reason for this is that the disturbance is observed
faster, which implies that the control signal responds faster to counteract the
disturbance. Compare the control signals for a : ;: 0.5 and a :: 10 in Fig. 5.12.
Also notice that the improvement in increasing a from 2 to 10 is marginal. The
reason for this is that with the chosen sampling period an observer with a =2
is close to a deadbeat observer. The response to load disturbances is essentially
determined hy the delay in observing the disturbance due to the sampling. The
influence of measurement noise is decreased by making the observer slower, as
is also clearly seen in Fig. 5.12. Selection of the observer polynomial is thus a
compromise between response to load disturbances and measurement noise.

Figure 5.12 Simulation of pole-placement controllers when changing the
observer poles. (a) Output for a = 0.5 (dashed), 2 (solid), and 10

(dashed-dotted). (b) Control signal when a
a = 10.

= 0.5. (c) Control signal when

Changing the Sampling Period
The sampling period was chosen so that mh =' 0.2, where (J) represented the
dominating (slowest) closed-loop poles. Figure 5.13 shows the response of the
system when the sampling period is changed.The figure is obtained by sampling
the system and calculating the control laws for different sampling periods. Figure 5.13 shows clearly that the sampling period has a significant infiuence on
the response to load disturbances. The error due to load disturbances increases
with increasing sampling period and decreases with decreasing sampling period.
The reason is that with a sampled system there is always a delay in observing
and reacting to a disturbance. This is clearly noticeable in the control sigual
in Fig. 5.13. The disturbance is a step in the load applied at t : ;: 50. With a
sampling period h :;: 2 the control system first reacts at time t : ;: 52 when the
disturbance has generated a large error. With a sampling interval h : ;: 0.2 the
control signal reacts much quicker before a control error is huilt up. The result
is that the overshoot in the control signal is also much smaller. The benefits
in making the sampling period shorter than 0.2 are marginal. The reason is
that the observer poles are at a : ;: ~2. Witp.. h ::=. 0.2 the disturbance response

Figure 5.13 Simulation of pole-placement controllers when changing the
sampling period. (a) Output for h : 0.1 (dashed-dotted), 1 (solid). and 2
(dashed). (b) Control signal when h = 2. (c) Control signal when h ~ 0.1.

is essentially determined by a. It is necessary to reduce h and increase a to
further improve the response to load disturbance.
Notice that a reasonable choice of sampling period is ah ~ 0.2. We can
thus draw the importantconclusion that to choose the sampling period properly,
it is necessary to consider all closed-loop poles, notjust the roots of Ac •

sensitivity to Modeling Errors

The process model has one parameter, the process gain k. Figure 5.14 illustrates
the consequences of changing the process gain for the nominal design with
k = 1. A gain change of 20% has little effect on the system, but an increase
or decrease of a factor of 2.5 is not acceptable. An interesting observation is
that the sensitivity to process changes is reduced by using a shorter sampling
period. This is illustrated in Fig. 5.15.
Additional insight into the sensitivity to modeling errors is obtained by
investigating the loop-transfer function

L = BS
AR

Sec. 5.7

201

Design of a Controller for the Double Integrator
(b)

(a)

.... 1

...>

1

::I

:l

a,

fr
~

....

;:l

o

o
50

100

50

100

50

100

50
Time

100

(c)

Time

Figure 5.14 Outputs of the system with the nominal controller when the
process gain is changed. (a) k = 0.4, (b) k = 0.8, (c) k == 1.2, and (d) k = 2.5.

(a)

(b)

.e-

.... 1
~
o.
....

0

0

.... 1
::J

~

;;l

50

50

(c)

10C

50
Time

100

100

(d)

.... I

.... 1

.e-

c,
....

:l

::;)

~

6

0

50
Time

100

Figure 5.15 Outputs of the system with the controller obtained for h = 0.2
when the process gain is changed. (a) k = 0.4, (b) k =0.8, (c) k = 1.2, and
(d) k = 2.5.

whose Bode diagram is shown in Fig. 5.16 for systems with samplingperiods 0.2
and 1. Figure 5.16 gives a good insight into the behavior ofthe system. Thelooptransfer function has a phase lag of - 270 at low frequencies. The controllers
provide a significant phase lead to obtain a stable closed-loop system. Notice that
the phase curves of the two systems are almost the same for low frequencies.
The phase of the system with sampling period h = 1 does, however, decrease
Q

Chap. 5

Pole.Placement Design: A Polynomial Approach

202

10000 .--..-----....-------,.--------,---~----.

100

Q
....

d

1

...

-

....

.....

-,

0.011--------1------.1....-------'---=----------..1
0.1
10
1
-100

.------r------,------~------,

- --

" ~. ,.... "
,

41
m

~ -200

.-

..

\

~

\
\

-300 ' - - - - - - - - ' - - - - - - - - - ' - - - - - - ' - - - - - - - - '
0.1
1
10
Frequency, radls

Figure 5.16 Bode diagram for the loop-transfer functions L of the systems
with sampling periods h ::; 0.2 (dashed line) and It -;; ; 1 (solid line).

more rapidly after the maximum. With h "" 1 the phase margin is fPm ::: 42°;
and the closed-loop system is stable for 0.53 ;; k :5 3.03. For h : : ; 0.2 the
corresponding values are rpm =:; 57'~ and stability of the closed-loop system is
, obtained for 0.25 s k s 4, which explains the differences in robustness for
systems with different sampling rates.

-

. ,.,,;. I~.-:--

1
l::

"C;

o

o.i

,

/

0.01

/

'"
0.01

~.~

'" '"
0.1

1

10

Frequency, rad/s
Figure 5.17 Amplitude curve for the sensitivityfunction 5 for systems with
sampling periods h = 0.2 (dashed) and h =- 1 (solid line).

Sec. 5.8

Design of a Controller for the Harmonic Oscillator

203

A Bode diagram of the sensitivity function 5 is shown in Fig. 5.17. The
maximum sensitivity is 1.8 when h == 1 and 1.3 when h = 0.2. The curve
indicates the frequency ranges where high model precision is required. Even if
the bandwidth ofthe system measured from the command signal to the output
is 0.2 rad/s , it is necessary that the process model is reasonably accurate for
frequencies up to 1 rad/s, The model precision required in the frequency range
0.1 to 1 rad/ s is a little higher if the sampling period h = 1 is used. The precision
at frequencies higher than 1 rad/s is, however, less for the system with slow
sampling. If there are considerable unmodeled dynamics at frequencies higher
than 2 rad/s, the design with h = 1 may thus be preferable. Also notice that in
a properly designed system there will be antialiasing filters that influence the
sensitivity. This will be discussed in the next section.

5.8 Design of a Controller for the Harmonio OsciUator
The discussion uf pole-placement design based on polynomial methods will be
continued in this section. The process considered is the harmonic oscillator.
Particular emphasis is given to the influence of the anti aliasing filter.

Process Model

Let the process be the harmonic oscillator with the transfer function
G{s);;::

2
S

w2

0 2

+ (1)0

Wo

=1

See Example A.3. The sampled pulse-transfer function is

H(z) = (1- 13Hz +1) = B(z~
Z2 - 2f3z + 1
A(z)

f3

= cos ((.()oh)

Specifications

The desired response is characterized by the continuous-time characteristic
equation

The sampled-data form of this polynomial is Ac(z). Because the pulse-transfer
function has a zero at -1, no zero cancellation is allowed. This implies that
B + = 1 and Bill::::: const B. It is specified that the controller should have
integral action. This implies that the observer polynomial at least should be of
second order. We choose it as the discrete-time equivalent of

Pole-Placement Design: A Polynomial Approach

204

Chap. 5

Control1er Design
The Diophantine equation (5.4) is
(z2 - 2f3z + l)R(z) + (1- fJHz + 1)8(z) = Ao(z)Ac(z)

:=;:

P(z)

where

R(z) = {z + r)(z - 1)
S(z)

::=: SOZ2

P(z)

::=:

+ SlZ + 82

AI](z)Ac(z)

=Z4 +PIZ 3 + P2Z'l + P3Z + P4

The controller parameters are given by
P(-1)
1 - 4(1 + fJ)

r ;:

PI - r + 1 + 2f1

1 - [3

So =
81

P2 - PI - 2[3 + 2(1 + f3)(r - 1)
=
1 - f3

S2

= 1- fJ

P4 + r

The polynomial T is given by
T( ) :::: Ac(l)Ao(z)
B(l)

Z

(a)

(b)

r

..., 1
~

.s-

\

~

------

....

~ 1

7

..
::s

a.

V

:I

0

0
0

20

0

0
0

40

~ 2

40

20

40

~2

....,

20

~

e,

P-

~

I:;

0

0

20
Time

0

40

0

Time

Figure 5.18 Simulation of the nominal design for the harmonic oscillator
when

to =

1.51

Woos

=:

3, ~ ;;;; ~QbB

;;;;

0.7, and h

integrator. (b) With an integrator in the controller.

= 0.2.

(a) Without an

205

Design of a Controller for the Harmonic Oscillator

Sec. 5.8

(b)

(a)
~l

1

c.
....

0

-

.... 1
:;l
c.
....

.&

0

='

V

7

::l

=s

0

0

20

0
0

40

20

40

20

40

~2

~2

c.

Q.

c

r=:

>-l

~

0

0

0

20
Time

40

0

Time

Figure 6.19 Response of the pole-placement design for the harmonic oscillator for different observer dynamics. (a) llJoba =4. (b) (i)obs ::: 8.

Nominal Design
The nominal parameter values are chosen as ? = 0.7, OJ = 1.5, ?obs = 0.7,
Wobs ::: 3, and h ::: 0.2. These specifications imply that significant damping is
introduced and that the response speed is increased compared with the openloop system. The choice of sampling rate implies that roh = 0.3 and Wobsh = 0.6.
Recall the rule ofthumb 0.1 ~ wk ::; 0.6. Figure 5.18 shows the output and input
when the reference sigual is a step at t = 0, a step disturhance at the input
at t = 15, and discrete-time white measurement noise with standard deviation
0.01 at t =30.

Changing Observer Poles
Figure 5.19 shows the response when the observer poles are changed to mobs
= 4 and 8. The load disturbance is eliminated faster with a faster observer
dynamics, but the noise sensitivity also increases.

Changing theSampling Period
The sampling period in the nominal design was chosen such that

which is according to the upper limit of the rule of thumb. Figure 5.20 shows
the responses when the sampling period is changed, h ::; 0.1 and 1. As for the
double integrator in the previous section, the controller will respond faster after
load disturbances when the sampling interval is decreased. A too-long sampling

Pole·Placement Design: A Polynomial Approach

206
(a)

.... 1 -(

-

(b)

.

v

::l

0.
::l

.;.0

Chap. 5

-l->

='

1

fr
::l

0

0

0
0

o

20

40

20
Time

40

0
0

20

40

20

40

Time

Firure 5.20 Response of the pole-placement design for the harmonic oscillator for sampling intervals (a) h =0.1 and (b) h = 1.

interval will increase the deviation after the load disturbance. Also) the aliasing
effect is seen when there is measurement noise, because no antialiasing filter
is used. The example shows that the rule of thumb for the choice of sampling
interval gives a sensible result.

Influence ofAntlaUaslng Filter
Figure 5.18 indicates that a significant amount of measurement noise is injected
into the system. A properly designed antialiasingfilter can reduce this. The filter
will, however, introduce extra dynamics into the system. The closed-loop system
will be unstable when the nominal controller is used because of the phase lag
of the antialiasing filter. The filter dynamics should thus be considered when
designing the controller. This will be discussed in detail in Chapter 7. Bessel
filters are commonly used as antialiasing filters. One of their nice properties is
that their dynamics can be approximated with a time delay) which simplifies
the design and reduces the order of the controller. A sixth-order Bessel filter
is approximated as a delay of t = 2.7/WB. The filter bandwidth is chosen as
(tJn = 2Jl', which gives t ~ 0.43. To incorporate the delay it is necessary to
increase the order of the controller such that deg R = deg S z: deg T = 5.
Figure 5.21 shows the response with an antialiasing filter when the design is
made by approximating the filter by a delay. The measurement noise, which is
a discrete-time white-noise sequence with a sampling period of 0.01, starts at
t ;; 30. A comparison with Fig. 5.20 shows that the fluctuations of the control
signal due to measurement noise are reduced substantially. The filter, however,
will increase the deviation after the load disturbance because of the additional
dynamics.

207

Design ofa Controller for the Harmonic Oscillator

Sec. 5.8

v
O~---------'

o

20
Time

o

40

20

40

Time

Figure 5.21 Response of pole-placement design when using an antialiasing

filter, Output and input when the filter is approximated with a delay in the
design.

Robustness
The consequences of modeling errors will now be investigated. To do this it is
assumed that the real process has the transfer function

instead of 0(8) =(05/(8 2 + w~). This means that the real system has additional
phase lag that has been neglected in the design. Figure 5.22 shows the influence
of unmodeled dynamics when ad ;:; 15 and 10 and when the nominal controller
is used. The flgure also shows the sensitivity to gain variations.
The Bode diagram for the loop-transfer function L in the nominal case is '
shown in Fig. 5.23. The figure shows that the phase margin is reduced when the

(a)

.

A

.... 1

.. I

"

V

:::I
e,

(b)
;:j

g,

;.lI

.4-)

;l

:l

0

0

0

0

20

0

40

{c)

0

20

40

20

40

(d)
~

.... 1
~

;:3
Q.

1

...,

Q,
..j.>

~

::l

0

0

0

0

20
Time

0
40

0

Time

Figure 5.22 Responses when using the nominal controller when (a)
= 15 and k = 1, (b) ad :: 25 and k ;; 0.5, (c) ad "" 10 and k ::; 1,
and (d) ad :;; 25 and k == 1.5.

ad

Pole-Placement Design: A Polynomial Approach

208

Chap. 5

10000 r------...,....----------r------~

100

...
s::

~

o

1

-

0.01 '"-_ _
0.01

-

.

~~~....--J-~~_~_~____'__~--~-~

1

0.1

10

100,----------r------......,..--------,

o
\I)
!/}

~
~

-100

.. _ _ v
_

-200

~

-300'-----------'-------.. . . . . . - - - - - 0.1
0.01
10
1
Frequency, radfs
Figure 5.23 Bode diagram for the loop-transfer function L for the nominal

process for the harmonic oscillator.

gain is decreased. This explains the simulations in Fig. 5.22 where the system
becomes more oscillatory when the gain is decreased.

5.9 Design of a Controller for a Flexible Robot Arm
In this section we will discuss design of a controller for a robot arm with a fiexible joint. This problem was discussed in Sec. 4.7. The process that is described
hy Eq. (4.65)is ofthird order. It has one integrator, two poorly damped complex
poles at -0.05 ±O.999i, and one zero -10. Guided by the analysis in Sec. 4.7
we choose a sampling period h = 0.5 s. Furthermore we choose a second-order
antialiasing filter

8

2

+ l.4wr s + (J)7

with wr = 2 rad/s. The filter has a gain of about 0.1 at the Nyquist frequency
(J)N ~ 6 rad/s.
We will consider two different controllers. One controller does not attempt
to damp the poorly damped process pole. The other will introduce active damping of the process pole.

209

Design of a Controller for a Flexible Robot Arm

Sec. 5.9

1

, ~ " ', X '" '"

.' O' 0-,' ; .
. . ..

·0

.'

., . '

r

' -.

·" , x , : ,
.

,

• I ,'
I ,

I

•

I I

•

•

-1

-2

o

-1

1

Real axis
Figure 5.24 Pole-zero diagram for the process and the filter sampled with
h = 0.5. The leftmost zero represents the zero at -12.1314.

Sampling the Process

The poles of the filter and the process and the antialias filter are of the same
magnitude. The filter dynamics must thus be taken into account in the design.
Sampling the process and the filter with h := ' 0.5 gives a discrete-time
model model with
A(z)

= (Z2 - 0.7505z + 0.2466)(Z2 - 1.7124z + 0.9512)(z '-

....L

V

filter

B (z) :::: 0.1420· 10··

..,

1)
---'

process

3(z

+ 12.1314)(z + 1.3422)(z + a.2234)(z - 0.0023)

The poles and zeros of the sampled system are shown in Fig. 5.24.
Specifications
It is desired to obtain a closed-loop system with a good response to command
signals. The response should be similar to a second-order system with We = 0.5
rad/s and a relative damping (c = 0.7. These specifications were discussed in
Sec. 4.7. The system composed of the robot joint and the antialias filter is of
fifth order, The polynomial AI' is thus also of fifth order. Three ofthe poles are
cbosen as the discrete-time equivalents of

(s2 + 2(rltJc s + (tJ;)(s + aWe)

The remaining poles are chosen as the discrete-time equivalents of the poles of
the antialiasing filter.

210

Pole-Placement Design: A Polynomial Approach

Chap. 5

Notch Filter Design
The frequency associated with the mechanical resonance Wo = 1 is close to the
desired closed-loop frequency me = 0.5. It is then necessary to take the mechanical resonance into account when designing the control loop. A classic method
for doing this is to introduce a compensating network that avoids unnecessary
excitation of the oscillatory process poles. The filter that accomplishes this is
called a notch filter because its Bode diagram has a notch at the frequency of
the undesired modes. This approach ensures that the oscillatory modes will not
be excited hy the command signals or the control action. However, it does not introduce any damping of the oscillatory modes. This means that the system will
respond to excitation of the oscillatory modes in the same way as the open-loop
system. A notch filter can be designed using pole placement simply by canceling
the factor A+ (z) corresponding to the oscillatory modes. In the particular case
we have

At (z) = Z2 - 1.7124z + 0.9512
The Diophantine equation (5.28) is

It follows from the degree condition of the general pole-placement procedure,
Algorithm 5.3, that the closed-loop system is of order 9. The polynomial At is
of second order, Ae is of fifth order, and the ohserver polynomial Ao is thus of
second order. We choose All to have the same poles as the antialiasing filter. The
controller polynomials Rand S are of fourth order. Introducing S = A+ S into
the preceding equation gives the following Diophantine equation for Rand S.

The response to command signals is given by the transfer function BT/ At AcAo.
If we choose

the command signal will not excite the resonant models A+ and the steady-state
gain is une. The response of the closed-loop system when using the notch-design
controller is shown in Fig. 5.25. The reference signal is a step at t := 0, and the
disturbance v is a pulse at t = 25 of height -10 and a duration of 0.1 s. The
response of the system is according to the specifications. Compare with Fig. 4.20.
There is no excita tion of the weakly damped modes by the reference signal or by
the control signal. However, it is unavoidable that the pulse disturbance excites
these mod&s and causes the oscillation in the response. The oscillation does,
however, not introduce any control actions because of the notch filter.

Design of a Controller for a Flexible Robol Arm

Sec. 5.9

...,
;;1

211

1

.fr
~

0

0

40

...,
::I

0..
C

1'"-'1

80

40

0
2

80

1
0
-1

0

Time
Figure 5.25 Response of the closed- loop systemusing the a controller based
on a notch filter.

Active Damping of Oscillatory Modes
With the notch-filter design the controller makes no attempt to damp the oscillatory modes. A new design will now be done such that the servo performance
is the same but the oscillations are also damped. Assume that the damping of
the oscillatory modes should be changed from the open-loop damping = 0.05
to 0.707. Further assume that the damped frequency should be the same as
before. This corresponds to the continuous-time poles

'0

P12 :::

-0.707 ±0.707i

Let the corresponding discrete-time polynomial be denoted Ad. Because deg A =
5 the closed-loop system is of ninth order. The polynomial Ar is the same as
before and we choose the observer polynomial as Ao = A /Ad. The Diophantine
equation (5.28) then becomes

and the solution is ohtained in the usual manner. The response of the closedloop system is shown in Fig. 5.26. Compare Figs. 4.20 and 5.25. The servo
performance is the same as before and the oscillatory modes are now damped
by the controller.
Comparison
To obtain additional insight into the properties of the controller we compute
the loop-transfer functions L for both systems. This is shown in Fig. 5.27. The

Pole·Placement Design: A Po~ynomjal Approach

212

oW

5-

+>
;::I

0

1~1
a

40

80

40
Time

0
2

....
;:l

Chap. 5

80

1

p.,

~
..... 0

-1

0

Figure 5.26 Response of the closed-loop system using the controller designed for active damping,

figure shows that the design based on a notch filter has higher gain at lower
frequencies. This can also be seen by comparing the magnitude ofthe first peak
of the load disturbance responses in Figs. 6.25 and 5.26. The loop-transfer function for the controller with the notch filter is, however, misleading because of
the canceled factor that does not appear in the loop-transfer function. The systern with active damping has a much higher gain around the frequency 1 rad/s,
which corresponds to the poorly damped mode.
The sensitivity functions for the systems are shown in Fig. 5.28. The figure
shows that the design with active damping is more sensitive to modeling errors
than the design based on the notch filter.

100,.-.--------r-------,-..---------,

-

••• . , ;,.0

'\

.~

• •\

,

. . . , • •• , • • • • • "

""
0,01

• • •

\
\
\

0,01

0.1

1

10

Frequency,radJs
Figure 5.27 The magnitude ofthe loop-transfer function L. Gain is shown
with notch design (solid line) and active damping (dashed line).

213

Relations to Other Design Methods

Sec. 5.10

~

' (;3

o

0.1

0.01

1

0.1
Frequency,

10

rad/s

Figure 5.28 Amplitude curve for the sensitivity function S for a system
with notch design (solid line) and a system with active damping of the resonant mode (dashed line).

5.10 Relations to Other Design Methods
Pole placement is a generalapproach to the design ofsingle-input-single-output
systems. Many other design methods may be interpreted as pole-placement design. It is useful to do tbis because it gives a unified description of seemingly
different design methods. The interpretation as pole-placement also gives insights into the different design methods.
Root Loeus

The root-locus method is a classical technique for the design ofcontrol systems.
The method is based on the idea of attemptingto place the closed-loop poles in
desired positions. Thus it is closely related to pole placement. In this method,
polynomials Rand S are first chosen as R :;::: 1 and S :;;; K , which correspond
to proportional control. The gain K is then changed and the roots of the characteristic equation

A+ KB = 0
are investigated. Theroots ofthis equation can easily be sketched for varying K.
If a reasonable pole placement cannot be obtained, the orders of the polynomials
Rand S are increased using heuristic rules. The procedure is then repeated.
The root-locus method can clearly be regarded as a pole placement technique. By applying pole placement the complexity of the controller required to
position all poles can be found directly. With pole placement all poles are positioned in one operation. The complexity of the controller is determined by the
complexity of the process model used in the design.
Error Feedback with Complete cancellation

In some systems the process output y and the command signals U c are not
available because only the error e :::; U c - Y is measured. This case is called

214

Pole-Placement Design: A Polynomial Approach

Chap. 5

error feedback. A typical case is a CD player in which only the deviation from
the track can be measured. This means that a two-degree-of-freedom controller
cannot be used. Mathematically it means that the polynomials Sand T in the
controller are identical and the control law (5.2) becomes

Ru = Siu; - y)
Several design schemes combine error feedback with cancellation of aU poles
and zeros of the process. To analyze a system assume that the process has
tbe pulse-transfer function B (z) jA (z) and that the desired closed-loop pulse
transfer function is Bc(z)j Ac(z). The closed-loop characteristic polynomial is
A(z)B (z)A.c(z) and the Diophantine equation (5.4) becomes

AR +BS:::: ABAr

(5.55)

It follows from this equation that R == BRand S = AS. 'lb obtain the desired
closed-loop response Be must be a factor of S. The minimum-degree controller
is then

S = B~l and it follows

from (5.55) that

The controller thus becomes

S
R

(5.56)

In this case we find that there is a very simple explicit solution to the poleplacement problem. A severe drawback of the method is that both poles and zeros of the process are canceled. To do this they must be stable and well damped.
It must also be required tbat they are not heavily excited by disturbances.

The Oahlin..Higham Algorithm
The Dahlin-Higham design method was popular in early digital process control
design because the calculations required for the design are very simple. It is
a special case of error feedback with complete cancellation, where the process
pulse-transfer function has the form

b
H(z):: Z d(z- a )

(5.57)

and the desired closed-loop response is given by

I-a
r)
z- ac

Hc(z)::: d{
Z

(5.58)

215

Relations to Other Design Methods

Sec. 5.10

It follows from Eq. (5.56) that the controller is

S(z)
zd(z-a)(l-a c }
R(z) = bzd(z -ac } - b(l- ac)

(5.59)

The control law can be written as

T

u(k) = I-a ( y(k) -ay(k-l) ) +acu(k-l) + (l-ac)u(k-d-l)

(5.60)

Because the algorithm is based on cancellation of all poles and zeros of the
process, no poles or zeros can be allowed outside the unit disc. There will also
be problems with ringing due to cancellationof stable but poorly damped zeros.
Smith-Predictor

The Smith-predictor is a special method of dealing with systems with time
delays. A block diagram of the controller is shown in Fig. 5.29. The controller
consists ofa feedback controller GT and a loop around it that contains a process
model. The controller Gr is designed as if the time delay T in the process
was absent and the feedback around the controller ensures that the system
with the time delay will be well behaved. The Smith-predictor can give a very
good response to command signals. The limitations inherent with time delays of
course cannot be avoided. We will illustrate the properties ofthe Smith-predictor
with an example.
Example 5.11 Smith-predictor
A time-delay process is described in Example A.4. The process can, for instance,
represent a paper machine. Assume that the process in (A.lO) has a delay of 2
time units and that the sampling time is h ;:;;; 1. The system is then described by
the model
)'(k

+1) = O.37y(k) + O.63u(k -

2)

~~------------l

I Controller

Process model

I
I
I
I

G)
J

I

u

I

L-

-1 +e -sf

\

J

-1

Figure 5.29 Block diagram of a Smith-predictor,

y

Pole·Placement Design: APolynomial Approach

216

1:1 1

r:."':"'.-/~...:=--=_..-_-~

.&
~

o

/

/

1

~_~.....c--=-.::::...:o_-

;:I

c:
l-4

I
r

.I

~.

20

r,

Q.

I -; . . . -----....,
-

/

o V
o
~

Chap.S

40

__- __
11

...

\

L

1...-......;;;.----------l

...
O'--------------L..----------.I
o

20

40

Time

Figure 5.30 PI-control (dashed) and Smith-predictor control (solid) of the
process in Example 5.11 with a time delay.

(see Example 2.6). If there were no time delays, a Pl-controller with gain 0.4 and
integration time Tj =0.4 would gr;e good control. This PI-controller will not give
good control if the process has a time delay. 1b obtain good Pl-regulation, it is
necessary to have a gain of 0.1 and 1i = 0.5. The response of this controller is
illustrated in Fig. 5.30. The set point is changed at t ;;:; 0 and a step disturbance
is introduced in the output at t = 20. In Fig. 5.30 we also show the response of
the Smith-predictor. Notice that the step response is faster and that the system
recovers faster from tha load disturbance.
_

Having found that the Smith-predictor can be effective we will now proceed to
analyze it from the point ofview of pole placement. Consider a process with the
pulse-transfer function
H z _ B(z) _ B(z) _ B'(z}
( ) - A(z) - zdA'(z) - zdA'(z)

(5.61)

where the polynomial deg AI > degB.
First, design a controller for the system B(z}jA'(z) without delay to give
a closed-loop characteristic polynomial A~I' The Diophantine equation (5.4) for
this problem becomes
(5.62)

furthermore we have T' :;; toAo.
Now consider the system with delay. Determine a controller that gives
a closed-loop system with the characteristic polynomial zdA(z)A~l(z). The Diophantine equation for this problem is

(5.63)

Sec. 5.10

217

Relations to Other Design Methods

The solution is such that S =

AS. Hence
-

d

R +B8 =z Aci

(5.64)

Among the infinitely many solutions to this equation we choose

S = 8'
d

(5.65)

-

R=zAcl-B

This solution is causal because deg B ::: deg A + deg A' - 1 and deg R = d +
2degA' -1;; degA -t degA" -1. Notice that

R = zdA d

-

S =zdA'R' + (zd -1)B8 = AR' +(zd -l)BS'
1

Furthermore T == AT'. The controller

Ru:::; Tuc-Sy
then becomes

(AR' + (zd -l)B

8') u:::: «r« - AB'y

This control law can be written as

(5.66)
A comparison with Fig. 5.29 shows that the controller is the discrete-time equivalent of the Smith-predictor in the figure. Notice that we can immediately conclude that the Smith-predictor is based on cancellation of all process poles.
Thus it can only be applied to stable processes. It is, however, easy to modify
the procedure to give a stable closed-loop system simply by replacing A on the
right-hand side in Eq. (5.63) with a stable polynomial.

lnternal-Model Control
The internal model controller (IMC) is a control structure that has been particularly popular in process control. A block diagram of the system is shown
in Fig. 5.31. The idea is conceptually simple and attractive. It follows from the
figure that if Hp = H rn, then the signal e does not depend on the control signal. Moreover it is identical to the disturbance e. Perfect compensation of the
disturbance is then obtained if H~ is chosen as the inverse of Hp • Such a controller is not realizable and some approximate inverse is therefore chosen. It is
also common to introduce a filter H f in the loop, as is shown in the figure. The
controller in the dashed lines has the pulse-transfer function

He

=

HrH~

I-HfH~Hm

Chap.S

Pole-Placement Design: A Polynomial Approach

218

Controller

e

~----------_._---~----~-------,

I

Ur

I

I
I
I

I
I
I

Process

y

I

I
I
I

I
I

,
I
I
I
I
I
I
I

L

I
I

----_----_---J

Figure 5.31 Block diagram of a process with a controller based on the
internal model principle.

The controller can be interpreted as a pole-placement controller with cancellation of process poles and zeros. Assume that the process has the pulse-transfer
function
B
Hp = zdA'

(5.67)

where the polynomials A and B are chosen so that degA' :;; deg B. Furthermore consider the ideal case when Hm. = Hp • An approximate realizable system
inverse is then
(5.68)
Furthermore let the filter be

(5.69)
Simple calculations show that the controller is in the standard form (5.2) with
R:: (AAr -A'Bf)B
S =AA'B f

(5.70)

T=S
Notice that if the filter has unit static gain, that is, H f (1) :::; 11 it follows that
R(l) = 0, which implies that the controller has integral action.
The closed-loop characteristic polynomial is
(5.71)

The closed-loop poles are thus equal to the poles and zeros of the process, the
poles of the model and the poles of the filter Hr. The poles and zeros of the

219

Relations to Other Design Methods

Sec. 5.10

process must thus be stable and well damped. Notice the similarities with the
Youla·Kucera parameterization in Fig. 5.7.
There are many different versions of the internal model controller. They
differ in the way the approximate inverse is computed and in the selection of
the filter H f .

The Torque Observer
The torque observer shown in Fig. 5.32 is a control scheme for motion-control
systems that is similar to the IMC . The idea is that disturbances in motioncontrol systems typically appear as torques at the process input. The idea is
similar to the IMC. The transfer function H m is a model of the process, H- is
the noninvertible part of Hi'll' and H~ is' an approximate inverse of H m • The
error e is identical to the disturbance torque v if H- = 1 and H~ is an exact
inverse. If the process cannot be inverted exactly e is an approximation of u, This
disturbance is then compensated by feedback through filter H f . Assume that
the pulse-transfer function is given by (5.67), that Hi'll = Hp • Then H - = z-d,
the inverse H t is given by Eq. (5.68), and the filter is given by Eq. (5.69). Simple
calculations show that the controller can be written on the standard form with

R ~ (zdAr-Bf)BR o

s = zdArBSo+ABfR o
S

=

{5.72)

zdArBTo

If the filter has unit static gain we have Ar(l) = B((1), which implies that
R(l) = 0 and that the controller has integral action.
The closed-loop characteristic polynomial is

(5.73)
Controller
llc

r------------,

v
Process
y

Ro,So, To

L

:

Hf

I
r---L-_I
H;;. I
E+

t

I

L

H

m

L

I
I
I
I

-.J

Figure 5.32 Block diagram of a process with a controller based on a torque

observer.

220

Pole-Placement Design: A Polynomial Approach

Chap. 5

The closed-loop poles are thus the poles of the system without the torque observer, the process zeros) and the poles of the filter H f. We must thus require
that the filter is stable and that the process has no unstablezeros. It is straightforward to avoid these assumptions by applying a general pole-placement algorithm. Also notice the similarities with the Youla-Kueera parameterization in
Fig. 5.7.

5.11 Conclusions
It is quite natural to approach pole-placement control by polynomial calculations. In this chapter we have investigated control of the system
A(q)y(k} = B(q)u(k)
A general controller can be represented as

R(q)u(k)

= T(q)uc(k) -

S(q)y(k)

and the design reduces to solving the Diophantine equation
A(z)R(z) + B(z)S(z) = Acl(Z)

where Ad(z) is the desired closed-loop characteristic polynomial. By making
analogies to the state-space approach we also found that for a simple design
problem, the closed-loop characteristic polynomial Act can be factored into a
controller polynomial Ac and an observer polynomial ~+ This gives a very convenient way to compute Luenberger observers and other reduced orderobservers.
The problem of cancellation of poles and zeros has also been discussed. It was
shown that requirements on attenuation of disturbances and model following
can be expressed by requiring that the polynomials Rand S have specified
factors.
With the polynomial approach we also obtain a natural way to discuss
the effects of uncertainties in the process model used to design the controller.
Finallywe showed that many different design techniques canbe conveniently interpreted as pole placement. In summary we find that the polynomial approach
is a valuable complement to the state-space approach. It gives additional insight
and other computetional procedures.

5.12 Problems
5.1 Use Euclid's algorithm to determine the largest common factor of the polynomials
B{z) -=

i - 22 2 + t45z -

0.35

A(z) -= Z4 - 2.6z3 + 2.25z2 - 0.8z + 0.1

Sec. 5.12

221

Problems

5.2 Given the pulse-transfer function
1

H{z) = z+a

and let the desired system be given by
Hm(z) = 1 + a

z+a

(a) Detennine a controller ofthe fonn (5.2) using Algorithm 5.1.

(b) Determine the characteristic polynomial of the closed-loop system.
5.3 Consider the system given by the pulse-transfer function

z+O.7
R{z} =

Z2 _

1.& + 0.81

Use polynomial design to determine a controller such that tbe closed-loop system
has the characteristic polynomial
Z2 -

1.5z +0.7

Let the observer polynomial have as low order as possible and place all observer
poles in the origin. Consider the following two cases:

(a) The process zero is canceled.
(b) The process zero is not canceled.
Simulate the two cases and discuss the differences between the two controllers.
Which oneshould be preferred?
5.4 For the system in Problem 5.2, assume that the feedback can be made only from
the error. Thus the controller has the form

S

u{k):=; R (u~(k) - y(k)}
(a) Determine SIR such that the desired closed-loop system is obtained.

(b) Determine the characteristic equation ofthe closed-loop system and compare
it with Problem 5.2. Consider, for instance, the case when lal > 1.
5.5 Consider the system in Problem 5.2 and assume that the closed-loop system should
be able to eliminate stt!p disturbances at the input ofthe process. This means that
v in Fig. 5.3 is a step.
(a) Analyze what happens when the controller derived in Problem 5.2 is used and
wben u is a step.
(b) Redesign the controller such that the specifications will Ire fulfilled.
5.6 Show that (5.41) is correct.

5.7 Consider the system in Problem 5.2 and assume that a

= - 0.9 and a ; : : -0.5.

222

Pole-Placement Design: A Polynomial Approach

Chap. 5

(a) Use straightforward calculations to determine the influence of modeling errors. Assume that the design is made for a ::= -0.9 and determine the stability
of the closed-loop system if the true process has R pole in aO.
(b) Use Theorem 6.5 to determine the influence ofmodeling errors. What happens

when a is decreased?
5.8 Consider the system in Problem 5.2. Use (5.52) to determine the maximum value
of the control signal as a function of a and a when the command signal is a step.
5.9 A polynomial design for the normalized motor is given in Example 5.5 Simulate
the system and investigate the sensitivity of the design method with respect to the
choice of the sampling interval. Assume that the closed-loop specifications eorrespend to a second-order continuous-time system with damping' ,;; 0.7 and natural
frequency (j) =I rad/s.
5.10 Consider the system described by

A1(z)x(k)

= B1 (z)u(k)

A2(z)y{k) =B2(z)x(k)

Assume that the variable to be controlled is x{k), but that the measured variable is
y(k). Further assume that A2 has its roots inside the unit disc. Derive a controller
of the form (5.2) such that the closed-loop system is

What are the restrictions that have to be imposed? How will uncertainties in A 2
and B2 influence the pulse-transfer function of the closed-loop system?
5.11 Consider the two-tank systemin Problem 2.10 for h

= 128.

(a) Use polynomial methods to design a controller with an integrator. Assume
that the desired clcsed-loop characteristic equation is
Z2 -

This corresponds to

~

,;; 0.7 and

1.55z + 0.64 '" 0
(0 ,,;

0.027 rad/s.

(h) Redesign the controller for different values of (I) and study how the magnitude
ofthe control signal varies with w.
5.12 Consider the control of the normalized motor in Example A2. Show that velocity feedback can be designed using pole-placement design. (Hint: First. design a
feedback law with position feedback only. Show then that the control law can he
rewritten as a combination of position and velocity feedback)
5.13 Generalize the results in Problem 5.12 to a general process with several outputs.
5.14 Assume that the desired closed-loop system is given as the continuous-time model
G ( ) _
III

S - S2

0.01

+ 0.145 + 0.01

(a) Choose an appropriate sampling interval.

Sec. 5.13

223

Notes and References

(b) Determine the corresponding discrete-time transfer operator. Sketch the singularity diagram for the continuous- and the discrete-time systems, respectively.
5.15 Assume that the process has the pulse-transfer operator

H( ) =

O.4q +0.3
q2 - 1.6q

,q

+0.65

Use pole placement to design a controller satisfying the following specifications:

•
•
•
•
•

Static gain = 1
Minimal degree of the observer polynomial
Cancellation of process zero
No integrator
Desired characteristic polynomial
At

=q

~

-O.7q +0.25

5.16 Consider the process and specifications in the previous problem. Redo the design
under the assumption that the controller has an integrator.
:;.17 Consider the system
z

H(z) = ~(z~--1"""'){z---2-)

Determine an error-feedback controller that places hoth poles in the origin, that is,
use the controller
Ru(k)

= -Sy(k) +Tuc(k}

with S = T. Show by using the Diophantine equation that there is more than
one causal controller that solves the problem. Assume that the observer poles are
placed at the origin. Determine two controllers that fulfill the specifications, and
determine the closed-loop zeros.

5.13 Notes and References
The polynomial approach for pole placement is treated in Wolowich (1974),
Kucera (1979, 1991), and Pernebo (1981). The method discussed in this chapter has been used in connection with adaptive pole-placement algorithms, as
in AstroID and Wittenmark (1995). The Dahlin-Higham algorithm was derived
independently in Dahlin (1968) and Higham (1968) . The internal model principle is described in Morari and Zafiriou (1989), and Morari and Lee (1991).
The Smith-predictor is introduced in Smith (1957) and the model algorithmic
controller is discussed in Richalet et al. (1978).
Solution of the Diophantine equation is discussed in Blankenship (1963),
Kucera (1979,1991), and Jezek (1982). More about the Sylvester matrix can
be found in Barnett (1971, 1983).

6
Design: An OveNiew
6.1 Introduction
This chapter views the control problem in a wider perspective. In practice, more
time is often spent formulating control problems than on solving them. It is
therefore useful to be aware of these more general problems, although they are
seldom discussed in textbooks.
Most control problems arise from design of engineering systems . Such
problems are typically large-scale and poorlydefined. Typical tasks are design of
power plants, chemical processes, rolling mills, industrial robots, aircraft, space
vehicles, and biomedical systems. Control theory on the other hand deals with
small-scale, well-defined problems. A typical problem is to design a feedback
law for a given system, which is described by linear differential equations with
constant coefficients, so that the closed-loop system has given poles.
A major difficulty in control-system design is to reconcile the large-scale,
poorly defined, real problems with the simple, well-defined problems that control
theory can handle. It is, however, in this intermediate area that a control engineer can use creativity and ingenuity effectively. This situation is not peculiar
to control engineering. Similar situations are encountered in almost all fields
of engineering design. Control is, however, one field of engineering in which a
comparatively sophisticated theory is needed to understand the problems.
It is useful to have some perspective on the design process and a feel for
the role of theory in the design process. First, a good engineering design must
satisfy a large number of specifications, and there often are many equally good
solutions to a design problem. A good design is often a compromise based on
reasonable trade-off's between cost and performance. Sadly enough, it is often
true that the best is the worst enemy of the good. Consequently, when words
like optimal are used in this context, they should be taken with a grain of salt.
Another aspect is that design is often arrived at by interaction between
customer and vendor. Many subjective factors-such as pride, tradition, and
ambition-enter into this interaction. This situation with regard to customer

224

Sec. 6.2

Operational Aspects

225

preference is particularly confused when technology is changing. Typical examples are discussions concerning pneumatic or electronic controllers or analog
versus .digital control, which have been abundant in the trade journals.
What theory can contribute to the design process is to give insight and understanding. In particular, theory can often pinpoint fundamental limitations on
control performance. There are also some idealized design problems, which can
be solved theoretically. Such solutions can often give good insight into suitable
structures and algorithms.
It is also useful to remember that control problems can be widely different
in nature. They can range from design of a simple loop in a given system to
design of an integrated control system for a complete process. The approach to
design can also be widely different for mass-produced systems, and one-of-akind systems. For mass-produced systems , a substantial effort can be made to
obtain a cheap system that will give good performance. For unique systems, it
is often much better to install a flexible standard system and to tune it in situ.
The relation between process design and control design is also important.
Control systems have traditionally been introduced into given processes to simplify or improve their operation . It has, however, become clear that much can
he gained by considering process design and control design in one context. The
availability of a control system always gives the designer an extra degree of
freedom, which frequently can be used to improve performance or economy.
Similarly: there are many situations where difficult control problems arise be
cause of improper process design. An understanding of control also makes it
possible to design a process so that difficult control problems are avoided.
Some operational aspects of control systems are first discussed in Sec. 6.2.
This includes interfaces to the process, the operator, and the computer. Various aspects of design, commissioning, and process operation are also given.
The problems of structuring are discussed in Sec. 6.3. The basic problem is
to decompose a large, complicated problem into a set of smaller, simpler problems. This includes choice of control principles, and selection of control variables and measured variables. The common structuring principles-top-down,
bottom-up, middle-out, and outside-in-are also discussed. The top-down approach is treated in Sec, 6.4. This includes choice of control principles and
selection and grouping of control signals and measurements. The bottom-up
approach is discussed in Sec. 6.5, including a discussion of the elementary control structures, feedback, feedforward, prediction, estimation, optimization, and
adaptation. Combinations of these concepts are also discussed. The design of
simple loops is discussed in Sec. 6.6. Design methods for simple loops are also
reviewed.
a

6.2 Operational Aspects
It is useful to understand how the control system interacts with its environment.
This section discusses the interfaces between process and controller design.
Commissioning, operation, and modification of the system are also discussed.

Design: An Overview

226

Chap. 6

Process and ControUer Design
In the early stages of automation, the control system was always designed when
the process design was completed. This still happens in many cases. Because
process design is largely based on static considerations, it can lead to a process
that is difficult to control. For this reason, it is very useful to consider the control
design jointly with the process design. The fact that a process will be controlled
automatically also gives the process designers an additional degree of freedom,
which can be used to make better trade-off's. The process and the controller
should therefore be designed together. An example illustrates the idea,
Eumple 6.1 Elimination of disturbances by mixing
Elimination of inhomogeneities in a product stream is one of the major problems
in process control. One possibility for reducing the variations is to introduce large
storage tanks and thus increase the material stored in the process. A system with
large mixing tanks has slow dynamics. It will take a long time to change product
quality in such a system. One consequence is that the product may be offthe specifications for a considerable time during a change in quality. Another possibility
for eliminating inhomogeneities is to measure the produce quality and to reduce
the variations by feedback controL In this case, it is possible to use much smaller
tanks and to get systems with a faster response. The control system does, however, become more complicated. Because the total system will always have a finite
bandwidth, small mixing tanks must be used to eliminate rapid variations.
_

StablUty Versus Controllability (Maneuverability)
It frequently happens that stability and controllability have contradictory requirements. This has been evident in the design of vehicles, for instance. The
Wright brothers succeeded in the design oftheir aircraft, because they decided to
make a maneuverable, but unstable, aircraft, whereas their competitors were
instead designing stable aircrafts. In ship design, a stable ship is commonly
difficult to turn, but a ship that turns easily tends to be unstable. Traditionally,
the tendency has been to emphasize stability. It is, however, interesting to see
that if a control systam is used, the basic system can instead he designed for
controllability. The required stability can then be provided by the control system. An example from aircraft, design is used to demonstrate that considerable
savings can be obtained by this approach.
Example 6.2 Design of a supersonic aircraft
For a high-performance aircraft, which operates over a wide speedrange, the center
of pressure moves aft with increasing speed. For a modern supersonic fighter, the
shift in center of pressure can be about 1 m. If the aircraft is designed so that it
is statically stable at subsonic speeds, the center of mass will be a few decimeters
in front of the center of pressure at low speed. At supersonic speeds, the distance
between the center of mass and the center of pressure will then increase to about
1 m. Thus there will he a very strong stabilizing torque, which tends to keep the
airplane on a straight course. The torque will be proportional to the product of the
thrust and the distance between the center of mass and the center of pressure.

Sec. 6.2

Operational Aspects

227

To maneuver the plane at high speeds, a large rudder is then necessary. A large
rudder will, however, give a considerable drag.
There iB a considerable advantage to change the design so that the center
of mass is in the middle of the range of variation of the center of pressure. A
much smaller rudder can then be used, and the drag induced hy the rudder is then
decreased. The drag reduction can he over 10%. Such an airplane will, however,
be statically unstable at low speeds-that is, at takeoff and landing! The proper
stability, however, can be ohtained by using a control system. Such a control system
must, of course, be absolutely reliable,
Current thinking in aircraft design is moving in the direction ofdesigning an
aircraft that is statically unstable at low speeds and providing sufficient stability
hy using a control system. Similar examples are common in the design of other
vehicles.
_

There are analogous cases also in the control of chemical processes. The following is a typical case.
Example 6.3 Exothennic chemical reactor
To obtain a high yield in an exothermic chemical reactor, it may be advantageous to
run the reactor at operating conditions in which the reactor is open-loop unstable.
Obviously, the safe operation then depends critically on the control system that
stabilizes the reactor.
_

ControJlabllity, Observability, and Dynamics
When designing a process, it is very important to make sure that all the im-

portant process variables can be changed conveniently. The word controllability
is often used in this context, although it is interpreted in a much wider sense
than in the formal controllability concepts introduced in Sec. 3.4.
To obtain plants that are controllable in the wide sense, it is first neeessary to have a sufficient number of actuators. If there are four important
process variables that should be manipulated separately, there must be at least
four actuators. Moreover, the system should be such that the static relationship between the process variables and the actuators is one-to-one. To achieve
good control, the dynamic relationship between the actuators and the process
variablesshould ideally be such that tight control is possible. This means that
time delays and nonminimum phase relations should be avoided. Ideally the dynamic relations should be like an integrator or a first-order lag. It is, however,
often difficult to obtain such processes. Nonminimum phase loops are therefore
common in the dynamics of industrial processes.
Simple dynamic models are often very helpful in assessing system dynamics at the stage of process design. Actuators should be designed so that the
process variahles can be changedover a sufficient range with a good resolution.
The relationships should also be such that the gain does not change too much
over the whole operating range. A common mistake in flow systems is to choose
a control valve that is too large. This leads to a very nonlinear relation between
valve opening and flow. The flow changes very little when the valve opening is

228

Design: An Overview

Chap. 6

reduced until the valve is almost closed. There is then a drastic change in flow
oyer a very small range of valve position.
The process must also have appropriate sensors, whose signals are closely
related to the important process variables. Sensors need to be located properly
to give signals that are representative for the important process variables. For
example, care must be taken not to position sensors in pockets where the properties of the process fluid may not be typical. Time delays must also be avoided.
Time lags can occur due to factors such as transportation or encapsulation of
temperature sensors.
Simple dynamic models, combined with observability analysis, are very
useful to assess suggested arrangements of sensors and actuators. It is also
very useful for this purpose to estimate time constants from simple dynamic
models.

Controller Design or On-Line Tuning
Another fact that drastically influences the controller design is the effort that
can be spent on the design. For systems that will be produced in large numhers, it may be possible to spend much engineering effort to design a controller.
A controller with fixed parameters not requiring any adjustments can then be
designed. In many cases, however, it is not economically feasible to spend much
effort on controller design. For such applications it is common to use a standard general-purpose controller with adjustable parameters. The controller is
installed and appropriate parameters are found by tuning.
The possibilities for designing flexible general-purpose controllers have
increased drastically with computer controL When a controller is implemented
on a computer, it is also possible to provide the system with computer-aided tools
that simplify design and tuning. In process control, the majority of the loops for
control of liquid level, temperature, flow, and pressure are designed by rules
of thumb and are tuned on line. Systematic design techniques are, however,
applied to control of composition and pH, as well as to control of multivariable,
nonlinear, and distributed systems like distillation columns.

Interaction Among Process, Controller, and Operator
The controller and the process must, of course, work well together. A controller
is normally designed for steady-state operation, which is one operating state.
It is, however, necessary to make sure that the system will work well also
during startup and shutdown and under emergency conditions, such as drastic
process failures. During normal conditions it is natural to design for maximum
efficiency. At a failure, it may he much more important to recover and quickly
return to a safe operating condition.
In process control, it has been customary to use automatic regulation for
steady-state operation. In other operating modes, the controller is switched to
manual and an operator takes over. With an increased level of automation, good
control over more operating states is. however, required.

Sec. 6.3

Principles of S1ructuring

229

6.3 Principles of Structuring
As mentioned earlier, real control problems are large and poorly defined, and
control theory deals with small well-defined problems. According to the dictionary, structuring can mean to construct a systematic framework for something.
In this context, however, structuring is used to describe the process of bridging
the gap between the real problems and the problems that control theory can
handle.
The problems associated with structuring are very important for controlsystem design. Unfortunately, these problems cannot yet be put into a complete
systematic framework. For this reason they are often avoided both in textbooks
and in research. As an analogy, structuring can be said to have the same relation
to control-system design as grammar has to composition. It is clearlyimpossible
to write well without knowing grammar. It is also clear that a grammatically
flawless essay is not necessarily a good essay. Structuring of control systems
must he based on the scientific principles given by control theory. However,
structuring also contains elements of creativity, ingenuity, and art. Perhaps the
best way to introduce structuring is to teach it as a craft.
The problem ofstructuring occurs in many disciplines. Formal approaches
have also been developed. The terminology used here is borrowed from the fields
of computer science and problem solving, where structuring of large programs
has heen the subject of much work. There are two major approaches, called
top-down and bottom-up.
The top-down approach starts with the problem definition. The problem
is then divided into successively smaller pieces, adding more and more details.
The procedure stops when all pieces correspond to well-known problems. It is
a characteristic of the top-down approach that many details are left out in the
beginning. More and more details are added as the problem is subdivided. The
buzz word successive refinement is therefore often associated with the top-down
approach.
The bottom-up approach starts instead with the small pieces, which represent known solutions for subproblems. These are then combined into larger
and larger pieces, until a solution to the large problem is obtained.
The top-down approach is often considered to be more systematic and more
logical. It is, of course, not possible to use such an. approach unless the details
of the system are known very well. Similarly, it is not easy to use the bottomup approach unless the characteristics of the complete problem are known. In
practice, it is common to use combinations of the approaches. This is sometimes
called.an inside-out-outsule-in approach.
Structuring is an iterative procedure. It will be a long time before a fully
systematic approacb to structuring is obtained. It is difficult to appreciate the
structuring problems unless problems of reasonable size and complexity are
considered. Therefore, mostofthe work on structuring is donein industry. It also
appears that many industries have engineers who are very good at structuring.
Students are therefore advised to learn what the "structuring masters" are
doing, in the same way as painters have always learned from the grand masters.

230

Design: An Overview

Chap. 6

6.4 ATop·Down Approach
This section describes a top-down approach to control-system design. This involves the selection of control principles, choice of control variables and measured variables, and pairing these variables.

Control Principles

Acontrolprinciple gives a broad indication ofhow a process should be controlled.
The control principle thus tells how a process should respond to disturbances
and command signals. The establishment of a control principle is tbe starting
point for a top-down design. Some examples of control principles are given next.
Example 6.4 Flow control
When controlling a valve, it is possible to control the valve position. the flow,
or both. It is simplest and cheapest to control the valve position. Because flow
is, in general, a nonlinear function of the valve opening, this leads to a system
in which the relationship between the control variable (valve position) and the
physical variable (flow) is very nonlinear. The relationship will also change with
such variables as changing pressure and wear of the valve. These difficulties are
avoided if both valve position and flow are controlled. A system for flow control is,
however, more complicated because it requires a flow meter.
Example 6.5 Composition control
When controlling important product-quality variables, it is normally desired to
keep them close to prescribed values. This can be done by minimizing the variance
of product-quality variations. If a flow is fed to a large storage tank with mixing, the
quality variations in the mixing tank should he minimized. This is not necessarily
the same as minimizing quality variations in the flow into tbe tank.
_
Emntple 6.6 Control of a drum boiler
Consider a turbine and a generator, which are driven by a drum boiler. The control
system can bave different structures, as illustrated in Fig. 6.1, which sbows three
control modes: boiler follow, turbine follow. and sliding pressurecontrol. The system
has two key control variables, the steam valve and the oil flow. In the boiler follow
mode, the generator speed. w, is controlled directly by feedback to the turbine
valve, and the oil flow is controlled to maintain the steam pressure, p . In the
turbine follow mode, the generator speed is used instead to control the oil flow to
the boiler, and the swam valve is used to control the drum pressure. In sliding
pressure control, the turbine valve is fully open, and oil ftow is controlled from the
generator speed.
The boiler follow mode admits a very rapid control of generator speed and
power output because it uses the stored energy in the boiler. There may be rapid
pressure and temperature variations, however, that impose thermal strains on the
turbine and the boiler. In the turbine follow mode, steam pressure is kept constant
and thermal stresses are thus much smaller. The response to power demand will,
however, be much slower. The sliding pressure control mode may he regarded as a
compromise between boiler follow and turbine follow.
_

Sec. 6.4

231

A Top-Down Approach
(c)

Figure 6.1 Control modes for a boiler-turbine unit: (a) boiler follow, (b)
turbine follow, and (c) sliding pressure.

Example 6.7 Ship control
When designing an autopilot for a highly maneuverable ship, there are many alternatives for design. One possibility is to design the autopilot so that the captain
can order a tum to a new course with a specified turning rate. Another possibility
is to specify the turning radius instead of the turning speed. The advantage of
specifying the turning radius is that the path of the ship will be independent of
the speed of the ship. Control of the turning radius leads to a more complicated
system, because it is necessary to measure both turning rate and ship speed. _
Example 6.8 Material"balance control
Many processes involve flow and storage ofmaterials. Although the processes are
very different, they all include material storage. The reason for introducing these
is to smooth out variations in material flow. It is therefore not sensible to control
these systems in such a way that the storages have constant mass. Instead the
criteria should be to maintain the following:
• Inventories between maximum and minimum limits
• An exact long-term material balance between input and output
• Smooth flow rates

•

Example 6.9 Constraint control
When designing systems, it is frequently necessary to consider several operating
conditions. This means that constraints for safety or economical conditions may
need to be considered. It may also bo necessary to consider constraints during startup and shutdown. The control during these situations is usually done with logical
controllers. Today the logical control and the analog control are often done within
the same equipment, programmable logic control (PLC) systems. This means that
there are good possibilities to integrate different functions of the control system.

•
The choice of a control principle is an important issue. A good control principle
can often simplify the control problem. The selection often involves technical
and economical trade-offs. The selection of a control principle is often based
on investigations of models of the process. The models used for this purpose
are typically internal models derived from physical principles. It is therefore
difficult to define general rules for finding control principles.

Design: An Overview

232

Chap. 6

Choice of Control Variables
After the control principle has been chosen, the next logical step is to choose
the control variables. The choice of control variables can often be limited for
various practical reasons. Because the selection of control principle tells what
physical variables should be controlled, it is natural to choose controlvariables
that have a close relation to the variables given by the control principle. Because mathematical models are needed for the selection of control principles,
these models also can be used for controllability studies when choosing control
variables.

Chotce of Measured Variables
When the control principle is chosen, the primary choice of measured variables
is also given. If the variablesused to express the control principle cannot be measured' it is natural to choose measured variables that are closely related to these
control variables. Mathematical models and observability analysis can be very
helpful in making this choice. Typical examples are found in chemical-process
control, where temperatures-which are easy to measure-are used instead of
compositions, which are difficult and costly to measure.

Pairing of Inputs and Outputs
A large system will typically have a large number of inputs and outputs. Even
if a control principle, which involves only a few variables, is found initially,

(a)

.------1 Production supervision .....- - - - - ,
Intermediate storages

Intermediate storages

Figure 6.2 Material-balance control (a) in the direction ofthe flow and (b)
in the direction opposite to the flow.

Sec, 6.5

A Bottom-Up

Approach

233

many variables typically must be considered once the variables that can be
manipulated and measured are introduced. Witha top-down approach, a system
should be broken down into small subsystems. It is then desirable to group
different inputs and outputs together, so that a collection of smaller systems
is obtained. If possible, the grouping should be done so that (1) there are only
weak couplings between the subsystems; and (2) each subsystem is dynamically
well behaved, that is, time constants are of the same magnitude and time delay,
nonminimum phase, and severe variationsin process dynamics are avoided.
There are no general rules for the grouping. Neither are there any good
ways of deciding if it is possible to find a grouping with the desired properties. Trial and error, combined with analysis of models, is one possibility. The
following example illustrates the pairing problem.
Example 6.10 Material-balance control
A system with material flow is shown in Fig. 6.2. The system consists of a series of

tanks. The flows between the tanks are controlled by pumps. The figure illustrates
two different control structures. In one structure, the flow out of each tank is
controlled from the tank level. This is called control in the direction of the flow. 'Io
maintain balance between production and demand, it is necessary to control the
flow into the first tank by feedback from the last tank level. In the other approach,
the flow into each tank is controlled hy the tank level. This is called control in the
direction opposite to the flow. This control mode is superior, because all control loops
are simple flrst-order systems and there are no stability problems. With control in
the direction of the flow, there may be instabilities due to the feedback around all
tanks. It can also be shown tbet control in the direction opposite to the flow can
_
be done by using smaller storage tanks.

6.5 A Bottom-Up Approach
In the bottom-up approach, a choice of control variables and measurements
comes first. Different controllers are then introduced until a closed-loop system,
with the desired properties, is obtained. The controllers used to build up the
system are the standard types based on the ideas offeedback, feedforward, prediction and estimation, optimization, and adaptation. Because these techniques
are familiar from elementary courses, they will be discussed only briefly.
Feedback

The feedback loops used include, for example, simple PID controllers and their
cascade combinations. When digital computers are used to implement the controllers, it is also easy to use more sophisticated control, such as Smith-predictors for dead-time compensation, state feedback, and model reference control.
Feedback is used in the usual context. Its advantage is that sensitivity to disturbances and parameter variationscan be reduced. Feedback is most effective
when the process dynamics are such that a high bandwidth can be used. Many

Design: An Overview

234

Chap-6

Process
Measured disturbance
w
Hft

y

Figure 6.3 Reduction of disturbances by feedforward.

systems that are difficult to implement using analogtechniques may be easy to
implement using computer-control technology.

Feedforward
Feedforward is another control method. It is used to eliminate disturbancesthat
can be measured. The basic idea is to use the measured disturbance to anticipate the influence of the disturbance on the process variables and to introduce
suitable compensating control actions. See Fig. 6.3. The advantage compared
to feedback is that corrective actions may be taken before the disturbance has
influenced the variables. If the transfer functions relating the output y to the
disturbance wand the control u are R w and Hp , the transfer function R ft of
the feedforward compensator should ideally be

If this transfer function is unstable or nonrealizable, a suitable approximation
is chosen instead. The design ofthe feedforward compensator is often based on
a simple static model. The transfer function H ff is then simply a static gain.
Because feedforward is an open-loop compensation, it requires a good process modeL With digital control, it is easy to incorporate a process model. Thus it
can be anticipated that use of'feedforward will increase with digital control. The
design of a feedforward compensator is in essence a calculation of the inverse
of a dynamic system.

Selector Control

There are many cases in which it is desirableto switch control modes, depending
on the operating condition. This can be achieved by a combination of logic and
feedback controL The same objective can, however, also be achieved with a
combination of feedback controllers. A typical example is control of the air-tofuel ratio in boiler control. In ship boilers it is essential to avoid smoke puffs
when the ship is in the harbor. To do this it is essential that the air flow leads
the oil flow when load is increased and that the air flow lags the oil flow when

Sec. 6.5

235

A Bottom-Up Approach
Air flow

Max

1-------11....

sp
MV

Power demand

MY
Min

r-----...

SP
Oil flow

Figure 6.4 System with selectors for control of the air-to-fuel ratio in a
boiler.

the load is decreased. This can be achieved with the system shown in Fig. 6.4,
which has two selectors. The maximum selector gives an output signal that
at each instant of time is the largest of the input signals, and the minimum
selector chooses the smallest of the inputs. When the powerdemand is increased,
the maximum selector chooses the demand signal as the input to the air-flow
controller, and the minimum selector chooses the air flow as the set point to the
fuel-flow controller. The fuel will thus follow the actual air flow.
When the power demand is decreased, the maximum selector will choose
the fuel flow as the set point to the air-flow controller, and the minimum selector
will choose the power demand as the set point to the fuel-flow controller, The
air flow will thus lag the fuel flow.
Control using selectors is very common in industry. Selectors are very
convenient for switching between different control modes.

Prediction and Estimation
State variables and parameters often cannot be measured directly. In such a
case it is convenient to pretend that the quantities are known when designing a feedback. The unknown variables can then be replaced by estimates or
predictions. In some cases such a solution is mfact optimal. The notions of predictions and estimation are therefore important. Estimators for state variables
in linear systems can easily be generated by analog techniques. They can also
easily be implemented using a computer. Parameter estimators are more difficult to implement with analog methods. They can, however, easily be done with
a computer, Prediction and estimation are thus easier to use with computer
control.

Design: An Overview

236

Chap. 6

Optimization
Some control problems can be conveniently expressedas optimization problems.
With computer-control systems, it is possible to include optimization algorithms
as elements of the control system.

Combinations
When using a bottom-up approach, the basic control structures are combined to
obtain a solutionto the control problem. It is often convenient to makethe combinations hierarchically. Many combinations, like cascadecontrol, state feedback,
and observers, are known from elementary control courses. Very complicated
control systems can be built up by combining the simple structures. An example is shown in Fig. 6.5. This way of designing control using the bottom-up

r--------..,..------I Feedforward t - - - - - - - - - ,
Vessel feed
Pressurizing

inlet
Jacket outlet

Feed·
forward

Figure 6.5 An example of a complicated control system built up from sim-

ple control structures. (Redrawn from Foxboro Company with permission.)

Sec. 6.6

237

Design of Simple Loops

Process parameters
Speciifications

Design
calculation

/ , Parameter

-----

estimation

Measured

Controller
parameters

output
signal

Command
signal

,.. Controller

Process
Control
signal

Figure 6.6 Bluck diagram of an adaptive controller obtained by combining
a parameter estimator with a design calculation,

approach is in fact the technique predominantly used in process control. Its
success depends largely on the experience and skill of the designer.
An adaptive system, which is obtained by combining a parameter estimator
with a design procedure, is shown in Fig. 6.6.

6.6 Design of Simple Loops
If a top-down approach is used, the design procedure will end in the design of
simpleloops containing oneor several controls, or measurements. If a bottom-up
approach is used, the design will start with the design of simple loops. Therefore, the design of simple loops is an important step in both approaches. The
design of simpleloops is also one area in which there is substantial theory available, which will be described in detail in the book. 'Ib give some perspective,
an overview of design methods for simple loops is given in this section. The
prototype problems of controller and servo design will be discussed.

Simple Criteria
A simple way to specify regulation performance is to give allowable errors for
typical disturbances. For example, it can be required that a step disturbance
give no steady-state error, and that the error due to a ramp disturbance be
a fraction of the ramp velocity. These specifications are typically expressed in
terms of the steady-state behavior, as discussed in Sec. 3.5.The error coefficients
give requirements only on the low-frequency behavior. The bandwidth of the
system should therefore be specified, in addition to the error coefficients.
Another more complete way to specify regulation performance is to give
conditions on the transfer function from the disturbances to the process output.

Chap. 6

Design: An Overview

238

Set pointfor regulator
with low variance

0.5
Test limit

, Set point for regulator
: with high variance
-:-- .....

....

,,

" " ....
-2

o

2
Process output

4

....
6

Figure 6.7 Expressing regulation performance in terms of variation in
quality variables.

Specifications for the Controller Problem
The purpose of regulation is to keep process variables close to specified values
in spite of process disturbances and variations in process dynamics.

Minimum-variance control. For regulation of important quality variables, it is often possible to state objective criteria for regulation performance.
Acommon situation is illustrated in Fig. 6.7, which shows the distribution ofthe
quality variahles. It is often specified that a certain percentage of the production should be at a quality level above a given value. By reducing the quality
variations, it is then possible to move the set point closer to the target. The
improved performance can be expressed in terms of reduced consumption of
energy or raw material or increased production. It is thus possible to express
reductions in quality variations directly in economic terms.
For processes with a large production, reductions of a fraction of a percent
can amount to a large sum of money. For example, a reduction in moisture
variation of 1% in paper-machine control can amount to savings of $100,000
per year.
If the variations in quality can be expressed by Gaussian distributions,
the criterion would simply be to minimize the variance of the quality variables.
In these problems, the required control actions are irrelevant as long as they
do not cause excessive wear or excessively large signals. A control strategy
that minimizes the variance of the process output is called minimum-variance
control.

Sec. 6.6

Design of Simple loops

Optimal control.

239

Minimum-variance control is a typical example ofhow

a control problem can bespecified as an optimization problem. In a more general
case, it is not appropriate to minimize the variance of the output. Instead there

will be a criterion of the type

El

/l

g(x(s),u(s))ds

In

where x is the state variable, u is the control variable, and E denotes the mean
value. An example of such a criterion is given next.
Example 8.11 Ship steering
It can he shown that the relative increase in resistance due to deviations from a
straight-line course can be approximately expressed as

where ~ is the heading deviation, 6 is the rudder angle, R is the resistance, and p
is a parameter. Typical parameter values for a tanker are k == 0.014 and p =0.1.

•

Techniques for Controller Design
Regulation problems are often solved by feedback, but feedforward techniques
can be very useful if disturbances can be measured.
If the specifications are given in terms ofthe transfer function, relatingthe
output to the disturbance, it is natural to apply methods that admit control of
this transfer function. One method is pole placement, which allows specification
of the complete transfer function. This straightforward design technique was
discussed in detail in Chapters 4 and 5. It is often too restrictive to specify the
complete closed-loop transfer function, which is a drawback.
Another possibility is to use a frequency-response method, which admits
control of the frequency response from the disturbance to the output. Such
problems are most conveniently expressed in terms of continuous-time theory.
The controllers obtained can then be translated to digital-control algorithms
using the techniques described in Chapter 8.
If the criteria are expressed as optimization criteria, it is natural to use
design techniques based on optimization. Techniques based on minimizing the
variance ofthe process outputand other types ofquadraticcriteria are discussed
in Chapters 11 and 12.

The Servo Problem
In the servo problem, the .task is to make the process variables respond to
changes in a command signal in a given way. Servo performance is typically
specified in terms of requirements on the step response or the frequency response. Typical specifications for step responses include settling time and overshoot. Specifications can also be given in the frequency domain, for example.

Design: An Overview

240

Chap. 6

in terms of bandwidth. An alternative is to use a model that gives the desired
response to command signals.
It is often very advantageous to use a two-degree-of-freedom configuration,
because this admits a complete decoupling of the responses to disturbances and
command signals. For such systems the feedback is first designed to solve the
regulation problem and the feedforward is then designed to solve the servo
problem. Examples of this were given in Sees. 4.6 and 5.4.

6.7 Conclusions
This chapter presents an overview of the design problems. There is a large step
from the large and poorly defined problems of the real world to the small and
well-defined problems that control theory can handle. Problems of structuring
are discussed.
The notion of the control principle is introduced in order to apply the topdown approach. It is also shown how a bottom-up approach can be used to build
complex systems from simple control structures such as feedhack, feedforward,
estimation, and optimization. Finally, specifications and approaches to the design of simple loops are discussed.
A chemical process consists of many unit operations, such as performed by
reactors, mixers, and distillation columns. In a bottom-up approach to controlsystem design, control loops are first designed for the individual unit operations. Interconnections are then added to obtain a total system. In a top-down
approach, control principles-such as composition control and material-balance
control-are first postulated for the complete plant. In the decomposition, these
principles are then applied to the individual units and loops.
In process control the majority of the loops for liquid level, flow, and pressure control are most frequently designed empirically and tuned on-line. However, control of composition and pH, as well as control of nonlinear distributed
large systems with strong interaction, are often designed with' care.
Control systems can be quite complicated because design is a compromise
between many different factors. The following issues must typically be considered:
• Command signals
• Load disturbances
• Measurement noise
• Model uncertainty
• Actuator saturation
• State constrainte
• Controller complexity
There are few design methods that consider all these factors. The design methods discussed in this book will typically focus on a few of the issues. In a good

Sec. 6.8

Problems

241

design it is often necessary to grasp all factors. Th do this it is often necessary
to investigate many aspects by simulation. The relation between process design
and controller design should also be considered.

6.8 Problems
6.1 Consider the material-balance problem shown in Fig. 6.2. Assume that each tank
(storage) is an integrator and that each controller is a proportional controller, Discuss the influence on the two systems when there is a pulse disturbance out from
the raw material storage.
6.2 Identify and discuss the use of (a) cascade control, (b) feedforward, and (c) nonlinear elements in Fig. 6.5.

6.9 Notes and References
The problem discussed in this chapter touches on several aspects of problem
solving. A reader with general interests may enjoy reading Polya (1945), which
takes problems from the mathematical domain. and Wirth (1979),which applies
to computer programming.There is some workon the structuring problem in the
literature on process control; see, for instance, Buckley (1964), Bristol (1980),
Balchen and Mumme (1988), and Shinskey (1988). Buckley (1978) contains
much useful material of general interest although it deals with a very specific
problem. Foss (1973) is more general in scope.
There are only a few areas in which control design and process design
have been considered jointly. Design of high-performance aircrafts is a notable
example. See Boudreau (1976) and Burns (1976).
Specifications of controller performance for simple loops are discussed in
depth in standard texts onservomechanisms; see, for instance,Franklin, Powell,
and Emami-Naeini (1994) and Dorfand Bishop (1995).

7
Process-Oriented Models
7.1 Introduction
Mathematical models for a sampled-data system from the point of view of the
computer are developed in Chapter 2. These models are quite simple. The variabies that represent the measured signal and the control signal are considered
at the sampling instants only. These variables change in a given time sequence
in synchronization with the clock. The signals are naturally represented in the
computer as sequences of numbers. Thus the time-varying nature of sampleddata systems can be ignored, because the signals are considered only at times
that are synchronized with the clock in the system. The sampled-data system
can then be described as a time-invariant discrete-time system. The model obtained is called the stroboscopic model.
The stroboscopic model has tbe great advantage of being simple. Most of
tbe problems in analysis and design of sampled-data systems can fortunately
be handled by this model. The model will also give a complete description of
the system as long as it is observed from the computer, but sometimes this is
not enough. The main deficiency is that the model does not tell what happens
between the sampling instants. Therefore it is useful to have other models that
give a more detailed description. Such models are needed when the computercontrolled system is observed from the process, for example, if a frequency response is performed by cutting the loop on the analog side. The models required
are necessarily more complicated than those discussed in Chapter 3 because
the periodic nature of the system must be dealt with explicitly to describe tbe
intersample behavior.
A detailed description of the major events in a computer-controlled system
is given in Sec. 7.2. Section 7.3 give a discussion of sampling and reconstructing
continuous-time signals. The alias problem encountered in Chapters 1 and 2 is
analyzed in Sec. 7.4. Control of a system using predictive first-order-hold is
discussed in Sec. 7.5. The key problem when making process-oriented models is
the description of the sampling process. This is descrihed using the modulation

242

Sec. 7.2

243

A Computer-Controlled System

model in Sec. 7.6. Section 7.7 deals with the frequency response of sampled-data
systems-several unexpected things can happen. The results give more insight
into the aliasing problem. An algebraic system theory for sampled-data systems
is outlined in Sec. 7.8. Multirate systems are discussed in Sec. 7.9.

7.2 A Computer-Controlled System
A schematic diagram of a computer-controlled system is given in Fig. 7.1. In
Chapter 2 the loop is cut inside the computer between the A-D and D·A converters -for example, at C in the figure. In this chapter the loop is instead
cut on the analog side -for example, at A in the figure. The discussions of this
chapter require a more detailed description of the sequence of operations in a
computer-controlled system . The following events take place in the computer:
1. Wait for a clock pulse.

2. Perform analog-to-digital conversion.
3. Compute control variable.

4. Perform digital-to-analog conversion.
5. Update the state of the regulator.
6. Go to step 1.
Because the operations in the computer take some time, there is a time
delay between steps 2 and 4. The relationships among the different signals in
the system are illustrated in Fig. 7.2. When the control law is implemented in a
computer it is important to structure the code so that the calculations required
in step 3 are minimized (see Chapter 9).
It is also important to express the synchronization of the signals precisely.
For the analysis the sampling instants have been arbitrarily chosen as the time
when the D-A conversion is completed. Because the control signal is discontinuous, it is important to be precise about the limit points. The convention of

Clock

4-

~
A-D

t
Computer

rY

n

~
D-A

u

Process

y
~

Figure 7.1 Schematic diagram of a computer-controlled system.

Chap. 7

Process-Oriented Models

244

Y (t)

l - . -_ _~ ~ t

Process

Computer

L
·k

•

y(t )

•
••

•

•• •

• ••

~---

t

t

Figure 7.2 Relationships among the measured signal, control signal, and
their representations in the computer.

continuity from the right was adopted. Notice that the real input signal to the
process is continuous because of the nonzero settling time of the D-A converter
and the actuators.

7.3 Sampling and Reconstruction
In this section we will discuss sampling and reconstruction of continuous-time
signals. The periodic nature of sampled-data systems are considered.

The Sampling Theorem
Very little is lost by sampling a continuous-time signal if the sampling instants
are sufficiently close, but much of the information about a signal can be lost if
the sampling points are too far apart. This was illustrated in Examples 1.4 and
3.14.
It is, of course, essential to know precisely when a continuous-time signal is uniquely given by its sampled version. The following theorem gives the
conditions for the case of periodic sampling.
7.1 SHANNON'S SAMPLING THEOREM A continuous-time signal
with a Fourier transform that is zero outside the interval (-mo, lOo) is given
uniquely by its values in equidistant points if the sampling frequency is higher
than 2wo. The continuous-time signal can be computed from the sampled signal
by the interpolation formula
THEOREM

({t):

t
k=-oo

((kh) Sin~~~(~~~~~2) :

f=
k~-oo

({kh) sine ",,(I; kh)

(7.1)

SeC. 7.3

245

Sampling and Reconstruction

where m is the sampling angular frequency in radians per second (rad/s).
s

Proof

Let the signal be f and let F be its Fourier transform.

F(co)

=

1
:

e-i(JJt f(t) dt

1
00

f(t) = -1
2Jr

eiOJlF(w)dw

(7.2)

-00

Introduce
1

Fs(ro)

= Ii

00

L F(w + kco

s)

(7.3)

k = - oo

The proof is based on the observation that the samples f(kh) can be regarded
as the coefficients of the Fourier series of the periodic function Fs(w). This is
shown by a direct calculation. The Fourier expansion of Fs is
00

Fs(w}

=L

Cke-ikhW

(7.4)

Ao;=-o;>

where the coefficients are given by

By using the definition of the Fourier coefficients and the relations given in
(7.2) and (7.3) , it is straightforward to show that

Ck :: f(kh)

(7.5)

It thus follows that the sampled signal (f (kh), k = ... , - 1, 0,1,... } uniquely
determines the function Fs ( m). Under the assumptions ofthe theorem the function F is zero outside the interval (-mo,mo). If a, > 2wo, it follows from (7.3)
that
hFS(W)

F(m)

=

{o

(7.6)

The Fourier transform ofthe continuous-time signal is thus uniquely given by

Fa, which in turn is given by the sampled function {f(kh). k =... , -1, 0,1,.. . }.

Process-Oriented Models

246

Chap. 7

The first part of the theorem is thus proved. 'Th show Eq. (7.1), notice that it
follows from (7.2) and (7.6) that

where the last equalityfollows from (7.4) and (7.5). Interchanging the order of
integration and summation,
f(t) ==

L
oo

k." -

a;!

L

h
f(kh) 2n:

00

==

k.. -00

f(kh)

1(0./2 eiM-laJkh dill
-0),/2

h

m./2
eiw!-iwkh

21T( t - kh)

-w./2

_ ~

(h sin(ws(t - kh)/2)
- ~ f k) n(t _ kh)/h
k=- oo

Because {JJsh = 27r, Eq. (7.1) now follows.

•

Remark 1. The frequency (J)N :;:: (J)s/2 plays an important role. This
frequency is called the Nyquist frequency.
Remark 2. Notice that Eq. (7.1) defines the reconstruction of signals
whose Fourier transforms vanish for frequencies larger than the Nyquist frequency OJN = Ct}8/2.
Remark 3. Because ofthe factor l/h in Eq. (7.3), the sampling operation
has a gain of 11k.

Reconstruction
The inversion of the sampling operation, that is, the conversion of a sequence
of numbers {f(tk) : k E Z} to a continuous-time function f(t} is called reconstruction. In computer-controlled systems, it is necessary to convert the control
actions calculated by the computer as a sequence of numbers to a continuoustime signal that can be applied to the process. In digital filtering, it is similarly
necessary to convert the representation of the filtered signal as a sequence of
numbers into a continuous-time function. Some different reconstructions are
discussed in this section.

Sec. 7.3

247

Sampling and Reconstruction

o

-10

10

Time
Figure 7.S The impulse response of the Shannon reconstruction given by
(7.7) when h ::: 1.

Shannon Reconstruction

For the case of periodic sampling of band-limited signals, it follows from the
sampling theorem that a reconstruction is given by (7.1). This reconstruction
is called the Shannon reconstruction. Equation (7.1) defines an inverse of the
samplingoperation, which can be considered as a linear operator. It is, however,
not a causal operator because the value of f at time t is expressed in terms of
past values {f(kh) : k ::; t/h} as well as future values {f(kh) : k > tilt}. The
characteristics ofthe Shannon reconstruction are given by the function
h(t)

= sin ((f)stI2)
ws t/ 2

(7.7)

See Fig. 7.3. This reconstruction win introduce a delay. The weight is 10% after
about three samples and less than 5% after six samples. The delay implies that
the Shannon reconstruction is not useful in control applications. It is, however,
sometimes used in communication and signal-processing applications, where
the delay can be acceptable, Other drawbacks of the Shannon reconstruction
are that it is complicated and that it can be applied only to periodic sampling.
It is therefore useful to have other reconstructions.

Zero-Order Hold (ZOH)

In previous chapters zero-order-hold sampling has been used. This causal reconstruction is given by

(7.S)
This means that the reconstructed signal is piecewise constant, continuous from
the right, and equal to the sampled signal at the sampling instants. Because
of its simplicity, the zero-order hold is very common in computer-controlled systems. The standard D-A converters are often designed in such a way that the old
value is held constent until a new conversion is ordered. The zero-order hold
also has the advantage that it can be used for nonperiodic sampling. Notice,
however, that the reconstruction in (7.8) gives an exact inverse ofthe sampling

Process-Oriented Models

248

Chap. 7

Figure 7.4 Sampling and zero-order-hold reconstruction of a continuous-time signal.

operation only for signals that are right continuous and piecewise constant over
the sampling intervals. For all other signals, the reconstruction of (7.8) gives

an error (see Fig. 7.4).
Higher-Order Holds
The zero-order hold can he regarded as an extrapolation using a polynomial of
degree zero. For smooth functions it is possible to obtain smaller reconstruction errors by extrapolation with higher-order polynomials. A first-order causal
polynomial extrapolation gives

The reconstruction is thus obtained by drawing a line between the two most
recent samples. The first-order hold is illustrated in Fig. 7.5.
Predictive First-Order Hotd
A drawback of the zero- and first-order hold is that the output is discontinuous.

Figure 7.6 Sampling and first-order-hold reconstruction of a continuous-time signal.

Sec. 7.4

Aliasing or Frequency Folding

249

Figure 7.6 Sampling and predictive first-order hold reconstruction of a
continuous-time signal.

A way to avoid this problem is to use a predictive first-order-hold. The intersample behavior with this hold circuit is a linear interpolation of the sampled
values; see Figure 7.6. Mathematically the reconstruction can be described by

(7.9)
Notice that this requires that f(tk+l) is available at time tk. For general applications the predictive first-order hold is not realizable. The value f(tk+l} can be
replaced by a prediction. This can be done very conveniently in a feedback loop,
as will be discussed in Section 7.5.

7.4 Aliasing or Frequency Folding
If a continuous-time signal that has the Fourier transform F is sampled periodically, it follows from (7.4) and (7.5) that the sampled signal f(kh),k =
... , -1,0,1, ... can be interpreted as the Fourier coefficients of the function Fs.
defined by (7.3).
The function F, can thus be interpreted as the Fourier transform of the
sampled signal. The function of (7.3) is periodic with a period equal to the sampling frequency ({)s. If the continuous-time signal has no frequency components
higher than the Nyquist frequency, the Fourier transform is simply a periodic
repetition of the Fourier transform of the continuous-time signal (see Fig. 7.7).
It follows from (7.3) that the value ofthe Fourier transform of the sampled
signal at 00 is the sum of the values of the Fourier transform of the continuoustime signal at the frequencies (J) + nw s . After sampling, it is thus no longer
possible to separate the contributions from these frequencies. The frequency w
can thus be considered to be the alias of (J) + nws . It is customary to consider
only positive frequencies. The frequency m is then the alias of ms - 00, COs + OJ,
2ms - w, 2m$ + 0), ••• , where 0 ~ W < WN. After sampling, a frequency thus
cannot be distinguished from its aliases. The fundamental alias for a frequency

Process-Oriented Models

250

J;

F(w )

~

Chap. 7

~

~r---rJ-~

-2 (ON

-(lJN

0

2WN

Figure 7.7 The relationship between the Fourier transform for continuous
and sampled signals for different sampling frequencies. For simplicity it has
been assumed that the Fourier transform is real.

WI

> (ON is given hy

(7.10)
Notice that although sampling is a linear operation, it is not time-invariant.

This explains why new frequencies will be created by the sampling. This is
discussed further in Sec. 7.7.
An illustration ofthe aliasing effect is shown in Fig. 7.8. Two signals with
the frequencies 0.1 Hz and 0.9 Hz are sampled with a sampling frequency of
1 Hz (h = 1 s]. The figure shows that the signals have the same values at the
sampling instants. Equation (7.10) gives that 0.9 has the alias frequency 0.1.
The aliasing problem was also seen in Fig. 1.11.
1

o
-1'---

o

'---

5

----'

10

Time
Figure 7.8 '1\1/0 signals with different frequencies, 0.1 Hz and 0.9 Hz, may
have the same value at all sampling instants.

Sec. 7.4

Aliasing or Frequency Folding

251

Pressure
Steam
Feed
watpT

To boiler

Pump

\
Condensed Temperature
water

Figure 7.9 Process diagram for a feed-water heating system of a boiler.

Example 7.1 Aliasing
Figure 7.9 is a process diagram of feed-water heating in a boiler of a ship. A valve
controls the flow of water. There is a backlash in the valve positioner due to wear.
This causes the temperature and the pressure to oscillate Figure 7.10 shows a
sampled recording of the temperature and a continuous recording of the pressure.
From the temperature recording one might believe that there is an oscillation
with a period of about 38 min. The pressure recording reveals, however, that the
oscillation in pressure has a period of 2.11 min. Physically the two variables are
coupled and should oscillate with the same frequency.
The temperature is sampled every other minute. The sampling frequency
is (I)~ = 2tr/2 = 3.142 rad/min and the frequency of the pressure oscillation is
Wo = 2R'j2.11 = 2.978 rad/min, The lowest aliasing frequency is (Us -lIJo ::: 0.1638
red/min. This corresponds to a period of38 min, which is the period ofthe recorded
oscillation in the temperature.
•

I

38 min

........'.
--

,.•'

I

"l

•••••••••••. 11-'"
----i ~

.. ..

.•

2 min

Time
Figure 7.10 Recordings of temperature and pressure.

Process-Oriented Models

252

Chap. 7

Sampled

spectrum

Figure 7.11 Frequency folding.

Frequency Folding

Equation (7.3) can also be given another interpretation. The graph of the spectrum of the continuous-time signal is first drawn on a paper. The paper is then
folded at abscissas that are odd multiples ofthe Nyquist frequency, as indicated
in Fig. 7.11. The sampledspectrumis then obtainedby adding the contributions,
with proper phase, from all sheets.
Prefiltering
A practical difficulty is that real signals do not have Fourier transforms that
vanish outside a given frequency band. The high-frequency components may

Table 7.1 Damping' and natural frequency f.J) for Butterworth, ITAE (Integral Time Absolute Error), and Bessel filters. The higher-order filters with
arbitrary bandwidth WB are nhtained by cascading filters ofthe form (7.12).

,

lV

ITAE

Butterworth

,

Bessel

,

Order

{O

2

1

0.71

0.99

0.71

1.27

0.87

4

1

0.38

0.32

1.60

0.92

1.49
0.84

0.83

1.43

0.62
0.96

0.26

1.51

0.71

1.13

1.90
1.69

0.49
0.82

0.97

0.92

0.24
0.6D
0.93

1.61

0.98

6

1

(J)

Sec. 7.4

253

Anasing or Frequency Folding
Table 7.2 Approximate time delay

Td ofBessel filters ofdifferent orders.
Order
2

1.3/wB

4

2.1lmB
2.71mB

6

appear to be low-frequency components due to aliasing. The problem is particularly serious if there are periodic high-frequency components. 'TO avoid the alias
problem, it is necessary to filter the analog signals before sampling. This may
be done in many different ways.
Practically all analog sensors have some kind of filter, but the filter is
seldom chosen for a particular control problem. It is therefore often necessary
to modify the filter so that the signals obtained do not have frequencies above
the Nyquist frequency.
Sometimes the simplest solution is to introduce an analog filter in front of
the sampler. A standard analog circuit for a second-order filter is
(j)'l

G (s) f

-

'"'""::""""---:-:------=-

S2

+ 2{ms + ())2

{7.11)

Higher-order filters are obtained by cascading first- and second-order systems. Examples of filters are given in Table 7.1. The teble gives filters with
bandwidth ltJB = 1. The filters get bandwidth ill B by changingthe factors (7.11)

to
(7.12)
where ltJ and { are given by Table 7.1. The Bessel filter has a linear phase
curve, which means that the shape of the signal is not distorted much. The
Bessel filters are therefore common in high-performance systems.
The filter must be taken into account in the design of the regulator if
the desired crossover frequency is larger than about (OB /10, where (J)B is the
bandwidth of the filter. The Bessel filter can, however, be approximated with
a time delay, because the filter has linear phase for low frequencies. Table 7.2
shows the delay for different orders of the filter. Figure 7.12 shows the Bode plot
ofa sixth-order Besselfilter and a time delay of 2.7/(J)n. This property implies
that the sampled-data model including the antialiasing filter can be assumed
to contain an additional time delay compared to the process. Assume that the
bandwidthof the filter is chosen as

Chap. 7

Process-Oriented Models

254
1 r---------~-=-=-=-~-

-----------

0,01

10

1

0.1

or=======----.-----------,
C1l

00

-l80

(IS

f
-360
0.1

10

1

Frequency, rad/s
Figure 7.12 Bode plot of a sixth-order Bessel filter (solid) when (JJo = 1
and 11 time delay Td ;;;; 2.7 (dashed) .

where Cl)N is the Nyquist frequency, and G(la(s) is the transfer function of the
antialiasing filter. Table '7.3 gives some values of Td • as a function of p. First,
the attenuation f3 is chosen. The table then gives the bandwidth of the filter
in relation to the Nyquist frequency. The delay measured in the units of the
Table 7.3 The time delay Td as a function of the desired attenuation at the
Nyquist frequency for fourth- and sixth-order Bessel filters . The sampling
period is denoted h.

Fourth Order

Sixth Order

p
0.001

0.1

5,6

0.2

4.8

0,01

3.2
2.1

0.3

3.1

0.05

0.2
0.3

0.1

0.4

1.7

0.2

0.5
0.7
1.0

1.4
0.9
0.7

0.4
0.4
0.5

2.3
2.0
1.7

0.'7

1.2
0.9

0.5

0.7

1.0

255

Aliasing or Frequency Folding

Sec. 7.4

'.. ..

(a) 1

\

o
I.

-1

o
(c)

10

20

o

30

o

.

o•
.... .... •••• ......

-1

10

20

30

-1

20

10

.

{dl 1

1 •••.••••••••••

o

\

-1

30

•
•

..............
'-------~-----'

o

Time

10

20

30

Time

Figure 7.13 Usefulness of a prefilter, (a) Signal plus sinusoidal disturbance. (b) The signal is filtered tbrough a sixth-order Bessel filter. (c) Sample
and hold of the signal in (a). (d) Sample and hold of the signal in (b).

sampling period is also obtained, that is, if a small value of {J is desired, then
the bandwidth of the filter must be low and the corresponding delay is long.
Example 7.2 Prefiltering
The usefulness of a prefilter is illustrated in Fig. 7.13. An analog signal composed
of a square wave with a superimposed sinusoidal perturbation (0.9 Hz) is shown
in (a). The result of sampling the analog signal with a period of 1 Hz is shown in
(c). The Nyquist frequency is 0.5 Hz. The disturbance with the frequency 0.9 Hz
has the alias 0.1 Hz [see (7.10)]. This signal is clearly noticeable in the sampled
signal. The output of a prefilter, a sixth-order Bessel filter with a bandwidth of
0.25 Hz, is shown in (b), and the result obtained by sampling with the prefilter
is shown in (d). Thus the amplitude of the disturbance is reduced significantly by
the prefilter.
_

Example 7.3 Product-stream sampling
In process control there is one situation in which prefiltering cannot he used:
namely when a product stream is sampled and sent to an instrument for analysis . Examples are samples taken for mass spectrographs, gas chromatographs,
and laboratory analysis. In such cases it is advisable to take many samples and
to mix them thoroughly before sending them to the analyzer. This is equivalent to
taking several samples and taking the mean value.

_

When Can Dynamics of Antfaliasing Filters Be Neglected?

We have mentioned that the dynamics in the antialiasing filter often must be
taken into account. The following analysis gives additional insight. The phase

Process-Oriented Models

256

lag at the frequency

COo

Chap. 7

introduced by a second-order Butterworth filter (7.11)

IS

2.6 W
o
a;;::;--

I1J Ws

where to, is the samplingfrequency, and fJ is the attenuation of the filter at the
Nyquist frequency. For a Bessel filter of sixth order the relation is

Our rules for selectingthe samplingrates in digital systems require that Noh is
in the range of 0.2 to 0.6. With Noh = 0.2 the preceding equation implies that
the phase lag of the second-order antialiasing filter is
0.083
a= - -

/1i

With fJ =0.1 we get a = 0.26 rad, or 15°. Withthe sixth-order Bessel filter as an
antialiasing filter and fJ = 0.1 , we get a =. 0.4 rad, or 23°. These calculations
show that it is necessary to take the dynamics of the antialiasing filter into
account for practically all digital designs. Approximating the filter by a delay is
a convenient way of doing that.

Postsampling Fillers

The signal from the D-A converter is piecewise constant. This may cause difficulties for systems with weakly damped oscillatory modes because they may
be excited by the small steps in the signal. In such a case it is useful to introduce a special postsampling filter that smoothes the signal before applying it to
the actuator. In some cases this can be achieved by suitable modification of the
actuator dynamics. In extreme cases it may be advisable to design special D-A
converters that will give piecewise linear control signals.

7.5 Designing Controllers with Predictive First-Order Hold
Design ofcomputer-controlled systems basedon a first-order holdwas discussed
in Chapters 4 and 5. In this section it will be shown that the methods used in
these chapters can easily be generalized to deal with systems where the D-A
conversion is based on a predictive first-order hold.
The reason for using other hold devices is that the control signal changes
stepwise, which implies that high-frequency signals are injected into the process. This is not a serious drawback for processes that attenuate high-frequencies effectively. It can, however, he a severe drawback for systems with poorly
damped oscillatory poles. For hydraulic systems it may also create severe hydraulic transients . The remedy is to replacethe first-order hold by a holdcircuit

Sec. 7.5

Designing Controllers with PredIctive First-Order Hold

257

that gives smooth control signals. A simple fix is to introduce a smoothing filter
after the D-A converter, as was discussed in Sec. 7.4. Another possibility is to
use the predictive first-order hold. This device, which was discussed in Sec. 7.3,
generates an output that is piecewise linear.

lmplementation of a Predictive First-Order Hold
The predictive first-order hold is described by Eq. (7.9). The system can be
implemented by switched operational amplifiers. It is, however, often more
convenient to implement an approximation with a multirate sampled system.
The time interval (tk, tk+l) is then subdivided into a N equal parts of length
tJ./ = (tk+l - th) and the output of the hold circuit is incremented by

at each time increment tJ. t . If N is large, the output from the hold circuit is then
a staircase function with very small steps, which is very close to the output
given by ErL • (7.9). If necessary the output can also be filtered.

Predictive First-Order-Hold Sampling: A State-Space Approach
We will now consider a system in which the sampling period is constant and
equal to h. In Chapter 2 we showed that the behavior of the system at the
sampling interval at the sampling instants t = kh could he conveniently described by a difference equation. The key idea was that the system equations
could be integrated over one sampling interval if the shape of the input signal
was known. In Chapter 2 the calculations were based on the assumption that
sampling was made by a zero-order hold, which implies that the control signal is constant over the sampling intervals. It is straightforward to repeat the
calculations in Chapter 2 for the case when the control signal is affine over a
sampling interval. The modifications required can also he obtained as follows.
Consider a continuous-time system described by

dx
(
dt == Ax t) + Bu(t)

(7.13)

y(t) == Cx{t ) + Du(t)
Assume that the input signal is linear between the sampling instants. Integration of (7.13) over one sampling period gives

x(kh + h) ~ eAhx(kh)
{kh+h

+ i.

eA(kh+h-S}B[u(kh) + s-h

kh

(u{kh+h)-u(kh))] ds (7.14)

Chap. 7

Process.Qriented Models

258

Hence
x(kh + h)

::=

«1>x(kh) + fu(kh) + ~ fl (u(kh + h) - u(kh))

= 4lx(kh) + ~ f1u(kh + h) +

(r - ~ f

1)u(kh)

where
€I> ;:: eAh

r =

r,

=

f
f.. .

e"'d.B

(7.15)

( h-s)dsB

The pulse-transfer function that corresponds to ramp-invariant samplingthus
becomes
(7.16)
It follows from (7.14) that the matrices '4l, C and f

1

satisfy the differential

equations
d4l(t}
dt

=4l(t)A

dr(t) = €I>(t)B
dt

dfl(t)

= f(t)

dt
These equations can also be written as

d [4l(t) f(t) .f l(t) ]
[«1>(t) r(t) fl(l)] [A B
dt
0
I
It
=
0
1
It
0 0
001
001
00

O~]

This implies that the matrices «1>, I', and I'1 can be obtained as

The calculation of ramp-invariant systems is illustrated by some examples.

Sec. 7.5

Designing Controllers with Predictive First-Order Hold

259

Example 7.4 Ramp-invariant sampling of an integrator
Consider a system with the transfer function G(s} = l/s. In this case we have
A '" D = 0 and B = C '" 1. Using (7.17) we get

(~

r

f,

1= (1
==

(1

1

0 0 exp (
h

(~ ~ ~

H

~ h2 )

The pulse-transfer function becomes
!zh + h - !h

H(z)

== 2

2

z-l

h z

-t

1

== _ _

2 z-l

This pulse-transfer function corresponds to the trapezoidal formula for computing
an integral. Also notice that Tustin's transformation gives the same result in this
case.
_

Example 7.5 Ramp-invariant sampling of a double intelJl'Btor
Consider a system with the transfer function O(s) "" l/s 2 , This system has the
realization

~~ == (~ ~) r + (~) u
Y=(lO)x
for the matrix

and its matrix exponential

eA.

=

[~ 1T

Hence from (7.17)

~ = (~ ~)
The pulse-transfer function is now obtained from (7.16), that is,
H(z) =

(1

01

[z ~ z-:J'([ ~:: 1

h2

(z -1)2

z+

(h~2l_ [~::])

~2 + 4z + 1

6

1

-

Process-Oriented Models

260

Chap. 7

y

t

u

Figure 7.14 Inputsandoutputs ofa process with predictive first-order-hold
sampling.

Predictive First-Order-Hold Sampling: An ~nput ..Output Approach

The pulse-transfer function obtained by predictive first-order-hold sampling of
a system with a transfer function G(s) can also be obtained by a direct calculation. Figure 7.14 shows the inputs and the outputs of a system with predictive
first-order-hold sampling. Let u be the input of the system and let y denote
the output. The piecewise affine input u can be generated as the output of an
integrator whose input is the piecewise constant signal

v(t) = u(kh + h) ~ u(kh)
h

(7.18)

Because this signal is constant overthe sampling intervals, the results of Chapter 2 can be applied and we find that the z-transfonn of the output is given by

G{S))
Y(z) == Szoh ( 7
V(z)

(7.19)

wbere 5zon denotes the map of transfer functions to pulse-transfer functions
through zero-order-hold sampling. This operator is given by Eq. (2.30). Combining Eqs. (7.18) and (7.19) we get

Y(z) = S"',

(G~s)) z ~ 1 U(z)

We have thus obtained the input-output relation for sampling witb a predictive
first-order-hold that can be expressed as follows.
Spfob ( G (s))

z-1

;:;; -h- Szoh

(G(S))
-8-

(7.20)

Sec. 7.5

261

Designing Controllers with Predictive First-Order Hold

By using Eq. (2.30) it follows that the pulse-transfer function obtained by the
predictive first-order-hold sampling of a continuous system with the transfer
function O(s) can be expressed by

H(z) =

(z -1)2 1
zh 27fi

I

T I :x:l
+

y-loo

eSh. G(s)
--ds
z - esh s2

(7.21)

We illustrate the results with an example.
Example 7.6 Predictive first-order-hold sampling of an integrator
An integrator has the transfer function G(s) == l/s. The zero-order-hold sampling
of the double integrator is
h2 z + 1
2" (z - 1)2
It then follows from Eq, (7.20) that

H(z)

= ~ z +1
2 z-l

This is the same result obtained in Example 7.4.

•

Example 7.7 Predictive flrst-order-held sampling of a double integrator

A double integrator has the transfer function G(s) "'" l/s 2• It follows from Table 2.1
that the zero-order-hold sampling of 1/s3 is

It then follows from Eq. (7.20) that
2z2+4z+1

H(z) = h
6 (z-lJ2

Notice that in this case the orders ofthe numerator and denominator polynomials
are the same. Thill is due 1.0 the predictive nature of the hold.
•

Control Design
We have thus found that predictive first-order-hold sampling is similar to zeroorder-hold sampling. In both cases the behavior of a system at the sampling
instants can be described as a time-invariant discrete-time system. The methods
for designing controllers obtained can then be used with minor modifications.
We will illustrate this by giving the results for pole-placement control.
Consider a system with the pulse-transfer function H (z) = B (z) / A(z) obtained bypredictive first-order-hold sampling. Ageneral linearcontroller witha
two-degree-of-freedom structure can bedescribed bythe triple (R(z), S(z), T(z}).

Process-Oriented Models

262

Chap. 7

With a predictive hold the controller must generate the signal u(kh + h) at time
kh. This means that the controller polynomials have the property
deg R(z) ~ deg S(z) + 1

{7.22)

degR (z) ~ degT(z) + 1

Specifying a desired closed-loop characteristic polynomial Arl we find that the
Diophantine equation associated with the design problem becomes
A(z)R(z) + B(z)S(z) == Ad(z)

(7.23)

and the control design can then be done in the same way as in Chapter 5. The
only difference is that the order condition (7.22) is different. We illustrate the
procedure by an example.
Example 7.8 Pole-placement design of a double integrator
In Example 7.7 we derived the pulse-transfer function for a double integrator under
predictive first-order-hold sampling. It follows from this example that the system
is characterized by
A(z)

= (z -1)2

B(z) ==

It'l

'6 (22 + 4z +1)

Assuming that a controller with integral action is desired we find that the Diophantine equation (7.23) becomes
3h ~
(z -1) R(z) + 6 (z + 4z + l)S(z)

2

= Ar!(z)

where R(z) = (z - l)R(z). The minimum-degree solution of this equation has
the property deg 8(z) = 2. It then follows from the order condition (7.22) that
degR(z)=3 and consequently that degR(z) ='- 2. The minimum-degree solution
thus gives a closed-loop system of order five. The previous Diophantine equation
becomes

The solution ofthis equation was discussed in Sec. 5.3.

•

7.6 The Modulation Model
A characteristic feature of computer-controlled systems with zero-order hold is
that the control signal is constant over the sampling period. This fact is used
in Chapter 2 to describe how the system changes from one sampling instant to
the next by integratingthe system equations over one sampling period; this section attempts to describe what happens between the sampling instants. Other

Sec. 7.6

263

The Modulation Model

Clock

Figure 7.15 Schematic diagram of a sample-and.hold circuit.

mathematical models are then needed, becauseit is no longersufficient to model
signals as sequences (functionsthat map Z to R); instead they must be modeled
as continuous-time functions (functions that map R to R).
The central theme is to develop the modulation model. This model is more
complicated than the stroboscopic model discussed in Chapter 2. The main difficulty is that the periodic nature of sampled-data systems must be taken into
account. The system can he described as an amplitude modulator followed by
a linear system. The modulation signal is a pulse train. A further idealization
is obtained by approximating the pulses by impulses. The model has its origin
in early work on sampled-data systems by MacColl (1945), Linvill (1951}, and
others.
In the special case of computer control with a unit-gain algorithm and
negligible time delay, the combined action of the A-D converter, the computer,
and the D-A converter can be described as a system that samples the analog
signal and produces another analog signal that is constant over the sampling
periods. Such a circuit is called a sample-and-hold circuit. An A-D converter
can also be described as a sample-and-hold circuit. The hold circuit keeps the
analog voltage constant during the conversion to a digital representation. A
more detailed model for the sample-and-hold circuit will first be developed.
A Model of the Sample-and-Hold Circuit

A schematic diagram of an analog sample-and-hold circuit is shown in Fig. 7.15.

It is assumed that the circuit is followed by an amplifier with very high input
impedance. The circuit works as follows: When the sampling switch is closed. the
capacitor is charged to the input voltage via the resistor R. When the sampling
switch is opened, the capacitor holds its voltage until the next closing.
'Ib describe the system, a function m, which describes the closing and
opening of the sampling switch, is introduced. This function is defined by
m(t)

=

G

if switch is closed
if switch is open

The current is then given by
.
u- y
t= - - m

R

Process-Oriented Models

264

Chap . 7

m

--

-

-

-

h

1-

2h

~

-

r~

Figure 7.16 Graph ofthe modulation function m with period h and pulse
width r .

The current is thus modulated by the function m, which is calledthe modulation
function. If the input impedance of the circuit that follows the sample-and-hold
circuit is high, the voltage over the capacitor is given by

C dy(t) ::: i(t) = u(t) - yet) m{t)

dt

R

(7.24)

The differential equation of (7.24) is a linear time-varying system. The time
variation is caused by the modulation. If the sampling period Ii is constant and
if the switch is closed for t seconds at each sampling, the function m has the
shape shown in Fig. 7.16. Because m is a periodic function the system becomes
a periodic system.
Once a mathematical model of the circuit is obtained the response of the
circuit to an input signal u can be investigated. It follows directly from Eq.
(7.24) tbat the voltage across the capacitor is constant when the switch is open,
that is, when m(t) ;; O. When the switch is closed, the voltage y approaches the
input signal u as a first-order dynamic system with the time constant RC. The
time constant of the RC circuit must be considerably shorter than the pulse
width; otherwise, there is no time to charge the capacitor to the input voltage
when the switch is closed.
A simulation of the sample-and-hold circuit is shown in Fig. 7.17. With
the chosen parameters, the pulse width is so long that the input signal changes
significantlywhen the switch is closed.
Figure 7.18 shows what happens when the pulse width is shorter. The
results shown in Fig. 7.18 represent a reasonable choice of parameter values.
The sample-and-hold circuit quickly reaches the value of the input signal and
then remains constant over the sampling period.

Practical Samplers
In practice, a sampler is not implemented, as shownin Fig. 7.15. Theyare today
made using semiconductor technology, but the circuits can still be described by
Eq. (7.24). 'lb avoid difficulties with noise and ground loops, it is important to
have the computer galvanically isolated from the process signals. This can be
achieved using the flying capacitor technique, which combines electrical insulation with sample-and-hold action in an elegant way. A capacitor is charged

265

The Modulation Model

Sec. 7.6

(a)

2

~

...... l

/

'.1.

I'

o

i/

-

......,.. ....::,.-J

'1

<,

10

5

0
(b) 2
1

I

0

1

I

I

r
. --"

-1

0

5

-- - .

_r

.....- --...-

10

(c)

1

a

5
Time

10

Figure 7.17 Simulation of a sample-and-hold circuit. The pulse width r is
0.2 s and the time constant is RC = O.OL s, (a) The continuous-time signal
(dashed) and the output of the sample-and-hold circuit (solid); (h) the current
i(t) in the sample-and-hold circuit; (c) the modulation function m{t).

to the input voltage when it is connected to the input line. When the capacitor is connected to the D-A converter it holds its voltage. Electrical isolation
is obtained because the capacitor is connected either to the process or to the
D-A converter of the control computer. In practice it is common to charge the
capacitor via an operational amplifier. The flying capacitor circuit can also be
described by Eq. (7.24).

A Mathematical Idealization
The pulse-modulation scheme is easy to simulate but difficult to analyze. A more
easily used mathematical idealization will therefore be introduced. It seems
reasonable to design the sample-and-hold circuit so that the pulse width t is
much shorter than the sampling period. It also seems reasonable to choose the
time constant RC to be aborter than the pulse width. The current through the
capacitor will then consist of short pulses. Both the height and the time integral
of a pulse are proportional to the difference u - y between the input voltage u
and the capacitor voltage y at the sampling instant.

Chap. 7

Process-oriented Models

266

-

(a)

2

/

/

-- <, l

............. l

_1

01/
0

-

'~
<,
10

o

(b) 2
]

l

0

r

r

I

1

J

f

-1

5

0

10

(c)

1

o1--__...

.........
_

n._~I_--IIIoooo-_"'--

o

5

.........

._..~

10

Time
Figure 7.18 Simulation of a sample-and-hold circuit. The pulse width is
0.05 s and the time constant is Be = 0.01 e. (a) Thecontinuous-time signal
(dashed) and the outputofthe sample-and-hold circuit (solid); (b) the current
i(t) in the sample-and-hold circuit; (c) the modulation function m(l).

In the idealization, the current pulses are replaced by impulses. For simplicity the integral of the impulse is chosen to be proportional to the value of
the input signal u at the sampling instant. The capacitor is then replaced by
an integrator. Because the pulses were chosen to be proportional to u and not
to u - y, it is necessary to reset the integral to zero when a new pulse arrives.
The current is then represented as

u'

~

um

(7.25)

where
'X.

m(t):::

2: 8(t - kh)

(7.26)

k= - 'X.

and 0 is a delta function [compare with (7.24)]. The signal u' is called the
sampled representation ofthe continuous signal u. It is useful to remember that
u' is related to the current through the capacitor of the sample-and-hold circuit
in Fig. 7.15.

Sec. 7.6

267

The Modulation Model

-1

Sampler

S&H

Hold

--l Hh") t-

~

~

Figure 7.19 Block diagram of a sample-and-hold circuit and its idealized
representation.

The signal u" can be thought of as a modulation of u with a carrier signal
in the form of an impulse train. The model is therefore called the impulse-train
modulation model. The signal u1< carries the same information as the sequence
{u(kh),k = ... ,-I,O,l, ... }. Notice, however, that u" is a (generalized) time
function. The signal u~ is introduced to represent a sampled signal in a form
that can be processed by linear filtering.

The Hold Circuit
The hold circuit can be represented as an integrator that is automatically reset
to zero after one sampling period. Such a system has the transfer function

Gzoh()
S

::;:

1
S (1 - e- ~h \)

(7.27)

The impulse response of the transfer function lIs is a unit step and the impulse
response of (l/s) exp(-sh) is a unit step that is delayed h time units. Subtraction
of these impulse responses gives the impulse response as a pulse of unit height
and duration h.
Notice that the steady-state gain of the hold circuit is Gzoh (0) = h. Section 7.3 shows that ideal sampling could be said to have a gain Ilh . The combination of a sampler with a hold circuit thus has unit steady-state gain. For
very fast sampling, the sample-and-hold circuit thus acts as a continuous-time
system with unit transfer function.
The idealized model of a sample-and-hold circuit is thus obtained by combining a sampler with impulse modulation given by (7.25) and (7.26) with a hold
circuit given by (7.27). A block-diagram representation of the system is shown
in Fig . 7.19. Because the impulse modulator is a periodic system it follows that
the sample-and-hold circuit is also a periodic system.

Input-Output Relationships
Once a convenient representation of a sample-and-hold circuit is obtained, the
response of a sampled-data system to an arbitrary input signal can be computed.
Consider the system shown in Fig. 7.20(a), which is composed of a sample-andhold circuit connected to a time-variant linear dynamic system with the transfer
function G. This is a typical representation of a sampler and a D·A converter
connected to a process. Use of the impulse-modulation model of the sample-andhold circuit allows the system to be represented as in Fig. 7.20(b).

Process-Oriented Models

268

Chap. 7

(b)

(a)

Clock
Sampler

u

-~S&H

G(s)

y

Hold

Process

.s:> ~ ~~-e-';)~
~

V

)

F(s)

Figure 7.20 (a) Schematic diagram ofa sample-and-hold circuit connected
to a linear system and (b) its representation using the idealized model of a
sample-and-hold circuit.

Let u be the input, y the output, and F the transfer function of the combination of the zero-order-hold circuit and the process, that is,

1

F(s) = - (1- e-sh)G(s)
s

(7.28)

The input-output relationship is easily determined using transform theory. The
Laplace transform of u" is given by

The Laplace transform of the output signal is then given by
x

Y(s) = F(s)

2: e-

skh

u(kh)

(7.29)

k=Q

It is thus straightforward to calculate the Laplace transform of the output signal. Notice, however, that it is not possible to factor out the Laplace transform of
the signal u on the right-hand side of (7.29) . This means that the input-output
relationship of the system cannot be characterized by an ordinary transfer function. This is because the system is not time-invariant. How to get around this
problem is discussed in Sec. 7.8.

7.7 Frequency Response
Many powerful methods for analysis and design of control systems are based on
frequency response. The key idea is to use the fact that a linear time-invariant
system can be completely characterized by its steady-state response to sinusoidal signals. It would be highly desirable to extend these results to sampleddata systems. We have in fact done this intuitively, for example, when plotting
the sensitivity function , S(e iWh ) , for discrete-time systems in Chapter 5, There

Frequency Response

Sec. 7.7

269

are, however, some difficulties in interpreting the results that we must be aware
of. The frequency response of a discrete-time system is a well-defined quantity.
When dealing with sampled systems it is, however, also necessary to consider
what happens between the sampling instants, There is an essential difficulty
because sampled systems are time-varying. One consequence of this is that a
sinusoidal input of frequency generates outputs with many frequencies. This
was illustrated, for example, in Example 1.4.
In this section we will explore sampled systems from the point of view of
frequency response. We will first investigate how sinusoids propagate through
sampled systems. The results are useful when organizing and interpreting experiments with frequency response. We will then briefly outline how frequency
response of a sampled system can be defined rigorously. The section ends with
a few practical remarks.
ASpecial Case

When performing the frequency-response test, it is natural to cut the loop on the
analog side, for example, at A in Fig. 7.1. 1b simplify the analysisconsider the
special case in which the output of the D~A converter is equal to the input ofthe
A~D converter. The action ofthe computer on the signalscan then be described
as a sample-and-hold circuit. It follows from Fig. 7.19 that a sample-and-hold
circuit can be represented as a sampler followed by a hold circuit. The problem
is thus reduced to calculation ofthe response ofa sampler followed by a linear
time-invariant system.
Equation (7.25) gives the sampled representation u· of the input signal u.
Afonnal Fourier series representation ofa sequence ofdelte functions gives
1

~

m(t)

=

L

~

6(t-kh)=h(1+2Lcoskw,t)
l=l

Ai =-00

where h is the sampling period, and tV, is the corresponding sampling frequency
in radians per second.
Assume that the input to the system is
u(t) =sin(lDt +,) :;; hn (exp i(lDt + f'))

The series expansion of the output rl

u·(t) =

=um· of the sampler then becomes

K[SiD(lDt + f') +2 fCOS(km.t)8in(mt+ 9')]
.=1

=

~ [Sin(lilt + ,) +

f:(
'=1

sin(kOl,1 +lilt +

9') - sin(kOJ,1 -1tIt - 9'))]

The signal u· has a component with the frequency m of the input signal. This
component ismultiplied by 1/h because the steady-state gain of a sampler is

Process-Oriented Models

270

-2w.~

+w

-ws +a>

()J ~

Chap. 7

+ (J)

Figure 7.21 Frequency content of the sampled input signal u' when
u sin (ll.It + ((J ).

=

I/h. The signal also has components corresponding to the sidebands kto, ± w.
The frequency content of the output u" of the sampler is shown in Fig, 7.21.
The output signal y is obtained hy linear filtering of the signal u* with a system
having the transfer function F(s). The output thus has components with the
fundamental frequency m and the sidebands kta, ± w.
For ta f. kWN t where WN is the Nyquist frequency, the fundamental component of the output is

For W :::: kWN, the frequency of one of the sidebands coincides with the fundamental frequency. Two terms thus contribute to th.e component with frequency
w. This component is

y(l) ::

~ 1m (F(iw)el (((/ l+~ ) -

F(iw)e ,IM-ql»)

:::: ~ Im ((1 - e2 1q1 ) F(if1J)e i ((rJl- CP l)
:::: ~ Im (2ei()T/2-~)sin qJF(im)eilwti-9l))
If the input signal is a sine wave with frequency (()~ it is found that the output
.
contains the fundamental frequency (JJ and the sidebands Iu», ± (J), k ::: 1,2, . _
(compare with the discussion of aliasing in Sec. 7.4). The transmission of the
fundamental frequency is characterized by

1 '
h F( uv).

~ F(iw)ei(Jf!2- q?) sin tp

h

For OJ f: kOJN I the transmission is simply characterized by a combination of the
transfer functions of the sample-and-hold circuit and the system G, The factor
11k is due to the steady-state gain of the sampler.

Sec. 7.7

271

Frequency Response

1

o

5

10

5

10

5
Time

10

1

o
-1

o
1

o
-1

o

Figure 7.22 Sampling of a sinusoidal signal at a rate that corresponds
to the Nyquist frequency. Notice that the amplitude and the phase of the
sampled signal depend strongly on how the sine wave is synchronized to the
sampling instants.

The fact that the signal transmission at the Nyquist frequency OJN critically depends on tp-that is, how the sinusoidal input signal is synchronized
with respect to the sampling instants-is illustrated in Fig. 7.22.
There may be interference between the sidebands and the fundamental
frequency that can cause the output of the system to be very irregular. A typical
illustration of this was given in Example 1.4. In this case the fundamental
component has the frequency 4.9 Hz and the Nyquist frequency is 5 Hz. The
interaction between the fundamental component and the lowest sideband, which
has the frequency 5.1 Hz, will produce beats with the frequency 0.1 Hz. This is
clearly seen in Fig. 1.12.
If the sideband frequencies are filtered out, the sampled system appears
as a linear time-invariant system except at frequencies that are multiples of the
Nyquist frequency, ws /2. At this frequency the amplitude ratio and the phase
lag depend on the phase shift of the input relative to the sampling instants.
If an attempt is made to determine the frequency response of a sampled
system using frequency response, it is important to filter out the sidebands
efficiently. Even with perfect filtering, there will be problems at the Nyquist
frequency. The results depend critically on how the input is synchronized with
the clock of the computer.

Process-Oriented Models

272

Chap. 7

Clock

----

~

~

t
Algorithm

A-D

D-A

u

y

Process

~

Figure 7.23 Open-loop computer-controlled system.

The General Case
It is easy to extend the analysis to the general rase of the system shown in
Fig, 7,1. The corresponding open-loop system is shown in Fig. 7.23.
It consists of an A-D converter, the computer, a D·A converter, and the
process. It is assumed that the D-A converter holds the signal constant over
a sampling interval. It is also assumed that the calculations performed by the
computer can be expressed by the pulse-transfer function H(z) and that the
process is described by the transfer function G (s).
If a sinusoid

v(t) :: sin(wt + qJ) = 1m (expi(cot + ep))
is applied to the A-D converter, then the computer will generate a sequence of
numbers that in steady state can be described by

h)e
w(kh) = Im (H(e iM l (6Jkh+/P J)

k:;: .. . - 1,0,1, .. ,

This sequence is applied to the D-A converter. Because the D-A converter holds
the signal constant over a sampling period, the output is the same as if the
signal w were applied directly to a hold circuit. The discussion of the previous
section can thus be applied: The output contains the fundamental component
with frequency wand sidebands k(Q~ ± to. The signal transmission of the fundamental component may be described by the transfer function

!
K(iw)

'=

H(eiWh)F(ico)

h

( XH(eiaJh)F (iw)e (1I'/2- 'P ) sin ffJ
i

. where

CON

is the Nyquist frequency and
F (s) :::;

~ (1 - e-Sh )

G(s)

273

Frequency Response

Sec. 7.7

o~-----------..-----.------::-------.........,

~
IlJ

~

-100

~

-200 L - -

--'-

o

10
Frequency, rad/s

-'

20

Figure 7.24 Magnitude and argument curves of the transfer function for

first-order-hold (full) and zero-order-hold (dashed) circuits. The Nyquist frequency is

(() N

= lr.

When (J) is not a multiple of the Nyquist frequency, the signal transmission of
the fundamental component can be characterized by a transfer function that
is a product of four terms: the gain 1/ h of the sampler, the transfer function
(1- exp(-sh))1s of the hold circuit, the pulse-transfer function H(exp(sh) ) of
the algorithm in the computer, and the transfer function G(s) of the process.
Notice, however, that there are other frequencies in the output ofthe system
because of the sampling. At the Nyquist frequency the fundamental component
and the lowest sideband coincide.
It follows from the discussion that the hold circuit can be interpreted as
a filter. The frequency functions of zero-order and first-order-hold circuits are
shown in Fig. 7.24. It is clear from the figure that both the zero-order and the
first- order hold permit significant signal transmission above the Nyquist frequency OJN = Jr 1h. Notice that the phase CUIVe is discontinuous at arguments
OJh ;: 2kJr k == 1. 2,.... Because the phase is defined modulo 2Jr, the discontinuities may be ±Jr. In the figure they are shown as n for convenience only.
The following example illustrates the calculation and interpretation ofthe
frequency response of a sampled system.
1

Example 7.9 Frequency response of a sampled-data system
Consider a system composed of a sampler and a zero-order hold, given by (7.27),

Process-Oriented Models

274

Chap. 7

followed by a linear system, with the transfer function
G(s)

= ~1
s+

The sampling period is h = 0.05 8. The Nyquist frequency is thus lr/O.05 = 62.8
rad/s. Figure 7.25 shows the Bode diagram of the system. For comparison, tbe
Bode diagram of the transfer function G is also shown in the figure. The curves are
very close for frequencies that are much smaller than the Nyquist frequency. The
deviations occur first in the phase curve. At (J) ;;;;: O.lwN the phase curves differ by
about 10°. There is no signal transmission at frequencies that are multiples ofthe
sampling frequency ills. because the transfer function of the zero-order hold is zero
for these frequencies. The phase curve is also discontinuous at these frequencies.
(Compare with Fig. 7.24.) Notice also that tbere are ambiguities of the transfer
function at frequencies that are multiples of the Nyquist frequency that are not
shown in Fig. 7.25. The value of (fJN is indicated by a vertical dashed line in
Fig. 7.25.
The interpretation of the Bode diagram requires some care because of the
modulation introduced by the sampling. If a sine wave of frequency OJ is introduced,
the output signal is the sum of tbe outputs of the sine wave and all its aliases.

lr-------~

..r:=
.
o
til

0.001

0.1

1000

10

OF===----------r----,------~

:l

- - - - - +- -":1

-ilOO ' - - - - - - - - -_ _....:......_L0.1
10
Frequency, rad/s

---=:.-_-=-----_ .

--l

1000

Figure 7.25 Bode diagrams for a zero-order sample-and-hold circuit followed by a first-order lag (solid). The sampling period is 0.05 s. The dashed
line is the frequency curvefor the continuous-time first-order lag. The vertical
dotted lines indicate the frequencies OJ = 5, 60, and 130 rad/s, respectively.
The vertical dashed line indicates the Nyquist frequency.

275

Frequency Response

Sec. 7.7
(a) ....

:::s
0.

1

1

c:
...
-e

~

c.

:::l

0.
....

...... 0
~

S
til

00

0

-1

-1
0

(b) ....
;:::l

c..

2

~

'a

0

4

1
0..

0

~

;::l

0

0
c.

2

4

::l

rn -1
::I

4

+"

e
I.'J

(c) .....

2

0.02

~
....

-e

0

2

0

-0 .02

4

0
1

1

...
~

.....

"'C

C.
...

::I

...... 0
p,
~

~

r.t:J

;:l

0

0

-1

-1

0

2
Time

4

0

2
Time

Figure 7.26 Steady-state responses to sinusoids with different frequencies
for a zero-order hold followed by a first-order system with a unit time constant. The sampling period is 0.05 s, The frequencies are 5 rad/s in (a).
60 rad/s in (b), and 130 rad/s in (c). They are indicated by dotted hnes ill
Fig. 7.25.

'Ihis is illustrated in Fig. 7.26, which shows the steady-state outputs for different
frequencies. For frequencies smaller than the Nyquist frequency, the contribution
from the fundamental frequency dominates. At frequencies close to the Nyquist
frequency, there is a substantial interaction with tbe first alias, to, - w. Typical
beats are thus obtained. At the Nyquist frequency, the signal and its first alias have
the same frequency and magnitude. The resulting signal then depends on the phase
shift between the signals. For frequencies higher than the Nyquist frequency, the
contribution from the alias in the frequency range (0, WN ) dominates.
This clearly shows how important it is to filter a signal before the sampling,
so that the signal transmission above the Nyquist frequency is negligible. Compare
this conclusion with the discussion of aliasing in Sec. 7.4.
•

Frequency Response of an Internal-Combustion Engine
An internal-combustion engine is a typical example of a system that is inherently sampled. The sampling is caused by the ignition mechanism, and its frequency is the number of independently fired cylinders divided by the time required for a full cycle.

276

Process-Oriented Models

Chap. 7

When an attempt was made to investigate the dynamic response of the engines, reproducible results were easily obtained for frequencies lower than the
sampling frequency. For a long time, however, the results for higher frequencies were erratic ; Different results were obtained at different measurements
and results of experiments could not be verified when the experiments were
repeated. This was due to the sampled nature of the process. For input signals
with a frequency close to the Nyquist frequency, there is interference from the
sidebands. At the Nyquist frequency, the results depend on how the sinusoid is
synchronized to the ignition pulses .
When the source of the difficulty was finally understood, it was easy to find
a solution. The sinusoid was simply synchronized to the ignition pulses; then
it became possible to measure the frequency response to high frequencies. A
typical result is shown in Fig.7.27. Notice, in particular, that the measurement
is done in a range of frequencies that includes the Nyquist frequency.

The Idea of Lifting
The notion of lifting is an elegant way to deal with periodicallysampled systems.
The idea is to represent a finite-dimensional sampled system as a time-invariant
infinite-dimensional discrete system. In this way it is possible to define a notion
of frequency response properly. It is also possible to give a nice description of
intersample behavior.
Consider a system described by Eq. (2.1). Assume that the system is sampled with a period h, and that the input signal and tbe states are in L2 . We
introduce the discrete signal Uk E L 2(0 ,h) defined by

o< t

<h

(7.30)

and the signals Xk and Yk, which are defined analogously. Define the discrete
signal Xk is the same way. It follows from Eq. (2.1) that

Xk 41(r)
Yk( r)

= tp(r)xk(h) + J,t 'II(e -S)BUk(S)ds

(7.31)

=CXk( r)

where

tp( t) = eAt
lJl {t) = eA(riB
This system is a time-invariant discrete-time system. Equation (7.31) gives a
complete description of the intersample behavior because the function Yk{ r),
which is defined for 0 ~ r .5 h; is the output in the interval kh s t $ kh + h.
The description thus includes the phenomenon of aliasing. Notice, however, that
Uk, Xk, and Yk are elements of function spaces. Because the system is linear and
time-invariant, the frequency response can be defined as H (e ill1h ), where H is

Sec. 7.7

Frequency Response

a

o

o

a

N

co

"I"

o
....

I
I

0

o _~

"

·v

Q

..

o

""

~

I.

b~.

liI~ ~_

C

~

_-I'"

...

':l

g:
<PI

.0

c

~

f--

....
Q

0

~.;I Ct
'"
011

,..' "

'Il

Il

0

Cl

.<1

00

-'"

0

•
I

-....
.

IC

....11
1

<l

o

11

Q~
~

<l0"'J{

oJ' ~
.

.•

<l

,

<
a:

ClJt'
It

Ie

f.)1'"

->'U

Oz

l.LJ

=>

a
UJ

J<l

n

...

o~

~

....

r"

0::

u.

...~o::

<II

I~.

Ii'
~D

~

~.

~I(

•

«
"

~

'!.

o

6

10-

<l~
t.

t

'I

c

~

x<I

"-

0;'

jl'II

il

•
•

<l

..

I:J

"
)(

1

0

Cl

000
N

ijP- 3anllldH\I

"t"

o
o
6

~~ NOllJnG3~

Figure 7.27 Measured frequency response for a diesel engine. The frequencies are normalized with respect to the sampling frequency. [Redrawn
from D. E. Bowns, "The Dynamic Transfer Characteristics of Reciprocating
Engines," Proc. Meek. Eng., 185. (1971) with permission.]

278

Process-Oriented Models

Chap. 7

the transfer function of the infinite-dimensional system (7.31). The transfer
function His, however, a nontrivial mathematical object. It can he computed
numerically by a finite-dimensional approximation of the state. This can, for
example, be obtained through the discrete-time system obtained by dividing
the sampling interval h into N equal parts . A complete treatment requires
functional analysis, which is outside the scope of this book. Details are given in
the References.
Another way to deal with frequency response of sampled systems is to
realize that the output generated by a sinusoid with frequency (tJo contains the
frequencies CUll ;;: noi; ± wo oThe system can then be properly characterized by
the transfer functions for all those frequencies.

Practical Consequences
The fact that sampled systems are time-varying means practically that some
care must he exercised when interpreting frequency responses of sampled systems. Discrete frequency responses such as H (ej(~h) , L(e ' Cll h ) , and S(e wJh) give
a correct description of what happens at the sampling instants, hut they may
give misleadingresults when intersample behavior is considered. For example,
if we compute a phase margin based on .L{e ' aJh ) it may happen that the system
becomes unstable for a much smaller increase of the phase lag of the physical
process. Realize that the reason for the difficulty is that a sinusoidal input,
with frequency mo, to a sampled system gives outputs that contains many other
frequencies. With an ideal antialiasing filter the signal components with frequencies different from Wo will not be present and the difficulty disappears.
Ideal antialiasing filters cannot be implemented practically. There will not be
muchdifficulties with plants with good attenuation ofhigh frequency if the sampling period and the antialiasing filter are chosen properly. There may, however,
he severe problems if there are resonant modes close to the Nyquist frequency,
In such cases it is necessary to choose sampling rates and antialiasing filters
very carefully. It is also advisable to use the theory of lifting to compute the
proper frequency responses.

7.8 Pulse-franster..Function Formalism
Linear continuous-time systems can be conveniently described, analyzed, and
synthesizedusing algebraic methods. When the theory ofsampled-data systems
was developed. it was natural to try to develop similar algebraic tools. Much
of the early development of the theory of sampled-data systems went in this
direction.
Theapproach is useful, simple, and successful if the system is viewed from
the computer or if the process is observed at times that are synchronized with
the computer clock, because the system is then time-invariant. (See Chapter 3
for the appropriate analysis.] However, when the system is analyzed from the
process point of view, as is done in this chapter, the system is time-variable. The

Sec.1.8

Pulse-Transfer-Function Formalism

279

algebraic approach then loses someof its simplicity, because multiplication with
time functions does not commute 'with differential and difference operators. For
the case of completeness, a brief description of the algebraic system theory in
the more complicated case is given. The main reason is historical. Much of the
theory of sampled-data systems was originally developed using this approach,
which is also used in many papers.

Goals
Before going into the details, it is useful to state the goals, The main purpose is
to develop a formalism for manipulating the system descriptions. The formalism will have many properties in common with the transform methods for linear
time-invariant systems. Each A-D and D-A converter is associated with a sampling operation. Becausesamplingcan be described as an amplitude modulation,
the time-varying parts will be associated with these operations. The system can
then be separated into different parts: Some parts are ordinary linear timeinvariant systems that can be handled by the ordinary transform methods; the
other parts consist of the samplers that are intrinsically time-varying.

The z-Transform
Section 2.7 introduces z-transforms as mappings from sequences to functions of
a complex variable. A different z-transform whose domain is continuous functions can be defined as follows:
7.1 THE z-TRANSFORM
function is defined as
DEFINITION

The z-transform of a continuous-time

oc

F(z) =

Lz- f(kh)
k

(7.32)

k=O

The inverse transform is given by

f(kh)

= ~21. J i- 1F(z )dz
In

where the contour of integration

Ir

r encloses all singularities ofthe integrand.

•

The a-transform of a continuous-time signal is tbus ohtained by sampling the
signal and then applying the z-transform to the sampled sequence. Because
the transform depends only on the values at the sampling instants, all time
functions that agree at the sampling instants have tbe same transform.
Notice that the transform is inherently related to the clock) which defines
the sampling instants. Also notice that the inverse transform defines the function at the sampling instants only.
These properties ofthe z-transform ofa continuous-time function are easily
misunderstood and have led to much confusion and many mistakes.

Process-Oliented Models

280

Chap. 7

Two Basic Theorems
Th develop an algebra that allows forma) manipulation ofthe systems, two theorems are needed. The first theorem tells how the z-transform ofa continuoustime function is related to its Laplace transform.
THEOREM 7.2
Let the function f have the Laplace transform F and
the a-transform F, and let F· be the Laplace transform of the sampled representation
of f. Assume that for some e > 0, IF(s)1 ~ !Sl-l-f for large 1
s1
then

r

_

F~(s) = F(e

1

sh

)

00

L

Ii

=

F(s + ikws)

(7.33)

h::-oo

where W, = 2Jr/h is the samplingfrequency.
Proof

The definition of F· gives

F·(s) ~
=

=

1
00

e-stt(t) dt

1°C e-S'f(t)m(t) dt

f

'-"f(t)

(.too

0(1- kh)) dt

where the last equality is obtained from (7.26). Interchange the order of integration and summation gives

r(s) =

f:['

,-"{(t)o(t - kh) dt

-co 0
00

:=

L(eshtkf(kh)
h:{)

: :; it(e sh)
The last equality follows from (7.32).
Because the Laplace transform of a product oftwo functions is a convolution of their transforms, it follows that
1
F*(s) = F(s) *M(s) = -2.
:=

1
2/tl

I

1Ct

T ioo
+

.

r-1OO

l,+ioo F(v)M(s- u) dv
y-iO(,

(7.34)

1

F () 1 - e- h(8- U) dv
u

The integration path should be to the right of all poles of F and to the left of
all poles of M (see Fig. 7.28). If F goes to zero faster than /S/-l-E as lsi ~ 00,

Pulse-Transfer-Function Formalism

Sec. 7.8

281

1m
x

x

Poles of F

I\x

PolesofM

x

x

1

0

x

x

r

x

Figure 7.28 Singularities of F and M and the integration contour

r.

the integral of FM on a large semicircle will vanish. Upon completion of the
integration path by a large semicircle to the right, the integral can be evaluated
with residue calculus. In the domain enclosed by the contour the integrand has
simple poles at the zeros of
eh(s-v)

=1

that is, at

k

=... - 1,0,I, ...

The residues at these poles are
1
21tik)
- F ( s+-h
h

Summation ofthe residues now gives (7,33).

Remark 1.

•

Notice that Eq. (7.33) can also be written as

Notice that if F is analytic for Re s < ~ro, the integration
path in (7.34) may be closed by a large semicircle to the left. The following
formula is obtained:

Remark 2.

This gives a proof of formula (2.31).

Process-Oriented Models

282

Chap, 7

Clock

u

F (s )

y•

'Y

Figure 7.29 Block diagram of a system with two samplers.

Remark 3. The theoremcan be extended to the casein which the function
F goes to zero as l/\sl for large lsI. Equation (7.33) is then replaced by

F*(s)

=~

t

F(s + ikms ) + ~ {(O+)

k ", .. x,

Remark 4. In the literature the same notation is sometimes used for the
functions F* and F, This is confusing and should be avoided.

Remark 5. Notice that (7.33) is closely related to (7.3) for the Fourier
transform of a sampled signal.
Pulse-transfer functions. Section 7.6 shows that the input-output relationship of a sampler followed by a linear transfer function is given by Eq.
(7.29). This equation cannot be described by a transfer function. If a fictitious
sampler is added to the system output, the configuration shown in Fig. 7.29
is obtained. For this system it is possible to define a transfer function. The
input-output relationship is given by

The following theorem is useful for obtaining the corresponding transforms.
Let ( and g be functions that have Laplace transforms
and let m be the modulation function corresponding to an impulse train. Then
THEOREM 7.3

m(t) (f(t) '" (m(t)g(t))) = (m(t)f(t)) * (m(t)g(t))

(7.35)

or, equivalently,

(7.36)
Proof Use of the definition of a convolution allows the left-hand side of
(7.35) to be written as

({*g~)'(t) =m(t)

,
f

{(t - r )g'(r) di ::

1:

m(t)f(t- r)m(r)g(r) dt

Sec.7.a

283

Pulse-Transfer-Function Formalism

Similarly, the right-hand side of Eq. (7.36) can be written as

(I" * g~)({I;;

I:

m(t

.:
l

=

r)f(t

r)m(r)g(r) dt

m(t)f (t - r)m(r)g (r) dr

The last equality holds because m(r ) f. 0 only for t

= nh and m(t - nh) = m(t).

•
Remark 1.

The Laplace transformation of (7 .35) gives

r = F'(s)C "(s)

(F(s)C '[s]

(7.37)

Remark 2. Notice that the multiplicationby m outside the brace in (7.35)
can be interpreted as introduction of a fictitious sampler.

A Formalism

It is now straightforward to develop a formalism for dealing with sampled systems. First, a system is represented by a block diagram. Eacb A-D converter is
represented as an ideal sampler. Each D-A converter is represented as a hold
circuit having the transfer function (7.27). Linear continuous-time blocks are
represented by their transfer functions, and linear calculationsin the computer,
by their pulse-transfer functions. The paths between the samplers can be reduced using ordinary rules for linear time-invariant systems. The equations
describing the system are then written down. Theorems 7.2 and 7.3 are then
used to rewrite the equations. The procedure is illustrated by two examples.
Example 7.10 Translation of a simple computer-controlled system
Consider the standard configuration of a computer-controlled system shown in
Fig. 7.30(a). The process is characterized by a linear transfer function G1 and
the calculations perfonned in the computer are represented by a pulse-transfer
function H . The analog and digitalparts of the systemare, as usual, connected via
D-A and A-D converters. To apply the formalism, the A-D converter is represented
by an ideal sampler. The computer is represented as a system that transforms an
impulse-modulated signal to another impulse-modulated signal. TheD·Aconverter
is represented by a sampler, followed by a zero-order hold. It is assumed that the
samplers are perfectly synchronized. The block diagram shown in Fig. 7.30(h) is
then obtained. The analog parts are thus the holdand the process. 'Their combined
transfer function is

The Laplace transform Y of the output y is given by
Y{s)

~

F(s)U'(s)

Process-Oriented Models

284
(a)

rl......--H

Computer

A-D

H(z)

H= ~A P-f

Chap. 7

Process
G(s)

Jt

(b)

Clock

~

v
,.-."

~

y

Algorithm
H(z)

~

-

u V u
~

Hold

y

1(1- e ~$h)

G(s)

s

\...

)

Y
F(s)

(c)

....-

{II (kh)}

{Y(kh>}

-

H{z)

F(z)

Figure 7.30 Standard configuration of a computer-controlled system.
The sampled output has the transform
Y"(s)

=(F(s)U'{s))'

=:

FO(s)U'(s)

where (7.37) is used to obtain the last equality. The relationship between
u· can thus be represented by the pulse-transfer function

F(z) ;;: r(s)

i

and

Is;(lnz)/h

The calculations in the computer can furthermore be represented by the pulsetransfer function H(z). If the loop iacut inthe computer the pulse-transfer function
is thus

H(z)F(z)
A block diagram ofthe properties ofthe systemthat can be seenfrom the computer
is shown in Fig. 7.30{c). By considering an signals as sequences like {y(kh),k :::;
... - I,O,I, .. . } and by introducing appropriate pulse-transfer functions for the algorithm and the process with the sample-and-hold, a representation that is equivalent to the ordinary block-diagram representation ofcontinuous-time systems was
thus obtained.
•

A further illustration is given by a slightly more complicated exampJe

Sec. 7.8

285

Pulse-Transler-Puncfion Formalism

Example 7.11 Translation of a computer-controlled system with two loops
The system illustrated in Fig. 7.31(a) has two measured analog signals, YI and Y2,
and one analog command signal, Ur . The analog signals are scanned by a multiplexer and converted to digital form , The computer calculates the control signal,
which is fed to the process via the D-A converter. Figure 7.31(h) is obtained by the
procedure given in Example 7.10. We now introduce
1

_

F1(s) ~ 0 1(8) - (1 - e sh)
S

F:!(s) ;;; G2(s)F1(s }

The Laplace transforms of the output signals are then given by

Yds) ::: F1(s)U'(s)
Y2(s)

= F2(s)U·(s )

Hence
Y;(5)
Y;(8)

= (FI(s)U~(s)r = F;(s)U'(s)
= (F2(s)U·(s))" = F;(s)U·(s)

It follows from (7.33) and (7.37) that

Ydz) =F1(z)U(z)
Y2 (z) == F2{z)U(z)
Let the calculations performed by the control computer be represented by

The relationship between the output, Y2 , and the sampledcommand signal, U , is
c

Notice, however, that the relationship hetween the analog signals Yl and Uc cannot
be represented by a simple pulse-transfer function because of the periodic nature
of the sampled-data system.
With the introduction ofthe sampled signals as sequences and pulse-transfer
functions, the system can be represented as in Fig. 7.31(c).
•

Modified zooTransforms

The problem ofsampling a system with a delay canbehandled by the modified ztransform defined in Definition 2.2. Themodified z-transform is useful for many
purposes-for example, the intersample behavior can easily be investigated using these transforms. There are extensive tables of modified a-transforms and
many theorems about their properties (nee the References).

Chap. 7

Process-oriented Models

286
(a)

Multiplexer
llr

-

pfa ees...
~

AIgon m
ith

•
U

A-D r-- H

f----

D-A r-- G1

Y1

G2

Y2
-~

"

(b)

Clock

uc "

He

u

Hz
YI ~

Hold

~

l(t-e -Sh)

G1

R

\..

Process
Y1

G2

J

Y

F1

HI

F2

(c)

{uc(kh)}
He
{)'2(kh)}

~

H'].

rQL

{u(kh)}

FI

&1 (kh)}

_;F2 FI

{Y2 (kh)}

HI

Figure 7.31 Computer-controlled system with multiplexer and two feedback loops and equivalent block diagram.

7.9 Multirate Sampling
So far only systems in which the A-D and the D-A conversions are made at
the same rates have been discussed. In the discussion of postsarnpling filters in
Sec. 7.4 it was indicated that it may be advantageous to make the D~A conversion more rapidly. There are also situations where the converse is true. It is,
for example, difficult to implement antialiasing filters with long time constants

Sec. 7.9

287

Multlrate Sampling

using analog techniques. In such cases it is much easier to sample the signals
rapidly with analog antialiasing filters and to do digital filtering afterward.
In both cases the systems have two samplers that operate at different rates.
This is called multirate sampling . Such sampling schemes may be necessary for
systems with special data-transmission links or special sensors and actuators
and are useful for improving the responses of systems in which measurements
are obtained at slow rates, for example, when laboratory instruments are used.
Multirate systems may allow better control of what happens between the sampling instante. In multivariable systems it may also be advantageous to have
different sampling rates in different loops to reduce the computational load and
to improve the numeric conditioning. Use of multirate sampling is also natural
in multiprocessor systems.
A detailedtreatment ofmultirate systems is outside the scope of this book;
however, a short discussion of the major ideas will be given to show how the
methods presented in the book can be extended to also cover multirate systems.
State-Space Descriptions

Consider a system composed of two subsystems that are continuous constantcoefficient dynamic systems. Assume that there are two periodic samplers with
periods hI, and h2• Let the ratio of the periods be a rational number h l /h2 =
mdm2, where ml and m2 have no common factor. Then there exists a smallest
integer m and a real number h such that
hz

= hm2
m

IT the samplers are synchronized, it follows that the control signals will be
constant over samplingperiods of length him. Sampling with that period gives
a discrete-time system that is periodic with period h. The system can then he
described as a constantdiscrete-time system if tbe values ofthe system variahles
are considered only at integer multiples of h. The ordinary discrete-time theory
can then he applied. An example illustrates the idea.
Example 7.12 Multirate systems
Consider the system shown in Fig.7.32, which has two subsystems and two samplers with periods 0.5 and 1. It is assumed that the samplers are synchronized.
It is also assumed that the hold circuits are included in 'the subsystems. If the

Period h

Period 2 h

L~ SIY~~~
Figure 7.32 Block diagram ofa simple multirate system.

Process-Oriented Models

288

Chap. 7

subsystems are sampled with period 0.5 and 0.5 is chosen as a time unit, then
o 1(k
t
{

+ 1) = If)jxl{k) + rJUI(~)

Y1 (k)

= C1Xl (k)

x2(k + I} :::: ¢1X2(k) + r2U2(k)
{
Y2(k) = C2X 2(k )
The interconnection are described by
ur(k)

=Y2(k)

uAk) = Yl(k)

k ::::

k

- 1,0, 1,2, .

= - 1, O. 1, 2

..

The system is periodic with a period of two sampling intervals. A time-invariant
description can be obtained by considering the system variables at even sampling
periods only Straightforward calculations give
.

This equation can be used to analyze the response of the multirate system. For
example. the stability condition is that the matrix on the right-hand side of (7.38)
has all its eigenvalues inside the unit disc. The values of the state variables at odd
sampling periods are given by

•
The analysis illustrated by the example can be extended to an arbitrary number of samplers provided that the ratios of the sampling periods are rational
numbers. Delayed sampling can also be handled by the methods described in
Sec. 2.3.

Input-Output Methods
Multirate systems can also be investigated by input-output analysis . First, observe as before that tbe system is periodic with period h if the ratios of the
sampling periods are rational numbers. The values of the system variables at
times that are synchronized to the period can then be described as a timeinvariant dynamic system. Ordinary operator or transfer-function methods for
linear systems can then be used. The procedure for analyzing a system can be
described as follows: A block diagram of the system including all subsystems
and all samplers is first drawn. The period h is determined. All samplers appearing in the system then have periods him, where m is an integer. A trick
called switch decomposition is then used to convert samplers with rate him to a
combination of samplers with period h. The system can then be analyzed using
the methods described in Sec. 7.8.

Sec. 7.10

289

Problems

(a)

h

(b)

h

e shim

e 2s1t 1m
e shl2

e

h

e

-shl m

h

.h/2

e-slm-llh/m
Figure 7.33 Representation ofsamplers with periods (a) h/2 and (b) him
by switch decomposition.

Switch Decomposition

To understand the concept of switch decomposition, first consider a sampler
with period h/2. Such a sampling can be obtained by combining a sampler with
period h and another sampler with period h that is delayed h/2. The scheme is
ill ustrated in Fig. 7.33(a). The idea can easily be extended to sampling at rate
him, where m is an arbitrary integer [see Fig. 7.33{b)).

Multlrate Systems with Nonrational Periods
The methods described so far will work only when the ratios of the sampling
periods are rational numbers. If this is not the case, it is not possible to obtain
a periodic system; different techniques must then be used. The multirate techniques also lead to complicated analysis if there are many samplers with a wide
range of periods.

7.10 Problems
7.1 The signal

is the input to a zero-order sample-and-hold circuit. Which frequencies are there

at the output if the sampling period is h

=:

O.2?

7.2 A signal that is going to be sampled has the spectrum shown in Fig. 7.34. Of interest
are the frequencies in the range from 0 to II Hz. A disturbance has a fixed known
frequency with (2 == 5fl. Discuss choice of sampling interval and presampling filter.

Process-Oriented Models

290

Chap. 7

Figure 7.34
7.3 Show that the system in Fig. 7.35 is an implementation of a first-order hold and
determine its response to a pulseofunit magnitude and a duration of'one sampling
interval.

ZOH ........~

1
sh

Figure 7.35

7.4 Sample a sinusoidal signal u(t) ~ sin(t) using zero-order hold. first-order hold, and
predictive first-order hold. Compare the different hold circuits when the sampling
period is changed.
7.5 The magnitude of the spectrum ofa signal is shown in Fig. 7.36. Sketch the magnitude of the spectrum when the signal has been sampled with (a) h = 2Jr/lO s,
(b) h = 2Jr/20 S, and (c) h '" 2Jr/50 s,

tP(w)

Figure 7.36
7.8 Consider the signal in Problem 7.5, but let the spectrum be centered around (()

100 rad/a and with (a) (J)~

= 120 rad/s and (b) (J)$

""

=

240 rad/s.

7.7 A camera is used to get a picture of a rotating wheel with a mark on it. The wheel
rotates at r revolutions per second. The camera takes one frame each h seconds.
Discuss how the picture will appear when shown on a screen. (Compare withwhat
you see in western movies.)

291

Notes and References

Sec. 7.11

7.8 The signal y(t) =sin3Jrt is sampled with the sampling period h. Determine h such
that the sampled signal is periodic.
7.9 An amplitude modulated signal
u(t) '" sin (%lot) cos (2wot)

is sampled with h ; lr/3roo. Determine the frequencies
are represented in the sampled signal.

f, 0

~

f

$

3wo/2ft that

7.10 Find Y' for the systems in Fig. 7.37.

(b)

(c)

y'

V

Figure 7.37
7.11 Write a program to compute the frequency response of a sampled-data system. Let
the following be the input to the program:
(a) The polynomials in the pulse-transfer function H(z).
(b) The sampling interval.

(c) The maximum and minimum frequencies.
Use the program to plot H(exp{iwh)) for the normalized motor sampled with a
zero-order hold and compare with the continuous-time system.

7.11 Notes and References
Thefact that a sinusoid can be retrieved from its sampled values if it is sampled
at least twice per period was stated in Nyquist (1928). The sampling theorem
in the form presented in this chapterwas introduced in Shannon (1949), where
the implications for communication were emphasized. Theresults had, however,
been known earlier as a theorem in mathematics. In the Soviet communication
literature, the theorem was introduced by Kotelnikov (1933) . A review of the
sampling theorem with many references is given in Jerri (1977).

292

Process-Oriented Models

Chap. 7

There are many ways of sampling. A review of different schemes is given
in Jury (1961) . Different types of hold circuits are discussed in more detail in
Ragazzini and Franklin (1958). Selection ofthe sampling period for signal processing is discussed in Gardenhire (1964) .The different trade-off's in the areas
ofcontrol and signal processing may lead to very different rules for choosing the
sampling rate. Predictive first-order hold is discussed in Barnhardsson (1990)
and an application to motion control is described in AstroID and Kanniah (1994).
The approach taken in this chapter corresponds to the classictreatment of
sampled-data systems. The modulation model was proposed by MacColl (1945)
and elaborated on by Linvill (1951). A more detailed treatment is given in the
classic texts by Ragazzini and Franklin (1958) and Juri' (1958). The idealsampler approximation is discussed in Li, Meiry, and Curry (1972) .
Frequency response is important from the point of view of both analysis and design. A fuller treatment of this problem is given in Lindorff (1965).
Practical applications of frequency-response analysis are discussed in Flower,
Windett, and Forge (1971). New aspects offrequency analysis of sampled-data
systems are found in Araki and Ito (1993 ), Yamamoto (1994), Yamamoto and
Araki (1994), and Yamamoto and Khargonekar (1996).
More material on the z-transform is given in Jury (1982). The modified
z-transform is discussed inJury (1958). Tables ofmodified z-transforms are also
given in that book.
Systems with multirate sampling were first analyzed in Krane (1957).
Additional results are given in Jury (1967a, 1967b),Konar and Mahesh (1978),
Whitbeck (1980), and Crochieve and Rabiner (1983).

8
Approximating ContinuousTime Controllers
8.1 Introduction
There are situations when a continuous-time controller is already available.
A typical case is when an analog-control system is replaced by a computercontrol system. It is then natural to try to convert the continuous-time controller to a discrete-time controller directly. A straightforward approach is to
use a short sampling interval and to make some discrete-time approximations
of the continuous-time controller. This approach is illustrated in Example 1.2.
See, for example, Fig. 1.6, which compares a continuous-time controller with
an approximating discrete-time controller. In Sec. 8.2 we will present several
methods for approximating a continuous-time controller given in terms of their
transfer functions. Similar methods for controllers given in state-space form
are presented in Sec. B.3. In Sec. 8.5 the results are used to obtain digital PID
controllers. Some practical aspects of implementinga digital PID controller will
also be discussed in that section.

8.2 Approximations Based on Transfer Functions
This section assumes that a continuous-time controller is given as a transfer
function, G (s). It is desired to find an algorithm for a computer sothat the digital
system approximates the transfer function G(s) (see Fig. 8.1). This problem is
interesting for implementation ofbotb analog controllers and digital filters. The
approximation may be done in many different ways. Digital implementation
includes a data reconstruction, which also can be made in different ways-for
example, zero- or first-order hold.
293

294

Chap.S

Approximating Continuous-Time Controllers
Htz)

<;

G(8)

r-------------------~

u(t)

I
I

I
I

{y(kh)}

{u(kh )}

D-A

Algorithm

A·D

t

j

I

Clock

I
L

I

y(t)

I
I
I
I
I
I

Figure B.l Approximating a continuous-time transfer function, G(s), using
a computer.

Differentiation and Tustin Approximations
A transfer function represents a differential equation. It is natural to obtain a
difference equation by approximating the derivatives with a forward difference
(Euler's method)
px(t) :;; dx(t) ~ x(t + h) - x(t)
dt
h

=q -

1 x(t)

h

or a backward difference
_ dx(t) ,.,. x(t) - x(t - h) _ q - 1 (t)
'"
- -- x
dt
h
qh

px (t ) - -

In the transform variables, this corresponds to replacing s by (z - l)/h
or (z - l}/zh. Section 2.8 shows that the variables z and s are related in some
respects as z = exp(sh). The difference approximations correspond to the series
expansions
z

=:

efih ::::::: 1 + sh

1
z = esh:::::_~
1- sh

(Euler's method)

(8.1)

(Backward difference)

(8.2)

Another approximation, which corresponds to the trapezoidal method for
numerical integration, is
sh
1 + sh/2
z = e ~ 1- sh/2

(Trapezoidal method)

(8.3)

In digital-control context, the approximation in (8.3) is often caUed Tustin's
approximation, or the bilinear transformation, Using the approximation methods above, the pulse-transfer function H (z) is obtained by simply replacing the

Sec. 8.2

Approximations Based on Transfer Functions

Forward differences

Backward differences

Tustin

Figure 8.2 Mapping of the stability region in the s-plane on the a-plane
for the transformations (8.4), (8.5" and (8.6).

arguments in G(s) by s', where

s' ==

z-1

--

h

z-l

s' ::; - -

zh

s'

2 z -l
=h 'z +l

(Forward difference or Euler's method)

(8.4)

(Backward difference)

(8.5)

[Tustin's approximation)

(8.6)

Hence

H(z) "" G(s')
The methods are very easy to apply even for hand calculations. Figure 8.2 shows
how the stahility region Re s < 0 in the s-plane is mapped on the z-plane for
the mappings (8.4), (8.5), and (8.6).
With the forward-difference approximation it is thus possible that a stable continuous-time system is mapped into an unstable discrete-time system.
When the hackward approximation is used, a stable continuous-time system
will always give a stable discrete-time system. There are, however, also unstable continuous-time systems that are transformed into stable discrete-time
systems. Tustin's approximation has the advantage that the left. half-a-plane
is transformed into the unit disc. Stahle continuous-time systems are therefore transformed into stable sampled systems, and unstable continuous-time
systems are transformed into unstable discrete-time systems.

Frequency Prewarplng
One problem with the approximations discussed earlier is that the frequency
scale is distorted. For instance, if it is desired to design band-pass or notch
filters, the digital filters obtained by the approximations may not give the correct
frequencies for the band-pass or the notches. This effect is called frequency
warping. Consider an approximation obtained by Tustin's approximation. The

Approximating Continuous-Time Controllers

296

o

o
•

WJ

Chap. 8

t

Approximation

-ua'

Figure 8.3 Frequency distortion (warping) obtained with approximation .

transmission of sinusoids for the digital filter is given by

The first two factors are due to the sample-and-hold operations; compare with
(7.28). The argument of Gis
2 e1wh - 1 2 eiwh/ 2 - e -/ltJh /2
h eiwh + 1 ~ h ejwh/ 2 + e- uJJh/ 2

2i

==

h

(Wh)
tan

2

The frequency scaleis thus distorted. Assume, for example, that the continuoustime system blocks signals at the frequency w'. Because of the frequency distortion, the sampled system will instead block signal transmission at the frequency
OJ, where
at

J

=

2
Ii tan (Wh)
2

That is,
ill

=

2
h tan - I

(O/h) ~
-2-

I (

{O

(OJ'h)2)

1 - -'--1-2'-

(8.7)

This expression gives the distortion of the frequency scale (see Fig. 8.3). It
follows from (8.7) that there is no frequency distortion at W = 0 and that the
distortion is small if mh is small . It is easy to introduce a transformation that
eliminates the scale distortion at a specific frequency WI by modifying Tustin's
transformation from (8.6) to the transformation

s' =

Clh

z-l
. _-

tan(w}h/2) z + 1

(Tustin with prewarping)

(8.8)

Sec. 8.2

297

Approximations Based on Transfer Functions

From (8.8L it follows that

that is, the continuous-time filter and its approximation have the same value
at the frequency mI. There is, however, still a distortion at other frequencies.
Example 8.1 Frequency prewarping

Assume that the integrator
1

G(s) :::: -

S

should be implemented as a digital filter. Using the transformation of(8.6) without
prewarping gives

Hr(z)

=2

1
h z -+- 1
z-l =2" '-z--1

- '2 ~- 1
h

Prewarping gives

The frequency function of H p is

Hp(e iW )
II

= tan ((Jhh/2)
WI

. e'{dh

+ 1 = tan (w1hj 2)

el(o!t -

thus G(iw) and H p (e Hllll ) are equal for ill

1

=WI.

WI

1
i tan (wh/2)

•

Step 'nvariance
Another way to generate approximations is to use the ideas developed in Chapter 2. In this way it is possible to obtain approximations that give correct values
at the sampling instants for special classes of input signals. For example, if the
input signal is constant over the sampling intervals, Table 2.1 Of Eq. (2.30) give
an appropriate pulse-transfer function H(z) for a given transfer function G(s).
Because this relation gives the correct values of the output when the input signal is a piecewise constant signal that changes at the sampling instants, it is

called step inuariance .

Ramp Invariance
The notion of step invariance is ideally suited to describe a system where the
input signal is generated by a computer, because the input signal is then constant over the sampling period. The approximation is, however, not so good
when dealing with input signals that are continuous. In this case it is much

Approximating Continuous-TIme Controllers

298

Chap. 8

better to use an approximation where the input signal is assumed to vary linearly between the sampling instants. The approximation obtained is called ramp
invariance because it gives the values of the output at the sampling instants
exactly for ramp signals. It is identical to predictive first-order-hold sampling
that was discussed in Sec. 7.5. Notice that because of the predictive nature of
ramp invariance there must be one delay in the controller; see Sec. 7.5.

Comparison of Approximations
The step-invariant method is not suitable for approximation of continuous-time
transfer functions. The reason is that the approximation of the phase curve
is unnecessarily poor. Both Tustin's method and the ramp-invariant method
give better approximations. Tustin's method. is a little simpler than the rampinvariant method. The ramp-invariant method. does give correct sampled poles.
This is not the case for Tustin's method. This difference is particularly important when implementing notch filters where Tustin's method gives a frequency
distortion. Anotherdrawback with Tustin's method. is that very fast poles ofthe
continuous-time system appear in sampled poles close to z = -1, which will give
rise to ringing in the digital filter, The different approximations are illustrated
by an example.
Example 8.2 Sampled approximations of transfer function
Consider a continuous-time system with the transfer function
{s + 1)2(s:! + 2s + 400}

G S'I =:
(,

(s

+ 5)2(8 2+ 2s + lOO}(s2 +3s +2500)

Let H(z) be the pulse-transferfunction representing the algorithm in Fig. 8.1. The
transmission properties of the digital filter in Fig. 8.1 depend on the nature ofthe
D-A converter. If it is assumed that the convener keeps the output constant betweenthe sampling periods, the transmission properties ofthe filter are described
by

where the pulse-transfer function H depends on the approximation used. Figure 8.4
shows Bode diagrams of H for the different digital filters obtained by step equivalence, ramp equivalence, and Tustin's method. The sampling period is 0.03 s in an
cases. This implies that the Nyquist frequency is 105 fad/so All methods except
Tustin's give a good approximation of the amplitude curve. The frequency distortion by 'Iuatin's method is noticeable at the notch at 20 radl s and very clear at the
resonance at 50 radls.
The step-equivalence method gives a noticeable phase error.This corresponds
approximately to a time delay of half a sampling interval. Ramp equivalence gives
a negligible phase error. The phase curve for Tustin's approximation also deviates
because of the frequency warping. Notice that all approximations suffer from the
time delay due to the sample and hold. Ramp equivalence gives the best approximation of both amplitude and phase.
_

Sec. 8.2

299

Approximations Based on Transfer Functions

10- 2
w

"C

10-3

::l

....
....

&
til

:E

10-4

10-5

100

10

1

2

10

o

-200
1

10
Frequency, radls
Figure 8.4 Bode diagrams of a continuous-time transfer function G(s)
and different sampled approximations H(c JIl ) , continuous-time transfer function [soiid}, ramp invariance (dashed-dotted), step invariance (dashed), and
Tustin's approximation (dotted).

Antialiaslng Filters

The consequences of aliasing and the importance of antialiasing filters were
discussed in Sec. 7.4. Choice ofsampling rate and antialiasing filters is important in digital systems that are based on translation of analog design. Some
consequences of the selection ofsampling rates have been discussed previously.
The sampling rate must be so large that the errors due to the approximation
are negligible.
Thenecessity oftaking the antialiasingfilterinto account in the control designcan be determined from the results ofSec. 7.4. In general, the antialiasing
filter must be taken into consideration when making the design ofthe controller.
$election of Sampling Interval

The choice of sampling period depends on manyfactors. One way to determine
the sampling period is to use continuous-time arguments. The sampled system
canbe approximated bythe holdcircuit, followed bythe continuous-time system.
For small sampling periods, the transfer function of the hold circuit can be

Approximating Continuous-TIme Controllers

300

Chap. 8

approximated as
l_e- sh
sh

---~

1-1+sh-(sh}2j2t · ··
sh
:::.1--+,, ·
sh
2

The first two terms correspond to the series expansion of exp(-sh/2). That is,
for small h, the hold can be approximated by a time delay of half a sampling
interval. Assume that the phase margin can be decreased by 50 to 15°. This
gives the following rule of thumb:

luo;

~

0.15 to 0.5

where we is the crossover frequency (in radians per second) of the continuoustime system. This rule gives quite short sampling periods. The Nyquist frequency will be about 5 to 20 times larger than the crossover frequency.
Example 8.3 Digital redesign of lead compensator
Consider the system in Example A.2, which is a normalized model of a motor. The
closed-loop transfer function

is obtained with the lead compensator

(8.9)
The closed-loop system has a damping of ~ ;;; 0.5 and a natural frequency of Wo ;:;
2 rad/s. The objective is now to find H(z) in Fig. 8.5, which approximates (8.9).

Euler's method gives the approximation
HE{z)

=4 z ~ 1 + h

:; ; 4 z - (1- h)
z-1+2h
z-(1-2h)

(8.10)

while Tustin's approximation gives

Hr(z ) == 4 (2 + h)z - 2 + h :;: 4 ~ . Z - (2 - h)j(2 + h)
(2 + 2h)z - 2 + 2h
2 + 2h z - (1- h)/(l + h)

etkh}

A·D

,..---..,
D-A

H(zJ

utt)

.----..

-1
Figure 8.5 Digital control of the motor example.

y (t)

Approl(imations Based on State Models

Sec. 8.3

301

.. . ,.

l'
c,
:l

1

o

10

....
::l

0.

....

4

2

~

0

-2

10

0

Time
Figure 8.6 Process output, y(t}, when the motor is controlled using the
compensator of (8.l0) when h = 0.1 (dashed-dotted). 0.25 (solid), and 0.5
(dotted) . The control signal is shown for h = 0.25. For comparison, the continuous-time signals are also shown (dashed).

Finally, zero-order-hold sampling of (8.9) gives

H (} '" 4z - 2(1 + e- Zh )
zch Z

= 4 z - 0.5(1 + e- 2h)

Z _ e-2h

z _ e-2h

All approximations have the form

The crossover frequency of the continuous-time process in cascade with the
compensator (8.9) is Q}~ ;;; 1.6 rad/s, The earlier rule of thumh gives a sampling
period of about 0.1 to 0.3 S.
Figure 8.6 shows the control signal and the process output when Euler's
approximation has been used for different sampling times. The other approximations give similar results. The closed-loop system has a satisfactory behavior for
all compensators when the sampling time is short. The rule of thumb also gives
reasonable values for the sampling period. The overshoot when h = 0.5 is about
twice as large as for the continuous-time compensator. In the example, the change
in Ue occurs at a sampling instant. This is not true in practice, and there may be
a delay in the response of at most one sampling period.
_

8.3 Approximations Based on State Models
In this section we will make discrete-time approximations of controllers described by continuous-time state-space models. State-feedback controllers can

Approximating Continuous-Time Controllers

302

Chap.S

be regarded as generalized P-controllers. The formulation of the problem assumes that the process is described by the equations
dx
dt
y=

-=Ax+Bu

(8.11)

ex

where all the states are assumed to be measurable. By using a controller ofthe
form

u(t} = Mu,(t) - Lx(t)

(8.12)

it is possible to place the poles ofthe closed-loop system arbitrarilyif the system
is controllable. The controller in (8.12) can be implemented in digital form by
sampling the states and holding the control signal constant over the sampling
intervals.This is how the control is done in Example 1.2. If the sampling period
is increased, then the behavior ofthe closed-loop system starts to deteriorate. It
is, however, possible to modify the controller in order to improve the performance
of the closed-loop system. Assume that the discrete-time controller is

u(kh) = Muc(kh) - Lx(kh)

(8.13)

One way to solve the problem is to design the controller in (8.12) usingsampleddata theory. This is done in Chapter 4. Here, an approximate method is used to
translate the controller in (8.12) into discrete-time form.
Controlling (8.11) with the continuous-time controller in (8.12) gives the
closed-loop system
dx

dt

=

(A - BL}x + BMu,- = Acx + BMu,

y = ex

If u,(t) is constant over one sampling period, then this equation can be integrated; this gives
x(kh +h) := c1J cx(kh) + fcMuc(kh)

(8.14)

where
c1Jc~eAch

r,=

f ..

"ds B

If the discrete-time controller in (8.13) is used to control (8.11), then
x(kh +h) :=; (<11- rL):r(kh) + rMuc(kh)

(8.15)

303

Approximations Based on State Models

Sec. 8.3

where <I> and r are the system matrices obtained when (8.11) is sampled. It is
in general not possible to choose t: such that

$c=tP-rL
However, we can make a series expansion and equate terms of different
powers of h. Assume that

then

and
<I> -

r L ~ I + (A - BLo)h + ( A2 - AB Lo - BL1) h2 /2 + "

The systems (8.14) and (8.15) have the same poles up to and including
order h 2 when

L = L(1 + (A - B L)h/2)

(8.16)

Without modification of L the poles are the same up to and including order h.
The modification of M is determined by assuming that the steady-state
values are the same for (8.14) and (8.15). Let the reference value be constant
and assumethat the steady-atate valueofthe state is ,P. This gives the relations
(1- et>c)xo

= rcMuc

and

(1 - (<I> - rL) )xo~ fMu c
Theseries expansions ofthe left-hand sidesofthese two relations are equal
for powers of h up to and including h2 . Now determine Sf such that the series
Assume that
expansions of the right-hand sides are the same for hand

v.

M=Mo+Mth/2
then

reM ~ BMh + (A - BL)BMh 2 {2 + ...
and
2

~

rM

R;

BMoh + (BM1 +ABMo)h /2 +...

This gives

M== (I -

LB hj2)M

(8.17)

The modifications (8.16) and (8.17) are easily computed using the continuous-time system and the continuous-time controller.

Approximating Continuous-Time Controllers

304

=
0

1

Chap. 8

~ '-- '

:-2
(Il

0
~

0

10

0

0.5

~
'8

0
.....

>-0.5
0

10

1

....
~

c.

l::

--

0
-1

0

10

Time
Figure 8.7 Digital control of the double integrator (solid) using the control
law in (8.19) when h = 0.5. The continuous-time response when using (8.18)
is shown by the dashed curves.

Example 8.4 Modification of a state-feedback controller
The system in Example A.I is the double integrator; that is, the system is defined

by the matrices
and
Let the continuous-lime controller be

u(t) = u, (t) -

(1 1) x(t)

(8.18)

Figure 8.7 shows the behavior when the sampled controller

u{kh} = uc(kh) is used when h

(1 1) x(kh)

/8.19}

= 0.5. Using the modifications in (8.16) and (8.17), we get
L~

(1 - O.5h 1)

it = 1- O.5h

(8.20)

Frequency-Response Design Methods

Sec. 8.4

305

1 . . . . " .. .. . , . , .~, .~~~,~:-:-:,", :.~.. -_.........-_-~
.. . . . , .. . . :", , . , ~

d

o
....
....

+..l
Cil

o

~

0

10

0
0,5
~

'g
,.....

0

~

-0.5
10

0
1
.....

:::l
0C

-

0

-1

10

0

Time

Figure 8.8 Control of the double integrator using the modified controller
in (8.20) when h :;; 0.5 (solid). The continuous-time response when using
(8.18) is also shown (dashed).

Figure 8.8 shows the behavior when the modified controller is used for h = 0.5;
there is an improvement compared with the unmodified controller. However, the
sampling period cannot he increased much further before the closed-loop behavior
starts to deteriorate. even whenthe modified controller is used. Theexample shows
that 8 simple modification can have a large influence on the performance.
_

8.4 Frequency·Response Design Methods
This chapterhas sofar shown how continuous-time controllers can betranslated
into discrete-time forms. This section discusses how continuous-time frequencydesign methods can be used to design discrete-time controllers.
Frequency-design methods based on Bode and Nichols plots are useful
for designing compensators for systems described by transfer functions. The
usefulness of the methods depends on the simplicity of drawing the Bode plots
and on rules of thumb for choosing the compensators. The Bode plots are easy
to draw because the transfer functions are in general rational functions in io,
except for pure timedelays. Frequency curves for discrete-time systems are more

Approximating connnuous- Time Controllers

306

Chap. a

difficult to draw because the pulse-transfer functions are not rational functions
in uo, but in exp(iwh). The ui-tronsform method is one way to circumvent this
difficulty. The method can be summarized into the following steps:

1. Sample the continuous-time system that should be controlled using a zeroorder-hold circuit. This gives H (2) .
2. Introduce the variable
2 z-l
h z+1

w: - - -

[compare (8.6)]. Transform the pulse-transfer function of the process into
the a-plane giving

H'(w) = H(z)
Z

For z

=

l+wh /~

l-wh /2

= exp(imh) then
w

=i ~

tan(mhj2} = iu

(compare frequency prewarping in Sec. 8.2). The transformed transfer function H'(iu) is a rational function in io.
3. Draw the Bode plot of H'(iv) and use conventional methods to design a
compensator H~(iv) that gives desired frequency domain properties. The
distortion of the frequency scale between v and (f) must be taken into
account when deciding, for instance, crossover frequency and bandwidth.
4. Transform the compensator back into the z-plane and implement Hc(z) as
a discrete-time system.
The advantage with the w-transform method is that conventional Bode
diagram techniques can he used to make the design. One difficulty is to handle
the distortion of the frequency scale and to choose the sampling interval.

8.5 Digital PID-Controllers
Many practical control problems are solved by PID-controllers. The "textbook"
version of the PID-eontroller can be described by the equation

u(t)

= K (e(t) +

iJ'

e(s) ds +

r. ddt))

(8.21)

where error e is the difference between command signals U c (the set point) and
process output y (the measured variable). K is the gain or proportional gain

Sec. 8.5

Digital PID·Gontrollers

307

of the controller, T, the integration time or reset time. and Td the derivative
time. The PID-controller was originally implemented using analog technology
that went through several development stages, that is, pneumatic valves, relays and motors, transistors, and integrated circuits. In this development much
know-how was accumulated that was embedded into the analog design. Today
virtually all PID-controllers are implemented digitally. Early implementations
wereoften a pure translation of (8.21), which left out many ofthe extra features
that were incorporated in the analog design. In this section we will discuss the
digital Pllr-controller in some detail. This is a good demonstration that a good
controller is not just an implementation of a "textbook" algorithm. It is also a
good way to introduce some of the implementation issues that will be discussed
in depth in Chapter 9.

Modification of Linear Response
A pure derivative cannot, and shouldnot be, implemented, becauseit will give a
very large amplification of measurement noise. The gain of the derivative must
thus be limited. This can be done by approximating the transfer function sTd
as follows:

The transfer function on the right approximates the derivative well at low frequencies but the gain is limited to N at high frequencies. N is typically in the
range of 3 to 20.
.
In the work with analog controllers it was alsofound advantageous not to
let the derivative act on the command signal. Later it was also found suitable
to let only a fraction b ofthe command signal act on the proportional part. The
PID·algorithm then becomes

where U, V and Y denote the Laplace transforms of u, u., and y. The idea
CI

of providing different signal paths for the process output and the command
signal is a good way to separate command signal response from the response
to disturbances. Alternatively it may be viewed as a way to position the closedloop zeros. There are also several other variations of the Pill-algorithm that
are used in commercial systems. An extra first-order lag may be used in series
with the controller to obtain a high-frequency roll-off. In some applications it
has also been useful to include nonlinearities. The proportional term Ke can be
replaced by Kell.'j and a dead zone can also be included.

Discretization
The controller described by (8.22) can be discretized using any of the standard
methods such as Tustin's approximation or ramp equivalence. Because the PID-

308

Approximating Continuous-Time Controllers

Chap. 8

controller is so simple, there are some special methods that are used. The following is a popular approximation that is very easy to derive. The proportional
part
P(t)

= K (bue(t) - y(t))

requires no approximation because it is a purely static part. The integral term

I(t) ;:: K
T

jt e(s) ds

i

is approximated by a forward approximation, that is,
Kh
I{kh + h) ;:: I(kh) + T e(kh)

(8.23)

!

The derivative part givenby
Td

dD + D ;:: -KT dy

N dt

d

dt

is approximated by taking backward differences. This gives

This approximation has the advantage that it is always stable and that the
sampled pole goes to zero when Td goes to zero. Tustin's approximation gives
an approximation such that the pole instead goes to == -1 as Td goes to zero.
The control signal is given as
u(kh) = P(kh) + j(kh) + D(kh)

(8.24)

This approximation has the pedagogical advantage that the proportional, integral, and derivative terms are obtained separately. The other approximations
give similar results. They can all be represeuted as
R(q)u(kh) ::: T(q)uc{kh) - S(q)y(kh)

(8.25)

where the polynomials R, S and T are of second order. The polynomial R has
the form
I

R(q) =- (q - l)(q - ad)

(8.26)

The number ad and the coefficients of the polynomials Sand T obtained for
different approximation methods are given in Table 8.1.

Sec. 8.5

309

Digital PID·Controllers

Table 8.1 Coefficients in different approximations of the continuous-time

PID-controller.

Special

Ramp Equivalence

Tustin

K(l+b,+b d )

So

K(l + bd)

81

-K(l + ad + 2bd - bi)

S2

to

K(ad + bd - biad)
Kb

K lad + b« - biad)
K(b + b1)

tl

-K (b(l + ad) - bi)

-K (b(l + ad) - b,(l- ad))

t2

Kad(b - bi)
Td
Nh+Td

ad
bd
bi

-K ( 1 + ad + 2ba - bi(l- ad))

Kad(b - bi)
2Td-Nh
2Td + Nh
2NTd
2Td + Nh
h
2Tj

Nad
h

t.

exp (-

~;)

Td
- (1- ad)
h
h
2Tr

Incremental Algorithms

Equation (8.24) is called a position algorithm or an absolute algorithm. The
reason is that the output of the controller is the absolut value of the control
signal, for instance, a valve posibon. In some cases it is advantageous to move
the integral action outside the control algorithm. Thisis natural when a stepper
motor is used. The output ofthe controller should then represent the increments
ofthe control signal, and the motor implements the integrator. Another case is
when an actuator with pulse-width control is used.
To obtain an incremental algorithm the control algorithm is rewritten so
that its output is the increment of the control signal. Because it follows from
(8.26) that the polynomial R in (8.25) always has a factor (q - 1) this is easy
to do. Introducing
~u(kh)

= u(kh) - u(kh - h)

we get
(q - ad)Au(kh + h) = T(q)uc(kh )- S(q)y(kh)

This is called the incremental form of the controller. A drawback with the incremental algorithm is that it cannot be used for P- or PD-controllers. If this is
attempted the controller will be unable to keep the reference value, because an
unstable mode z - 1 is canceled.

Approximating Oontinuous-Time Controllers

310

Chap.B

Integrator Windup
A controller with integral action combined with an actuator that becomes saturated can give some undesirable effects. If the control en-or is so large that the
integrator saturates the actuator, the feedback path will be broken, because the
actuator will remain saturated even if the process output changes. The integrator, being an unstable system, may then integrate up to a very large value.
When the error is finally reduced, the integral may be so large that it takes
considerable time until the integral assumes a normal value again. This effect
is called integrator windup. The effect is illustrated in Fig. 8.9.
There are several ways to avoid integrator windup. One possibility is to
stop updating the integral when the actuator is saturated. Another method is
illustrated by the block diagram in Fig. 8.10(a).In this system an extra feedback
path is provided by measuring the actuator output and forming an error signal
(e s ) as the difference between the actuator output (u c ) and the controlleroutput
(v) and feeding this error back to the integrator through the gain 11Tt • The
error signal e, is zero when the actuator is not saturated. When the actuator is
saturated the extra feedback path tries to make the error signal e, equal zero.
This means that the integrator is reset, 80 that the controller output is at the
saturation limit. The integrator is thus reset to an appropriate value with the
time constant Til which is calledthe tracking-time constant.The advantage with
this schemefor antiwindup is that it can be applied to any actuator, that is, not
only a saturated actuator but also an actuator with arbitrary characteristics,
such as a dead zone or an hysteresis, as longas the actuator output is measured.
If the actuator output is not measured, the actuator can be modeled and an

2

....
::l

/

e,
...,
::l

0

1)/
0
0

0.1

".

'

...

....

-

'

/'
//

....

....

"-

/

"

/'

"

,...

-.
/

". /

40

20

_...-

60

..,

I

,

I

I

I

I

I
Ir - - - - ___ J

I

1

I
I

I

0

I

-0.1

0

80

,..-

I
I

I

::l
0-

,,

-~--I

~

~

'

20

I

I

I

.J

t.- _ _ .l

40
Time

60

80

Figure 8.9 Illustration of integrator windup. The dashed lines show the

response with an ordinary PID-eontroller. The solid lines show the improvement with a controller having antiwindup.

Sec. 8.5

(a)

311

Digital P1D·Controliers

-y

KTdli

Actuator

e

~

K

K
-

L.-.,

T·
I

~

1

-

s

v

u

-

~

~

+
e~

-

1

Tt

(b)

-y
Actuator model
e

Actuator

K

K

1

T·
I

s

es

-1
Tt
Figure 8.10 Controller with antiwindup, A system in which the actuator
output is measured is shown in (a) and a system inwhich the actuatoroutput
is estimated from a mathematical model is shown in (b).

equivalent signal can be generated from the model, as shown in Fig. 8.l0(b).
Fignre 8.9 shows the improved behavior with controllers having an anti-windup
scheme. Antiwindup is further discussed in Sec. 9.4.
Operational Aspects

Practically all PID-eontrollers can run in two modes: manual and automatic.
In manual mode the controller output is manipulated directly by the operator, typically by push buttons that increase or decrease the controller output.
The controllers may also operate in combination with other controllers, as in
a cascade or ratio connection, or with nonlinear elements such as multipliers
and selectors. This gives rise to more operational modes. The controllers also
have parameters that can be adjusted in operation. When there are changes of

Chap. 8

Approximating Continuous-TIme Controllers

312
(a)

1

s
Inc PID

t--------'

1
(b)

l+sT[

A

IncPD

1
(c)

~::l

l +sT;

MCU
u

A

IncPD
Figure 8.11 Controllers with bumpless transfer from manual to automatic
mode. The controller in (a) is incremental. The controllers in (b) and (c) are
special forms of position algorithms. The controller in (c) has antiwindup
(MeU ;;;; Manual Control Unit) .

modes and parameters, it is essential to avoid switching transients. The way
mode switchings and parameter changes are made depends on the structure
chosen for the controller.

Bumpless transfer. Because the controller is a dynamic system it is
necessary to make sure that the state ofthe system is correct when switching the
controller between manual and automatic mode. When the system is in manual
mode, the controller produces a control signal that may be different from the
manually generated control signal. It is necessary to make sure that the value
of the integrator is correct at the time of switching. This is called bumpless
transfer. Bumpless transfer is easy to obtain for a controller in incremental
form. This is shown in Fig. 8.11(a). The integrator is provided with a switch so
that the signalsare either chosen from the manual or the automatic increments.
Because the switching only influences the increments, there will not be any large
transients .A related scheme for a position algorithm is shown in Fig. 8.11(b). In
this case the integral action is realized as positive feedback around a first-order

313

Digital PID-Controllers

Sec. 6.5

I---------i

r .-..----,
+

1

1
s

Tm

y

PD

u"

e

1

Tr

M

u

J

1
s

+
1
Tr
Figure 8.12 PID-controller with bumpless switching between manual and
automatic control.

system. The transfer function from v to u is
1
1-

1
1 + sTl

For simplicity the filters are shown in continuous-time form. In a digital system
they are ofcourse realized as sampled systems. The system can alsobe provided
with an antiwindup protection, as shownin Fig. 8.11(c). A drawback with this
scheme is that the PID-controller must be of the form

G(s) = K' (1 + ST~i~ + sT~)

(8.27)

I

which is less general than (8.22). Moreover the reset-time constant is equal
to Tf. More elaborate schemes have to be used for general PID.algorithms on
position form. Such a controller is built up of a manual control module and a
Pllr-module, each having an integrator. See Fig. 8.12.
Bumpless Parameter Changes

A controller is a dynamic system. A change of the parameters of a dynamic
system will naturally result in changes of its output even if the input is kept
constant. Changesin the output can in some cases be avoided by a simultaneous

314

Approxjmating Continuous-TIme Controllers

Chap. 8

change ofthe state of the system. The changes in the output will also depend on
the chosen realization. With a PID-controller it is natural to require that there
be no drastic changes in the output if the parameters are changed when the
error is zero. This will obviously hold for all incremental algorithms,because the
output ofan incremental algorithm is zero when the input is zero irrespective of
the parameter values. It also holds for a position algorithm with the structure
shown in Figs. 8.11(b) and (c).For a position algorithm it depends, however, on
the implementation. Assume, for example. that the state is chosen as

x,

Jte(s) ds

=

when implementing the algorithm. The integral term is then

Any change of K or T, will then result in a change of 1. To avoid bumps when
the parameters are changed it is therefore essential tbat the state be chosen as
Xl

=

K(s)
T,(s) e(s) ds

J
t

when implementing the integral term.

Tuning

A PID-controller has parameters K, Ti , Td, Ttl b, N, Ul ow , and Uhigh that must"
be chosen. The primary parameters are K, Til and Td . Parameter N can often
be given a fixed default value, for example, N = 10. The tracking-time constant
(Tt ) is often related to the integration time (TJ In some implementations it
has to be equal to Ti; in other cases it can be chosen as 0.1 to 0.5 times TI • The
parameters Ulow and Uhigh should be chosen close to the true saturation limits.
If the process dynamics and the disturbances are known parameters, then
K, T!1 and Td can be computed using the design methods of Chapters 4, 5: 11,
and 12. Some special methods have, however, been developed to tune the PIDparameters experimentally. The behavior of the discrete-time PID-controller is
very close to the analog PID-controller if the sampling interval is short. The
traditional tuning rules for continuous-time controllers can thus be used. There
are two classical heuristic rules due to Ziegler and Nichols (1942) that can be
used to determine the controller parameters: the step-response method and the
ultimate-sensitivity method.
The step-response method. In this method the unit step response ofthe
open-loop process is determined experimentally. The technique can be applied to
processes whose step response is monotone or essentially monotone apart from
an initial nonminimum phase characteristic. To use the method the tangent to

Sec. 8.5

315

Digjtal PID·Controliers

t

L

Figure 8.13 Determination of parameters a ~ RL and L from the unit
step response to be used in Ziegler-Nichols step-response method.

the step response that has the steepest slope is drawn and the intersections of
the tangent with the axes are determined. See Fig. 8.13. The controller parameters are then obtained from Table 8.2. The Ziegler-Nichols rule was designed
to give good response to load disturbances. It does, however, give fairly low
damping of the dominant poles.
Parameter L is called the apparent deadtime. For stable processes parameter T , wbich is called the apparent-time constant, can also be determined from
a step response of the open-loop system..

In this method the key idea l~ to determine the point where the Nyquist curve of the open-loop system intersects
the negative real axis. This is done by connecting the controller to the process
The ultimate-sensitivity method

and setting the parameters so that pure proportional control is obtained. The
gain of the controller is then increased until the closed-loop system reaches the
stability limit. The gain (KIl ) when this occurs and the period of the oscillation
(Tu ) are determined. These parameters are called ultimate gain and ultimate
period. The controller parameters are then given by Table 8.3.

Assessment

The Ziegler-Nichols tuning rules are conceptually attrac-

tive. Process dynamics is characterized by two parameters that are easy to determine experimentally and the controller parameters are then obtained from

Table 8.2 PID parameters obtained from
the Ziegler-Nichols step-response method.
Controller Type

K

P
PI
PID

Iia

T·t

O.91a 3L
1.2/a 2L 0.5L

Approximating ContinuQus-Time Controllers

316

Chap. 8

Table

8.3 PID parameters obtained from
Ziegler-Nichols ultimate-sensitivity method.

K

Controller Type

P
PI
PID

O.5Ku
0.45K u
0.6Ku

simple tables. Because of this the rules have been very popular; they are the
basis for much of practical controller tuning. The Ziegler-Nichols rules do however have some very serious drawbacks. The closed-loop systems obtained with
the rules have very low relative damping typically ahout ~ ~ 0.2. The tuning
rules do not give all controller parameters, and the integrations time is always
four times the derivative time. The damping can be improved by modifying the
numerical values in the tables. To characterize process dynamics by two parameters is quite crude. More parameters are required for improved tuning. Much
can be gained hy also including the static gain Kp of a process. Tuning rules
of the Ziegler-Nichols type should therefore be used with care. They can give a
rough approximation but the tuning can often be improved.
Selection of Sampling interval

When DDC-tontrol was first introduced, computers were not as powerful as
they are today. Long sampling intervals were needed to handle many loops. The
following recommendations for the most common process variables are given for
DDC-control.
Type of variable

Sampling time, S

Flow
Level
Pressure
Temperature

1-3

5-10
1-5
10-20

Commercial digital controllers for few loops often have a short fixed-sampling
interval on the order of200ms. This impliesthat the controllerscan be regarded
as continuous-time controllers, and the continuous-time tuning rules may be
used. Several rules of thumb for choosing the sampling period for a digital PID·
controller are given in the literature. There is a significantdifference between
PI- and Plll-controllers, For PI-controllers the sampling period is related to the
integration time. A typical rule of thumb is

h
T. ~ 0.1 to 0.3
I

Sec. 8.5

317

Digital PIC-Controllers

When Ziegler-Nichols tuning is used this implies

h

L ~ 0.3 to 1

or

h

T

u

~ 0.1 to 0.3

With Pill-control the critical issue is that the sampling period must be so short
that the phase lead is not adversely affected by the sampling. This implies that
the sampling period should he chosen so that the number hNlTd is in the range
of 0.2 to 0.6. With N = 10 this means that for Ziegler-Nichols tuning the ratio
hI L is between 0.01 and 0.06. This gives

hN
T

~ 0.2 to 0.6

d

Significantly shorter sampling periods are thus required for controllers with
derivative action. If computer time is at a premium, it is advantageous to use
the sampled-data design methods used in this hook.

Computer Code
A typical computer code for a discrete PID-controller is given in Listing 8.1
on page 318. The discretization of the integral term is made using a forward
difference. The derivative term is approximated using a backward difference.
The calculation PIn_lui t is made initially only. This saves computing time. In
a real system these calculations have to be made each time tbe parameters are
changed. The code given admits bumpless parameter changes if b = 1. When
b "f 1 the proportional term (P) is different from zero in steady state. To ensure
bumpless parameter changes it is necessary that the quantity P + I is invariant
to parameter changes. This means that the state I has to be changed as follows:

Word length and integration offset. The integral part in digital PIDcontrollers is approximated as a sum. Computational problems, such as iniegration offset, may then occur due to the finite precision in the representation
in the computer. Assume that there is an error, e(kh). The integrator term is
then increased at each sampling time with [see (8.23)]

Approximating Continuous-Time Controllers

318

Chap .B

Listing 8.1 C code for FlD-controller based on 'fustin discretization.
#include<Kernel.h>
1* Import real-time primi tives ~I
1* prD controller based on Tustin discret ization */
struct PID_Data {
struct {
double uc;
f* Input : s~ ~i~
*f
double y ;
*f
1* Input : Measured variable
double u:
/* Output Controller output
*f
double v;
1* Output: Limited controller output *f
} Signals;
struct {
double I;
/* Integral part
double Dj
/* Derivative part
double yold:
/* Delayed measured variable
} States;
struct {
double K;
/* Controller gain
*/
.;
double 1i;
1* Integral time
double Td;
/* Derivative time
*/
double Tt;
f. R9~et time
*/
double N;
1* Maximum derivative gain
*/
double b;
/ * Fraction of setpoint in prop. term */
double ulow;
f* Low output limit
*/
double uhigh ;
1* High output limit
*/
double h;
/- Sampling period
*1
double bi, ar, bd, ad;
} Par;
} pid_data;

void PIO_Init(struct PIO_Data *data)
{

data->States .I
= 0;
data->States.O
; 0;
data->States .yold = OJ
data->Par .K = 4.4 ;
data->Par .Ti = 0.4;
data->Par ,Td = 0.2;
data->Par .Tt - 10;
data->Par.N ; 10;
data->Par .b ;:: 1;
data->Par .ulow - -1;

data->Par.uhigh

=

1;

data->Par.h - 0.03 ;
data->Par.bi = data->Par.K*data->Par.h/data->Par.Tl;
data->Par.ar = data->Par.h/data->Par.Tt;
data->Par .bd = data~>Par.K*data->Pat.N*data->Par ,Tdf
(data->Par.Td+data->Par.N.data->Par.h);
data->Par ,ad = data->Par.Td/(data->Par.Td+data->Par.N*data->Par .h);
}

Sec. 8.5

Digital PIO-Controllers

319

Listing 8.1 (Continued)
void

PID~CalculateOUtput(struct

PID_Data *data) {

/* Proportional part *1
double P

m

data->Par.K*(data->Par.b*data->Signals.uc data->Signals.y);

/. Derivative part *1
data-)States.D ~ data->Par.aa + data->States.D data->Par.bd * (data->Signals,y - data->States.yold);
/. Calculate control signal */
data->Signals.v $ P + data->States.I + data->States,D;

I. Handle actuator limitations *1
if ( data->Signals.v < data->Par.ulow ) {
data->Signals.u ~ data->Par.ulow;
} else if ( data->Signals.v > data->Par.uhigh ) {
data->Signals.u = data->Par.uhigh;
} else {
data->Signals.u = data->Signals.v;
}
}

void PID_UpdateStates(struct PID_Data *data) {
1* Integral part */
data->States.I = data->States.I +
data->Par.bi*{data->Signals.uc - data->Signala.y) +
data->Par.ar*(data->Signals.u - data->Signals,v);
data->States.yold: data->Signals.y;
}

void PlO_Main() {
Kernel_Time time;
PID_Init(&pid-data);
Kernel_CurrentTime(&time);

1* Get current time */

tor (;;) {

Kernel_IncTime(ttime. 1000

* pid_data.Par.h);

1+ Increment "time" with hi
read_y(&(pid_data.Signals,y»j
read_uc(~(pid_data.Signals.UC»i

PID_CalculateOutput(&pid_data);
write_u(pid_data.Signals.u);
PID.UpdateStates(kpid_data);
1* Wait until "t ime" *1
Kernel_lolaitUntil(time) ;
}
}

Approximating Continuous-Time Controllers

320

Chap. B

Assume that the gain is small and that the reset time is large compared to the
sampling time. The change in the output may then be smaller than the quantization step in the D-A converter. For instance, a 12-bit D-A converter (that
is, a resolution of 1/4096) should give sufficiently good resolution for control
purposes. Yet if K = h = 1 and T, = 3600, then any error less than 90% of the
span of the A-D converter gives a calculated change in the integral part less
than the quantization step. If the integral part is stored in the same precision
as that of the D-A converter, then there will he an offset in the output. One way
to avoid this is to use higher precision in the internal calculations. The results
then have an error that is less than the quantization level of the output . Frequently at least 24 bits are used to implement the integral part in a computer,
in order to avoid integration offset.

8.6 Conclusions
Different ways of translating a continuous-time controller to a digital controller
have been presented. The problem is of substantial interest if an analog design is available, and a digital solution is needed. Several methods to compute a pulse-transfer function that corresponds to the continuous-time transfer
function have been discussed, based on step invariance, ramp invariance, and
Tustin's approximation. Tustin's method is commonly used because of its simplicity. It does, however, distort the frequency scale of the filter. The method
based on ramp invariance gives very good results and is only moderately more
complicated than Iustin's method. Digitel systems designed in this way arc always {slightly) inferior to analog systems because of the inherent time delay
caused by the hold circuit. This time delay is approximately h/2.
The translation methods work well if the sampling period is short. A good
way to choose the sampling period is to observe that the extra time delay decreases the phase margin by wc h/2 radians or by 180mc/w degrees, where W c
s
is the crossover frequency. There are possibilitiesofcreating better designsthan
those discussed in this chapter, as discussed in the following chapters.

6.7 Problems
8.1 Find how the left half-s-plane is transformed into the a-plane when using the mappings in (8A) to (8.6).
8.2 Use different methods to make an approximation of the transfer function
a

G(s} = s+a
(a) Euler's method
(b) Tustin's approximation
(c) Tustin's approximation with prewarping if the warping frequency is WI

rad/s

=a

Sec. 8.7

321

Problems

8.3 The lead network given in (8.9) gives about 20" phase advance at to,
Approximate the network for h = 0.25 using

= 1.6 rad/s ,

(a) Euler's method

(b) Backward differences
(c) Tustin's approximation

(d) Tustin's approximation with prewarping using
quency

= (JJr

WI

as the warping fro-

(e) Zero-order-hold sampling
Compute the phase ofthe approximated networks at z

==

exp(iwch).

8.4 Verify the calculations leading to the rule of thumb for the choice of the sampling
interval given in Sec, 8.2.
8.5 Show that (8.24) is obtained from (8.22) by approximating the integral part using
Euler's method and backward difference for the derivative part. Discuss advantages
and disadvantages for each of the following cases.
(a) The integral part is approximated using backward difference.

Hin.t: Consider
(b) The derivative part is approximated using Euler's method. [
the case when Tri is smail.)
8.6 A continuous-time Pl-controller is given by the transfer function

Use the bilinear approximation to find a discrete-time controller. Find the relation
hetween the continuous-time parameters K and T1 and the corresponding discretetime parameters in (8.24).

8.7 Consider the tank system in Problem 2.10. Assume the following specifications for
the closed-loop system:
1. The steady-state error after a step in the reference value is zero.
2. The crossover frequency of the compensated system is 0.025 rad/s,
3. The phase margin is about 50
Q

•

(a) Design a PI-controller such that the specifications are fulfilled.

(b) Determine the poles and the zero ofthe dosed-loop system. What is the damping corresponding to the complex poles?
(c) Choose a suitable sampling interval and approximate the continuous-time
controller using Tustin's method with warping. Use the crossover frequency
as the warping frequency.
(d) Simulate the system when the sampled-data controller is used. Compare with
the desired response, that is, when the continuous-time controller is used.
8.8 Make an approximation, analogous to (8.16) and 18.17), such that the modifications
are valid for terms up to and including h 3 •

Approximating Continuous-Time Controllers

322

Chap.S

8.9 The normalized motor has a state-space representation given by (A.5). The control
law

u(t) =Muo(t) - Lx(t)
with M

=4 and L::::

(2 4) gives the continuous-time transfer function

S2

from

Ur

4
+ 35 + 4

to y. This corresponds to { ; 0.75 and 0)0

= 2.

(a) Make a sampled-data implementation of the controller.
(b) Modify the control law using (8.16) and (8.17).
(e) Simulate the controllers in (a) and (b) for different sampling periods and
compare with thecontinuous-time controller.

8.10 Given the continuous-time system

~; = (~3 ~2 )x + (~)
y; (1 o)x

U

(a) Determine a continuous-time state-feedback controller
u(t) :::: -Lx(t)

such that the characteristic polynomial of the closed-loop system is
S2 ... 8s

+ 32

A computer is then used to implement the controller as
u(kh)

= -Lx(kh)

(b) Modify the controller using (8.16).

(c) Simulate the controllers in (a) and (b) and decide suitable sampling intervals.
Assume that x(O)

~

[1 0].

8.11 Usethe w-plane method to design 8 compensator forthe motor in Example 8.3when
h ; 0.25. Design the compensator such that the transformed systam has a crossover
frequency corresponding to 1.4 rad/s and a phase margin of 50°. Compare with
the continuous-time design and the discrete-time approximations in Example 8.3.
Investigate how long a sampling interval can be used for the w-plane method.

8.12 Consider the ccntinuous-time double integrator described by (A.2) . Assume that a
time-continuous design bas been made giving the controller
u(t) ; 2ut (t) -

(1 2) x(t)

d~~t) =Ax(t) + Bu(t} + K(y(t} withJ(T= (11).

Citt))

Sec. 8.8

323

Notes and References

(a) Assume that the controller should be implemented using a computer. Modify
the controller (not the observer part} for the sampling interval h =0.2 using
(8.16) and (8.17) .

(b) Approximate the ohserver using backward-difference approximation.
(c) Simulate the continuous-time controller and the discrete-time approximation.

Let the initial values be x(O)

=

(1 1)

T

and £(0) '"

(0 0)

T.

8.13 Derive ramp-invariant approximations of the transfer function
1

G(s ) = S

+ Q,

and
s
G{s) = 5 +a

8.14 Derive the ramp-invariant equivalent of the PID-controller.
8.15 There are manydifferent ways to sample a continuous-time system. The key differenceis the assumption made on the behavior ofthe control signal over the sampling
interval. So far we have discussed step invarianee and ramp invariance. Derive formula for impulse invariant sampling ofthe system (B. II} when the continuous-time
signal is assumed to he a sequence of impulses that occurjust after the sampling
instants,
8.16 Derive the impulse-invariant approximations of the transfer functions in Problem 8.13.
8.17 The frequency prewarping in Sec. 8.2 gives the correct transformation at one frequency along the imaginary axis. Derive the necessary warping transformation
such that one point at an arbitrary ray through the origin is transformed correctly.

8.8 Notes and References
The problem of designing digital filters that implement analog-transfer functions approximately is discussed in the digital-filtering literature: Rabiner and
Gold (1975), Antoniou (1979), and Oppenheim and Schafer (1989). Interesting views on similarities and differences between digital signal processing and
control theory are presented in Willsky (1979). A more control-oriented presentation of different approximations is found ,in Franklin and Powell (1989).
Redesign of state feedback is discussed in more detail in Kuo (1980).
Digital Plll-controllers and their operational aspects are thoroughly discussed in Goff (1966), Bristol (1977), Shinskey (1988), and !strom and Hagglund (1995). The classical reference for tuning PID-eontrollers is Ziegler and
Nichols (1942). A modification of the rules by Ziegler and Nichols which takes
the length of the sampling interval into account is given in Takahashi, Chan,
and Auslander (1971).

9
Implementation of Digital
Controllers
9.1 Introduction
Design of algorithms for computer control is discussed in the previous chaptern. The problem of implementing a control algorithm on a digital computer
is discussed in this chapter. The control algorithms obtained in the previous
chapters are discrete-time dynamic systems. The key problem is to implement
a discrete-time dynamic system using a digital computer. An overview of this
problem is given in Sec. 9.2, which shows that it is straightforward to obtain
a computer code from the discrete-time algorithm. There are, however, several
issues that must be considered. It is necessary to take the interfaces to the sensors, the actuators, and the human operators into account. It is also necessary
to consider the numerical precision required.
The sensor interface is discussed in Sec. 9.3. This covers prefiltering and
computational delays andshows that the computational delay depends critically
on the details of the algorithm. Different ways to shorten the computational
delay by reorganizing the code are discussed. Methods of filtering the signals
effectively by introducing nonlinearities, which may reduce the influence of unreliable sensors, are shown. This is one of the major advantages of computer
control. Most theory in this book deals with linear theory. There are, however,
a few nonlinearities such as actuator saturation that must be taken into account. Different ways of handlingtbese are discussed in Sec. 9.4. This leads to
extensions ofthe methods for antireset windup usedin classical process control.
The operator interface is important factor; it is discussed in Sec. 9.5. This
includes treatment of operational modes and different ways to avoid switching transients. The information that should be displayed and different ways of
influencing the control loop are also discussed. Digital computers offer many in324

Sec. 9.2

An Overview

325

teresting possibilities; sofar they have been used only to a very modest degree.
There are many opportunities for innovations in this field. It is important to
have sound numerics in the control algorithm, which is the topic ofSec. 9.6. Effects of a finite word length are also discussed. Realization ofdigital controllers
is treated in Sec. 9.7. Programming ofcontrol algorithms is discussed in Sec. 9.8.
For more ambitious systems in which parameters and control algorithms are
changed on-line, it is necessary to understand concurrent programming.

9.2 An Overview
This section gives an overview of implementation of digital control laws. Different representations of the control laws obtained from the design methods in
Chapters 4,5, and 8 are first given; the algorithms are then implemented. A list
ofsome important problems is given. These problems are discussed in greater
detail in the following sections.
Different Representations of the Controller

The design methods of the previous chapters give control laws in the form of a
cliscrete-time dynamic system. Different representations are obtained, depending on the approaches used. The design methods based on pole placement by
state feedback in Sec. 4.5 give a controller of the fonn

x(klk)
u{k)

= x(klk -

1) + K (Y(k) - y(klk - 1))

= L (xm(k) - x(klk)) + Lcuc(k)

x(k + 11k) = <l>x(klk) + fu(k)

xm(k + 1)

(9.1)

= f(~m(k),uc(k))

Y(k + Ill) ::: Cx(k + 11k)

x

x

In this representation the state of the controller is and X m , where is an
estimate of the process state, and Xm is the state of the model that generates
the desired response to command signals Uc ' The form in (9.1) is called a state
representation with an explicit observer because of the physical interpretation
of the controller state. It is easy to include a nonlinear model 'for the desired
state in this representation.
If the function f in (9.1) is linear, the controller is a linear system with
the inputs y and u; and the output u. Such a controller may be represented as

x(k + 1) ::: Fx(k) + Gy(k) + Gcuc{k)
u(k) : Cx(k) + Dy(k) + Dcuc(k)

(9.2)

where x is the state of tbe controller (see Problem 4.7). Equation (9.2) is a
general-state representation of a discrete-time dynamic system. This form is

Implementation of Digital Controllers

326

Chap.9

more compact than (9.1). The state does, however, not necessarily have a simple
physical interpretation.
The design methods for single-input-single-output systems discussed in
Chapter 5, which are based on external models, give a controller in the form of
a general input-output representation
R(q)u(k)

= T(q)uc(k) -

S(q)y(k)

(9.3)

where R(q), S{q), and T{q) are polynomials in the forward-shift operator q.
There are simple transformations between the different representations (compare with Chapter 2).
Realization

A control law is a dynamic system. Different realizations can be obtained by
different choices ofthe state variables. The different representations are equivalent from an input-output point ofview if we assume that the calculations are
done with infinite precision. With finite precision in the calculations, the choice
of the state-space representation is very important. Quantization and roundoff
introduce nonlinearities, Linear and nonlinear operations do not commute. For
instance, Q(a + b) F Q(a) + Q{b), wbere Q(.) represents the quantization ofa
signal. It is thus important in which order different operations are done when
an algorithm is implemented. A bad choice of the representation may give a
controller that is sensitive to errors in the computations.
It is very important that the controller is transformed into a robust form
before the controller is implemented as a computer program. Suitable forms
are serial and parallel realizations of first- and second-order blocks. It is also
importantto organize the computations in a numerically good way. Forinstance,
it should be avoided to take the difference oflarge numbers. These aspects are
further discussed in Sec. 9.7.
Implementing a Compuler-Controlled System

The implementation of a discrete-time system described by (9.1), (9.2), or (9.3)
using a digital computer is straightforward. The detailsdepend onthe hardware
and software available. To show the principles, it is assumed that the system
described by (9.2) should be implemented using a digital computer with A·D
and D~A converters and a real-time clock. A graphical representation of the
program is shown in Fig. 9.1. The execution of the program is controlled by the
clock. The horizontal bar indicates that execution is halted until an interrupt
comes from the clock. The clock is set so that an interrupt is obtained at each
sampling instant. The code in the box is executed after each interrupt.
The body ofthe code is given in Listing9.1. Analog-to-digital conversion is
commanded in the first line. The appropriate values are stored in the arrays y
and tic. The control signal u is computed in the second line using matrix-vector
multiplication and vector addition. The state vector x is updated in the third
line, and the digital-to-analog conversion is performed in the fourth line. To

Sec. 9.2

An Overview

327
r

Clock interrupt -,...
Code:
A-D conversion
Compute control variable
D-A conversion

Figure 9.1 Graphical representations of a program used to implement a
discrete-time system.

obtain a complete code, it is also necessary to have type declarations for the
vectors u, uc, x, and y and the matrices F, G, Gc, C, D, and Dc. It is also necessary
to assign values to the matrices and the initial value for the state x. When
using computer languages that do not have matrix operations, it is necessary to
write appropriate procedures for generating matrix operations usingoperations
on scalars. Notice that the second and third lines ofthe code correspond exactly
to the algorithm in (9.2).
To obtain a good control system, it is also necessary to consider
• Prefiltering and computational delay
• Actuator nonlinearities
• Operational aspects

• Numerics

• Realization
• Programming aspects
These issues are discussed in the following sections.

Listing 9.1 Computer code skeleton for the control law of (9.2). Line numbers are introduced only for purposes ofreferencing.

Procedure Regulate
begin

1
2
3
4

Adin y ue
u:=C*x+D*y+Dc*ue
x:=F*x+G*y+Gc*uc
Daout u
end

328

Implementation of Digital Controllers

Chap. 9

9.3 Prefiltering and ccmputationat Delay
The interactions between the computer and its environment are important when
implementing a control system. Compare with Chapter 7. The sensor interface
is discussed in this section. The consequences of disturbances are discussed in
Chapters 4 and 7. The importance of using an analog prefilter to avoid aliasing
is treated in Chapter 7.
It is also clear from Sec. 9.2 that there is always a time delay associated
with the computations. The prefilter and the computational delay give rise to
additional dynamics, which may be important when implementing a digital
controller. These effects are now discussed.

Analog PrefUtering

To avoid aliasing (see Sec. 7.4), it is necessary to use an analog prefilter for
elimination of disturbances with frequencies higher than the Nyquist frequency
associated with the sampling rate. Different prefilters are discussed from the
signal-processing point ofview in Sec. 7.4. The discussion is based on knowledge
of the frequency content of the signal. In a control problem there is normally
much more information available about the signals in terms of differential equations for the process models and possibly also for the disturbances.
It is often useful to sample the analog signals at a comparativelyhigh rate
and to avoid aliasing by an ordinary analog prefilter designed from the signalprocessing point of view. The precise choice depends on the order of the filter
and the character of the measured signal. The dynamics of the prefilter should
be taken into account when designing the system. Compare the discussion in
Sees. 5.8 and 5.9. If the sampling rate is changed, the prefilter must also be
changed. With reasonable component values, it is possible to construct analog
prefilters for sampling periods shorter than a few seconds. For slower sampling
rates, it is often simpler to sample faster with an appropriate analog prefilter
and apply digital filtering to the sampled signal. This approach also makes it
possible to change the sampling period of the control calculations by software
only.
Because the analog prefilter has dynamics, it is necessary to include the
filter dynamics in the process model. If the prefilter or the sampling rate is
changed, the coefficients of the control law must be recomputed. With normal
sampling rates-that is, 15 to 45 times per period-it is necessary to consider
the prefilter dynamics in the controller design (compare with Sees. 5.9 and 7.4).

Computational Delay
Because A-D and D-A conversions and computationstake time, there will always
be a delay when a control law is implemented using a computer. The delay,
which is called the computational delay, depends on how the control algorithm
is implemented. There are basically two different ways to do this (see Fig. 9.2).
In case A, the measured variables read at time tk may be used to compute the
control signal to be applied at time tk+)' Another possibility, case B, is to read

Sec. 9.3

329

Prefillering and Computational Delay

Case B

Case A

Time

u

u

...

....
o

o

.t

j...,

c
o

'---+-_ _-+-_ _+-

_

thI

C,)

r::
o

Computational
lag r

Time

o

L.....-+-----.,f----;-+-_~

Figure 9.2 Two ways of synchronizing inputs and outputs. In case A the
signals measured at time t" are used to compute the control signal to be
applied at time tk +l ' In case B the control signals are changed as soon as
they are computed.

the measured variables at time tk and to make the D·A conversion as soon as
possible.
The disadvantage ofcase Ais that the control actions are delayed unnecessarily; the disadvantage of case B is that the delay will be variable, depending
on the programming. In both cases it is necessary to take the computational
delay into account when computing the control law. This is easily done by including a time delay of h (case A) or r (case B) in the process model. A good
rule is to read the inputs before the outputs are set out. If this is not done,
there is always the risk of electrical cross-coupling.
In case B it is desirable to make the computational delay as small as
possible. This can be done by making as few operations as possible between
the A-D and D-A conversions. Consider the program in Listing 9.1. Because the
control signal u is available after executing the second line of code, the D-A
conversion can be done before the state is updated. The delay may be reduced
further by calculating the product C*x after the D-A conversion. The algorithm
.
in Listing 9.1 is then modified to Listing 9.2.
To judge the consequences ofcomputationaldelays, it is also useful to know
the sensitivity of the closed-loop system to a time delay. This may be evaluated
from a root locus with respect to a time delay. A simpler way is to evaluate how
much the closed-loop poles change when a time delay of one sampling period is
introduced.

Implementation of Digital Controllers

330

Chap. 9

Computer code skeleton that implements the control algorithm
(9.2). This code has a smaller computational delay than the code in Listing 9.1.

Listing 9.2

Procedure Regulate

1
2

begin
Adin '! uc
u;=u1+D*y+Dc*uc

3

Daout u

4

x:=F*xtG*y+Gc*uc

5

ul:~C*x

end

Outliers and Measurement Mal'unctions
The linear filtering theory that will be discussed in Chapter 11 is very useful in
reducing the influenceof measurement noise. However, there may also he other
types oferrors, such as instrument malfunction and conversionerrors. Theseare
typically characterized by large deviations. which occur with low probabilities.
It is very important to try to eliminate such errors 80 that they do not enter into
the control-law calculations. There are many good ways to achieve this when
using computer control.
The errors may be detected at the source. In systems with high-reliability
requirements) this is dune by duplication of the sensors. Tw-o sensors are then
combined with a simple logic, which gives an alarm if the difference between
the sensor signals is larger than a threshold. A pair of redundant sensors may
be regarded as one sensor that gives either a reliable measurement or a signal
that it does not work.
Three sensors may be used in more extreme cases. A measurement is then
accepted as long as two out of the three sensors agree (two-out-of-three logic). It
is also possible to use even more elaborate combinations of sensors and filters.
An observer can also be used for error detection. For example, consider
the control algorithm of (9.1) with an explicit observer. Notice that the one-step
prediction error
e(k) ~ y(k) - y(klk -1)

=:

y(k) - Ci(klk -1)

(9.4)

appears explicitly in the algorithm. This error can be used for diagnosis and
to detect if the measurements are reasonable. This will be further discussed in
connection with the Kalman filter in Chapter 11.
In computer control there are also many other possibilities for detecting
different types ofhardware and softwareerrors. A few extra channels in the A-D
converter, which are connected to fixed voltages, may be used for testing and
calfhration. By connecting a D-A channel to an A-D channel, the D-A converter
may also be tested and calibrated.

Sec. 9.4

331

Nonlinear Actuators

9.4 NonUnear Actuators
The design methods of Chapters 4, 5, and 8 are all based on the assumption
that the process can be described by a linear model. Although linear theory has
a wide applicability, there are often some nonlinearities that must be taken into
account. For example, it frequently happens that the actuators are nonlinear, as
is sbown in Fig. 9.3. Valves are commonly used as actuators in process-control
systems. This corresponds to a nonlinearity of the saturation type where the
limits correspond to a fully open or closed valve. The system shown in Fig. 9.3
can be described linearly when tbe valve does not saturate. The nonlinearity is
thus important when large changes are made. There may be difficulties with the
control system during startup and shutdown, as well as during large changes,
if the nonlinearities are not considered.. A typical example is integrator windup.
Other typical nonlinearities in practicalsystems are rate limitations, hysteresis,
and backlash.
The rational way to deal with the saturation is to develop a design theory
that takes the nonlinearity into account. This can be done using optimal-control
theory. However, such a design method is quite complicated. The corresponding
control law is also complex. Therefore, it is practical to use simple heuristic
methods.
Difficulties occur because tbe controller is a dynamic system. When the
control variable saturates. it is necessary to make sure that the state of the
controller behaves properly, Different ways of achieving this are discussed in
what follows.
Antlwindup for State-Space Controllers with an Explicit Observer

Consider first the case when the control law is described as an observer combined with a state feedback (9.1). The controller is a dynamic system, whose
state is represented by the estimated state x in (9.1). In this case it is straightforward to see how the difficulties with tbe saturation may be avoided.
The estimator of (9.1) gives the correct estimate if the variable u in (9.1)
is the actual control variable up in Fig. 9.3. If the variable Up is measured, the
estimate given by (9.1) and the state of the controller will he correct even if
the control variable saturates. If the actuator output is not measured, it can be
estimated-provided that the nonlinear characteristics are known. For the case
Process
r-.-------./'-.-----~--"""

Actuator

Linear dynamics

Figure 9.3 Block diagram of a process with a nonlinear actuator having
saturation characteristics.

Implementation of Digital Controllers

332

Chap . 9

Xm

Actuator

State feedback

Observer

L

Figure 9.4 Controller based on an observer and state feedback with
anti-windup compensation.

ofa simple saturation, the control law can be written as
x(klk):;; x(klk - 1) + K(Y(k) - Cx(klk
'=

-1))

(I - K C)<Px(k - 11k - 1) + Ky(k) + (I - KC)rup(k - 1)

up(k) ~ sat ( L(xm(k) - x(k~k)) + DUc(k))

(9.5)

x(k + 11k) = <1>.i(k\k) + rUp(k)

where the function sat is defined as
U1
0W

j

u

Ulow

Uhigh

sat s =

(9.6)

U ~ Uhigh

<

U

<

Uhigh

for a scalar and

(9.7)

satu ::::
sat Un

for a vector. The values U)ow and Uhigh are chosen to correspond to the actuator
limitations. A block diagram of a controller with a model for the actuator nonlinearity is shown in Fig. 9.4. Observe that even if the transfer function from Y
to u for (9.1) is unstable, the state ofthe system in (9.5) will always be bounded
if the matrix (I - KC)¢> is stable. It is also clear that x will be a good estimate
ofthe process state even if the valve saturates, provided that Ulow and Uhigh are
chosen properly.
Antiwindup for the General Slate-Space Model

The controller may also bespecified as a state-space model ofthe form in (9.2):

x(k + 1) = Fx(k) + Gy(k)
u(k) = Cx(k) + Dy(k)

(9.8)
(9.9)

Sec. 9.4

333

Nonlinear Actuators

(b)

(a)
y

u

u

Figure 9.5 Different representations of the control law.

which does not include an explicit observer. The command signals have been
neglected for simplicity. If the matrix F has eigenvalues outside the unit disc
and the control variable saturates, it is clear that windup may occur. Assume,
for example, that the output is at its limit and there is a control error y. The
state and the control signal will then continue to grow, although the influence
on the process is restricted because of the saturation.
To avoid this difficulty, it is desirable to make sure that the state of (9.8)
assumes a proper value when the control variable saturates. In conventional
process controllers, this is accomplished by introducing a special tracking mode,
which makes sure that the state ofthe controller corresponds to the input-autput
sequence {up(k) ,y(k)} . The design of a tracking mode may be formulated as
an observer problem. In the case of state feedback with an explicit observer,
the tracking is done automatically by providing the observer with the actuator
output Up or ita estimate up' In the controller of (9.8) and (9.9), there is no
explicit observer. To get a controller that avoids the windup problem, the solution
for the controller with an explicit observer will be imitated. The control law is
first rewritten as indicated in Fig. 9.5. The systems in (a) and (b) have the same
input-output relation. The system SB is also stable. By introducing a saturation
in the feedback loop in (b), the state of the system S B is always bounded if y and
u are bounded. This argument may formally be expressed as follows. Multiply
(9.9) by K and add to (9.8). This gives

x(k + 1)

= F:c(k) + Gy(k) + K (u{k) - Cx(~) ~ Dy(k))
;: (F - KC)x(k) + (G - KD )y(k) + Ku(k)
= Fox(k) + Goy(k) + Ku(k)

If the system of (9.8), and (9.9) is observable, the matrix K can always be cbosen
so that Fo = F - KC has prescribed eigenvalues inside the unit disc. Notice
that this equation is analogous to (9.5). By applying the same arguments as for
the controller with an explicit observer, the control law becomes

x(k + 1) == Fox(k) + Goy(k) + Ku(k)

u(k)

=sat(Cx(k ) + Dy{k))

(9.10)

The saturation function is chosen to correspond to the actual saturation in the
actuator. A comparison with the case of an explicit observer shows that (9.10)
corresponds to an observer with dynamics given by the matrix Fo. The system

C~ap.9

Implementation of Digital Controllers

334

D

F
y

q -1

G

x

c

D

F-KC r--

y

G-KD

kD--

«:

x

C

~

sat

u

l--..--

K

Figure 9.6 Block diagram of the controller (9.2) and the modification in
(9.10) that avoids windup.

of (9.10) is also equivalent to (9.2) for small signals. A block diagram of the
controller with antireset windup compensation is shown in Fig. 9.6.
Antiwindup forthe lnput-Output Form

The corresponding construction can also be carried out for controllers characterized by input-output models. Consider a controller described by
R(q)u(k)

=:

T(q)uc (k) - S(q)y(k)

(9.11)

where R, S, and T are polynomials in the forward-shiit operator. The problem is
to rewrite the equation so that it looks like a dynamic system with the observer
dynamics driven by three inputs, the command signal Un the process output y,
and the control signal u. This is accomplished as follows.
Let Aaw(q) be the desired characteristic polynomial of the antiwindup observer. Adding Aaw(q)u(k) to both sides of (9.11) gives

Aawu = Tu c - By + (A aw - R)u

sec. 9.4

335

Nonlinear Actuators
(b)

(a)

lle

Ut

1

u y

R
y

T

T

-8

1 v
Aow

u

J

-8
AlIll'-R

FIfure 1.7 Block diagram of the controller of (9.11) and

the modification

in (9.12) that avoids windup.

A controller with antiwindup compensation is then given by

Aawu = Tu, - Sy + (Aow - R)u
u:: satv

(9.12)

This controller iI equivalent to (9.11) when it does not saturate. When the
control variable saturates, it can be interpreted as an ob8erver with dynamics
given by polynomial Aow.
A block diagram of the linear controller or (9.11) and the nonlinear modi·
fication of (9.12) that avoids windup is shown in Fig. 9.7. A particularly simple
case is that of a deadbeat observer, that ii, A:ao =1. The eontroller can then be
written

88

An example illustrates the implementation.
BDmple 1.1 Double iDtelNtor with IIIltire.t wiJldup
A cootlWler with integral action for the double integrator wu deriped in See. 5.7.
In this eumple we Ole the ame design procedure with ~ t» • 0.4 and
t»1l == 0.2. The reault when uaing the antinlet windup procedwe in Fig. 9.7 with
A.. = (q-0.6)' is shown in Fit. 9.8. The antizeaet windup giv_1ess ov8l'lhoot and
the eontrol signal it 0Il1y aaturatiDg at I:Jle maximum value. The response with tha
antiteMt windup is similar but eomewbat e10wer than for the unsaturated cae. •

Ageneralization ofthe antireeet windup in Fig. 9.7 is given in Fig. 9.9. An extra
deaRe of freedom is introduced through the polynomial A.. This pol:fllODlial,
aswell as Aaw, should be monic and stable. The case in Fig. 9.7 i.e obtained for
A.. = 1. The polynomial AJt can be used to shape the response from erron due
to the saturation.

Chap. 9

Implementation of Digital Controllers

336
(a)

(bJ

....,

....,

1 .... . .

::l

:::l

~

£<
0

,

. ~

~

0

;3

::J

0

25

....
;3

~

::3

0..
C

0

25

0

0

0.
l=:

H

'"'"

-0.1

-0.1

25

0

25

0

Time

Time

Figure 9.8 Output and input when the double integrator is controlled with
a controller (a) without and (b) with antirest windup given by (9.12). The
dashed lines show the behavior when there is no saturation.

9.5 Operational Aspects
The interface between the controller and the operator is discussed in this section. This includes an evaluation of the information displayed to the operator
and the mechanisms for the operator to change the parameters ofthe controller.
In conventional analog controllers it is customary to display the set point, the
measured output, and the control signal. The controller may also be switched
from manual to automaticcontrol. The operator may changethe gain (orproportional band), the integration time, and the derivative time. This organization
was motivated by properties of early analog hardware. When computers are
used to implement the controllers, there are many other possibilities. So far the

---

T

~

-8

u

"

~0--

An

Aa lQ

U

r-

J

u

Ao",-AnR
All

Figure 9.9 A generalization of the antiwindup scheme in Fig.9.7.

Sec. 9.5

Operational Aspects

337

potentials of the computer have been used only to a very modest degree.
To discussthe operator interface, it is necessary to consider how the system
will be used operationally. This is mentioned in Sec. 6.2 and a few additional
comments are given here. First, it is important to realize the wide variety of
applications of control systems. There is no way to give a comprehensive treatment, so a few examples are given, For instance, the demands are very different
for an autopilot, a process-control room, or a pilot plant.
Example 9.2 Importance of operational aspects
To illustrate that the operational aspects and security are important we take two
examples from practical implementations.
The first example is a control system for a steel rolling mill. In this application the control, signal conditioning and logic took about 30% of the code and the
rest was related to operator interface and security measures.
The second example is the implementation of an aut:.otuner based on relay
feedhaek. A straightforward implementation of the tuning algorithm could be done
in 1.5 pages ofC code. Thecommercial algorithm with all bells and whistles needed
for operator communication and security required 15 pages of code.
_

Operating Modes

It is often desirable to have the possibilityof running a system under manual
control. A simple way to do this is to have the arrangement shown in Fig. 9.10,
where the control variable may be adjusted manually. Manual control is often
done with push buttons for increasing or decreasingthe control variable.
Because the controller is a dynamicsystem, the state ofthe controller must
have the correct value when the mode is switched frommanual to automatic.
If this is not the case, there will be a switching transient. A smooth transition
is called bumpless transfer, or bumpless transition.
In conventional analog controllers, it is customary to handle bumpless
transition by introducing a tracking mode, which adjusts the controller state
so that it is compatible with the given inputs and outputs of the controller. A
tracking mode may be viewed as an implementation of an ohserver.
Increase
Decrease

...

umanual

Ramp

...

generator
Manual
Automatic

r

<__

Process

)

Regulator

Figure 9.10 Control system with manual and automatic control modes.

Implementation of Digital Controllers

338

Chap. 9

A tracking mode is obtained automatically in the controllers of (9.5), (9.10),
and (9.12) because they have an observer built into them. To run them in a
tracking mode, simply put
Ulow

=

Uhigh :::: Umanual

This implies that the control signal is always equal to the manual input signal.
The state of the controller will be reset automatically because of the internal
feedback in the controller. The saturation introduced in the controller to handle
actuator saturation will automatically give bumpless transfer. There are also
other ways to have modes for semiautomatic control by keeping some feedback
paths for stabilization.
With computer control, it is possible to have many other operating modes.
Parameter estimation and control-design algorithms can be included in the controller. An estimation mode, in which a model of the process is estimated. may
be introduced. The estimated model may be used in the design algorithm to give
an update of the parameters of the controller in a tuning mode. Adaptive control
modes, in which the parameters are updated continuously, may also be added .
Computer control offers many other interesting possibilities. The performance
of the control loop may be displayed instead of set point and error.

InItialization
Because a controller is a dynamic system, it is important to set the controller
state appropriately when the controller is switched on. If this is not done , there
may be large switching transients. In conventional PI-controllers, the controller
has one state only-namely, the integrator. It is customary to initialize such a
controller by operating it in manual control until the process output comes close
to its desired value. For an algorithm with an explicit observer, the controller
state may be initialized by keeping the control signal fixed for the time required
for the observer to settle. A controller with antiwindup may also be initialized
by running it in manual mode during a period that corresponds to the settling
time of the observer.

Parameterization and Parameter Changes
In conventional process controllers, the operator can manipulate the set point
and the parameters in the control law (gain, integration time, and derivative
time). With computer control, there are many other interesting alternatives.
Because of the simplicity of computing, it is possible to use one parameterization in the control algorithm and another in the operator communication. The
parameters displayed to the operator may then be related to the performance of
the system rather than to the details of the control algorithm. The conversion
between the parameters is made by an algorithm in the computer.
To illustrate the idea of performance-related parameters, consider design
of a servo using the pole-placement method described in Chapter 5. The closedloop properties may he specified in terms of the relative damping { and the

Sec. 9.5

339

Operational Aspects

bandwidth (08. To perform the design, it is also necessary to have a model of
the open-loop dynamics . One possibility is to have the process engineer enter
the desired bandwidth and damping and a continuous-time model. The computer can then make the necessary conversions in order to obtain the control
law. If the computer also has a recursive estimation algorithm, it is not necessary to introduce the model. Clearly) there are many interesting possibilities if
estimation and design algorithms are included in the controller.
There are two operational problems with on-line parameter changes. One
problem is related to real-time programming. Data representing parametors are
shared among different programs. It is then necessary to make sure that one
program is not using data that are being changed by another program. This is
discussed in Sec. 9.8.
The other problem is algorithmic. There may be switching transients when
the parameters are changed in a control algorithm. To get some insight into what
can happen, consider tbe simple PI-algorithm

e::uc-y
u:=k*(e+i/ti)
i:=i+e*h
It is clear that a change of the integration time ti will cause a step in the
control signal unless the integral part, i, is zero. The problem can be avoided
by changing the state from i to i*ti/ti " where ti J is the new value of the
integration time. Another simpler way is to write the algorithm as

e:=uc-y
u ;=k*e+i
i :=i+k*e*h/ti
Compare with Sec. 8.5. The need for changing the state when parameters are
changed is dictated by the fact that the state of the controller depends on its
parameters. One way to obtain bumpless parameter changes is to store a set of
past input-output data and to run an observer when the controller parameters
are changed. However, it is often possible to use a simpler solution.
To see what should be done, consider the algorithm of (9.5) with an explicit
observer and state feedback. First, a realization should be chosen 80 that the
matrices C and D do not depend on the adjustable parameters. If the state x
represents an estimate of physical state variables, there are very few difficulties
because the estimated state will not change drastically when model parameters
are changed. Transients due to changes in the feedback gain cannot be avoided
if there is a nonzero error e =
Similarly, there will not be any switching
transients with the algorithm in (9.10), provided that there is a representation
in which the matrices C and D do not contain any parameters that are modified.
It is more complicated to see what should be done with the algorithm of (9.12).
In the representation of (9.12), the state is delayed inputs and outputs. This
state is not minimal. Although the state does not depend on the coefficients of
the polynomials R, S, and T, there is no guarantee that the given R, S, T, U ,

x-x.

Implementation of Digital Controllers

340

Chap. 9

and yare compatible with Eq. (9.12) . With the representation of (9.12), there
will be switching transients when the parameters are changed.

Security
It is very important to make sure that a computer-control system operates safely.
Ideally, this means that the system should either give the correct result or an
alarm if it is not functioning properly Systems with extremely high require.
ments may be tripled (or quadrupled) and the output accepted if two subsystems
give the same result. For simpler systems, it may be sufficient to rely on selfchecking. There are many ways to do this using computer control. Arithmetic
units may be checked by computing functions with known results. Memory and
data transmission may be checked through checksums. A-D and D-A converters
may be checked by using a few extra connected channels. A D-A conversion is
commanded and the result of an A-D conversion ofthe same channel is checked.
Timing may similarly be investigated by connecting a network with a known
time constant between a D-A and an A-D converter.

9.6 Numerics
When implementing a computer-control system it is necessary to answer questions such as: How accurate shouldthe convertersbe?Wha.t precisionis required
in the computations? Should computations be made in fixed-point or floatingpoint arithmetic? To answer these questions, it is necessary to understand the
effects of the limitations and to estimate their consequences for the closed-loop
system. This is not a trivial question, because the answer depends on a complex
interaction of the feedback, the algorithm, and the sampling rate. Fortunately,
only crude estimates have to be done. For instance, should the resolution be 10
or 12 bits and should the word length be 24 or 32 hits? Such questions may be
answered using simplified analysis.

Error Sources
The major sources of error are the following:
• Quantization in A-D converters
• Quantization of parameters
• Roundoff, overflow, and underflow in addition, subtraction, multiplication,
division, function evaluation, and other operations
• Quantization in D-A converters
Common types of A-D converters have accuracies of8, 10, 12, and 14hits, which
correspond to a resolution of 0.4%, 0.1%, 0.025%, and 0.006%, respectively. The
percentages are in relation to full scale. The D-A converters also have a limited
precision. An accuracy of 10 bits is typical. The error due to the quantization

SeC. 9.6

341

Numerics

of the parameters depends critically on the sampling period and on the chosen
realization of the control law.

Word Length
Digital-control algorithms are typically implemented on microcomputers and
minicomputers, which have word lengths of 8, 16, or 32 bits. The essential
numerical difficulty with short word length is illustrated by the example.
Example 9.3 Scalar-product calculations
Consider the vectors
a

~ (100 1 100)

b=

(100 1 -1(0)

The scalar product is (c, b) "" 1. If the scalar product is computed in floating-point
representation with a precision corresponding to three decimal places, the result
will be zero because 100 · 100 + 1 . 1 is rounded to 10,000. Notice that the result
obtained depends on the order ofthe operations. Finite-word-length operations are
neither associative nor distributive.
_

The difficulty may be avoided without using complete double-precision calculation by adding the terms in double precision and rounding to single precision
afterwards. This method can be applied to fixed-point and floating-point calculations . Notice that the multiply instruction for many computers is implemented
so that the product is available in double precision. Many high-level languages
also have constructions that support this type of calculation. Generally speaking, roundoff and quantization will give rise to small errors, whereas the effects
of overflow will be disastrous.
Digital-sigual processors (DSPs) are now commonly used to implement
computer-controllad systems when short sampling periods are required. The
low-cost signal processors are all using fixed-point calculations. For the TMS
family from Texas Instruments, the standard word length is 16 bits but the
accumulator is 32 bits wide. A I6-bit DSP from AT&T has a 36-hit accumulator, and Motorola has a nsp with 24-bit word length and a 56-bit accumulator.
The architecture with a long accumulator is ideal for computing scalar products, which is the key operation when implementing linear filters, because the
products of the terms can be accumulated in double precision. The sigual processors are very fast. The operation of multiply and accumulate (MAP) typically
takes 100 nanoseconds. There are also more expensive sigual processors with
floating-point hardware.
There is also an increased use of computer-controlled systems implemented
using special-purpose VLSI circuits. In these applications the word length is a
design parameter that can be chosen freely. Such a choice naturally requires
a more detailed investigation than a simple choice between single or double
precision. There are applications of custom VLSI both in the aerospace industry
and for mass-produced consumer goods like VCRs and CD players. For these

342

Implementation of Digital Controllers

Chap. 9

applications it is of major concern to minimize chip area. A typical example is
a CD player in which hoth audio and servo functions are implemented on one
chip. For a stationary CD player there are fewer demands on the servo than for
a CD player for a car. The chip area for the control system can thus be smaller
for the stationary player.
There are many number representations used in digital computers. Integers are typically 16,32, or 48 bits. For a long time there were many representations offloating-point numbers. The IEEE did, however, take the initiative to
standardize them, and a standard ANSI-IEEE 754 was published in 1985. In
this standard the numbers are represented as
±a·2 P

where 0 ~ a < 2 is the significand, a180 called the mantissa, and b is the
exponent. In the standard there are three types of floating-point numbers:
1 sign 8 exponent 23 significand
short real (32 bits)
1 sign 11 exponent 52 significand
long real (64bits)
short temporary real (80 bits) 1 sign 15 exponent 64 significand

The IEEE standard has gained widespread acceptance and the floating-point
chips from Intel and Motorola are based on it.
I

Overview of Effects of Roundoff and Quantization
The consequences of roundoff and quantization depend on the feedback system
and on the details of the algorithm. The properties may be influenced considerably by changing the representation of the control law Dr the details of the
algorithm. Thus it is important to understand the phenomenon.
A detailed description of roundoff and quantization leads to a complicated
nonlinearmodel, which is very difficult to analyze. Investigation of simple cases
shows, however, that roundoff and quantization may lead to limit-cycle oscillations. Such examples are presented later, togetherwith approximative analysis.
Limit-cycle oscillations have also been observed in more complex cases.
Some properties of roundoff and quantization in a feedback system may
also be captured by linear analysis. Roundoff and quantization are then modeled as ideal operations with additive or multiplicative disturbances. The disturbances may be either deterministic or stochastic. This type of analysis is
particularlyuseful for order-of-magnitude estimation. It allows investigation of
complex systems and it is useful when comparing different algorithms.
Techniques from sensitivityanalysis and numerical analysis are also useful in finding the sensitivityof algorithms to changes ofparameters. Such methods may beused tocompare and screen different algorithms. However, the methods are limited to comparison of tbe open-loop performances of the algorithms.
It is also necessary to compare the effects ofroundoff and quantizationwith the
other disturbances in the system.

Sec. 9.6

343

Numerics
(b)

(a)

1m

H(z)

NL

Re

-1

Figure 9.11 (a) Discrete-time system with one nonlinearity N L. (b) Using
the method ofdescribing function.

Nonlinear Analysis Using Describing Functions
If there is only one nonlinearity in the loop, it is possible to use the method of
describing function to determine limit cycles approximately.
Consider the system in Fig. 9.11(a). The method of describing function can
be regarded as a generalization of the Nyquist criterion. The critical point -1
is replaced by -l/Yc(A), where Yc(A) is the describing function of the nonlinearity. The describing function characterizes the transmission of a sinusoidal
signal with amplitude A through the nonlinearity. The method predicts a limit
cycle if

1
H( eiWh) =-Yc(A)
{compare with Fig. 9.11(b)]. The frequency, (01 (from the Nyquist curve), and
the amplitude, A 1 (from the describing function), at the intersection are the estimated frequency and the estimated amplitude of the limit cycle. The describing
function of a roundoff quantizer is

o
2n 2- 1 0 < A < 2n 2+ 1 0

The function Yc only takes real values. Its smallest value is zero and its largest
value is 4/lr ~ 1.27. The function is graphed in Fig. 9.12. This means that
the critical part for quantization consists of the part of the negative real axis
from -00 to -0.78. Describing function analysis thus predicts oscillations due to
quantization if the Nyquist curve of the loop gain intersects this line segment.
For stable systems this means that quantization will not give rise to oscillations if the amplitude margin is larger than 1.27. Describing function analysis
predicts oscillations for all systems that are open-loop unstable.

Implementation of Digital Controllers

344

Chap. 9

1

Ol....-_.l...-.~-----'-----~------L-_------'

o

4

2

Alb

Figure 9.12 The describing function of roundoff.

Example 9.4 Roundoff effects
Consider the system in Example 3.4 with the pulse-transfer function
O.25K
H(z) ::;: (z - l) (z - 0,5)
In Example 3.4 it is shown that the closed-loop system without roundoff is asymptotically stable if K < 2. With roundoff of the error signal in Fig. 3.5, the method
of describing function predicts that there will be a limit cycle if K is greater than
about 1.3. Figure 9.13 shows the behavior of the system for a roundoff level of
•
8 ::;: 0.2. The limit cycle is clearly noticeable for K ::;: 1.6.

Linear Analysis
The effects of roundoff and quantization may also be estimated by linear analysis. The idea is to represent the operations by their ideal models and an additive
disturbance ea . The D·A and A-D converters are then simply represented as linear gains with a disturbance that models the quantization. With fixed-point
calculations, the additions are exact. There will, however, be errors in multiplications, These are represented as exact multiplications, with an additive error,
which represent the roundoff This is illustrated in Fig. 9.14.
The errors may be modeled as deterministic or stochastic signals. In a
deterministic model, the error is modeled as constants having the sizes of quantization errors and with the resolution in the arithmetic calculations. In the
stochastic model, the error introduced by rounding or quantization is then described as additive white noise with a rectangular distribution. The errors at
different sampling times are thus assumed to he uncorrelated. If the quantization is done as rounding, then the error is equally distributed over the interval
(-8/2,0/2) , where 8 is the quantization step. If the quantization is done as
truncation, the error is equally distributed over (0,0). A rectangular noise distributed over an interval of length g has a variance of ~2/12.
By using the linear models of roundoff and quantization, it is possible to
reduce the problem of estimating the effect of the roundoff and quantization

Sec. 9.6

345

Numerics

(a)
~

II

:;:l

E' 1 ~
~

•

•

~ .. -

-" •

o

_

.. 41 fI

ll!.& iII "-L" fA.&;; I1111

.»

,u

4..U

Ill"

IIl"W'..

OO"'----~-~~~-~-~-~-~--L_--~~_.--...I

o

50

(b)

OH-------------------'-------------'
o

(c)

50

+

•

00
0

~

-

-

•

+
o
I

I

-

•

-.

.. ... ....
II.. ...
..
o'

-

-

"""

-

1-

....

• 0

..
.......

..1It

""
~ lilT'

.....

....
...jI.

"....

_

...........

• .. lit

-'.II •

0----------------'"----------'

o

50

Time
Figure 9.13 The output of the system in Example 9.4 when D ~ 0.2 and
(a) K ::;; 0.8, (b) K ~ 1.2, and (c) K =: 1.6.

to the problem of calculating responses of a linear system to deterministic or
stochastic inputs. By using the linear model, it is possible to assess the effects
of quantization qualitatively without going into detailed calculation. It is also
easy to compare roundoff with other disturbances in the system. In the linear
model, the effect of roundoff in the A~D converter is the same as the effect
of measurement noise. The effect on the control signal may be substantial for
those frequencies where the controller has high gain. The effect of roundoff in
the D-A converter is the same as a disturbance in the process input. Because the
process normally attenuates high frequencies, the effect on the process output
is normally small. Remember, however, that the linear model does not capture
all aspects of roundoff.

y

Q
Figure 9.14 Linear models for multiplication with roundoff.

346

Implementation of Digital Controllers

Chap. 9

o-.:...-

~

l~-..,....-::-,---------------------t

I

__

.J--

o

I

...L..__

_____l

150

100

50

1.02

0.98

o

50
100
150
0.05,..----- - - - . . . , . - - - - - - - - - - - , - - - - - - - - - ,

50

100

Time
Figure 9.15 Control ofa double integrator with a quantized A·D converter.
The sampling period is 1 s and the quantization level is 0.02. The middle
curve shows the quantized as well as the unquantized output.
se~ection

of Resolution of A-D and o.A Converters

Thday the resolution ofthe D-A converters are about10bits and theA-D converters have normally 14 bits. With double-precision arithmetic the computations
are typically done with a resolution of 64 bits. This implies that it is the accuracy of the converters that have the largest influence on the performance. A
couple ofexamples ill ustrate the inftuence ofthe quantization in the converters.
Example 9.5 Effects of A·D quantization for the double integrator
Figure 9.15 shows a simulation of digital control of a double integrator where the
AD converter is quantized with the level 0.02. The controller is the same as the
one used in Sec. 5.7. It is given by
R(q)u(k) '" T(q)u((k) - S(q)y(k)

where
R(q)

= {q -

l)(q + 0.188)

S(q) ;:: O.715q2 - 1.28lq + 0.580
T(q) == (3.473q2 - 2.555q + 4.700) . 10-

(9.14)
2

Sec. 9.6

347

Numerics

2

00
.....
~

r;I'l

~

0 ."" ,

'!ih
r;I'l

E

I--l

-2
-6

-2

-4

o

Real axis
Figure 9.16 Nyquist curve for the sampled loop gain for the double integrator, when using the controller defined by (9.14).

and the sampling period 1 s. The simulation clearly shows that there is a limitcycle oscillation where the output changes one quantization level. The period is
28 s. The describing functions analysis predicts a limit cycle with period 39 8. Set!
Fig. 9.16, which shows the Nyquist curve of the sampled loop gain. The describing
function method predicts that the amplitude of the oscillation is 8/2. which agrees
well with the behavior of the output of the process. Describing function analysis
gives correct qualitative results in this case, but the prediction ofthe period is poor
because the signals deviate significantly from sinusoids.
We will also use another method to estimate the amplitudes of the fluctuations caused by the quantization. To do this, first observe that the output signal
oscillates with one quantization level up or down at widely spaced intervals. This
means that the controller output is given by the pulse response of the controller,
that is,
-

~~~ ~

- 0.710 + 0.700z- 1 - O
.145z- 2 + O.0134z- a. ,.

(9.15)

multiplied by the quantization level.This gives an excellent prediction ofthe fluctuations in the control signal. Compare with Fig. 9.15. Notice that the first coefficient
in the expansion of -8/ R is equal to -so.
•

This example shows that the periodic ripple in the control signal due to quantization in the A-D converter can he estimated from a simple pulse-response
calculation. In the next example we will analyze the effect of quantization in
the D~A converter.

Implementation of Digital Controllers

348

Chap. 9

1
+'

:;l

p.,
-l->

::l

0

0

0
0.05

100

150

50

100

150

50

100

150

50
-----r

"'C
III

....
...
til

~

es

::l
0'
k

0

;:J

-0.05
0

0.05
+'

::l

Q,
~

0

1-4

-0.05

0

Time
Figure 9.17 Digital control of the double integrator with a quantized D-A
converter.

Example 9.G Effects of D·A quantization for the double integrator
Figure 9.17 shows a simulation of the double integrator with a D-A converter
with quantization level 0.01. The quantization causes a limit-cycle oscillation. The
process output is, however, much more sinusoidal than with A-D quantization. The
reason for this is that the nonlinearity is just before the process that attenuates
high frequencies. AF, before, the describing function predicts an oscillation with
the period 39 s whereas the actual period is 39 s, The amplitude of the oscillation
in the process output can be estimated by evaluating the magnitude of the pulsetransfer function ofthe controller at the period of oscillation. The controller gam is
approximately 0.12. With 8 == 0.01, the amplitude of the output can be estimated
to 0.04 and the measured amplitude is about 0.03. See Fig. 9.17.
Notice that the oscillations due to the quantization in the D-A converter can
be avoided if the output of the D-A converter is fed back into the control law in
the same way as was done to avoid windup.
_

By using the insightobtained from the examples, some recommendation onthe
selection ofresolution of the converters can now be given.
The resolution of the A-D converter must be chosen so that it gives the
desired precision in the process output. One should investigate whether quantization can give rise to limit-cycle oscillations. The magnitude of the ripple in
the control signal caused by the A-D quantization should be investigated. This

Sec. 9.7

Realization of Digital Controllers

349

can be estimated simply from Eq. (9.15). If the ripple in the control signal is
too large, better resolution of the A-D converter is required.
To determine the required resolution of the D-A converter, the frequency
of a possible limit cycle is first determined. If there is a limit-cycle oscillation,
the amplitude can be estimated crudely from tbe process gain at the oscillation
frequency, or more accurately using the theory of relay oscillations quoted in
the References. The estimates obtained in this way will typically give the order
of magnitude. It is recommended to use simulation to get more accurate results.
The procedure is illustrated by an example.
Example 9.7 Choosing resolution in D·A and A·D converters
Consider the double integrator that we have investigated. Assume that the process
output is in the range [-1, 1]' that the range of the control signal is [-0.04,0.04],
and that it is desired to control the output with a precision of 1%. If we let each
converter contribute 0.5%1 the A-D converter must have a resolution of at least
0.005, which is equivalent to 9 bits. Because the gain of the process at the limit
cycle is about 15, the resolution of the D-A converter must be better than 0.00033.
With the given signal range, this corresponds to 1 part in 240, or 8 bits.
•

9.7 Realization of Digital Controllers
The previous section illustrated how roundoff and quantization in A-D and D-A
converters influence tbe behavior of the system. Roundoff errors in the computations of the control law also cause quantization, which can be modeled and
analyzed in the same way as converter quantization. The quantization arising
from the computations depends critically on how the computations are organized, for example, on how the sampled-data controlleris realized. This section
discussesdifferent realizations. Some advantages and disadvantages ofdifferent
methods are given.
Assume that we want to realize the controller

Some different realizations are
• Direct form
• Companion form
• Series (Jordan) form
• Parallel (diagonal) form
• Ladder form

• o-operator form

Implementation ofDigital Controllers

350

Chap. 9

Coefficient-Pole Sensitivity
Finite precision in the representation ~f the coefficients ofthe controllergives a
distortion of the poles and zeros of the controller. The following analysis gives
quantitative results for the sensitivity ofthe roots of a polynomial with respect
to changes in the coefficients. Consider a linear filter with distinct poles in Pi
and the characteristic polynomial

The characteristic polynomial A can be regarded as a function of z and tu, When
the parameter ai is changedto a l +oai, the poles are changed fromp, to Ph +oPIr..
Hence

The first term on the right-hand side is zero. If terms ofsecond order and higher
are neglected, it follows that

s

oA/oai

Pk ~ - 8A/8z

Because
and
the following estimate is obtained:

(9.17)
If the polynomial has a root Pk with multiplicity m Eq. (9.17) hecomes
l

(9.18)
If the filter is stable, then Iphl < I and the numerator of (9.17) has its largest
magnitude for i "" n, The coefficient an is thus the most sensitive parameter.
Furthermore, the denominator will be small if the poles are close, which then
makes the system sensitiveto changes in the coefficients. Equation (9.18) shows
that the sensitivity is even higher if the polynomial has multiple roots. Equations (9.17) and (9.18) may be used to determine the conditioning numbers for
the transformation from the diagonal form to the companion form. It follows
from the equations that the computation of companion forms may be poorly
conditioned.

Sec. 9.7

Realization at Digital Controllers

351

Direct- and Companion·Form Realizations

The most straightforward way to realize (9.16) is to write it in the direct form
m

j:::O

y(k) ==

m

i= J

L biU(k - i) - L a,y(k - i)

It is then necessary to store y(k - 1)' y(k - 2), .. . ,y(k - n), and u{k - 1), ... ,
u(k - m), that is, n + m variables. The direct realization has n + m states
and thus is not a minimal realization. The controllable or observable canonical
forms, see Sec. 3.4, have n states. The direct form has the advantage that the
state variables are simply delayed versions ofthe input and output signals. This
means that the state does not have to be recomputed when the parameters are
changed. Both the direct form and the companion form have the disadvantage
that the coefficients in the characteristic polynomial are the coefficients in the
realizations. This makes the realizations extremely sensitive to computational
errors if the system is of high order and if the poles or zeros are close to one as
discussed before.

Well-Conditioned Realizations
The difficulty associated with the companion form can be avoided simply by
representing the system as a combination of first- and second-order systems. If
the dynamic system representing the controller has n r distinct real poles and
nc complex-pole pairs, the control algorithm may be transformed to the modal
form
i :::: 1,. . . .n,

i :::: 1, ... .n;
nr

(9.19)

It,

u(k) == Dy(k) + Lnz;(k) +

LoTUj(k)
i=1

1= I

where the complex poles are represented using real variables. Notice that Z, are
scalars and Vi are vectors with two elements. To avoid numerical difficulties, the
control law should be transformed to the form of (9.19), which is then implemented in the control computer. The transformation may easily be done in a
package for computer-aided design. It is easy to use fixed-point calculations and
scaling for equations in the form of (9.19). If the control law has multiple eigenvalues, a Jordan canonical form replaces (9.19). An eigenvalue A. of multiplicity
3 thus corresponds to a block

z(k + 1)

=

[~ 1 0)
A 1

o

A

z(k) +

[/h) y(k)
/32
/33

Implementation of Digital Controllers

352

Chap. 9

Ladder Realizations
Ladder realizations are other representations that avoidthe coefficient sensitivity in the implementations. One representation ofthe ladder networkis obtained
by making a continued-fraction expansion in the pulse-transfer operator in the
following way:
1

H(z) :; ao +

(9.20)
1

1hz +

1

al+

1

P2Z +

1
+---

an-l

Another realization is obtained by making the continued-fraction expansion in
Z-l. The ladder forms have low sensitivity against coefficient errors and roundofferrors. If
= B(z)
H( )
z
A(z)
where degA(z) ::;; deg B(z) ::: n, the coefficients (Xi and
in the following way: Compute an = B(z)divA(z), Adz)
B(z) modA(z) and repeat for i = 1 to n

Pi ::: At divzB
a,

j

= B, divAi+1

Pi can be computed
=A(z), and Bl(Z) :::

A i +l = Ai mod aS,
Bt+l :::::

B, mod Ai +1

Theladder-network representation can beexpressed by the following state equations:

Pn xll(k + 1) ::: - 1 (xn l (k) an-l
y(k) = Xl (k) + aou(k)

xn(k))- -

1

an

xn(k)

Sec. 9.7

Realization ofDigital Controllers

353

y

,

x·

1

u

+

----''---..-.t

1

2. ......---'~~(Xl-r:!)
al

Figure 9.18 Block diagram ofa ladder network representation ofthe transfer function (9. 20).

A block diagram of the representation is shown in Fig. 9.18. The name ladder
network derives from the shape of the graph.
Short-Sampling-Interval Modification

We have shown that it is useful to transform the system to a well-conditioned
form before it is implemented on a digital computer. This reduces the coefficient
sensitivity of the realization. An additional modification that is useful when
the sampling period is short will now be discussed. Consider the compensator
described by the general-state model (9.8) and (9 .9). For short sampling periods
the matrix F is close to the unit matrix, that is, all the eigenvalues are close
to one. Further, the matrix G is proportional to the sampling period. With a
short sampling period, the matrices F and G may therefore differ by several
orders of magnitude. By rewriting the state equation it is possible to obtain a
representation that is better conditioned. It is convenient to rewrite equation
(9.8) as

x(k + 1) == x(k) + (F - I)x(k) + Gy(k)

(9.21)

wbere the matrix F - I is also proportional to the sampling period h. The numerical representation ofF - I requires fewer decimals than the representation
of F itself. The term (F - I)x(k) + Gy(k) represents a correction to the state,
which will be small if the sampling period is short. This representation is particularlyuseful in fixed-word-length computations. The state is stored in double
precision. The change in the control is calculated using single-precision multiplication, and the product is then added to the stete. Compare with the discussion
of the scalar-product computation in Example 9.3.

Implementation 01 Digital Controllers

354

Chap.9

The 8-0perator
The system (9.21) can be written as
x(k + 1) = x(k) + h(Fx(k) + Gy(k))

(9.22)

where
hF

= F-1

kG

~ G

Instead ofthe shift. operator wecan now introduce the O..()perator that is defined

by
q-l
0=h

(9.23)

Equation (9.22) can now be written as
8x(k)

= Fx(k) + Gy(k )

A general pulse-transfer operator can be transformed from shift:; form to b-form
as
H( ) ::; B(q)
q
A(q)

= B(oh + 1)
A(8h + 1)

=

~(8) = H(8)
A(o)

The 8..()perator is thus equivalent to the shift operator. All the analysis done
for the shift; operator can be translated into O-form. The 8-operator has the
property
of(kh) = f(kh + h) - f(kh)
h

that is) it can be interpreted as the forward-difference approximation of the
differential operator p = d/dt. In this respect the o..()perator is "closer" to
the continuous-time domain than the shift operator. For instance. the stability
region in the 8-form is a circle with radius l/h and with the origin in -1 1k.
When h -+ 0 the stability region becomes the left half-plane.
The a-operator representation has the property that it translates into the
corresponding continuous-time system. when the sampling interval approaches
zero. Hence

lim H(8) = G(8)

h-+O

where G is the continuous-time transfer function. This implies, for instance,
that the zeros of the transfer function in the t5-form approach the zeros (finite
as well as infinite) of the continuous-time transfer function.

Sec. 9.7

355

Realization of Digital Controllers

Example 9.8 Double integrator in o-form
Consider the double integrator G{s) ;;;; 1/82 , Then

When h goes to zero we get
-

lim H(o) '"

1.-0

1

~2

;;;;

G(o)

(J

Notice that the o-form also has "sampling zeros," 0 ;;;; -2/h, Thiszero will approach
-IX) when h -+ O.
•
Heuristically we can interpret the o-operator as a shift of origin and scaling.
This is a common trick in numerical analysis and has the consequence that
the a-form can obtain hetter numerical properties than the shift operator. A
controller in 8-form can be described by the state equations

8x(kh)
u(kh)

= Px(kh) + Gy(kh) ~ d(kh)
= Cx(kh) + Dy(kh)

(9.24)

The shift operator and its inverse are implemented exactly using an assignment
statement. To make a realization in a-form we must implement the operator 0- 1 .
Solving (9 .24) for x(kh} gives

x(kh) = a-1d(kh)

= x(kh -

h) + hd(kh)

The extra amount of computations compared to the shift form is marginal. One
extra vector addition is necessary. Notice that because hd(kh) is normally much
smaller than x(kh - h), it is necessary to represent x(kh - h) with a sufficient
word length.

An Example

An example illustrates the properties of the different realizations. Consider a
system with the pulse-transfer function

b4
H(z) = (z+a )4

(9.25)

where b = 1 + a, The system has multiple poles that are close to one when
a is close to -1. The previous discussion then shows that the system is very
sensitive to coefficient perturbations.
To obtain the computer program, a state-space realization of the pulsetransfer function is first determined. The computer code is then obtained as
a direct implementation of the difference equations. There are many possible
choices of the coordinate system in the state-space realization, A controllable

Implementation of Digital Controllers

356

Chap. 9

Listing 9.3 Computer code for implementation of (9.25) based on the

shift-controllable canonical form,

begin
y;=b*b*b*b*x4
s ;=-a1*x1-a2*x2-a3*x3-a4*x4+u
x4:=x3
x3:=x2
x2:=xl
x1 :=s
end

canonical form in shift and "-operator and a Jordan canonical Conn are chosen
to demonstrate that the numerical properties may differ considerably. For the
shift-operator controllable form we implement
b4

(z + 0)4 =

b4
Z4

+ 4az3 + 6a 2z 2 + 4a3z + a4

The code is given in Listing 9.3. The numerical values of the parameters for the
controllable canonical form when a = - 0.99 are given by
a1 = 4a = -3.96
03

= 4a3 ::;: -3.881196

a2

= 60 2 = 5.8806

a4 = a4 ::; 0.96059601

Listing 9.4 gives an implementation based on the Jordan canonical form. By

rewriting the Jordan form as (9.21) Listing 9.5 is obtained. Notice that this
slightmodification gives a significant improvement over the form in Listing 9.4,
because the state is now obtained by adding a small correction to the previous
state.

Listiq 9.4 Computer code for implementing (9.25) based on the Jordan

canonical form.

begin
x4:=-a*x4+b*u
x3:=-a*x3+b*x4
x2:=-a*x2+b*x3
xl:=-a*xl+b*x2
y:'=x1
end

Sec, 9.7

357

Realization of Digital Controllers

Listing 9.5 Rearrangement to short-sampling-interval modification of the
code in Listing 9.4.

begin

x4:=x4+b*(u-x4)
x3:=x3+b*(x4-x3)
x2:~x2+b*(x3-x2)

xl:=x1+b*(x2 - x1)
y:;x1
end

For the 5·form we implement (in controllable canonical form)

b4

b4

---- =
=
(8 + 1 + a)4
(~ + b)4

--=-:-'-~::--

b4

=:::---::'7"""'---:--:'

8' + 4bt53 + 6b 282 + 4b3~ + b4
b4

:;:--------6' + bl63 + b-R + ba5 + b4
where b = 1 + a. Notice that b is a small number when a is close to -1. The
system is implemented using (9.21), where P and G have the same form as
for the shift-operator companion form in Listing 9.3. The implementation in
o-companion form is given in Listing 9.6, where bi are the coefficients in the
characteristic polynomial.
The implementation of the discrete-time system also includes a monitor
system that runs the program each sampling period. Notice that the code contains only addition, multiplication, and assignment statements; thus it can
easily be implemented using many computer languages. Because assignment
statements only transfer data, they will not introduce any numerical errors.
This means that 0 and 1 in a standard matrix representation are represented
exactly.

Listing 9.6 Computer code for implementing (9.25) based on a-operator
controllable canonical form.

begin

y:=b*b*b*b*x4
s:=-bl*xl-b2*x2-b3*x3-b4*x4+u
x4:=x4+x3
x3:=x3+x2
x2:=x2+xl
x1:=xl+s
end

358

Implementation of Digital Controllers

Chap. 9

(b)

(a)

1

.... 1 {
;:l
Eo
::l

0

0
0

500

500

1000

1000

500
Time

1000

(d)

(c)

.... 1
::l

1

\

0-

+"

'-

+.l

8

::l
0.
~
::l

0

500
Time

1000

0

0

Figure 9.19 Step responses for the system (9.251 for different implementations and different values of a: shift-operator controllable canonical form
(Listing 9.3) (dashed), Jordan form (Listing 9.4) and o·operator controllable
canonical form (Listing 9.6) are both the fun line. (a) a == -0.9, (b)a ~ -0.97,
(c) a ::: -0.98, and (d) a ::: -0.99.

Figure 9.19 shows simulations using ~T~. The simulation is simply
an iteration of the state equations in Listings 9.3, 9.4, and 9.6. The results are
obtained when chopping the result of all operations to seven digits. The figure
shows the results when different values of a are used. For a = -0.9 all the
implementations give compatible results, as shown in Fig. 9.19(a). When a is
decreased, the shift-operator controllable canonical form is very sensitive and
the solution is inaccurate. The other two implementations give approximately
the same results. They will, however, differ wheneven lower numerical precision
is used. The modified Jordan form is better than the c-operator controllable
canonical form when a is decreased further.
The sensitivity of the shift-operator controllable form with respect to parameter changes is given by (9.18). Perturbing the characteristicequationwith
a constant term f,

gives the roots

z

= 0.99 + (_£)1/4

The roots are moved from 0.99 to a circle with origin at 0.99 and the radius
r := 1£1 1/ 4 • If e =::. 10-8 then r = 10- 2; that is, the system can be unstable even
if the perturbation is very small.

Sec, 9.7

Realization of Digital Controllers

359

Making a similar calculation for the 0 companion form we get

which gives the roots

o == -0.01 + ( _ C)1/4
The roots are moved from -0.01 to a circle with origin at - 0.01 and the radius
r == lel l / 4 . If e =: 10- 8 then r ;:;; lO-2t which is the same as for the shift-operator
case. Notice, however, that the relative variation in parameters required to make
the system unstable is two orders of magnitude larger with the a-operator. The
companion form is thus less sensitive to parameter perturbations than the
shift companion form. Notice, however, that the Jordan realizations in shift or
a-forms are superior.

o

Effects 01 the Sampling Period

The sampling period also has a considerable influence on the conditioning, as
shown by the following example.
Eumple 9.9 Numerical precision required for PI-control
Consider the formula for updating the integral in a Pl-controller:
i(kh + h) =i(kh) + e(kh)· h/1i

If the sampling period is 0.03 s and the integration time is 15 min ;:;: 900 S, the
ratio h/Ti becomes 3.10- 5 , which corresponds to about 15 bits. Th avoid that the
quantity e(kh)h/Ti is rounded it is thus necessary to make the computations with a
longer word length. This is the reason why the integral term is often implemented
in 24·bit representation in dedicated Pl-eontrollers,
_

The examples show that a rapid sampling requires a high precision in the coefficients.

How to Choose Representations
The selection of representations is crucial when implementing a control law
using a digital signal processor or with custom VLSI. It is less crucial for irnplementa tions using microcomputers with floating-point hardware. The companion
forms should be avoided, because so much is gained by using series or parallel
forms. Each block should he implemented on Jordan form. This is particularly
important for high-order compensators and short sampling periods. For loworder controllers implemented with floating-point hardware and with poles well
inside the stability area, the choice of realization is less crucial. It is, however,
good practice to hedge against possihle numerical problems.

Implementation of Digital Controllers

360

9.8 Programming

Chap. 9

"

Practically all discrete-time controllers are implemented in a real-time operating
system. In some systems the different parts of the algorithms may be distributed
among different processors. The communication can then introduce time-varying
delays (jitter) in the sampling period. Programming is an important aspect of
the implementation of a control system, both with respect to the efficiency of
the system and the time required for the implementation.
The effort required and the approaches used depend on the available software and the nature of the control problem. The code is typically written in
C or C+ +. Ada, which was developed by the U.S. Department of Defense for
computer-control applications, is the first language designed and developed for
real-time applications. The character and the difficulty of the programming depend very much on the application. The requirements on operator communications are critical. The code required for operator communication is often much
larger than the pure control code. A few examples illustrate this.

A Simple Dedicated Control System
Consider a simple control loop that has a few measured signals, a few outputs, and limited operator communication. Information may be displayed to the
operator, and the operator may have a few buttons and a few dials. The programming of such a system is very simple. If a real-time clock is available, the
code is in essence given by Listing 9.7.
The first line is simply a procedure that halts execution until a clockinterrupt occurs. The procedure Regulate is the code required to implement the
desired control algorithm.
The procedure Display in Listing 9.7 computes some variables and displays
them in analog or digital form. Notice that it is straightforward to introduce
facilities for the operator to change parameters simply by introducing them as
analog inputs.
The program in Listing 9.7 is fairly easy to debug. The procedures Regulate
and Display are simple sequential procedures that can be tested off-line. It is
also easy to check that the wait procedure gives an interrupt every sampling
period. It will fail only if the time required to execute the procedures is longer
than one sampling period. This may be tested by timing.

Listing 9.7 Computer code skeleton for a simple control loop.

repeat
Wait for clock interrupt
Regulate
Display

forever

Sec. 9.8

361

Programming

False

Figure 9.20 Flow chart fora multiloop control law with two sampling rates.

More Complicated Control Loops
The principles used in the program in Listing 9.7 may be extended to more
complicated control systems with several loops having different sampling periods. A computer code, which may be represented by Fig. 9.20, is then obtained.
The program PO in Fig. 9.20 runs at the sampling rate given by the clock. The
programs Pl, P2, and P3 run each every third clock pulse. In order to obtain
the representation in Fig. 9.20, it is necessary that the time required to execute
each path be shorter than the shortest sampling period in the system. This is
easy to do for systems with long sampling periods. For systems with fast sampling, it may be necessary to split up the computations in a tedious, unnatural,
and error-prone fashion.
It is comparatively easy to debug the program shown in Fig. 9.20 if there
are few paths and if the procedures are simple. The difficulty in debugging
grows rapidly with increasing system complexity. New ideas and concepts are
needed to handle such problems in a convenient way.

Concurrent, or Real-Time, Programming
It is natural to think about control loops as concurrent activities that are running in parallel. However, the digital computer operates sequentially in time.
Ordinary programming languages can represent onlysequential activities. Thus
a key problem is to map a number of parallel concurrent activities into a sequential program. This may be done manually, as shown in Fig. 9.20. There are
also special-purpose software-real-time operating systems-that make it possible to schedule tasks without making a strict sequential program. It is outside
the scope of this book to discuss concurrent programs in detail. The basic ideas
are given, together with a few examples.
The notions of process and task are fundamental concepts in real-time programming. They represent activities that may be thought of as running in parallel in time. Using these notions, it is possible to think of the computer running
several activities in parallel. Hence,a real-time activity may be structured in the
same way as a sequential activity is structured, using the notion of procedure

362

Implementation of Digital Controllers

Chap. 9

or subroutine. The real-time operating system will organize the execution of the
processes so that the desired result is obtained. 1b do this, a priority is associated with each process. Processes may also he scheduled to run periodically or
in response to events such as interrupts or completion of other tasks.
The problem of shared variables and resources is one of the key problems
in real-time programming. If different processes are using the same data, it is
necessary to make sure that one process does not try to use data being modified
by another process. If two processes may use the same resource, it is necessary
to make sure that the system does not deadlock in a situation where both
processes are waiting for each other.
Timing is a third problem. Computing power must be sufficient to allow
all activities to be completed in the required time.

AController with Operator Interaction
A single control loop with operator .interaction is one of the simplest examples
of real-time programming. The task could be to run a control loop like the one in
Listing 9.7 with sampling rate of20 ms and to provide an interface so that the
operator may change parameters from a keyboard or a terminal. Assume that
the operator changes parameters by typing in a character string on the terminal.
Because the time required for this is considerably longer than one sampling
period, it is necessary to break down the operation into many small pieces in
order to use the solution shown in Fig. 9.20. This is both tedious and unnatural.
It is much more natural to think. of the problem in the form of two concurrent
processes, One process, control, should be run once every sampling period. The
other process, operator communication , may run whenever the process control is
idle. 1b ensure that control actions are taken at regular sampling periods. it is
necessary to impose the rule that the process control has priority over operator
communication and that it may interrupt the operator communication at any
time. For convenience, the rule that the process control runs to completion
once it has started is also introduced. In a case like this , control is called the
foreground task, or foreground process, and operator communicoium is called a
background task, or background process.

Rear..Tlme Operating Systems
For problems with only two processes, it is not difficult to write an operating
system that administrates the processes. Such a system may typically be written
in less than 100 lines of assembly code.
The simple operating system may be extended to several processes. It
is: however, a major task to make a program that can handle more complex
situations, Such an operating system, which is also called a real-time operating
system, may occupy anything from a few kilobytes to 20 kilobytes of code.
The real-time operating systems allow definition of tasks, or processes, in
a high-level language such as Pascal, Modula 2, C, or C+ +. It is also possible to
run processes at regular intervals or in given relationships to other tasks. Processes may also be introduced, started, and removed on-line. Priorities between

Sec. 9.9

Conclusions

363

different tasks may be introduced and modified. The introduction ofreal-time operating systems was one of the major innovations when process-control computers were introduced in the mid-1960s. Examples of such operating systems are
RSX from Digital Equipment Corporation, VxWorks® from Wind River Systems ,
psoS® from Integrated Systems , and QNX® from QNX Software Systems. Processes, or tasks, have also been introduced into simple languages such as BASIC.
Real-time operating systems are large general-purpose programs, which
are often written in assembly code. They are difficult to maintain and modify.
There has been a need to have real-time operating systems that can be tailored to specific applications. Computer languages with facilities for real-time
programming have therefore been developed. Concurrent Pascal and Modula2 are such languages. The language Ada is a standard tool for implementing
computer-eontrol systems in military systems .

DDC..Packages
Special techniques are used to program control systems consisting of a large
number of identical control loops. The code is often structured as follows:
Read all analog inputs and store in a table.
Convert all signals to engineering units and store results in a table.
Apply the control algorithm sequentially to all values in the table using
controller parameters stored in a parameter table .
Perform D-A conversion to all variables stored in the output table.
Programs of this type are called DDC-packages. The control algorithms are
typically of the PID·type. Modules for gain scheduling, logic, supervision, and
adaptation may also be available. The packages are easy to use because all programming is reduced to entering the appropriate data in the tables. Programs
of this type are called table-driven.
DDe-packages usually also contain modules, that make it possible to make
startup, shutdown , and alarm handling. Today these descriptions are often
based on the standard lEe 1131-3 for function-block languages.

9.9 Conclusions
Implementation of control laws using a computer is discussed in this chapter.
The key problem is to implement a discrete-time system. The principles for doing this have been covered in detail. It is straightforward to generate the code
from the control algorithm. The importance of prefiltering to avoid aliasing has
been mentioned . Sophisticated nonlinear digital filtering for removing outliers
has also been discussed. The computational delay is influenced considerably
by the organization of the computer code. Difficulties that arise from saturation in actuators and ways to avoid these difficulties are discussed. This also
automatically gives a solution to mode switching and initialization.

364

Implementation of Digital Controllers

Chap. 9

Numerical problems and consequences of finite word length are also discussed. It is found to be very beneficial to transform the equations describing

the control law to a form that is numerically well conditioned. Operational issues like mode switching and operator-machine interaction are discussed. There
are many new possibilities in this area. Finally programming of control algorithms is discussed. Although the presentation is fairly short, the information
given should be sufficient to implement control algorithms on minicomputers
and microcomputers using high-level languages.

9.10 Problems
9.1 Consider control of a double integrator with a sampling period of 1 s, Calculate
the deadbeat control for the system obtained using an antialiasing filter with the
transfer function
G(s)

= 82

1
+ l.4s + 1

Compare the deadbeat strategy obtained with the deadbeat strategy for the pure
double-integrator using simulation.

9.2 Write a program for computing the scalar product of two arrays
begin
5;"0

for i :-=1 to n do
5 : "'s+a(i] *b [i]

end

in each case.
(a) s: integer, a, b: arrays of integers.

(b)

double-precision integer, a, b: arrays of integers.
(c) s: real, a, b: arrays ofreals.
(d) s: double-precision real, a, b: arrays of reals.
5;

Compare the computing times and precision. Try to find computers that have
floating-point calculations in software, as well as in hardware.
9.3 Consider Example 9.9. Discuss the possibilities of using two loops with different
sampling periods in order to improve the precision in the calculation.
9.4 Write a code for a digital PI-controller where the antiwindup is implemented as an

observer with the time constant To9.5 Writea code for a digital PID-controller where the antiwindup is implemented as
a deadbeat observer.
9.6 Write a code in your favorite high-level language for a digital PID.algoritlun where
antiwindup is implemented as an observer with time constant To. Determine the
number of operations required for one iteration. Compile the program. Detennine
how many memory calls it requires. Time the program. How do the measured
computing times relate to the number ofoperations and the computing times given
in the computer manual?

Sec. 9.10

365

Problems

9.7 Consider the control algorithm of (9.1), where Xm is considered to be an input.
Assume that the state, the control variable, and the process outputhavedimensions
n;r, njJ, and ny, respectively, and that the matrices are full. Determine the number
of additions, multiplications, and divisions required for one iteration.
9.8 Consider the control algorithm of (9.2). Write a code that implements the control
algorithm in your favorite high-level language. Compile the code, determine how
much memory space the code occupies, and determine the execution time. Try to
find a good simple formula for determining the execution time.
9.9 Repeat Problem 9.8 but now use a subroutine to perform a scalar product. Discuss
how computing time and storage requirements are influenced by the restructuring
of the program.
9.10 Consider the control algorithm with rejection of outliers given by Eqs. (9.1) and
(9.4) . Make an estimate of the number ofcomputations required for one iteration.
(Hint: A matrix multiplication ofan 11. xp matrix by a p x r matrix requires N = npr
operations, where an operation corresponds to oneaddition and one multiplication.
Solution of the equation
Ax:;;;; B

where A is n x 11. and B is It X p, requires approximately

operations, where the major part of the calculations is the triangulation of the
matrix A.)

9.11 Consider a discrete-time system characterized hy the pulse-transfer function
H(z) _
1
- (z - a)n

Calculate the sensitivity ofthe poles with respect to the parameters using Eq. (9.18)
in each case.

(a) The filter is in companion form.
(b) The filter is in Jordan canonical form.
9.12 Make a flow chart similar to Fig. 9.20 for a system with loops having sampling
periods of 1, 2, 5, and 60 5.
9.13 Consider a system with the transfer function
1

H(z) == - - - -ll-1; - - - z'l + a lz - + ... + an
Assume that the system is realized with fixed-point arithmetic. Let the roundoff be
described as normal rounding to integers. Show that the condition for a steady-stete
error k with no inputs is given by
II

k + LQ(aik)
i=l

=0

Implementation of DigHal Controllers

366

Chap. 9

Furthermore, show that the condition for a limit-cycle oscillation with a period of
two sampling periods is
/I

k + 2)-1YQ(Q,k)
I"

=0

1

9.14 Consider the following algorithm for a PI-controller:
Min uc y
e:=uc-y
v: ;;he+i

u;=max(min(512,v) ,0)
Daout u
i:"'u+k*h*e!ti

Assume that the A-D and D-A converters have a resolution of Bbits and that all
calculations are made usingintegers. What is the word length required to represent
variable i if overflow should be avoided? Use k :=. 50 and (a) h = 1, ti =: 300 or
(b) h = 0.01. ti = 1500.
Discuss how the result is influenced by the sampling period.

9.15 Three different algorithms for a PI-controller are listed.. Use the linear model for
roundoff to analyze the sensitivity of the algorithms to quantization in A-D and D-A
converters and roundoff in the multiplications. Assume fixed-point calculations.
Also, disCU88 the word lengths necessary for the algorithms.
Algorithm 1:
e:"'uc-y
u: =k* (e+h*i1ti)

i:=i+e-h

Algorithm 2:
e:"uc-y

u:"k*(e+i)
i;=H-e*h/ti
Algorithm 3:

e:=uc-y
u;"Oi"'k*e
i;"'i-fok*h*e/ti
9.16 Consider a dynamic system with the pulse-transfer function

There are manyways to introduce the statas in a state-space representation. Show
that the system has the following state descriptions:

sec. 9.10

Problems

367

{a)
-a J

0

-a2

x(k + 1)

1 0
0 1

0

bl - boal
b2 - bOU2

=

x(k) +

- an - 1 0 0

1

0 0

0

- an

y(k) =

u(k)

(1

0 0 ...

bn- I - b Oa n- l
b; - boa n

o) x(k) + bou (k)

(b)

o
o
x(k + 1) :=

x(k) +

u(k + 1)

0 0

o

1

bll - 1

0 0

- all

0

bn

(1 0 0 ... 0) x(k )

y(k) ;;;;

(c)
-Ur.-l

bl

0

o

0

0

b2
0

o

o
o
o

1

o
o

o

o o
o o
o 1

0
0
0

o o

o

x(k + 1) ;;;;

-all

1

o

o

o

0

1

o

0

o o
o o

x(k)

0

bo

o
+

o
1

u(k + 1)

o
o
y(k)

= (1 0 0 " . 0 0)

x(k)

Assume that H(z) represents a controller. Discuss the advantages and disadvantages with the different realizations of the controller.

Implementation of Digital Controllers

368

Chap. 9

9.17 A digital controller with the sampling period h ;: 0.2 has the pulse-transfer function

'
H(Z )

=

6.25zt - 11.5z + 5.5
2
Z - 1.5z + 0.5

The controller is used to control a process with the transfer function

O(s)

1

=-+ 1
S2

Discuss the effect of roundoff and quantization noise when different realizations
are used to implement the controller on a computer having fixed word length.
9.18 Show that the continued-fraction representation (9.20) can be obtained recursively
as

where H.. +.(z) = O.

9.19 Determine the o-operator representations of the following continuous-time transfer
functions:
(a) 1/(5 2 + 1)

(h) Kj(l + Ts)

(c) 1/(s + a)3
Compute the poles and the zeros and investigate what happens when h --l> O.
9,20 Let H(z) be the pulse-transfer function obtained from step-invariant sampling of
the rational transfer function G(s). Define
H(6}

= H(l + oh}

Prove that
limH(o ) =G(o)

11 ·.0

Show that this is true also for ramp-invariant and impulse-invariant sampling.

9.11 Notes and References
Design of filters is covered in standard texts on networks. Kuo (1980) and
Williams (1981) are good sources. Useful practical advice is also found in the
handbooks published by manufacturers of operational amplifiers. Such handbooks are also useful for information about A-D and D-A converters. Makesure
to get a new version of whatever handbook you use because the technology
changes rapidly.

Sec. 9.11

Notes and References

369

The problems associated with windup of PID-controllers is discussed in
trade journals for the process industry. The general approach given in Sec. 9.4
wasintroduced in earlier editions ofthis book, see Astrom and Hagglund(1995).
The generalized form in Fig. 9.9 is described in Rdnnback, Walgama, and Sternby (1992). Other references on antireset windup are Hanus (1988) and Grrebe
and Ahlen (1996). Possibilities for error detection and rejection of outliers are
discussed in depth in Willsky (1979), which also contains many references.
A comprehensive text on the effects of quantization and roundoff in digital control systems is Moroney (1983), which contains many references. The
following papers are classics in the area, Bertram (1958), Slaughter (1964),
Knowles and Edwards (1965), Curry (1967), and Rink and Chong (1979). Describing function analysis is discussed in Atherton (1975, 1982). Limit cycles
due to roundoff can be determined using the theoryof relay oscillations. This is
described in Tsypkin (1984),
A review of digital signal processors is given in Lee (1988). Design of
special-purpose signal processors in VLSI is described in Catthooret al. (1988)
and in a series ofbooks titled VLSf Signal Processing I, II, and III, published by
IEEE. The books are based on presentations given at IEEE ASSIP workshops.
The 1988 volume is Brown and Campbell (1948). A readable account ofthe IEEE
standard and its impact on different high-level languages is found in Fateman
(1982). Problems associated with quantization, roundoff, and overflow are also
discussed in the signal-processing literature. Overviews are found in Oppenheim
and Schafer (1989). Specialized issues arc discussed in Jackson (1970a, 1970b,
1979), Parker and Hess (1971), Willson (1972a t 1972b), and Buttner (1977).
There are many standard texts on numerical analysis, Bjork, Dahlqvist,
and Andersson (1974) and Golub and Van Loan (1989) are good sources. Accuracy aspects in connection with control are found, for example, in Williamson
(1991) and Gevers and Li (1993) .
Concurrent programming is discussed in Brinch-Hansen (1973), Barnes
(1982), Bums and Wellings (1990), and Bums and Davies (1993). Much useful
information is also given in material from vendors of computer-control systems.
Theo-operator is an oldidea. SeeTschauner (1963a, 1963b). The 8-operator has
been given much attention because of its numerical properties. See Gawthrop
(1980), Middleton and Goodwin (1987, 1989), and Gevers and Li (1993).

10
Disturbance Models
10.1 Introduction
The presence of disturbances is one of the main reasons for using control. Without disturbances there is no need for feedback control. The character of the
disturbances imposes fundamental limitations on the performance of a control
system. Measurement noise in a servo system limits the achievable bandwidth
of the closed-loopsystem. The nature of the disturbances determines the quality
of regulation in a process-control system. Disturbances also convey important
information about the properties of the system. By investigating the characteristics of the disturbances it is thus possible to detect the status of the process,
including beginning process malfunctions. We have already taken disturbances
into account in the pole-placement design in Chapters 4 and 5. In this chapter
we will give a systematic treatment of disturbances.
Different ways to describe disturbances and to analyze their effect on a
system are discussed in this chapter. An overview of different ways to eliminate disturbances is first given. This includes use of feedback, feedforward, and
prediction. The discussion gives a reason for the different ways of describing
disturbances.
The classic disturbance models, impulse, step, ramp, and sinusoid, were
discussed in Sec. 3.5. All these disturbances can be thought of as generated by
linear systems with suitable initial conditions. The problem of analyzing the
effect of disturbances on a linear system can then be reduced to an initial-value
problem. From the input-output point of view, a disturbance may also be modeled as an impulse response of a linear filter. The disturbance analysis is then
reduced to a response calculation. This is particularly useful for disturbances
that are steps or sinusoids, In all cases the disturbance analysis can be done
with the tools developed in Chapters 3 to 5, and 8. When the response of a
system to a specific disturbance needs to be known, it is often necessary to resort to simulation, This is easily done with a simulation program because the
disturbance analysis is again reduced to an initial-value problem.
370

Sec. 10.2

Reduction of Effects of Disturbances

371

When disturbances can be neither eliminated at the source nor measured,
it is necessary to resort to prediction. To do so it is necessary to have models of
disturbances that lead to a reasonable formulation of a prediction problem. For
this purpose the concept of piecewise deterministic disturbances is introduced
in Sec. 10.3.
Another way to arrive at a prediction problem is to describe disturbances as
random processes. This formulation is presented in Sec. lOA. A simple version
of the famous Wiener-Kolmogorov-Kalman prediction theory is also presented.
As seen in Chapters 11 and 12, the prediction error expresses a fundamental
limitation on regulation performance. Continuous-time stochastic processes are
discussed briefly in Sec. 10.5. Such models are required because of the desire to
formulate models and specifications in continuous time . Sampling of continuoustime stochastic-state models is treated in Sec. 10.6.

10.2 Reduction of Effects of Disturbances
Before going into details of models for disturbances , it is useful to discuss how
their effects on a system can be reduced. Disturbances may be reduced at their
source. The effects of disturbances can also be reduced by local feedback or by
feedforward from measurable disturbances. Prediction may also be used to estimate unmeasurable disturbances. The predictable part of the disturbance can
then be reduced by feedforward. These different approaches will be discussed
in more detail.

Reduction at the Source
The most obvious way to reduce the effects of disturbances is to attempt to
reduce the source of the disturbances. This approach is closely related to process
design. The following are typical examples:
Reduce variations in composition by a tank with efficient mixing.
Reduce friction forces in a servo by using better bearings.
Move a sensor to a position where there are smaller disturbances.
Modify sensor electronics so that less noise is obtained.
Replace a sensor with another having less noise.
Change the sampling procedure by spacing the samples better in time or
space to obtain a better representation ofthe characteristics of the process.
These are just a few examples, but it is very important to keep these possibilities
in mind. Compare with the integrated process and control design discussed in
Chapter 6.

Chap. 10

Disturbance Models

372
Process
~

r

"\
Disturbance

A

B

u

y

Local
feedback
Figure 10.1 Reduction of disturbances by local feedback. The disturbance
should enter the system between points A and B. The dynamics between A
and B should be such that a high gain can be used in the loop.

Reduction by Local Feedback
If the disturbances cannot be reduced at the source. an attempt can be made
to reduce them by local feedback. The generic principle of this approach is
illustrated in Fig. 10.1. For this approach it is necessary that the disturbances
enter the systemlocally in a well-defined way. It is necessary to have access to a

measured variable that is influenced by the disturbance and to have access to a
control variable that enters the systemin the neighborhood of the disturbance.
The effect of the disturbance can then be reduced by using local feedback. The
dynamics relating the measured variable to the control variable should be such
that a high-gain control loop can be used. This use of feedback is often very
simple and effective because it is not necessary to have detailed information
about the characteristics of the process, provided that a high gain can be used
in the loop. However, an extra feedback loop is required. The following are
typical examples oflocal feedback:
Reduce variations in supply pressure to valves, instruments, and regulators by introducing a pressure regulator.
Reduce variationsin temperature control by stabilizing the supplyvoltage.

Reduction by Feedforward
Measurable disturbances can also be reduced by feedforward. The generic principle is illustrated in Fig. 6.3. The disturbance is measured, and a control signal
that attempts to counteract the disturbance is generatedand applied to the process. Feedforward is particularly useful for disturbances generated by changes
in the command or reference signals or for cascaded. processes when disturbances downstream are generated hy variations in processes upstream.

Sec. 10.3

373

Piecewise Deterministic Disturbances

Reduction by Prediction
Reduction by prediction is an extension ofthe feedforward principle that may be
usedwhenthe disturbance cannotbemeasured. Theprinciple is verysimple; tbe
disturbanceis predicted using measurablesignals, and the feedforward signal is
generated from the prediction. It is important to observe that it is not necessary
to predict the disturbance itself; it is sufficient to model a signal tbat represents
the effect of the disturbance on the important process variables.

Goals for Modeling

To evaluate the needs for reduction of disturbances it is necessary to be able to
estimate the influences ofdisturbances on important system variables, which is
basically a problem of analyzing the response ofa system to a given input. The
models used for disturbances can be fairly simple, as long as they represent the
major characteristics of true disturbances. Similarly simple models can also be
used to estimate possible improvements obtained by local feedback and feedforward. More accurate models of disturbances are needed if prediction is applied.
In this case the performance obtained depends critically on the character of
the disturbances. There are also some fundamental difficulties in formulating
disturbance models that give a sensible prediction problem.

10.3 Piecewise Deterministic Disturbances
The classical disturbance models discussed in Sec. 3.5 are useful for analyzing the effects of disturbances on a system. Possible improvements by using
local feedback and feedforward can also be investigated using these models.
The disturbance models discussed are, however, not suitable for investigating
disturbance reduction by prediction. Fundamentally different models are required to formulate a sensible prediction problem. This leads to introduction of
the piecewise deterministic disturbances.Alternativemodels, which also permit
formulation of a prediction problem, are discussed in Sees. 10.4 and 10.5.

A Fundamental Problem
It is not trivial to construct models for disturbances that permit a sensible
formulation of a prediction problem.
Example 10.1 Predictor for

8.

step signal

'Ib predict the future value of a step signal, it seems natural to use the current
value of the signal. For discrete-time signals, the predictor then becomes

y((k + m)h I kh)

:0

y(kh)

The notation y(t Is) means the prediction of y(t) based on data available at time
s. This predictor has a prediction error at times t == 0, h;2h•.. . •(m - l)h. that is,
m steps after the step change in y. It then predicts the signal without error.
_

Disturbance Models

374

Chap . 10

Example 10.2 Predictor for a ramp signal
A predictor for a ramp can be constructed by calculating the slope from the past

and the current observations and making a linear extrapolation, which can be
expressed by the formula

y({k + m)h I kh) =

=

y(kh) + m(Y(kh} - y(kh -

hl)

(1 + m)y(kh) - my(kh - h)

This predictor has an initial error for t
the signal without error.

= h,

2h. ... • mho After that it predicts

-

The Basic Idea
These examples indicate that the prediction eITOr will be zero except at a few
points. This observation is not in close agreement with the practical experience
that disturbances are hard to predict. The explanation is that the step and the
ramp are not good models for prediction problems. Analytic signals are useless
because an analytic function is uniquely given by its values in an arbitrarily
short interval. The step and the ramp are analytic everywhere except at the
origin.
One possibility of constructing signals that are less regular is to introduce
more points of irregularity.Thus signals canbe introduced that are generated by
linear dynamic systems with irregular inputs. Instead of having a pulse at the
origin, inputs that are different from zero at several points can be introduced. An
interesting class of signals is obtained if the pulses are assumed to be isolated
and spread by at least n samples, where n is the order of the system. It is
assumed that it is not known a priori when the pulses occur. The amplitudes
of the pulses are also unknown. Such signals are called piecewise deterministic
signals. The name comes because the signals are detenninistic except at isolated
points, wbere they change in an unpredictable way. An example of a piecewise
deterministic signal is shown in Fig. 10.2.
State-Space Models

Let a signal be generated by the dynamic system
x(k + 1) ::: <1>x(k) + v(k)

y(k) =: Cx(k)

(lO.l)

It is assumed that the output y is a scalar and that the system is completely
observable. The input u is assumed to be zeru except at isolated points. If tbe
state of the system is known, it is straightforward to predict the state over
any interval wbere the input is zero. However, when there is a pulse, the state
can change in an arbitrary manner, but after a pulse there will always he an
interval where the input is zero. Because the system is observable, the process
state can then be calculated. Exact predictions can tben be given until a new

375

Piecewise Determinis1ic Disturbances

Sec, 10.3

O~

e
<....

• l::

[00

o

;0.,''''

..... ....
t
o:l
~i
...

00

...

00

Cf.l~

I

I

I

I

o
o

o

Q

' ....

• c
o
;>,-:;

....

...... u
~

fni

. .. 100

If.l~+----'''----'''''''---=---"""""""T""""------r----'''

o

10

20

30

40

Time

Figure 10.2 Piecewise constant and piecewise linear signals and their
m-step predictions when m

= 3.

pulse occurs. This argument can beconverted into mathematics in the following
way. From the derivation of the condition for observability in Sec. 3.4, it is found
that the state is given by

x(k - n + 1} = W;l (Y(k - n + 1)

(10.2)

where W is the observability matrix given by Eq. (3.22), The following predictor
o
gives the state m steps ahead:
x(k + m i k)

= <l>m+n -1W;1

(Y(k- n + I) . ., Y(k))

T

{l O
.3)

The predictor for the signal is thus obtained from a linear combination of n
values of the measured signal. The predictor can be expressed as
y(k + m I k) = P*(q- l)y(k)
where P is a polynomial of degree n - 1.
The predictor can also be represented by the recursive equation
x(k I k)

=<l>x(k-ll k -1) + K(Y(k) -

x(k + m I k) ; If>mx(k I k)

Clf>x(k-ll k -1))

(10.4)

where the matrix K is chosen so that all eigenvalues of the matrix (I - K C )If>
are equal to zero.

Disturbance Models

376

Chap. 10

Simple calculations for an integrator and a double integrator give the same
predictors as in Examples 10.1 and 10.2. This is a consequence of the fact that
the important characteristics of the disturbances are captured by the dynamics
of the systems that generate the disturbances. These dynamics determine the
predictors uniquely; it does not matter if the systems are driven by a single
pulse or by several pulses. The properties of the predictors are i11ustrated in
Fig. 10.2.

Input-Output Models
Becausethe predictor for a piecewise deterministic signal becomes a polynomial)
it seems natural to obtain it directly by polynomial calculations. For this purpose
it is assumed that the signal is generated by the dynamic system
C(q)
y(k) == A(q) w(k)
where it is assumed that deg C := degA and that the input w is a signal that
is zero except at isolated points, which are spaced more than deg A + m. Define
F(z) and G(z) through the identity

zm-1C(z ) := A(z)F(z) + G(z)
It can be shown that the m-step predictor for y is given by the difference equation
C(q)y(k + m I k}

= qG(q)y(k)

A reference to the proof of this is given in Sec. 10.9.
Notice that the signals discussed in this section are similar to the classical
disturbance signalsdiscussed in Sec. 3.5 in the sense that they are characterized
by dynamic systems. The only difference between the signals is that the inputs
to the systems are different. This idea is extended in the next section.

10.4 Stochastic Models of Disturbances
It is natural to use stochastic, or random, concepts to describe disturbances.
By such an approach it is possible to describe a wide class of disturbances)
which permits good formulation of prediction problems. The theory of random
processes and the prediction theory were in fact developed under close interaction. The general theory of stochastic processes is quite complex. For computercontrol theory, it is fortunately often sufficient to work with a special case of
the general theory, which requires much less sophistication. This theory is developed in this section. First, some elements of the theory of random processes
are given, and then the notion of discrete-time white noise is discussed. Disturbances are then modeled as outputs of dynamic systems with white-noise

Sec. 10.4

377

Stochastic Models of Disturbances

inputs. The disturbance models are thus similar to the models discussed in the
previous sections; the only difference is the character of the input signals to the
systems. 100ls for analyzing the properties of the models are also given.

Stochastic Processes
The concept of a stochastic process is complex It took brilliant researchers
hundreds of years to find the right ideas. The concept matured in work done by
the mathematician Kolmogorov around 1930. A simple presentation of the ideas
is given here. Interested readers are strongly urged to consult the references.
A stochastic process (random process, random function) can be regarded
as a family of stochastic variables {x(t), t E T}. The stochastic variables are
indexed with the parameter t, which belongs to the set T I called the index
set. In stochastic-control theory, the variable t is interpreted as time. The set
T is then the real variables. When considering sampled-data systems, as in
this book, the set T is the sampling instants, that is, T ={... ,-h, 0, h, ... } or
T = {...• ~1, 0,1, ... } when the sampling period is chosen as the time unit. We
then have a stochastic process.
A random process may be considered as a function x(t, ill) of two variables.
For fixed to = 0)0 the function xC, OJo) is an ordinary time function called a
realization. For fixed t = to, the function x(to, .) is a random variable. A random
process can thus be viewed as generated from a random-signal generator. The
argument co is often suppressed.

Completely deterministic stochastic processes. One possibility of obtaining a random process is to pick the initial conditions of an ordinary differential equation as a random variable and to generate the time functions by
solving the differential equations. These types of random processes are, however, not very interesting because they do not exhibit enough randomness. This
is clearly seen by considering the stochastic process generated by an integrator
with random initial conditions. Because the output of the integrator is constant
it follows that
x(t,W) - x(t- h,m)

==

0

for all t.h, and to. A stochastic process with this properly is called a completely
deterministic stochastic process, because its future values can be predicted exactly from its past.
In general it will be said that a random process x(t,m) is called completely
deterministic if
f ( x(t, OJ))

=0

for almost all

ill

where f is an arbitrary linear operator that is not identically zero. This means
that completely deterministic random processes can be predicted exactly with
linear predictors for almost all w. (Almost all OJ means all to except for possibly
a set of points with zero measure.)

Chap. 10

Disturbance Models

378
Arealization

__
~-- X( ·,W2)
X
(.,W3 )
x{" lIJ4 )

Figure 10.3 A stochastic process and a finite-dimensional distribution

function.

The completely deterministic random processes are closely related to the
classical disturbance signals discussed in Sec. 3.5. These signals will be completely deterministic random processes if the initial conditions to the dynamic
systems are chosen as random processes. The completely deterministic processes
are normally excluded because they are too regular to be of interest.

Concepts. Some important concepts for random processes will now be
given. The values of a random process at n distinct times are n-dimensional
random variables. The function
F(;l,... ,4n;t l, .·· , in) = P{x(td :s; ~t , ... , x(tn) :s; 4/1}

where P denotes probabilities, is called the finite -dimensional distribution function of the random process. An illustration is given in Fig. 10.3. A random process is called Gaussian, or normal , if all finite-dimensional distributions are
normal, The mean-value function of a random process x is defined by
m(t)

= Ex(t) :::

.l:

~ dF(~~ t )

The mean-value function is an ordinary time function. Higher moments are
defined similarly. The covariance function of a process is defined by

rrx(s,t) = cov (x(s),x(t))

:: E((X(S)-m(s)) (x(t) -m(t))T)
=

11 (~l -

m(s))

(42 - m(t)) (iF(~1. ~2;
T

S.

t)

A Gaussian random process is completely characterized by its mean-value function and its covariance function. The cross-covariance function
Tx}' (S,

t)

=COy

(X(S)ly(t))

Sec. 10.4

379

Stochastic Models ofDisturbances

of two stochastic processes is defined similarly.
A stochastic process is called stationary if the finite-dimensional distribution of x(tt}.X(t2), '" ,x(tn ) is identical to the distribution of x(h + r) ,x(t2 +
r ), ... , X(tl1 + r ) for all r, n, ti , . . . . i «. The process is called weakly stationary' if
the first two moments of the distributions are the same for all r. The meanvalue function of a (weakly) stationary process is constant. The cross-covariance
function of weakly stationary processes is a function of the difference s - t of
the arguments only. With some abuse of function notation, write

The cross-covariance function of (weakly) stationary processes is a function of
one argument only. Hence
rrv ( r ) '" cov (x(t + r ), y (t) )
When x is scalar the function

called the autocovariance function,
The erose-spectral density of (weakly) stationary processes is the Fourier
transform of its covariance function. Hence.
¢Jxy( OJ) '"

2~

t

r;c.v (k)e -dan

(10.5)

k = -oj(,

and
(10.6)
It is also customary to refer to ¢xx and l/Jxy as the autospectral density and

the cross-spectral density, respectively. The autospectral density is also called
spectral density for simplicity.
Interpretation of covariances and spectra. Stationary Gaussian processes are completely characterized by their mean-value functions and their
covariance functions. In applications, it is useful to have a good intuitive understanding of how the properties of a stochastic process are reflected by these
functions.
The mean-value function is almost self-explanatory. The value fz(O) of the
covariance function at the origin is the variance ofthe process, It tells how large
the fluctuations of the process are. The standard deviation of the variations is

Disturbance Models

380

Chap. 10

equal to the square root of rx(O). If the covariance function is normalized by
fx{O), the correlation function, which is defined by

is obtained. It follows from Schwartz's inequality that

The correlation function is therefore less than one in magnitude. The value
Px(t) gives the correlation betweenvalues of the process with a spacing t . Values close to one mean that there are strong correlations, zero values indicate no
correlation, and negative values indicate negative correlation. An investigation
of the shape ofthe correlation function thus indicates the temporal interdependencies of the process.
It is very useful to study realizations of stochastic processes and their
covariance functions to develop insight into their relationships. Some examples
are shown in Fig. IDA. All processes have unit variance.
The spectral density has a good physical interpretation. The integral

represents the power of the signal in the frequency band (lOl' (.(2). The area
under the spectral-density curve thus represents the signal power in a certain
frequency band. The total area under the curve is proportional to the variance
of the signal. In practical work it is useful to develop a good understanding of
how signal properties are related to the spectrum (compare with Fig. 10.4).
Notice that the mean-value function, the covariance function, and the spectral density are characterized by the first two moments ofthe distribution only.
Signals whose realizations are very different may thus have the same first moments. The random telegraph wave that switches between the values 0 and 1
thus has the same spectrum as the noise from a simple RC circuit.

Discrete-Time White Noise
A simple and useful random process is now introduced. Let time be the set
of integers. Consider a stationary discrete-time stochastic process x such that
x(t) and X(8) are independent if t :f s. The stochastic process can thus be
.
considered as a sequence {x(t, w), t =... ,-1, O 1, .,,} of independent, equally
distributed random variables. The covariance function is given by

a2

r(r)::: { 0

t :=:

0

r = ±l, ±2, ...

Stochastic Models of Disturbances

Sec. 10.4

381

Output

Spectrum

Covariance
1~------,

101--

___

2

o

o

-2

0.1
-1 \......--------'

o

10

1

O~l

1

o

50

10
2

o
0.1
-1 '---------'
o
10

1

~

0.01

-2

o

1

50

10
2

o

o
-2

0.1

-1L...-----,..."
o
10

1

1

o

1

0.01

o

50

10

0.1
-1

""------~--'

o

10 0.01

tau

Omega

50
Time

Figure 10.4 Covariance functions, spectral densities, andsample functions
for some stationary random processes. All processes have unit variance.

A process with this covariance function is called discrete-time white noise. It
follows from (10.5) that the spectral density is given by

The spectral density is thus constant for all frequencies. The analogy with
the spectral properties of white light explains the name given to the process.
White noise plays an important role in stochastic control theory. All stochastic processes that are needed will be generated simply by filtering white noise.
This also implies that only a white-noise generator is needed when simulating
stochastic processes. White noise is thus the equivalent of pulses for deterministic systems.

Disturbance Models

382

Chap. 10

ARMA Processes
Large classes of stochastic processes can be generated by driving linear systems
with white noise. Let {e(k) , k == .. , • -1, 0, 1,. .. } be discrete-time white noise.
The process generated by
.y(k) = e(k) + b1e(k - I} + ... + bne(k - n)

is called a moving average, or an MA process. The process generated by
y(k) + aly(k - 1) + .. . + any(k - n) ::: e(k)

is caned an autoregression, or an AR process. The process
y(k ) + aly(k ~ 1) + ... + any(k - n) :;; e(k) + bie(k - 1) + . .. + bne(k - n)
is called an ARMA process. The process
y(k) + Gly(k - 1) + .. . + a7ly(k - n) :: bou {k - d) + ..'

+ bmu(k - d - m) + e(k) + cle(k - 1) + . .. 1" cne(k - n)
is calledan ARMAX process, that is, an ARMA process with an exogenous signal.

Stat.Space Models
The concept of state has its roots in cause-and-effect relationships in classical
mechanics. The motion of a system ofparticles is uniquely determined for all future times by the present positions and moments ofthe particles and the future
forces. How the present positions and moments were achieved is not important.
The state is an abstraction of this property; it is the minimalinformation about
the history of a system required to predict its future motion.
For stochastic systems, it cannot be required that the future motion be
determined exactly. A natural extension ofthe notion ofstate for stochastic 8y!:)·
terns is to require that the probability distribution of future states be uniquely
given by the current state. Stochastic processes 'with this property are called
Markov processes. Markov processes are thus the stochasticequivalents ofstatespace models. They are formally defined as follows.
DEFINITION 10.1 MARKov PROCESS Let t, and t be elements of the index
set T such that t I < t2 < ... < tn < t. A stochastic process {x(t). t E T} is called
a Markov process if

where P{- X(tl), ... ,x(t n)} denotes the conditional probability given X(tl), . .' ,
x(tn).
•
I

Sec. 10.4

383

Stochastic Models of Disturbances

A Markov process is completely determined by the initial probability distribu-

tion
F(~;

to) ; P{x(to)

s ~}

and the transition probability distribution

All finite-dimensional distributions can then be generated from these distributions using the multiplication rule for conditional probabilities.
The Markov process is the natural concept to use when extending the
notion of state model to the stochastic case.

Linear stochastic-difterence equations.

Consider a discrete-time system where the sampling period is chosen as the time unit. Let the state at time
k be given by x(k). The probability distribution of the state at time- k + 1 is
then a function of x(k). If the mean value is linear in x(k) and the distribution
around the mean is independent of x(k), then x(k + 1) can be represented as

x(k + 1) ;:; <l>x(k) + v(k)

(10.7)

where LI (k) is a random variable with zero mean and covariance R1 that is independent of x(k) and independent of all past values of x. This implies that v(k)
also is independent of all past v's. The sequence {v(k),k == ... ,-1,0.1, ... } is
a sequence of independent equally distributed random variables. The stochastic process {v(k)} is thus discrete-time white noise. Equation (10.7) is called a
linear stochastic-difference equation. To define the random process {x(k)} completely, it is necessary to specify the initial conditions. It is assumed that initial
state has the mean mOl and the covariance matrix Ro.

Properties of Unear stochastic-difference equations.

The character of
the random process defined by the linear stochastic-difference equation of (10.7)
will now be investigated and the first and second moments of the process will
be calculated. To obtain the mean-value function

m(k) = Ex(k)
simply take the mean values of both sides of (lO.7). Because v has zero mean.
the following difference equation is obtained:

m(k + 1) =<l>m(k)
The initial condition is

m(O) = mo

(10.8)

Disturbance Models

384

Chap. 10

Themean valuewill thus propagate in the sameway as the unperturbedsystem.
Th calculate the covariance function, we introduce
P(k)

= cov(x(k) ,x(k)) = Ei(k)xT(k)

where

x=x-m
It follows from Eqs. (10.7) and (10.8) that i satisfies Eq. (10.7)with the mean of
the initial condition equal zero. The mean value can thus be treated separately.
To calculate the covariance, form the expression
i(k+ 1)iT(k+ 1) = (<I>i(k) + v(k))(<I>i(k)+v(k))T
= <I>i(k)iT(k)<I>T + <I>i(k)vT(k) + v(k)iT(k)<I>T + u(k)vT(k)

Taking mean values gives
P(k + 1) = <l>P(k)<I>T + R 1

because v(k) and i( k) are independent. The initial conditions are
P(O) = Ro

The recursive equation for P tells how the covariance propagates.
To calculate the covariance function ofthe state, observe that
i(k + l)x T(k} = (<I>x(k) + v(k))iT(k)

Because v(k) and i(k) are independent and u(k) has zero mean,
Txx(k + l,k) = cov(x(k + 1),x(k))

=q,P(k)

Repeating this discussion,

The covariance function is thus obtained by propagating the variance function
through a system with the dynamics given by <1>. The results obtained are so
important that they deserve to be summarized.
THEOREM 10.1

FILTERED DISCRETE~TIME WHITE NOISE

Consider a random
process defined by the linear stochastic-difference equation (10.7), where {v(k)}
is a white-noise process with zero mean and covariance R 1. Let the initial state
have mean mo and covariance Ro. The mean-value function of the process is
then given by
m{k + 1) ;; Cl>m(k)

m(O) = mo

(10.9)

Sec. 10.4

385

Stochastic Models ofDisturbances

and the covariance function by

r(k + t,k) = cI> I P(k)

r>O

(10.10)

where P(k) = cov(x(k),x(k)) is given by

P(k + 1) = et>P(k)<I>T + R 1

P(O)

=Ro

(10.11)

•

Remark 1. If the random variables are Gaussian, then the stochastic process is uniquely characterized by its mean-value function m and its covariance
function r.
Remark 2. If the system has an output y = C X, then the mean-value
function of y is given by

my=Cm
and its covariance is given by

The cross-covariance between y and x is given by

Remark 3. Notice that the steady-state solution of (10.11) for the matrix
P is closely related to Eq. (3.9), which was used to calculate Lyapunov functions
in Chapter 3.

Remark 4. The different terms of (10.11) have good physical interpretations. The covariance P may represent the uncertainty in the state, the term
cI>P(k )cI>T tells how the uncertainty at time k propagates due to the system
dynamics, and the term RI describes the increase of uncertainty due to the
disturbance v.
Example 10.3 A first order system
Consider the first-order system

x(k+ 1) =ax(k)+v(k)
where v is a sequence of uncorrelated random variables with zero mean values
and covariances '1 . Let the state at time ku.have the mean 111<> and the covariance
roo It follows from (10.9) that the mean value

m{k) = Ex(k )

Disturbance Models

386

Chap. 10

ia given by
m(k + 1)

=am(k}

m(ko)

=mo

Hence

Equation (10.11) gives
P(k + 1)

= a2P(k) + Tl

P(ko) :: ro

Solving this difference equation we get

Furthennore,

rxU, k) =a'-k P(k)

l ~ k

and

If lal < 1 and ho ~ - 00, it follows that

m(k) ~ 0
rl

P(k) ~ 1- a2
rl
rl a1

rx(k + r,k) ~ ~1
~

-a

The process then becomes stationary because m is constant and the covariance
function is a function of r only. If an output

y(k) ::: x(k) + e(k)
is introduced, where e jg a sequence of uncorrelated random variables with zero
mean and covariance TS!, it follows that the covariance function of y becomes
r

=0

1'fO

The spectral density is obtained from (10.5). Hence

~

(tV) = _1 (r'l. + ild
r1
)
y
21r
(e - a )(e-illt - a)
1
= _1 (r2 + _--::-_r__ _ )

21l'

1 + 02 -

2acosw

•

Sec. 10.4

387

Stochastic Models ofDisturbances

u

..

I

H(z)

~

Figure 10.5 Generation of disturbances by driving dynamic systems with
white noise.

Input-Output Models

Foradditionalinsight an input-output description ofsignals generatedby linear
difference equations is given. Notice that the signal x given by (10.7) can be
described as the output ofa linear dynamic system driven by white noise. From
this viewpoint it is then natural to investigate how the properties of stochastic
processes change when they are filtered by dynamic systems.
Analysis. Consider the system shown in Fig. 10.5. For simplicity it is
assumed that the sampling period is chosen as the time unit. Assume that
the input u is a stochasticprocess with a given mean-value function m« and a
given covariance function T u • Let the pulse response of the systembe {h(k),k =
0,1 , .. . }. Notice that h has also been used to denote the samplingperiod. It is,
however, clear from the context what h shouldbe.The input-output relationship
is
k

y(k) =

00

L h(k -l)u(l) = L h(n)u(k - n)
l .. -00

(10.12)

1'1,,-0

Taking mean values
oo

my(k)

=Ey(k) :: E L h(n)u(k- n)
1'1=0

x

n=O

==

:x.

(10.13)

1'1=0

L h(n)Eu(k - n) = L h(n)mu(k - n)

The mean value of the output is thus obtained by sending the mean value of
the input through the system.
To determine the covariance, first observe that a subtraction of (10.13)
from (10.12) gives
oc

y(k) - my(k) =

L h(n) (u(k - n) - mu(k - n))
1'1",0

The difference between the input signal and its mean value thus propagates
through the system in the same way as the input signal itself. When calculating

the covariance, it can be assumed that the mean values are zero. This simphfies

Disturbance Models

388

Chap. 10

the writing. The definition of the covariance function gives

ry(r)

=Ey(k + 'f)yT(k)
= E ~h(n)U(k +T ~ nj (toh(l)U(k -I)
00

00

:; LL h(n)E(u (k +

t -

n)uT(k -l)

r

)h T (I)

(10.14)

n=O l=O

oc

:x:

:::; LLh(n)ru(r + l- n)hT(l)
n=OI=O

A similar calculation gives the following formula for the cross-covariance ofthe
input and the output:
00

ryu(r) = Ey(k + r)uT(k) :: E

L h(n)u(k + t - n)uT(k)
n=O

00

(10.15)

00

= Lh(n)E(u(k + r - n)uT(k)) = Lh(n)rlJ(r - n)
n~O

n=O

Notice that it has been assumed that all infinite sums exist and that the op-

erations of infinite summation and mathematical expectation have been freely
exchanged in these calculations. This must of course he justified; it is easy to
do in the sense of mean-square convergence, if it is assumed that the fourth
moment of the input signal is finite.
The relations expressed by Eqs. (10.14) and (10.15) can be expressed in
a simpler form if spectral densities are introduced. The definition of spectral
density in (10.5) gives

~y(a»

:::; ?>y(w) ::

2~

f:

e-in(l)ry(n)

11::-00

Introducing r y from (10.14) gives
1
?y( (0 ) :: 2Jl"

00

L

.

oo

OQ

L L h(k)ru(n + 1- k)hT (1)
k"O (=o

/1=>- - 00

1
=21l"

OQ

e- m w
00

LL

00

Le-ikfllh(k)e-i(Il+I-k)fllru(n + 1- k)eilttJhT(l)

,i:::o n= -00 1=0

= 2~

f
k:::O

e-ikwh(k)

f
lI=-:lO

e-inWr,An)

f
1=0

ei1mhT(l)

Sec. 10.4

389

Stochastic Models of Disturbances

Introduce the pulse-transfer function H(z) of the system. This is related to the
impulse response h(k) by
'JC

H(z) = Lz-kh(k)
k=O

The equation for the spectral density can then be written as

¢y(w)

= H(eiw)~Il((JJ)HT (e-

HI1
)

Similarly,
1

~YI4(m) = 21I'

L
00

n=

= .!.. L e-ikwh(k)
k=O

co

L
n=

-00

00

21l'

1

.

e-tnCllryu(n) ::: 21r

-00

00

L

.

00

e-~nCllLh(k)ru(n - k)

e-illwru(n)

k=O

= H(eiw )~u(w)

n",-oo

To obtain the general result, the propagation of the mean
value through the system must also be investigated.
Main result

THEOREM 10.2

Consider a stationary discrete-time dynamic system with sampling period 1 and the pulse-transfer
function H. Let the input signal be a stationary stochastic process with mean
m; and spectral density ¢u. If the system is stable, then the output is also a
stationary process with the mean
FILTERING OF STATIONARY PROCESSES

my = H(1)mu

(10.16)

and the spectral density
(10.17)

The cross-spectral density between the input and the output is given by
(10.18)

•

Remark 1. The result has a simple physical interpretation. The number
~ H ( eill.l)l is the steady-state amplitude of the response of the system to a sine
wave with frequency OJ. The value of the spectral density of the output is then
the product of the power gain IH (eiW)1 and the spectral density of the input
2
~u(m).

Remark 2. It follows from Eq. (10.18) that the cross-spectral density is
equal to the transfer function ofthe systemif the input is white noise with unit
spectraldensity. This fact can be used to determine the pulse-transfer function
ofa system.
The result is illustrated by an example.

Disturbance Models

390

Chap. 10

Example 10.4 Spectral density of a first order system
Consider the process x(k) in Example 10.3. From the input-output point of view,
the process can be thought of as generated by sending white noise through a filter
with the pulse-transfer function
1

H(z) = -

z-a

Because the spectral density of u(k) is

it follows from (lO.17) that the spectral density of x(k) is

¢x(w) = H(elt'J)H(e -iw ) ;~
1

rl
;;; 21l' ' (e

l Ql -

a)(e-

rl
lIlJ -

a)

= 2.tr(1 +

a2 -

2acosm)

Because x(k) and e(k} are independent the process
y(k) = x(k) + e(k)

has the spectral density

(Compare with the calculation in Example 10.3.)

•

Spectral Factorization
Theorem 10.2 gives the spectral density of a stochastic process obtained by fil~
tering another stochastic process. The spectral density of a signal obtained by
filtering white noise is obtained as a special case. The inverse problem is discussed next. A linear systemthat gives an output with a given spectral density
when driven by white noise will be determined. This problem is important because it shows how a signal with a given spectral density can be generated by
filtering white noise. The solution to the problem will also tell how general the
model in (10.7) is. It follows from Theorem 10.2 that the random process generated from a linear system with a white-noise input has the spectral density
given by (10.17). If the system is finite-dimensional, H is then a rational function in exp{im) and the spectral density ~ will also be rational in exp(ico) or
equivalently in cos lJ.J. With a slight abuse of language. such a spectral density
is called rational. Introducing

Sec. 10.4

Stochastic Models of Disturbances

391

the right-hand side of (10.17) can be written as

1
F(z) = 21( H(z)H T (z-l )

If z, is a zero of H(z), then z;l is a zero of H(z-l). The zeros of the function F
are thus symmetric with respect to the real axis and mirrored in the unit circle.
If the coefficients of the rational function H are real, the zeros of the function
F will also be symmetric with respect to the real axis. The same argument
holds for the poles of H. The poles and zeros of F will thus have the pattern
illustrated in Fig. 10.7.
It is now straightforward to find a function H that corresponds to a given
rational spectral density as follows: First, determine the poles PI and the zeros
z, of the function F associated with the spectral density. It follows from the
symmetry of the poles and zeros, which has just been established, that the
poles and zeros always appear in pairs such that
2 jZj

== 1

PiP}

=1

In each pair choose the pole or the zero that is less than or equal to one in
magnitude; then form the desired transfer function from the chosen poles and
zeros as
H(z) :;: K n(z -zt} = B(z)
n(z - Pi) i\(z)

Because the stochastic process is stationary, the chosen poles P, will all be
strictly less than one in magnitude. There may, however, be zeros that have
unit magnitude. The result is summarized as follows.
Given a spectral density ¢(ltJ), which is rational in cos e, there exists a linear system with the pulsetransfer function
THEOREM

10.3 SPECTRAL FACTORIZATION THEOREM

H( ) = B(z)
Z
A(z)

(10.19)

such that the output ohtained when the system is driven by white noise is a
stationary random process with spectral density a. The polynomial A(z) has all
its zeros inside the unit disc. The polynomial B (z) has all its zeros inside the
unit disc or on the unit circle.
•

Remark 1.

The spectral factorization theorem is very important. It implies that all stationary random processes can be thought of as beinggenerated
by stahle linear systems driven by white noise, that is, an ARMA process of a
special type. This means a considerable simplification both in theory and practice. It is sufficient to understand how systems behave when excited hy white
noise. It is onlynecessary to be able to simulate white noise. All other stationary
processes with rational spectral density can then be formed hy filtering.

392

Disturbance Models

Chap. 10

Remark 2.

Because a continuous function can be approximated uniformly arbitrarily well on a compact interval with a rational function, it follows
that the models in (10.7) and (10.12) can give signals whose spectra are arbitrarily close to any continuous function. Notice, however, that there are models
with nonrational spectral densities. In turbulencetheory, for instance, there are
spectral densities that decay as fractional powers of to for large o:
An important consequence ofthe spectral factorization theorem is that for
systems with one output, it is always possible to represent the net effect of
all disturbances with one equivalent disturbance. This disturbance is obtained
by calculating the total spectral density of the output signal and applying the
spectral factorization theorem.

Remark 3. It is often assumed that the polynomial B (z) has all its zeros
inside the unit disc. This means that the inverse ofthe system H is stable. The
results are illustrated by two examples.
Eumple 10.6 Spectral factorization
Consider the process y(k) of Examples 10.3 and 10.4. This process has the spectral
density
¢}' (w)

= 2~ (r 2 + (z _ a}~~-I - a)) .=~' I"
:; -.!.- ('I + '2(1 + a2) -

r2 a(z +
[z - a){z· 1 - a)

21t'

Z-I))
1=.""

The denominator is already in factored form. Th factor the numerator, we observe
that it can be written as

Identification of coefficients of equal powers of z gives

zo:

).2{1 + b2 )

Zl:

).2b

::::

rl

+ r2(1 + a2 )

= r2 a

Elimination of A gives a second-order algebraic equation for b. This equation has

the solution
rl

+ '2 (1 + a2 ) -

(r l + '2(1 + a)2) (r

l

+ r2(1 - a)2)

b = ---------'--------~---2ar2
The other root is discarded hecauss it is outside the unit disc. Furthermore, the
variable A. is given by

•

393

Stochastic Models of Disturbances

Sec. 10.4

o

l--~

__

__

---L

" " " " " = = - ~

o

-2

-4

-:::::::IlliII

2

_

4

Frequency
Figure 10.6 The spectral density (10.20) as function of w, that is, when
z

=e

JClJ
•

Exmnple 10.6 Generation of a stochastic signal
Assume that we for simulation purposes want to generate a stochastic signal with
the spectral density
F z _ 2- .
0.3125 + O.l25(z + %-1)
( ) - 21f 2.25 - 1.5(C1: + Z-l) + 0.5(z2 +z-2)

(10.20)

The spectrum is shown in Fig. 10.6. Factorization of F(z) gives the pole/zero pattern in Fig. 1O.7 and the desired noise properties are obtained by filtering white
noise through the filter
H(z)

= 0.5z +0.25

z2 <z + 0.5

•

Innovation's Representations

Theorem 10.3 has some conceptually important consequences. It follows from
the theorem that a process with rational spectral density can be represented as
11

y(k):::

L h(k- n)e(n)

(10.21)

n=-oo

where e is discrete-time white noise and h is the impulse response that corresponds to the pulse-transfer function (10.19). The system has a stable inverse
if the polynomial B (z) has all its zeros inside the unit disc. This means that
If

e(k) =

L g(k-n)y(n)
11=-00

where g is the impulse response, which corresponds to the stable pulse-transfer
function A(z) I B (z). It thus follows that the sequences y(k),y(k - 1),. .. and

Disturbance Models

394

Chap . 10

x

1

~

al

.~ 0 "", 0 , . . ,

· · ·0 · · · · · · ·:

til

e

~

-1

-2

o

-1

1

Real
Figure 10.7 Symmetry of the poles and zeros ofthe spectral-density function (10.20).

e(k),e(k -1), ... are equivalent in the sense that one sequence can be calculated
from the other.
Now consider
k

k+l

y(k + 1) =

L

h(k + 1- n)e(n) + h(O)e(k + 1)

7[::: -:;:.0

k

k

Jia:-:xl

=

L

h(k + 1 - n)e(n):::

n"-x

1=-00

L h(k + 1 - n) L: g(n -l)y(l) + h(O)e(k + 1)

The variable y(k + 1)can be written as the sum oftwo terms: One term is a linear function of y(k), y(k-l)"." and the other term is h(O)e(k + 1) .Thus elk + 1)
can be interpreted as the part of y(k + 1) that contains new information that
is not available in the past values y(k),y(k - 1),.... The stochastic process e(k)
is therefore called the innmxuicns ofthe process y(k) and the representation in
(10.21) is called the innovation's representation of the process. This representation is important in connection with filtering and prediction problems. The
tenn
k

L
n=-~

~

h(k + 1- n)

L g(n -l)y(l)
i~-~

is in fact the best mean-square prediction of y(k + 1) based on y{k),y(k -1)•. ...
This will be discussed in detail in Chapters 11 and 12.

Sec. 10.4

395

Stochastic Models of Disturbances

Example 10.7 Innovation's representation
Consider the process y(k) of Example 10.3. The process has the spectral density
¢,. (UJ) ==

~ (r2 + 1 + a'2 ~12a cos ro)

It follows from Example 10.5 that the spectral density can be factored as

The process y can thus be generatedby sending white noise through a system with
the pulse-transfer function

z-b
z-a

H (z) = = -

The input-output relation of such a system can be written as
y(k + 1) == ay(k) + e(k + 1)- be(k)

where e(k) is white noise with variance A,2.

•

Calculation of Variances
The variance of a signalobtained by filtering white noise can be calculated from
the recursive equation of (10.11), if the model is given in state-space form. For a
system described by transfer functions it is possible to use the same equations.
if the model is first transformed to state-space form. It is naturally convenient

to have similar formulas when the system is given in input-output form. Such
formulas will now be given.
Consider a signal generated by
y(k)

B(q)

= A(q) e(k)

(10.22)

where e is white noise with unit variance. It follows from Theorem 10.2 that
the spectral density of the signal y is given by
1 B(z)B(z-l)
¢(m) = 2Jr . A(z)A(z-l)
where z = exp(im). It also follows from Theorem 10.2 that the variance of the

signal y is given by the complex integral

(10.23)

Disturbance Models

396

Chap. 10

The evaluation ofintegrals of this form is closely related to Jury's stability test
(compare with Sec. 3.2). To evaluate the integral, the following table is formed:
ao

a1

an

an-l

al

bo

n
a0 - 1 an - 1
1

an~l

1
0. 0

bn

an-l

a1

an P,..

n- 1
a 11.-1 aIt-I
n- 2

an-l

0

1
0.1

a1
1

bn- l

n
n
b0 - 1 b1 - 1

an-l
n- 1

an-I an-l
n- 1
n- 2

an

ao

b1

an

an-1 an

1
a0

1
b0

0

1
aa

1

aD

1
a1

bO
0

an- l
0

Pn-1

i
b1

al

fl - 1
bn-l

/31
/30

where
an

= an/ao

f3n ;;;; bn/ao

Uk

= aVa~

Pk b:1o~
=;:

and
k-l
ai
bk - 1
I

k
=aik - ak a kk
= bk. - Pkalt .
l

I

-I

The left half of the table is the same as Jury's stabilitytest. The right half is
built up in the same way with the exception that the even rows are taken from
the left half of the table. The following theorem results.
THEOREM

10.4 VARIANCE

The integral (10.23) is given by

CALCULATION

1

Lb:Pi
ao

In ~ -

11

•

£=0

•

Application of the theorem gives the following values of the integral fOT n ::: 1
and 2.
I 1 ;:;:

(b~ + bnao - 2b ob 10 1
2

2

ao(ao - a1)

1 :::: BOaael - B10 0a 1 + B2 (ai - a2el)
2

ao((a~ - a~)el - (ao - a2)ai)

where

Bo ;: b~ + bi + b~
B1 =2(bob t + b1b2)
B2
el

2bob2
=a{) + a2

:=

Sec, 10.5

Continuous-Time Stochastic Processes

397

10.5 Continuous-Time Stochastic Processes
It may be useful to formulate models and specifications in continuous time
even if a computer is used to implement the control law. A brief account of
continuous-time stochastic processes is therefore given.

Definitions
Continuous-time stochastic processes can be defined in the sameway as discretetime processes. The only difference is that the index set T is the set of real
variables instead of a discrete set. Covariance functions and stationary processes are defined as for discrete-time processes using the finite-dimensional
distribution functions. A spectral density can also be introduced as the Fourier
transform of the covariance function. Equation (10.5) is then replaced by
(10.24)

The inverse transform is given by

(10.25)
which replaces (10.6). The spectral density has the same interpretation as for
discrete-time systems.

White Noise
White noise is defined as a stationary process witb constant spectral density. If

;((0) :; ~
21l'

it follows formally from (10.25) that the corresponding covariance is a delta
function, that is,

r(t) ~ ro6(t)
Continuous-time white noise thus has the property that values ofthe signal at
different times are uncorrelated as for discrete-time white noise. Continuoustime white noise has, however, infinite variance. This will cause Borne mathematical difficulties. Intuitively, continuous-time white noise is analogous to
delta functions in the theory of linear systems.
Some of the difficulties with continuous-time white noise can be avoided
hy introducing a stochastic process that fonnally is the time integral

w(t) "

1.'

e(o) do

Disturbance Models

398

Chap. 10

of white noise e. The stochastic process w has zero mean value. Its increments
over disjoint intervals are uncorrelated. If the covariance function of e is

cov(e(t),e(s))

= ro8(t -

s)

then the variances of the increments of ware given by

E(W(t)-W(S))2

~ lt-si·ro

The stochastic process {w(t), t € T} is called a WIener process if it also is Gaussian. The Wiener process is a model for random walk. The infinitesimal increment

dw

=w(t + dt) - w(t)

has the variance

E(dw)2 :: TO dt
The increment dw thus has the magnitude J ro di in the mean-square sense.
The number ro dt is called the incremental covariance ofthe Wiener process.

State-Space Models
State models for continuous-time processes can be obtained by a formal generalization of (10.7) to

dx
-::; Ax+o.
dt
where Ii is a vector whose elements are white-noise stochastic processes. Because v has infinite variance, it is customary to write the equation in terms of
differentials as

dx ::: Axdt + dv

(10.26)

where v is the integral of v. The signal v is thus assumed to have zero mean,
uncorrelated increments, and the variance
(10.27)
It is also assumed that dv is uncorrelated with x. Aprecise meaning can be given
to (10.26) without any reference to white noise. This form is therefore common
in mathematically oriented texts. The form is also useful as a reminder that dv
has a magnitude proportional to /di.
Equation (10.26) is called a stochastic differential equation. To specify it
fully, it is also necessary to give the initial probability distribution of x at the
starting time. The following continuous-time analog of Theorem 10.2 is then
obtained.

399

Continuous-Time Stochastic Processes

Sec. 10.5

THEOREM 10.5 FlLTERING OF CONTINUOUS-TIME PROCESSES

Consider a
stochastic process defined by the linear stochastic differential equation (10.26)
where the process v has zero mean and incremental covariance R1 dt . Let the
initial state have mean mo and covariance R o. The mean-value function of the
process x is then given by
dm(t) __ Am(t)
dt

m

(0)

(10.28)

::: mo

and the covariance function is given by
cov(x(s),x(t)) :: ~(s-t)P(t)

t

(10.29)

P(O) = Ro

(10.30)

8

2:

where P(t) = cov(x(t),x(t)) is given by

d~~t)

::: AP(t) + P(t)A T + R1

Proof The formula (10,28) for the mean value is obtained simply by
taking the mean value of (10.26), Notice that d» has zero mean,
1b obtain the differential equation in (10,30), notice that
d(xxT )

;;::

(x + dx)(x + dx)T - xxT

= X dxT + dx xT + dx dx T

Equation (10.26) then gives

d(xxT )

= x(Ax dt + dvf + (Ax dt + dv)xT + (Ax dt + du)(Ax dt + dvl

Taking mean values gives

because dv is uncorrelated with x. Furthermore, it follows from (10.27) that

E du duT

=Rs dt

Hence

dP =: PAT dt + AP dt + R1 dt + APAT (dt)2

Dividing by dt and taking the limit as dt goes to zero gives the differential
equation in (IO.30).1b obtain Eq. (10.29), let s ~ t and integrate (10.26). Hence
x(s) = eA(s-t)x(t) + is ~(S'-s') du(s')

Multiplying by xT(t) from the right and taking mathematical expectation give
(10.29). Notice that dv(s') is uncorrelated with x(t) if s' 2: t.
•

Disturbance Models

400

Chap. 10

Example 10.8 First-order continuous-time system
Consider the scalar stochastic differential equation

dx= -axdt+dv
x(to) ::; mo

var( x(to)) ::; ro

where the process {vlt), t E T} has incremental covariance
(lO.28) that the mean-value function is given by

rl

dt. It follows from

dm

-=-am
dt

This equation has the solution

The covariance function is given by

s~t

r{s,t)=cov(x(s),x(t)) =e-,](s-tlP{t)
and

r{s, t):::; e~(l-$lp{s)

s~t

Equation (1O.30) gives the following differential equation for P.

dP
-dt = -2aP +rl

P(to) :::; ro

This differential equation has the solution

P(t) ::; e-2G(Ho )ro +

it

e- 2a(H)rl

ds

10

== e - 2a(HO)ro + ~

A:D to -t
goes to

-00,

(1 _e-

2a (H

ol)

the mean-value function goss to zero and the covariance function

hecause the limiting covariance function depends only on the argument difference
s - t, the limiting process is (weakly) stationary and its covariance function can
be written as

Equation (10.24) gives the corresponding spectral density

r·
1
9(W) = -'- . - 2
2Ji

w + a~

•

Sec. 10.5

401

Continuous-Time Stochastic Processes

Filtering Continuous-Time Processes

The analysis of linear systems with continuous-time stochastic processes as
inputs is analogous to the corresponding analysis for discrete-time systems.
Consider a time-invariant stable system with impulse response g. The inputoutput relationship is
y(t) =

.l~ g(t ~ sluts) ds =

l'

g(s)u(t - s) ds

(10.31)

(compare with Eq. (10.12}]. Let the input signal u he a stochastic process with
mean-value function mu and covariance function r. ,
The following result is analogous to Theorem 10.2 for discrete-time systems.

10.6 FJLTERING STATIONARY PROCESSES Consider a stationary
linear system with the transfer function G. Let the input signal be a stationary
continuous-time stochastic process with mean value 1n u and spectral density
¢u. If the system is stable, then the output is also a stationary process with the
mean value
THEOREM

and the spectral density
(10.32)
The cross-spectral density between the input and the output is given hy

The result may he interpreted in the same way as the corresponding result for
discrete-time systems. Compare with Remarks 1 and 2 of Theorem 10.2.
•
Example 10.9 Spectral density of a continuous-time process
Consider the system in Example 10.8. The process x can be considered as the
result of filtering white noise with the variance ft /2lr through a system having
the transfer function

1

G(s) = s+a
It follows from (10.32) that the spectral density is given by

•

Disturbance Models

402

Chap. 10

Spectral Factorization
It follows from (10.32) that if the input is white noise with 4Ju
spectral density of the output is given by

= 1, then the
(10.33)

This means that any disturbance whose spectral density can be written in this
form may be generated by sending continuous-time white noise through a filter
with the transfer function G.
Becauselinear flnite-dimensional systems have rational transfer functions,
it follows that signals with arbitrary rational spectral densities can he generated
from linear finite-dimensional systems. The covariance function is nonnegative
and symmetric. It then follows from (10.24) that ¢ is also symmetric. If ¢ is
rational it then follows that its poles and zeros are symmetric with respect to
the real and imaginary axes. The transfer function G in (10.33) can then be
chosen so that all its poles are in the left half-plane and all its zeros in the left
half-plane or on the imaginary axis. The following analog of Theorem 10.3 is
thus obtained.
THEOREM 10.7 SPECTRAL FACTORIZATION Given a rational spectral density ¢ (zo} , there exists a linear finite-dimensional system with the rational transfer function
G(s) = B(s)
A(s)
such that the output ohtained when the system is driven by wbite noise is a
stationary stochastic process with the given spectral density. The polynomial A
has all its zeros in the left half-plane. The polynomial B has no zeros in the
right half-plane.
•

10.6 Sampling a Stochastic Differential Equation
If process models are presented in continuous time as stochastic differential
equations, it is useful to sample these equations to obtain a discrete-time model.
Consider a process described by
dx

= Axdt + dUe

(10.34)

where the process Vr: has zero mean value and uncorrelated increments. The
incremental covariance of Vr is R 1 dt. Let the sampling instants be {tk; k =
0, 1, ... }. Integration of (10.34) over one sampling period gives

Sec. 10.7

403

Conclusions

Consider the random variable

This varia.ble has zero mean because u(' has zero mean. The random variables
ll(t.. ) and V(tl) are also uncorrelated for k ~ I because the increments of v over
disjoint intervals are uncorrelated. The covariance of v(t.) is given by

(10.35)

It is thus found that the random sequence {x(t~).k ;:: O,l, ... } ohtained by
sampling the process {x(t)} is described by the difference equation
X(thl) = eA (t•• I-t·).r(t..) +v(tJt)

where {u(t.)} is a sequence of uncorrelated random variables with zero mean
and covariance (10.35).

10.7 Conclusions
The main purpose ofthis chapter is to develop mathematical models for disturbances. The result is a uniform approach to models for a wide variety ofsignals.
The signals are viewed as being generated from dynamic systems driven by a
pulse, a sequence of pulses, or white noise. Equivalently, the signals may be
considered 88 being generated by dynamic systems with initial conditions.
Simple disturbances like step, ramp, and sinusoid can be generated 88
outputs oflinear systsmsdriven by a pulse. More complicated disturbances may
beviewed as pulse responses ofmore complicated systsms. Section 10.3 shows
that the class of disturbences could be widened by driving the systems with
signals composed of several pulses. This leads to the piecewise deterministic
signals. A further extension is given in Sec. 10.4, where the input signal to the
disturhance-generating system was chosen as white noise.
A unified way of modeling different types ofdisturbances is obtained. The
disturbances are characterized by a dynamic system
y(k) =

~I:l

E(k)

(10.36)

where the input e is a pulse, several pulses, or white noise. The system is
called the disturbance generator. The dynamic systsm can, of course, also be
represented in state-space form.

404

Disturbance Models

Chap_ 10

The problem ofprediction is important when controlling systems with disturbances that cannot be measured. The problem of predicting a signal given
by (10.36) is in essence to compute e from y. This is the same as inverting
the dynamic system (10.36). To obtain a stable inverse, the polynomial B(q)
must then have all its zeros inside the unit disc. This will, in general, not be
the case for deterministic disturbances. A consequence is that the performance
of the prediction will deteriorate. It takes longer to obtain the prediction. For
a stochastic system it follows from the spectral factorization theorem that the
polynomial B (q) has all its zeros inside the unit disc or on the unit circle.
The essential point of the discussion is that the predictors for the signals
are uniquely given by the pulse-transfer function H = B I A. The predictors
are thus the same for inputs that are pulses, pulse trains, or white noise. This
means that predictors that are designed for deterministicdisturbancescanwork
very well also for stochastic disturbances if the disturbance generators for the
signals are the same. The unified approach to model disturbances also leads to
a substantial simplification of the theory becauseit is sufficient to work with a
few prototypes for disturbances only.

10.8 Problems
10.1 List situations in which it is possible to reduce the influence of disturbances by
(a) reduction at the source, (b) local feedback, and (c) prediction.
10.2 Show that the predictor (lOA) is equivalent to the predictor (10.3).
10.3 Determine the m-step predictor for the disturbance model
y(k)

C(q)
===

A(q) w(k)

where w(k) is zero except at isolated points that are spaced more than degA.
Use the result to determine the signal and the prediction when A(q) = q - 0.5 1
C(q} = q, and m = 3 and when w(k) is zero except for k = 0 and 5. The initial
conditions are assumed to be equal to zero.
10.4 Use Theorem 10.1 to compute the stationary covariance function ofthe process

x(k + 1) =

0.4 0)
(-0.6 0.2 x(k) + u(k)

where v is a white-noise process with zero mean and the variance

10.5 Consider a stationary stochastic process generated by
x(k + 1) == I1lx(k) + v(k)

y(k) =Cx(k)

Sec. 10.8

405

Problems

where II (k) is a sequence of equally distributed, independent, zero-mean, stochastic
variables. Let q, have the characteristic equation

Show that the autocovariance function of the output ry(r) satisfies

for t ;:: n + 1. (This equation is called the Yule- Walker equatiun.)

10.6 Consider tbe process
x(k + 1) '"
y(k)

(-a -b x(k) +v(k)
0)
o

= (1 1) x(k)

where v(k) is white noise with zero mean and the covariance matrix

Show tbat y(k) can be represented in the form

q+e

y{k)

=A. (q + a)(q + b) e(k)

where e(k) is white noise with zero mean and unit variance, Find the relationship
from wbich A. and c can be determined.
.

10.7 A stochastic process y(k) is described by
x(k + 1) = ax(k) + u(k)

y(k)

=x(k) + e(k)

where II and e are normally distributed white-noise processes with tbe properties

vare =
Ev(k}e(j)

r2

= r12

wben k '" j and 0 otherwise

Show that y(k} can be represented as the output of a linear filter
q-c
y(k) =A. e(k)

q-a

lei

~

1

where e{k) is white noise with zero mean and unit variance. Determine A and c.

Disturbance Models

406

Chap. 10

10.8 Detennine the covariance function, ry{ r), and the spectrum, 4'y(w), of the process
)'(k) when

y(k) - O.7y(k -1) ;: e(k) - O.5e(k -1)

where e(k) is white noise with unit variance.
10.9 Determine the variance of' the stochastic process y(k} defined by
y(k) -1.5y(k - 1) + O
.7y(k - 2) == e(k) + O
.2e(k - 1)

where e is white noise with unit variance.
10.10 Calculate the stationary covariance function ry{ r), r == 0, 1,2, ...• for the system
y(k) == e(k) - 2e(k - 1) + 3e(k - 2) - 4e(k - 3)

when e is zero-mean white noise with unit variance.
10.11 Assume that we want to generate a signal y(k) with the spectral density

1

¢y{m)

==

1.36 + 1.2cosw

(a) Determine a stable filter H(q) that gives the desired signal )'(k) ;: H(q)e(t),
where e is white noise such that e E N(O,t,.

(b) What is the variance of y?
10.12 Consider the discrete-time system
x(k + 1) == ( 0.3 0.2) x(k) + ( 0 ) u(k) + v(k)
o 0.5
1
y(k):=

(1 0) x(k) + e(k)

Assume that v and e are white-noise processes that are uncorrelated and with the
eovariances

respectively. Assume that the initial value has the zero-mean value and the
variances

00-

Compute the stationary value of the covariance ofthe state vector.
10.13 Assume that a white-noise generator is available that gives a zero mean output
with unit variance. Determine a filter that can be used to generate a stochastic
signal with the spectral density
1J(ltJ) _ .......-..,_ _3

_

2ft( 5.4-3 - 5.40 cos (fi)) )

Sec. 10.9

Notes and References

4D7

10.9 Notes and References
The principles for reducing disturbances by feedback and feedforward and the
classic disturbance models are a key element of classic feedback theory. See
Brown and Campbell (1948), Chestnut and Mayer (1959), and Gille, Pelegrin,
and Decaulne (1959).
The notion of piecewise deterministic signals was introduced in Astrom
(1980) where the formulas for prediction are proven and more details are given.
Tables for the integrals for computing the variancefor low values of n are given
in Jury (1982).
The ideas of representing disturbances as stochastic processes was also
part of classic feedback theory. See James, Nichols, and Philips (1947), Thien
(1955), Laning and Battin (1956), and Newton, Gould, and Kaiser (1957).
A reasonably complete treatment of stochastic processes requires a full
book. The following books give a good background: Parzen (1962), Papoulis
(1965), Karlin (1966) , Chung (1974L Kumar and Varaiya (1986) , and Caines
(1988). There are also shorter summaries in the books on stochastic control
listed in what follows.
Prediction theoryoriginated in Kolrnogorov (1941), Wiener (1949), Kalman
(1960b), and Kalman and Bucy (1961). The papers hy Wiener and Kolmogorov
are not easy to read. Areadableaccount of'Kolmogorov's work is found in Whittle
(1963). Wiener's results were originally published as an MIT report in 1942. It
became known as the "yellow peril" because of its yellow cover and its style
of writing. Kalman (1960b), which deals with discrete-time processes, is easy
to read. There are also full books devoted to prediction, filtaring theory, and
stochastic control: Astrom (1970), McGarty (1974), Box and Jenkins (1976) ,
and Anderson and Moore (1979).

11
Optimal Design Methods:
A State-Space Approach
11.1 Introduction
In Chapters 4 and 5 the synthesis problem is solved using pole-placement techniques. The main design parameters have been the locations of the closed-loop
poles, and the presentations have been limited to single-input-single-output
systems. In this chapter a more general control problem is discussed. The process is still assumed to be lineal', but it may be time-varying and have several
inputs and outputs. Further, process and measurement noise are introduced
in the models. The synthesis problem is formulated to minimize a criterion,
which is a quadratic function of the states and the control signals. The resulting optimal controller is linear. The problem, which is stated formally in
what follows, is called the LinearQuadratic (LQ) control problem, or the Linear
Quadratic Gaussian (LQG) control problem if Gaussian stochastic disturbances
are allowed in the process models. The stationary solution to the LQ-problem for
time-invariant systems leads to a control law of the same structure as the state feedback controllerin Chapter 4. The LQ-controller can also be interpreted as a
pole-placement controller. The degrees of freedom of the multivariable version
of the controller in Chapter 4 is resolved by the minimization of a loss function
instead of specifying only the closed-loop poles.
LQ-control is a large topic treated in many books. In this chapter, only
a brief review of the main ideas and results is given. The problem is stated
and some useful results are given in this section. The solution of the LQ-control
problem, if all the states are available, is given in Sec. 11.2,where the properties
of LQ-eontrollers are also discussed. If all the states are not measurable, they
can be estimated using a dynamic system) as in Sec. 4.4. For the case with
Gaussian disturbances, it is possible to determine the optimal estimator, which
408

Sec. 11 .1

409

Introduction

minimizes the variance of the estimation error. This is called the Kalman filter.
The estimator has the same structure as in (4.28). However, the gain matrix,
K I is determined differently and is in general time-varying. Kalman filters are
discussed in Sec. 11.3. The LQG-problem is solved in Sec. 11.4, where the states
are estimated using a Kalman filter. The solution is based on the separation
theorem or the certainty equivalence principle. This implies that the optimal
control strategy can be separated into two parts: one state estimator, which
gives the best estimates of the states from the observed outputs, and one linearfeedback law from the estimated states. The linear controller used is the same
as the one used if there are no disturbances acting on the system. Some practical
aspects are discussed in Sec. 11.5.

Problem Formulation
The design problem is specified by giving the process, the criterion, and the
admissible control laws.

The process.

It is assumed that the process to be controlled is described

by the continuous-time model

dx = Axdt + Budt + d»,

(11.1)

where A and B may be time-varying matrices. The process Vc has mean value
of zero and uncorrelated increments. The incremental covariance of Uc is R lc dt
(compare with Sec. 10.5). The model in (11.1) can be sampled as in Sec. 10.6.
Some modifications must be made because the system is allowed to be timevarying. The input u(t) is constant over the sampling period; for the noise-free
case the solution of (11.1) can be written as

x(t)

= ¢(t.kh)x(kh) + r(t,kh)u(kh)

(11.2)

where ¢(t, kh) is the fundamental matrix of (11.2) satisfying

d

dt c1>(t,kh) = A(t)¢(t,kh)
and

r(t,kh)

=

r-:

i;

¢(kh,kh)

=I

s)B (s) ds

Omitting the time arguments of the matrices, the sampled model can be
written as

x(kh + h)

= c1>x{kh} + ru(kh) + v(kh)
(11.3)

y(kh) ::: Cx(kh} + e(kh )

Chap, 11

Optimal Design Methods: AState-Space Approach

410

where v and e are discrete-time Gaussian white-noise processes with zero-mean
value and

Ev(kh)vT(kh)

= u, ~ [

,MRleeAT , ds

Eu(kh)eT(kh) = R12

Ee(kh'leT(kh) ::: R2

The expression for the covariance matrix R1 was given in Sec, 10.6. Further, it
is assumed that the initial state x(O) is Gaussian distributed with
Ex(O) = mo

and

cov(x(O)) = Ro

The matrices Ro,Rl' and R2 are positive semidefinite. The covariance matrices
may be time-varying. It is assumed that the model (11.3) is reachable and
observable.
As discussed in Chapter 4, it is possible to include other types of disturbances and effects from the environment by augmenting the state vector ofthe
process.
The criterion. The design criteria we will use is a way of weighting the
magnitudeofthe states and control signals.One way can be to look at the power
of the state) that is,

J =

!.

N lI
0

2

r

Ix(t)1 dt:::: Jo

X(t)Tx(t) dt

The components ofthe state may have different dimensions and we can instead
use a more general weighting

where Qlc is a symmetric positive semidefinite matrix. The control signal and
the state at the end time can be penalized in a similar way. This leads to a

control problem where we want to minimize the loss function
J

~ E((h (x1
(t)Q"x\t) + 2xT(t) Q12'U( t)
+ uT(t)Q"u(t)) dt + XT(Nh)QfkX(Nh))
=

E( (

(x T(t)

T

u (t) ) Q,

[~i:~)

(11.4)
T

dt + x (Nh )Qo,x(N

h))

Sec. 11.1

Introduction

411

with

and where the matrices Qoc. Qlc~ and Qz.. are symmetric and at least positive
semidefinite. The matrices in the loss function may depend on time.

Admissible control laws.

It is important to specify the data available for
determining the control signal. The first assumption is that periodic sampling
is used and that the control signal is constant over the sampling periods. Tbe
control problem can then easily be translated into a discrete time problem.
If C equals the unit matrix and if e(kh) = 0 in (11.3), then tbe full-state
vector is available. The control signal is then allowed to be a function of the state
up to and including time kh. This is called complete state information. In many
cases only the outputs can be measured. This implies that only noise-corrupted
measurements are available for the controller. This is called incomplete state
information. In this case the control signal at time kh is allowed to be a function of the outputs and inputs up to and including either time kh - h or time

kh.
The problem. The optimal control problem is now defined to be finding
the admissible control signal that minimizes the loss function of (11.4) when
the process is described by the model of (11.1) or the equivalent model of (11.3).
The design parameters are the matrices in the loss function and the sampling

period.

Sampling the Loss Function
The loss function in (11.4) is expressed in continuous time . It is first transformed
into a discrete-time 108s function . Integrating (11.4) over intervals of lengths h
gives

where

(11.5)
Using (11.2) in (11.5) and the fact that u(t) is constant over the sampling period
gives

Optimal Design Methods: A State-Space Approach

412

Chap. 11

where
(11.6)
(11.7)

(11.8)
Minimizing the loss function of {11.4) when u(t) is constant over the sampling
period is thus the same as minimizing the discrete-time loss function
J

~ E (~ ( xT(kh)Q,x(kh) + 2xT(kh)Q12U(kh)
+ uT(kh)Q.,u(kh)) + xT(Nh)Qox(Nh))

~ E(~ (xT(kh)

uT(kh)) Q

(11.9)

(:i~~D + xT(Nh)Qo,X(Nh l)

where

Q=

(Q~

Q12)
Q12 Q2

(11.10)

The matrices Q}, Q12, and Q2 are given by (11.6) to (11.8), respectively, and
Qo ;: Qoc. In the following it is assumed that Ql and Qo are positive semidefinite
and that Q2 is positive definite. The condition on Q2 will be relaxed in what
follows. Notice that the sampled loss function (11.9) will have a cross-coupling
term Q12 even if Q12c == o.
When the stochasticcase is considered, one additional term depending on
the noiseis obtained in (11.9). However, this term is independent ofthe control
signal and can thus be disregarded when performing the minimization.
The optimal-control problem has now been transformed into the discretatime problem of minimizing the loss function (11.9) when the process is described hy (11.3) . 'Th facilitete the writing in the sequel, it is assumed that the
sampling period is used as time unit, that is, h :: 1.

Completing the Squares

Quadratic functions will be minimized several times in the sequel, The loss
functions will have the form
(11.11)

Sec. 11.2

413

Linear Quadratic Control

and we want to find the minimum with respect to u. Then there exists an L
satisfying
(11.12)

such that the

1086

function (11.11) can be written as
(11.13)

This is easily shown by inserting (11.12) into (11.13). Rewriting (11.11) as in
(11.13) is called completing the squares. Because (11.13) is quadratic in u and

both terms are greater or equal zero, it is easily seen that (11.11) is minimized
for

u = -Lx

(11.14)

and that L is unique if Qu is positive definite. The minimum is

(11.15)

11.2 Linear Quadratic Control
The LQ-control problem will now be solved for the case of complete state information.
The Deterministic Case

Thedeterministiccase,where u(k) == 0 and e(k) = 0 in (11.3), is first considered.
The system is thus described by
r(k + 1) = t1>x(k) + ru(k)

(11.16)

where x(O) is given. The problem is now to determine the control sequence u(O),
u(1), . .. , u(N - 1) such that the 108s function in (11.9) is minimized.
The idea behind the derivation of the control law is to use the principle of
optimality and dynamic programming. The principle of optimality states that
an optimal policy has the property that whatever the initial state and initial
decision are the remaining decisions must be optimal with respect to the state
resulting from the first decision. By using this idea and starting from the end
time N and going backwards in time,it is possible to determine the best control
law for the last step independent of how the state at time N - 1 was reached.
The remaining loss-to-go will now depend on the state at time N - 1. Iterating
backwards to the initial time k = 0 determines the optimal-eontrol policy. The
procedure is called dynamic programming and was introduced by Bellman. The
solution is given by the following theorem.

Optimal Design Methods: A State~Space Approach

414

-I

o

Vk

... ,

I
k

i-t

..

Chap. 11

I
N

•
Time

Iteration direction

Figure 11.1 Illustration ofthe iteration procedure using dynamic programming.
THEOREM 1l.l LQ-CON'fROL OF A DE'l'ERMINISTIC SYSTEM Consider the
system of (11.16). Allow u(k) to be a function of x(k), x(k -1), .... We introduce

S(k) = ll>T S(k t 1)$ + Ql - (<I>T S(k t

x (rTS(k +

nr + Q12)

nr + Q2r-l (rTS(k+ 1)~ + Qf2)

(11.17)

with end condition S(N) = Qo. Assume that Qo is positive semidefinite and
that Q2 + r" S (k) r is positive definite. Then there exists a unique, admissible,
control strategy
u(k)

= -L(k)x(k)

(11.18)

where
(11.19)
that minimizes the loss (11.9). The minimal value of the loss is
minJ

=:

Vo = xT(O)S(O)x(O)

Further S(k) is positive semidefinite.

Prooi.

To prove the theorem, dynamic programming will be used. We
start from the end point and iterate backwards in time. See Fig. 11.1. Introduce

Vk can be interpreted as the loss from k to N (loss-to-go) and is a function of
the state x(k) at time k. For k = N we have

415

Linear Quadratic Control

Sec. 11.2

where
S(N)

=Qo

We will now show that Vk will be quadratic in x(k) for all k. For k == N - 1,
VN-l

=:

min (xT(N - 1)QIX(N - 1) + uT(N - l)Q.!u(N -1)

I.I(N-1)

T(N

+ 2x

- 1)Q12U(N - 1) +

(11.20)

VN)

Using (11.16) for k ::: N - 1 gives
VN -l

=:

min

u(N-l)

(x (N - l)QIX(N - 1) + u(N - 1)Q2u(N - 1)
T

T

+ 2xT (N ~ 1)Q12U(N -- 1)
+ (€I>x(N - 1) + ru(N - 1)) T S (N) (€I>x(N - 1) + fu(N =:

min

u(N-l)

1)))

(x (N ~ 1)(c. + ClJTS(N)€I»x{N - 1)
T

+ xT(N - 1) ($TS(N)r + Q12 )u(N - 1)
+ uT(N -l)(rTS(N)€I> + Qf2)X(N - 1)

+ uT(N - I} (rTS(N)r + Qz )u(N

=u(N-l)
min

-1))

(xT(N-l) uT(N-l))

x ( Qt + $T S(N)$ r T
S(N)¢J + Qf2) (X(N - 1) )
¢JTS(N)r + Q12

rTS(N)r + Q2

u(N -1)

This is a function that is quadratic in u{N - 1). By using (11.14) and (11.15) ,

the control law
u(N - 1) = -L(N - l)x(N - 1)
gives the minimum loss
VN - 1 ::; xT(N - l)S(N - l)x(N -1)

which is quadratic in x(N - 1) and where

Optimal Design Methods: A State-Space Approach

416

Chap. 11

and

Because VN-l is positive semidefinite, so is its minimum, that is, S(N - 1) is
positive semidefinite. Dynamic programming now gives
u-:
VN-2 ==

min

u(N-2),u (N-l) (

L (:t7(i)QI (i ) + uT(i )Q2u (i )
X

I :::

N

-2

+ 2xT UlQ"u(i)) +x (N)QoX(N))
T

=u(N-2) (xT (N - 2)QIX(N min

2) + uT (N - 2)Q2U(N - 2)

+ 2xT(N - 2)Q12U(N - 2) +

VN-l)

This is the same as (11.20), but with the time arguments shifted one step. The
procedure can now be repeated, and Vo = xT(O)S(Olx(O), which is the minimum
of J. is obtained by iterating backward in time. This proves (11,17) to (11.19).
It also follows that (11.17) can be written as

S(k)

= (<I> - rL(k))' S(k + 1}('" - rL(kl) + (I -Llk)')

Q (-:lk)

1

(11,21)

This implies that S(k) is positive semidefinite if S(N}
inite.

= QD is positive semidef•

Remerk 1. Notice that it is not assumed that Qz be positive definite,
only that Q2 + rTS(k)f is positivedefinite.

Bemerk 2. The calculations needed to determine the LQ·controller can
be made by hand only for very simple examples. In practice it is necessary to
have access to interactive programs, which can compute the control law and
simulate the systems.

The Riceall Equation
Equation (11.17) is called the discrete-time Riccati equation. It is possible to
use the Riccati equation to rewrite the loss function of (11.9), which gives the
following theorem.
Assume that the Riccati equationof (11.17) has a solutionthat is nonnegative definite in the interval
THEOREM 11.2 DISCRETE-TIME RICCATI EQUATION

Sec. 11 ,2

417

Linear Quadratic Control

o s k s N; then
N-l

T

x (N)Qox(N) +

2: (x

T

T(k)Q12

T

U
(k)QIX (k) + u (k)Q2 (k) + 2x

U (k))

k=Q
N-l

= xr (O)S(O)x(O)

+

L (u(k) + L(k)x(k))

T

k=O

x (rTS(k + l)r + Q2) (u(k) + L(k)x(k))

+[

(VT(klS(k +

1)(eJ>x(k) + rU(k)) + (<I>x(k) + rU(kl)'S(k+ l)V(k))

k=O
N-l

L uT(k)S(k+ l)v(k)

+

(11.22)

k",O
N-l

T

= x (O)S (O)x(O) +

L (u(k) + L(k )x(k) + i; (k)u(k))T
k=Q

X

(r TS(k + nr + Q2) (u(k) + L(k}x(k) + Lu(k)v(k))
N-l

+

2: vT(k) (S(k + 1) - L~(k)(rTS(k + nr + Q2)L (k)) v(k)
u

k=O
N -l

+

2: vT(k)S(kt l ) (fll - f L(k))x(k)
k=O

N-l

+

2: x (k) (€I> - rL(k))
T

T S(k + 1)v(k)

(11.23)

k=O

where L(k) is defined by (11.19) and

and x(k + 1) is given by (11.3).
We have the identity

Proof.

N-l

T

=x

(0) S(O)x(O) +

2: (x

T

(k + 1)S(k'" l)x(k + 1) - x1 (k)S(k)x(k))

k=O

(11.25)

Optimal Design Methods: A S1a1a-Space Approach

418

Chap. 11

Consider the different terms in the sum and use (11.3) and (11.17). Then
,?(k+ 1)S(k+ l)x(k+ 1)
::: (CIlx(k) + ru(k) + v(k)) T S(k + 1) (<1lx(k) + ru(k) + V(k))

(11.26)

and
xT(k)S(k)x(k) =xT(k) (CbTS(k + l)CIl + Ql

-

LT (k)(rTS(k +

nr + Q2)L(k) )x(k)

(11.27)

Introducing (11.26) and (11.27) in (11.25) gives
N-l

T

x (N)Qox(N)

T

= x (O)S (O)x(O) + L [(
CIlx(k) + rU(k)) S (k + 1 )u(k)
T

11',0

+ vT(k)S(k+ 1) (<Px(k) + rU(k)) + vT(k)S(k+ l)v(k)]
N-I

+ l:[uT(k)(fTS(k+ l)r+ Q2)u(k)
k=O

+ uT (k) (r T 8(k + 1)<1l + Qf2 )x(k)
+ xT(k )(CbTS(k + l)r + Q12 )u(k)

+ xT(k)LT(k) (rrS(k + l)f + Q2)L(k)x(k) - xT(k)QIX(k)
- uT (k)Q2U(k) - U(k)TQf2 X(k) - xT (k)Q12U(k)]

where the terms uTQzu, u(k)TQ12X(k), and xT(k)Q12U(k) have been added and

subtracted in the last sum. Rearrangement of the terms using (11.19) gives
(11.22). 1b show the second equality use (11.24) and insert that in (11.22).
Rearrangement of the terms gives (11.23) and completes the proof.
I

Mean Value of 8 Quadratic Form
In the following, expressions of the form
ExTSx

will be evaluated, where x is a Gaussian random variable with mean m and
covariance matrix R. We have

ExTSx = E(x-mfS(x-m)+EmTSx+ExTSm-EmTSm
::: E (x - m)TS(x - m) + mTSm

419

Linear Quadratic Control

Sec. 11.2

Further,
E(x-m)TS(x-m) == Etr(x-m)TS(x-m) = EtrS(x-m)(x-m)T
= trSE(x-m)(x-ml

= trSR

Thus

(11.28)
Complete State Information
Assume that u(k) .= 0 in (11.3} but that the initial state is uncertain. Theorem 11.2 gives

J =E

(E

(?(k)Q1 X(k) + uT(k)Q2 U(k) + 2xT(k)Q12u (k)) + XT(N)QoX(N»)

= E (x T (O)S(O)x(O))
+ E (};(u(k) + L(k)x(k)f (rTS(k +

ur + lh)(u(k) + L(k)X(k)))

Because S (k) is positive semidefinite, the second term is nonnegative. Further,
S(k) is independent ofu(kL and it follows that
~ ExT (O)S(O)x(O) ::: m~ S(O)mo + tr S(O)R o

Jcornplete

(11.29)

where (11.28) has beenused. Equality is obtained for the controJ law of (11.18).
Theorem 11.2 and (11.29) give an alternative way to prove Theorem 11.1.
Now assume that there are stochastic disturbances acting on the system
and that the full state is still measurable. Using Theorem 11.2. (11.22), and
that u(k) is independent of u(k) and x(k) gives

J

=

E(xT(O)S(O)x(O) + I>(k)S(k + 1)v(k)
'\"'0

E(

N-l

+

f

u(k) + L(k)x(k) (rTS(k + nr +

lh) (u(k) + L(k)x(k)))
(1l.30)

Using (11.28) gives the relationship
N-l

Jnoise;:::

m~S{O)mo+trS(O)Ro+ I:trS(ktl)R 1
11=0

(11.31)

Optimal Design Methods: A State-Space Approach

420

Chap . 11

Equalityis obtained for the control law of (11.18) which is an admissible control
law. The difference in the optimal costs of (11.29) and (11.31) is due to the
disturbance u(k). The control law of (11.18) thus minimizes the loss for the
complete state information case.
Assume on the other hand that v(k) is known when determining u(k).
From (11.23) it follows that the loss function is minimized for
I

u(k) :: -L(k)x(k)- LII(k)u(k)

(11.32)

where LIJ is given by (11.24) and the minimum loss is
N-l

= m5'S(O)mo + tr S(O)Ro + L tr S(k + 1)R 1

J

k=O
N-l

- L tr Lv(k)RIL~ (k) (r TS(k + nr + Q2)
k=O

This loss is less than (11.31) and shows the improved performance if v(k) could
be used.
The solution to the LQ-problem gives a time-varying controller. The feedbackmatrix does not depend on r and can be precomputed from k = N to k = 0
and stored in the computer. For time-invariant processes and loss functions,
usually only the stationary controller-the constant controller obtained when
the Riccati equation is iteratad until a constant S is obtained-is used. S(k)
will-under quita general assumptions--eonverge to a constant matrix as the
time horizon increases. In general, there exist several solutions resulting from
different Qo.
The stationary solution can he obtained by iterating (11.17) or by solving
the algebraic Riccati equation

Because Q in (11.10) is symmetric and positive semidefinite we can write

If the system of (11.16) is reachable and if

has full column rank for Izi :2: 1, that is,there are nounstable zeros to the system
defined by 4'1, r Ci, and Dl l then there exists only one symmetric nonnegative
definite solution to the algebraic Riccati equation (11.33).
I

421

Linear Quadratic Control

Sec. 11.2

.--

(a)

1~

(b)
1~

,

-

o \ ..,....., ..------\
\ .
.I

o '/.>. ~
\

-1 ........ I

-11-

o

o

10

10

(d)

(c)

--

1

1- ....

o

O~-.-.-.-

.....

-1

-1

o

o

10

10
Time

Time

Figure 11.2 Linear quadratic control of the double-integrator plant for
different weightings, p, on the control signal. The initial valueofthe state is
x(O) = [1 01. The position Xl (dashed), velocity X2 (dashed-dotted), and the
control signal u (solid) are shown. (a) p =0.01563, (b) P "" 0.05, (c) P =0.5,
and (d) p =10.

Example 11.1 LQ-control of the double integrator
Consider the double integrator (see Example A.1) and use the sampling period
h =1. Let the weighting matrices in (11.9) be

The influence of the weighting can now be investigated. The stationary feedback
vector has been calculated for different values of p , Figure 11.2 shows the states
and the control signal for some values. When p = 0, which means there is a
penalty only on the output, thenthe resulting controller isthe sameas the deadbeat
controller in Sec. 4.3. When p is increased, then the magnitude ofthe control signal
is decreased.
Figure 11.3 shews the stationary L vector as a function ofthe control weighting p. When p increases the gains go to zero and there will be almost no feedback.

•
Example 11.2 Time-varying controller
Consider the integrator process
x(k + 1)

=.r(k) + u(k)

Let the 1088 function be
.(

L(x (k) + lOu
2

,1:..0

2{k))

+

qox (5)
2

Chap. 11

Optimal Design Methods: A State-Space Approach

422

. . . . . . .- ---.--,

2 ,...._~--=---~--.---.---r--------.-

.... ..... --

......

-

Control weighting p
Figure 11.3 Linear quadratic controller for the double integrator. The stationary gains l1 (solid) and l2. (dashed) of the feedback vector L == [l1> l:d for
different values ofp .

That is, the time horizon is only five steps. The Riccati equation and the controller
gain become
s2(k + 1)
s(k) ;:: s(k + 1) + 1 - s(k + 1) + 10

8(5) ;:: qo

l(k) _ s(k + 1)
- s(k + 1) + 10
Figure 11.4 shows s(k), l(k), and the trajectory of the state when x{O) = 1 for
different values of qo. The value 90 = 3.70 corresponds to the stationary solution
_
of the Riccati equation. When qo is increasing x(5) approaches zero.

Properties of theLa-Controller

The pole-placement controller in Sec. 4.3 and the stationary LQ-controller have
the same structure. However, they are obtained differently, so there are some
differences in their properties.
The linear state-feedback controller of (11.18) has n parameters in the
single-input case. It is, in general, difficult to tune the parameters directly such
that a good performance of the closed-loop system is obtained. Instead, the
tuning procedure can be to choose the n eigenvalues of the closed-loop system
and use the design procedure in Sec. 4.3. This procedure is well suitedfor singleinput-single-output systems. It is, however, difficult to compromise between the
speed of the system and the magnitude of the control signal.
The LQ-controller has several good properties. It is applicable to multivariable and time-varying systems. Also, changing the relative magnitude between the elements in the weighting matrices means a compromise between
the speed of the recovery and the magnitudes of the control signals. The following two theorems give properties of the closed-loop system when using the
LQ-controller.
THEOREM 11.3 STABIIJTY OF THE CLOSEI).LOOP SYSTEM Let the system of
(11.16) be time-invariant and let the loss function of (11.9) be such that Q in

423

Linear Quadratic Control

Sec. 11.2

10,....-----------------------..

-

__--- ..... ---- .... - - ..
. - . - .-. - .- . -.

_r;'

-"--t_"-"'_III-.-

iI

- . - . ..

.-..

"-

•

-..

•

Ol.....-------------~--~----.........-.

o

-

5

0.5 ,....------------------=--....-----,

- .. _ _.. -.-.- .....
-

-

-

-1- -

-

-

-

...

-

.

-

-

..

.... ....

....

---.-..-- . ..... .....
-.
~

~

Ol.....-----------~-------_-----J

o
5
1"""="---------------------,

--O'-~---------------------'

o

5

Time

Figure 11.4 Simulation of the process in Example 11.2 for different values
of the weighting at the end point; qo ~ 10 (dashed), qo ;;;; 3.70 (solid), and
qo "" 0 (dashed-dotted).

(11.10) is positive definite. Assume that a positive-definite steady-state solution,

S, to (11.33) exists. Then the steady-state optimal-control strategy
u(k) == -Lx(k) = - (Q2 + r T Sf) -1 (r TS¢l + Qf2)x(k)

gives an asymptotically stable closed-loop system

= (11) - r L)x(k)

x(k + 1)

Theorem 3.4 can be used to show that the closed-loop system is
asymptotically stable. It is to be shown that the function
Proof

V(x(k))

:=:

xT(k)Sx(k}

is a Lyapunov function . V is positive definite and

~ V(x(k)) :::: xT (k + l)Sx(k + 1) - xT (k)Sx(k)
= xT (k)((f> -

~ -x T (k)(Ql

= -xT(k)

r Lf S(~ - r L)x(k) of-

xT (k)Sx(k)

L T Q2L ~ LT Qfz - Q12 L )X
(k)

(I _L

T

)

Q(

_IL) x(k)

Op'ima! Design Methods: A State-Space Approach

424

Chap. 11

where (11.17) and (11.21) have been used. Because Q is positive definite and
[1 - L T ] has full rank, t:. V is negative definite. The closed-loop system is thus
asymptotically stable.
_
The case with Q positive definite in Theorem 11.3 is very special. Much more
interesting results can be obtained. The poles of the closed-loop system can be
obtained in several ways. When the LQ-controller is used the poles are obtained

from
det(,tl- <I> + rL) = 0
It is possible to show that the poles are the n stable eigenvalues of the generalized eigenvalue problem

0
det

$1'

( [ T
r

-I
0

(11.34)

0

Equation (11.34) is called the Euler equation of the LQ-problem.
Theorem 11.4 is given without proof for the single-input-single-output
(8180) case. A proofis given in Sec. 12.5.
THEOREM 11.4 THE CLOSED-WOP POLES OF AN SISO SYSTEM Let the input and the output be scalar and assume that the steady-state optimal feedback
is used for a time-invariant system. Further assume that only the output and
the control signal are penalized in the loss function, that is, Ql ;:: eTc, Q2 = p,
and Ql2 = O. The poles of the closed-loop system are the n roots within the unit
circle of the 2nth-order equation

p + H{Z-l)H(z) :;: 0

(1l.35)

where

is the open-loop pulse-transfer function.

•

Example 11.3 LQ-control of the double integrator

To illustrate the dependence of the weighting matrices on the dosed-loop poles,
reconsider Example 11.1. Figure 11.5shows the poles of the closed-loop system for
different values of p. For p = 0 the root locus starts at z = - 1 and z ;;: O. As p
increases the roots move toward the poles of H(z), z = 1.
•
Theorem 11.3 shows that the LQ-controller gives a stable closed-loop system,
that is, all the poles of the closed-loop system are within the unit circle. It is

425

Linear Ouadraiic Control

Sec. 11.2

1

.

. .........- - - - -....."""'K

-1

o

-1

1

Real axis
Figure 11.5 Closed-loop poles given by (11.35) when the double integrator
is controlled with the optimal controller for p varying from 0 to 00. The stars
indicates the closed-loop poles for (8) p == 0.01563, (b) p = 0.05, (c) p ::: 0.5,
and (d) p ; ; ; 10, which are the values used in Fig. 11.2.

also possible to get the poles inside a circle with a radius less than 1. This is
done by introducing the transformation
<1> ..., <1> I F

r

~

r/f

where r < 1, and then solving the linear quadratic problem for the system
1
r

1
r

x(k + 1) = -::- 4lx(k) + ":: ru(k)

In the z-transforrn this implies that we make the substitution

This is further discussed in Sec. 12.6.
Theorem 11.3 shows that the closed-loop system is stable when the LQ-

controller is used. It is also possible to determine the gain margin ofthe closedloop system. Consider the system of (11.3) with u(k) = e(k) = O The pulse.
transfer function of the open-loop system is

H(z) = C(zI -

<1>r- 1r

Optimal Design Methods: A State-Space Approach

426

Chap. 11

Assumethat only inputs and outputs are penalizedin the loss function of (11.9),
that is,

and that Q12 = O. Let the system be controlled by the steady-state LQ statefeedback controller. The controller is then defined by the equations

S = cDTS¢I + Ql - LTRL
L ::: R- 1r" 8<1>

(11.36)

R:::; rTsr + Q2

The algebraic Riccati equation (11,36) can be written

The Riccati equation can now be used to rewrite an equation that corresponds
to (11.35) . This gives an expression for the closed-loop poles.

Q2 + H T (z-l)H(z)

= Qz + r" (Z-I/ - $t T CT C(zI - ¢lt1r
:::; Q2 + r T (S + S<I>(zl- ¢lt l + (Z-l/ - cDrT¢lTS
+ (z- 11 - cDrTLTRL(z/ -¢lt1)r

= R + RL(zI - ¢lt1r + r" (z -lJ - cDrTLT R
+ r" (z-1/ - $rTL TRL(zJ -

¢lttr

:; ; (I + L(Z-l] - <1>t1r) TR (I + L(zl - <Ilr1r )
= (I + Hdz- 1)) TR(1+ H1(z))
(11.37)
where

Equation (11.37) gives a spectral factorization of

Consider the SISO case. Then

H(z) :::; C(z! _ <1lt 1r

;:

B(z)

A(z)

Sec. 11,2

427

Linear Quadratic Control

and the closed-loop system is defined by

Hc(z) = C ( zl - (fl> - T'L) )

-1

I'

B(z)

= P(z)

Notice that H and He have the same zeros. Compare with Sec. 4.6. Further,
the return difference of the system with the LQ-controller is
1 + L (zl - fl>

P(z)
r 1r ::: A(z)

Hence
H ( ) = P(z) - A(z)
1Z
A(z)

Now assume that the controller in (11.18) is replaced by
u(k)

= -fjLx(k)

(11.38)

where fj is a positive scalar. The return difference when (11.38) is used is

Thus the stability ofthe closed-loop systemwhen (11.38) is used is determined
from
A(z) + f3 (P(z) - A(z)) = 0

(11.39)

The gain margin can now be determined from (11.39) by using root locus or
by plotting the Nyquist curve for (P - A)IA. Because A and P are monic and
deg A = degP, it follows that deg(P - A) ::; n - 1. This implies that the root
locus of (11.39) with respect to fj goes to infinity along at least one asymptote.
Hence the discrete-time LQ controller has a finite gain margin, as opposed to
the continuous-time LQ-controller, which has infinitegain margin.
In the scalar case, (11.37) can be written as
(11.40)
where r =

rrsr + p,

How to Find the Weighting Matrices
When using optimization theory, the loss function should ideally come from
physical arguments. In such cases the :LQ(kontrol theory may be viewed as
an approximation when the state equations are obtained from linearization of
equations of motion and the loss function is obtained from a nonlinear loss
function. Unfortunately, such formulations can be obtainedonly in a few cases.
One example is Example 11.4.

Optimal Design Methods: A State-Space Approach

428

Chap. 11

Example 11.4 Ship steering
The linearized dynamics that describe the steering of ships can be described by
the equation

(11.41)

where 0 is rudder angle, 't' is the heading angle, r is the turning rate, and lJ the
sway velocity. The relative increase in the drag due to steering may be approximated by the expression
(11.42)

The first term represents the Coriolis force due to coupling of sway velocity and
turning rate. The second term represents the drag induced by the rudder deflections.
-

In many cases it is difficult to find natural quadratic loss functions. LQ-control
theory has found considerable use even when this cannot be done. In such
cases the control designer chooses a loss function. The feedback lawis obtained
directly bysolving the Riccati equation. The closed-loop system obtained is then
analyzed with respect to transient response, frequency response, robustness,
and so on. The elements of the loss function are modified until the desired
result is obtained. Such a procedure may seem like a strange use ofoptimization
theory.
The fact that other methods, such as direct search over the feedback
gain or pole placement, are not used instead might be questioned. It has heen
found empirically that LQ-theory is quite easy to use in this way. The search
will automatically guarantee stable closed-loop systems with reasonable margins.

It is often fairly easy to see how the weighting matrices should be chosen to infiuence the properties of the closed-loop system. Variables Xi, which
correspond to significant physical variables, are chosen first. The loss function is then chosen as a weighted sum of Xi. Large weights correspond to
small responses. The responses ofthe closed-loop system to typical disturbances
are then evaluated. A particular difficulty is to find the relative weights between state variables and control variables, which can be done by trial and
error.

Sometimes tbe specifications are given in terms of the maximum allowed
deviations in the states andthe control signals for a given disturbance. One role
ofthumbto decide the weights in (11.4) is to choose the diagonal elements as the
inverse value ofthe squareofthe allowed deviations. Another way is to consider
only penalties on the state variables and constraints on the control deviations.
If the constraints are quadratic, a method using a Lagrange multiplier gives a
criterion such as (11.9).

Sec. 11.3

429

Prediction and Filtering Theory

Prediction

Filtering

Smoothing

k

k -1

k+l

Figure 11.6 Smoothing, filtering, and prediction.

11.3 Prediction and Filtering Theory
When using the LQ-eontroller, the full-state vector must be measurable. The
problem of estimating the states of (11.3) from measurements of the output is
discussed in this section. An estimator of the same structure as in Sec. 4.4 is
postulated. but the gain vector is now determined differently. The problem is
solved as a parametric optimization problem. where the variance ofthe estimation error is minimized.

Prediction, Filtering, and Smoothing
Different estimators for the states in (11.3) can be derived depending on the
availablemeasurements. Assume that the data

Yk ;:: {y(i), uti) lis k}
is known. Using Yk we want to estimate x(k + m}. We have three cases:
• Smoothing (m < 0)
• Filtering (m

= 0)

• Prediction (m > 0)

Figure 11.6 illustrates the different cases. In this section the prediction and
filtering problems are discussed. The resulting dynamic system is called a filter
regardless ofwhich of the problems is solved.

The Kalman Filter
Let the process be described by (11.3) with h
estimator of the form
x(k + 11 k)

:=

= 1. Postulate an one-step-ahead

€l>i(k I k - 1) + fu(k) + K(k) (y(k) - Cx(k I k -

1))

(11.43)

Optimal Design Methods: A State~Space Approach

430

The reconstruction error i ;:: x -

Chap. 11

xis governed by

i(k + 1) = <Pi(k) + u(k) ~ K(k) (y(k) - Cx(k I k - 1))

: : (<p - K(k)C)x(k) +v(k) =

(1

-K(k)) ([

K(k)e(k)

(11.44)

~ ) i(k) + [~~:m

In Sec. 4.4 K is used to give the system of (11.44) desired eigenvalues. The
problem is approached differently here: The properties of the noise are taken
into account and the criterion is to minimize the variance of the estimation
error, which is denoted by P(k}.
P(k) = E (i(k) - Ei(k))(x(k) - Ei(k)f

The mean value of x is obtained from (11.44)
Ei(k+l) ~ (~-K(k)C)Ei(k)

Because E:c(O) = mo, the mean value ofthe reconstruction error is zero for all
times k 2: 0 independent of K if x(O) = mo. Because i( k) is independent of u(k)
and e(k) Eq. (11.44) now gives

P(k + 1)

= EX(k + 1)x(k + l)T

= (1
=(

I

-K(k)) ( (

~) P(k) (~)

+

T

[:[2

~~2)) (-K~(k))

) ( ~p(k)lf>T + R 1 <PP(k)C +R 12 )
-K(k)
CP{k)tPT +Rf2 CP(k)CT +R2
T

(

I
)
-KT(k)

{11.(5)
Further, P(O) = Ro. From (11.45) it follows that if P(k) is positive semidefinite.
then P(k + 1) is also positive semidefinite. Equation(1l.45) has the sameform
as (11.11) and should be minimized with respect to K(k). By using the idea
of completion of squares, it follows that aT P(k + l)a is minimized by K(k)
satisfying

for any a. If CP{k)C T

+ R2 is positive definite then
(11.46)

Sec. 11.3

431

Prediction and Filtering Theory

This inserted into (11.45) or using (11.15) gives
P(k + 1) = <l>P(k)<ll + R 1
_ (<I>P(k)C T +

R12) (R 2 + CP(k)CT ) -1 (CP(k)<I>T + R[2)
(11.47)

P(O) = Ro
The reconstruction defined by (11.43), (11.46), and (11.47) is called the Kalm~
/Uter. This is summarized in the following theorem.
THEOREM 11.5 THE KALMAN FILTER-PREDICTOR CASE

Consider the process of (11.3). The reconstruction of the states using the model in (11.43) is
optimal in the sense that the variance of the reconstruction error is minimized
if the matrix R2 + CP(k)CT is positive definite and if the gain matrix is chosen
according to (11.46) and (11.47) , The variance of the reconstructing error is
given by (11.47) .
•
Remark 1. The reconstruction problem has been solved as a parametric
optimization problem by assuming the structure in (11.43) of the estimator. It
is in fact true that the structure is optimal for Gaussiandisturbances.
Remark 2. Better than the traditional notation for the variance P(k)
is P(k I k ~ 1). The latter notation indicates that measurements up to and
including time k - 1 are used. The different terms in the variance equation of
(11.47) can be interpretedin the following way: The term etIp~T shows how the
variance is changed due to the system dynamics, and R 1 represents the increase
in the variance due to the noise v [compare with (10.11)]. The last term shows
how the variance is decreased due to the information ohtained through the
measurements. Notice that P(k) does not depend on the observations. Thus the
gain can be precomputed in forward time and stored in the computer.
Remark 3. The Kalman filter can also be interpreted as the conditional
mean of the state at time k + 1 given Yk ; that is,
x{k + 11 k) ::: E(x(k + 1) I Yk)

P(k + 1)

~ E [(X(k+ 1) -x(k + 11 kl)(x(k + 1) -x(k+ 11 klf I YI]

Example 11.5 Kalman filter for a first order system
Consider the scalar system
x(k 1 1) := x(k)

y(k)

~

x(k) + e(k)

Optimal Design Methods: A stats-soace Approach

432
(a)

'a"
i::

~

1~

Chap. 11

---------

01-------1

500

0

(b)

'"'

1

ril

0

~

-1

500

0

(c)

'~
"

Iil

1
0

~-

-1

500

0

Time
Figure 11.7 Estimation error for the system in Example 11.5 when starting
from x(O) = -2, and when using (1 =1 and (a) K = 0.01, (b) K ;::: 0.05, and
(c) the optimal gain of (11.49).
where e has standard deviation (J and x(O) has the variance 0.5. The state is thus
constant and has to be reconstructed from noisy measurements. The Kalman filter
is given by
i(k + 11 k) "" i(k I k - 1) + K(k) (Y(k) - ilk I k P(k)

K(k}

= (}"2 + Plk) and

1))

(T2p(k)
P(k + 1) :;;; (T2 + P(k)

(11.48)
(11.49)

The variance and the gain are decreasing with time. Figure 11.7 shows realizations
of the estimation error when the Kalman filter is used and when (llAB) is used
with constant gain. A large fixed gain gives a rapid initial decrease in the error,
while the steady-state variance is large. A small fixed gain gives a slow decrease
in the error, but a better performance in steady state.
•

The Filter Problem
Thepredictor in (11.43) has the properlythat the state at time k is reconstructed
from y(k -1), y(k - 2), .. .. It is also possible to derive the filter, which also uses
y(k), to estimate x(k). In the filter case y(k) will containinformation about v(k),
which will be reflected in the equations that follow.

Sec. 11.3

433

Prediction and Filtering Theory

THEOREM 11.6 KALMAN FILTER-FILTER CASE

Consider the process (11.3)
and let Yk be available for the estimation of x(k). If the matrix R2 + CP(k \
k - l)CT is positive definite then the optimal filter is given by the following
equations:

= x(k l k -

x(k I k)

1) + Kr(k) (Y(k) - Ci(k I k - 1))

v(k I k) = KtJ(k) (Y(k) - Ci(k I k

-1))

(11.50)

x(k + 11 k) = t:l>i(k I k) + ruCk) + 6(k I k)
== <l>i(k I k - 1) + ru(k)

+ K(k) (Y(k) - Ci(k I k - 1))

where
P(k I k -l)C T ( CP(k I k ~ l)C T +R 2 ) -1

(11.51)

:=

R 12( CP(k I k -l)C T + Rz) -1

(11.52)

:=

<1.lKr(k) + Ku(k)

Kr(k)

:=

Ku(k)

K (k)

:;:: (CPP(k I k - l)C T + R1 2) ( CP(k I k - 1)CT + R2) -1

(11.53)

The variance is given by the Riccati equation

P(k + 1 I k) = CPP(k I k - l)<I>T + R 1

-K(k)(CP(klk-1)C T +R 2 )K T(k)
P(k I k)

z:

P(k I k - 1)
- P(k I k -l)C T ( CP(k I k -l)C T + R2 )

"en» I k-l)

P(O 1-1) == Ro

(11.54)

Proof

The proof is based on expressions analogous to (11.45).

•

Remark 1. The notation P(k I k - 1) is used here instead of P(k) to
specify the available data; P(k I k) is the variance of the estimation error at
time k given Yk.

Remark 2.

Notice that the expression for x(k + 1 I k) in (11.50) is the

same as in (11.43).

Remark 3. Notice that 6(k + 1 J k) = 0 because y(k) does not contain
any information about v(k + l}.

Optimal Design Methods: A State-Space Approach

434

Chap, 11

El:ample 1l.6 Kalman filter and prediction
Consider the first-order system
y(k) + ay(k - 1)

= e(k) + ce(k -

(11.55)

I}

where e has standard deviation cr. Further assume that
representation of (11.55) is given by

lei

< 1. A state-space

x(k + 1) ~ -ax{k ) + e{k)

y(k)

In this case R I

;:

~ (c - a)x{k)

+ e(k)

R 2 "" R 12 = a'l, The Kalman filter in steady state is given by

= _a2 --::-c - ao-)
_-_aP (_ _ -

K

(c - a)2p + 0''2

P

=a

2P

(72_aP(c _ a))2
2

--,-'_ _...".--_--::"-+(7 (c-a}ZP+cr 2

It is easy to verify that the solution is P '" 0 and K ;;- 1. The one-step-ahead
predictor of x is given by
x(k + 11 k)

-ai(k I k - 1) t y(k) - (c - a).i(k I k - 1)
-;:. -d(k I k -1) + y(k)

z:

Further, in steady state, the one-step-ahead prediction of the output is given by

y(k + 11 k) ;:: (c - a)x(k t 11k)
c-a
y(k)
- 1 + cq:'
If le i> 1 then (11.55) first has to be transformed to a new representation using
spectral factorization to get a stable C -polynomial.
•

Frequency-Domain Properties of Kalman Filters
Modeling is very important when design problems are solved using optimization
techniques because the optimal regnlator, or the optimal filter, is just a transformation of the model. It is thus useful to understand the properties of this
transformation. In this section some insight into the design of Kalman filters
is provided by analyzing the frequency-domain characteristics of a stationary
Kalman filter. Consider the problem of estimating the state of the system

x(k + 1) == <l>lx(k) + u(k)
based on noisy observations

y(k) :;; C1x(k) + n(k)

Sec. 11 .3

Prediction and Filtering Theory

435

where the noise n is given hy
n(k) = C2z(k) + e(k)
z(k + 1) = .p2z(k) + w(k)

In these models, u(k), e{k), and w(k) are sequences of uncorrelated random
variables. The steady-state Kalman filter for one-step prediction of x is given
by

or

The Kalman filter is thus characterized by the pulse-transfer function from y
to x and z:

A frequency-response plot of the transfer function shows how the filter attenuates different frequencies. It is veryuseful to determine the frequency responses
ofthe filter when designing Kalman filters. The properties of the frequency reo
sponse will, in general, depend on the model in a complicated way. There are,
however, some general properties that may be understood without detailed calculations.
LEMMA 11.1 TRANSM1SSION ZEROS OF THE KALMAN FILTER The transmission zeros of the pulse-transfer function (11.57) of the stationary Kalman filter
are given by

det(zI - <1J2) ;:; 0

Prool

A transmission zero is a complex number z such that an input
signal of the form zkYD gives zero output. For the system (11.56), x(k + I} =
x(k) :::; 0 implies that there exist Yo andi(k) ;:; zOZk where ~OO < k < 00 and
Yo f. 0 such that

K1C2Z0 - K1yo = 0
(zI - <I>2 + K2C2)ZO - K2 yo = 0

436

Optimal Design Methods: A State-Space Approach

Chap. 11

or

-K
-C 1
0 -K (I 0]

= (ZI- <IJ 2

2]
1

2

(io )

Yo:;;

0

There exists a nonzero solution to this equation only for those z that are eigenvalues of the matrix (J)2.
•
Remark. The Kalman filter will have zeros at the poles of the noise
model. To obtain a Kalman filter that blocks certain frequencies (a notch filter)
is just a matter of choosing a noise model with poles at those frequencies. The
attenuation of certain frequencies by the Kalman filteris enhanced if the energy
of the noise is increased at those frequencies in the noise model.

11.4 Linear Quadratic Gaussian Control
In the LQG-control problem, it is assumed that the system is governed by (11.3)
and that the loss function is given by (11.9). The admissible controls are assumed to be such that u(k) is a function of Yk-l or ofYk - 1 and y(k).
Theorem 11.2 and (11.30) still hold for the case of incomplete state information. Because (11.18) is not an admissible control strategy, the third term
in (11.30) cannot be made equal to zero. The solution is given by the following
theorem.
Consider the system in (11.3).
Let the admissible control strategies be such that u(k) is a function of Yll-l.
Assume that S(k) is given by (11.17) with initial condition S(N) ~ Qo and
with Qo positive semidefinite. If r T S(k)r + Q2 is positive definite then there
existe a unique admissible control strategy
THEOREM 11.7 THE SEPARATION THEOREM

u(k)

= -L(k)i(k k J

1)

(11.58)

that minimizes the expected loss (11.9) .The minimum value ofthe loss function
is given by
s-:

J ::: m& S(O)mo + tr S(O)Ro +

L tr S(k + 1)R

1

k"O
N-l

+

L tr P(k)LT(k)(rTS(k + nr + Q2)L(k)
k=O

(11.59)

437

Linear Quadratic Gaussian Control

Sec. 11.4

Proof. The theorem follows directly from Theorem 11.2and (11.22) and
that v(k) is independent of u(k) and x(k). Equation (11.28) gives the value of
I
the loss function.

Remark 1. The difference in the minimal losses given by (11.31) and
(11.59) is due to the estimation ofthe state variables,
It is possible to modify Theorem 11.7 to other admissible
control strategies-sfor instance, the case when u(k) is allowed to be a function
ofYk - 1 and y(k).1t follows from (11.23) that the control lawis given by [compare
with (11.32)]
Remark 2.

u(k} = -L(k)i(k I k) - Lv(k)O(k I k)

= -L(k)x(k I k - 1) - (L(k)Kf(k) + Lu(k)Ku(k)) (y(k) - Cx(k I k - 1))
= - (L(k) - M(k)C )x(k I k - 1) - M(k)y(k)

(11.60)

where v(k I k) is given by (11.50) and where

Further L(k), Lu(k), Kf(k) . and Kv(k) are given by (11.19), (11.24), (11.51).
and (11.52), respectively.
The controllers (11.58) and (11.60) can be written in a unified form as
u(k) = - (L(k) + M(k)C )£(k I k - 1) - M(k)y(k)

(11.61)

where
M(k)

o
={

if u

L(k)Kr(k) + Lu(k)K,,(k)

::::

((Yk - 1)

if u :: f(y(k), Yk- 1)

Substitution of (11.61) into (11.22) gives
N-l

J pred

= Jno ise +

L tr L(k)P(k)LT(k)(rTS(k + nr + Q2)
k=O

where J noise is given by (11.31). Further (11.61) gives in (11.23)
N-l

Jfilt :::

J pred

-

T(k)
L tr M(k)(CP(k)C T + R2)M (rTS(k + nr + Q2)
k=O

Chap. 11

Optimal Design Methods: A State-Space Approach

438

c-----

e

v

I Process

I

x

r

I
I
I

c

I
I

<I>

~

~

J

~

~tim~~---------------I

I
I
I

K
II

I
I
I
I
L

f.

r

~

I
I
I

_

~~

~taref~b~------

I

x
-L ....._ _

I

~

I
I
I

---J

J

-~-----,

I

I
J

Figure 11.8 The closed-loop system when the controller in the separation
theorem (Theorem 11.7) is used.

This shows that the loss is decreased when the current measurement is used to
determine the control signal.
One consequence of the separation theorem is that the synthesis problem
can be split into two parts, which can be solved separately. First, the deterministic control prohlem is solved, giving L(k) (and Lv(k)). Second, the state
is estimated using the Kalman filter. A block diagram of the system with the
optimal-control law is shown in Fig. 11.8.
Duality
The solutions to the LQ-control problem and the state-estimation problem are
very similar. It can be shown that the state-estimation problem is equivalent
to an LQ-problem. The equivalence is illustrated by Table 11.1, which shows
the substitutions required to convert the optimal-control problem to a stateestimation problem,

Sec. 11.4

439

Linear Quadratic Gaussian Control
Table 11.1 Substitutions required to convert the optimal-control
problem to a state-estimation problem.

Optimal-Control Problem

State-Estimation Problem

k

N -k

~

~T

r

CT

Qo

Ro
Rl

Ql

R 12
P
KT

Q12

S
L

Properties of the Closed-Loop System

The closed-loop system with LQG-control is described by
x(k + 1) = ~x(k) + ru(h ) + v(h)
y(k) = Cx(k) + e(k)
u(k) ;;;; -(L - M C}x(k I k - 1) ~ My(k)

x(k + Il/l) = ~.i(k 1 k -1) + ru(k) + K(Y(k) - Ci(k Ill-I))
By introducing x and x= x - Xl the equations can be written as

X
{k+l ))
( x(k+l)

=

(~-rL r(L-MC)] (X(h)]
0

ct>-KC

+ (~l v(k)+

i(k)

(-~:l elk)

The dynamics of the closed-loop system are determined by ct> - r Land <1> - K C,
that is, the dynamics of. the 'corresponding deterministic LQ~ontrol problem
and the dynamics of the optimal filter (compare with Sec. 4.5). Notice that
the closed-loop systems have the same poles independently even if the current
measurement is used or not to determine u.
The Servo Problem

The servo problem is discussed in Sec. 4.6 for the state-feedback controller. For
the LQG-problem, the reference signal can be introduced in the same way as
in Fig. 4.13. The only difference is that the feedback matrix L is obtained by
minimizing the quadratic loss function.

440

Optimal Design Methods: A State-Space Approach

Chap. 11

11.5 Practical Aspects
The previous sections show how the LQ~ and the LQG.control problems can
be solved. There are several practical problems when applying LQ-control. One
occurs in choosing the design parameters-that is, the weightings in the loss
function-which is discussed in Sec. 11.2, and the sampling period. Another
problem is the difficulty of obtaining good models for the process and the disturbances. Still another problem is making the numerical computations necessary
to get the resulting controller.

Model Comp'ex;ty
One criticism of LQ-control is that an accurate full-order model of the process
must be available. Most physical processes are of high order. However, for control purposes it is often sufficient to use a low-order approximation. Ways to
obtain mathematical models are discussed in Chapter 13.
One way to decrease the sensitivity to modeling errors is to decrease the
desired bandwidth of the closed-loop system by changing the weightings in the
loss function. Compare this with the robustness results in Sec. 3.3. Another way
to decrease the sensitivity to modeling errors is to introduce artificial noise,
which means that the noise covariances used in the design of the Kalman filter
are larger than the true values.

Solution of the Riccati Equation
In many cases, only the steady-state optimal controller is implemented, which
means that the steady-state values ofthe Riccati equations, (11.17) and (11.47),
have to be determined. There are several ways to do this numerically. Oneway
is to assume a constant S or P and solve the algebraic equations. A straightforward way to get the solution is to iterate the equations until a stationary
condition is obtained. The standard method uses orthogonal matrices to transfer the Euler equations to triangular (Schur) form with the stable eigenvalues
in the upper left part. It is, however, important to make the computations so
that the solution is guaranteed to he symmetric and positive definite. Special
methods have been derived to solve the Riccati equation, such as square-root
and doubling algorithms. When using the square-root method, the square root
of S or P is calculated. This gives better numerical properties. Doubling algorithms or fast algorithms speed up the calculation of the stationary value by
computing the solution at time 2k when the solution at time k is given. Many
books and papers about different methods are available.

Choice of Sampling Period
The choice of the sampling period is influenced by how the specifications are
given for the control problem. Two different cases are considered.
In the first case it is assumed that the specifications are given as a desired damping and response of the closed-loop system without using overly large

Sec. 11.6

441

Conclusions

control signals. It is then natural to determine the controllerby iterating in the
weightings of the sampled loss function of (11.9). To do this, a first choice of the
sampling period has to be made based on the specifications. It is reasonable to
choose the sampling periodin relation to the dynamics ofthe closed-loop system,
as discussed in Sec. 4.3. This means that it may be necessary to make one or
two iterations in the sampling period. The closed-loop dynamics is a complicated
function ofthe loss function.
In the second case it is assumed that the specifications are given in terms
ofthe continuous-timelossfunctionof (11.4). The continuous-time LQ-controller
then minimizes the loss. It is possible to get an approximationof the increase in
the loss due to an increase in the sampling period (see the References). When
good interactive design programs are availahle, it is easy to check the loss and
the performance for some sampling periods.

11.6 Conclusions
Optimal design based on state-space models are discussed in this chapter. The
LQ-controllers and Kalman filters have many good properties. The main problem with LQ-control is translating the specifications on the system into a loss
function. This is usually an iterative procedure, where it is necessary to have
good interactive computer programs available.

11.7 Problems
11.1 Consider the first-order system
dx

- = - ax + bu
dt
Assume that the loss function of (11.4) should be minimized with Qlc = 1 and
Q2c = p . Determine the corresponding discrete-time loss function (11.9).
11.2

Consider the continuous-time double integrator in Example A.1. Assume that the
loss function of (11.4) should be minimized with

QIe

=

(~ ~)

and

Q~ = 1

Determine Ql. Q12. and Q2 in the corresponding discrete-time lossfunction (11.9).
11.3 Given the system
x(k + 1) = ax(k) + bu(k}

with the loss function

Let the admissible control strategy be such that u(k) is a function of x(k). Determine the strategy that minimizes the loss.

442

Optimal Design Methods: A State-Space Approach

Chap. 11

11.4 Consider the system in Problem 11.3. Determine the control strategy that minimizes the loss when the admissible control strategies are such that u(k) is a
function of x(k - 1).
11.5 The inventory model in Example A.5 is described by
x{k + 1);
y(k) =

(~ ~) x{k) + (~) u(k)

(1 0) x(k)

(a) Determine the steady-state LQ-controller when Ql ;;;:; CT C and Q2

::::: p.

(b} Determine the poles of the closed-loop system and investigate how they depend on the weight on the control signal, p.
(c) Simulate the system using the controller in (a). Assume that x{Of -;:: 11
and consider the output and the control signal for different values of p .

11

11.6 Consider the two-tank system with the pulse-transfer operator given in Problem
2.10 (b). Use (11.35) and plot the root locus with respect to p that shows the
closed-loop poles when the system is controlled by the steady-stare LQ-controller
for the loss function
00

J::

2: (Y{k)2 +pU(k)2)
A: =O

11.7 Show that a deadbeat control law, a control law such that the matrix «1:1- r L has all
its eigenvalues at the origin, can be obtained from the discrete-time optimization
with Q2 = 0, Ql = 0, and Qo = 1.
11.8 Consider the ship-steering problem characterized by the model of (11.41) and
the loss function in (11.42). Use the numbers all = - 0.454, a12 = -0.433,
a:n ::::; -4.005, an = -0.807, b, : : ; 0.097, b2 :: -0.807, a = 0.014, and p == 0.08.
Determine the optimal state feedback when h "" 5 s,

11.9 The ship-steering problem is sometimes approximated further by using the secondurder model

and the following approximation of the loss function:

Determine tbe optimal feedback for a sampled regulator. Use the parameters
a = 0.001, k =:: 0.0005, and p = 0.08, and the sampling period h = 5 s.
1l.lQ Consider the LQ-controller determined in Problem 11.5 for the inventory model.

Use (11.39) to determine the gain margin.

Sec. 11.7

443

Problems

11.11 A stochastic process is generated

8S

=O +u(k)
.5x(k)
y(k) =x(k) + e(k)

x(k + 1)

where v and e are uncorrelated white-noise processes with the covariances 'I and
r2, respectively. Further, x{D) is normally distributed with zero mean and variance
"0, Determine the Kalman filter for the system. What is the gain in steady state?
Compute the pole of the steady-state filter and compare with the pole of the
system.
11.12 The double integrator with process noise can he described by
x(k + 1)

~ (~ ~) x(k) + (O~5 ) u(k) + (~) v(k)

y(k) =

(1 0) x(k)

where v{k) is a sequence of independent, normal, zero-mean, random variables
with unit variance. Assume that x(O) is normal with mean Ex{O) ~ (lIlT and the
covariance matrix Ro = 3 · I.
(a) Determine the equations forthe covariance matrix ofthe reconstruction error
and the gain vector in the Kalman filter.

(b) Simulate the covariance and gain equations and determine the speed ofconvergence and the steady-state values.
11.13 Consider the double integrator in Problem 11.12, but let the output be
y(k)::

(1 0) x(k) + v{k)

(a) Determine the equations forthe covariance matrix ofthe reconstruction error
and the gain vector in the Kalman filter.
(b) Simulate the covariance and gain equations and determine the speed ofconvergence and the steady-state values.

11.14 Given the system
x(k + 1) =
y(k) =

(~ ~) x(k) + (~) v(k) + (O~5)

(1 0) x(k)

where u{k) is zero-mean white noise with standard deviation 0.1.Assume the x(O)
is known exactly. Determine the estimateofx{h+3}, given y(k) that minimizes the
prediction error. Use that to determine the hest estimate of y(3) and its variance.
11.15 The signal x(k) is defined as

x(k + 1) =-= nx(k} +u(k)
y(k) = x(k) + e{k)

Optimal Design Methods: A State-Space Approach

444

Chap. 11

where v and e are independent white-noise processes with zero mean. The variances are 1 and. o , respectively. The signal x is estimated using exponential
smoothing as
x(k 1 k) ,;; Q'x(k - 1) I k - 1) + (1- a)y(k)
Determine an expression for how the variance of the estimation error depends on
the parameters a and (J. Compare with the steady-state optimal Kalman filter.
11.16 Show that Theorem 11.5 can be generalized to the situationwhen the disturbances

e(k) and v(k) have constant but unknown mean values. (Compare with Sec. 4.5.)
11.17 A constant variable x is measured through two different sensors. The measurements are noisy and have different accuracy. Let the system be described hy
x{k + 1) ~ x(k)
y(k) ;;;; Cx(k) + e(k)
where CT

'"

[11] and e(k) is a zero-mean white-noise vector with the covariance

matrix

Estimate r as

Determine the constants a1 and a2 such that tbe mean value of the prediction error is zero and such that the variance ofthe prediction error is as low as possible.
Compare the minimum. variance with the cases when only one of the measurements is used, Compare the solution with the Kalman filter.
H.I8 Prove that the filter estimate given by (11.50) to (11.54) is the optimal filter in
the sense that the variance of the estimation error is minimized.
11.19 Consider the design ofa Kalman filter for estimating the velocity in a motor drive
based on angle measurements. The basic dynamics of the motor, which relate the
angle to the current, is given by
G(s} _
1
- s(s + 1)

Assume that there are low-frequency disturbances (friction) that are modeled as

zdkh + h) ; zl{kh) + wdkh)
Also assume that it is desirable to filter out disturbances because of a mechanical
resonance at the frequency fJJ. This signal is modeled as the signal obtained by
driving a system with the transfer function
(j)2

G(s)

= s2 + 2~ ws + co2

with white noise. Determine the Bode diagrams for the Kalman filterfor { ; 0.05,
= 0.1, and w '" 2. Let the sampling period be 0.05 s, Also investigate the
influence ofdifferent relative intensities ofthe low-frequency and the band-limited
disturbance.

{J)

Sec. 11.7

445

Problems

11.20 Consider the system

1.45 -0.45)
( 1)
0
x(k) + 0 u(k)

x(k + 1) :: ( 1

y(k):: (0.5 0.38) x(k)
Determine the stationary controller u(k) = -L:r(k) that minimizes the lOBS function
00

J :;: ExT{k)CTCx(k)
~",l

11.21 A computer is used to control the velocity ofa motor. Let the process be described
by
x(k + 1) :: O.5x(k) + u(k)
y(k) :: x(k) + e(k)

where x is the velocity, lL i% the input voltage, and y is the tachometer measurement ofthe velocity. The measurement noise is white noise with the variance 0'2.
Assume that the initial speed is a stochastic variable with zero mean and unit
variance. Construct a controller that minimizes the loss function

The parameter p is used to control the amplitude of the control signal. It is further
desired that the velocity be as small as possible after two sampling intervals.

(a) Determine the optimal controller when a -': 0 and the regulator parameters
when p 1, p =0.1, and when p ~ O.
;:<

(b) Determine the optimal controller when the measurement noise has the variance (]2 :: 1.
11.22 Given the system

x(k + 1) :: x(k) + v(k)
ydk) = x(k) + e}(k)
Y2(k) :: x(k) + e2(k)
where [J E N(O,O.l), el e N(O, 0'1)1 and ez
mutually uncorrelated.

E

N(O, (12); and

LI, ell

and

(a) Determine the Kalman filter that gives i(k I k - 1) for the system.

(h) Compute the stetionary variance when a,
(c) Compute the stationary gain when (Jl

:;::

= 1 and (J2 =2.

1 and 0'2 ~ 2.

e2

are

446

Optimal Design Methods: AState-Space Approach

Chap. 11

11.8 Notes and References
LQG-control and optimal filters are the subjects ofmany textbooks, for instance,
Athans and Falb (1966), Bryson and Ho (1969),ktrom (1970),Andersson and
Moore (1971, 1979, 1990), Kwakemaak and Sivan (1972), and Kucera (1991).
The principle of optimality and dynamic programming are discussed, for instance, in Bellman (1957, 1961).
Kalman and Bucy made the main contributions to the development of
the recursive optimal filters discussed in Sec. 11.3. See Buey (1959), Kalman
(1960b), and Kalman and Bucy (1961) .
A good source for properties of the discrete-time as well as continuous-time
Riccati equationsis Bittanti, Laub, and Willems (1991). Numerical algorithms
for solving the Riccati equation are also discussed, for instance, in Kleinman
(1968), Biermann (1977), Pappas, Laub, and Sandell (1980), Van Dooren (1981).
Arnold III and Laub (1984), and Benner, Laub, and Mehrmann (1995). The
Euler equation is discussed, for instance, in Emami-Naeini and Franklin (1980),
Arnold III and Laub (1984), and Hagander and Hansson (1996).
Choice of the sampling interval for LQ-eontrollers is discussed in Astrom
(1963), Melzer and Kuo (1971), and Lennartson (1987).
The separation theorem Theorem 11.7 appeared first in economic literature: Simon (1956). Discrete-time versions of the separation theorem can be
found in Gunkel and Franklin (1963).
Gain margin for discrete-time LQ~ontrollers is discussed in Willems and
Van De Voorde (1978) and Safonov (1980). Robustness of LQG controllers is
discussed in Doyle and Stein (1981).
Many of the modifications for the third edition of the book are based on
Gustafsson and Hagander (1991). The cross terms in both the loss function
(Q12 I- 0) and the Kalman fil~r (R 1Z t- 0) are also discussed in Kwong (1991).

12
Optimal Design Methods:
A Polynomial Approach
12.1 Introduction
Optimal design methods based on input-output models are considered in this
chapter. Design of regulators based on linear models and quadratic criteria is
discussed. This is one class of problems that admits closed-form solutions. The
problems are solvedby other methods in Chapter 11. The input-output approach
gives additional insight and different numerical algorithms are also obtained.
The problem formulation is given in Sec. 12.2. This includes discussion
of models for dynamics, disturbances, and criteria, as well as specification of
admissible controls. The model is given in terms of tbree polynomials. A very
simple example is also solved using first principles. This example shows clearly
that optimal control and optimal filtering problems are closely connected. The
prediction problem is then solved in Sec. 12.3. The solution is easily obtained by
polynomial division. A simple explicit formula for the transfer function of the
optimal predictor is given.
The minimum-variance control law is derived in Sec. 12.4. For systems
with stable inverses, the control law is obtained in terms of the polynomials
that characterize the optimal predictor. For systems with unstable inverses,
the solution is obtained by solving a Diophantine equation in polynomials of
the type discussed in Chapter 5. The minimum-variance control problem may
thus be interpreted as a pole-placement problem. This gives insight into suitable
choices of closed-loop poles and observer poles for the pole-placement problem.
The LQG<ontrol problem is solved in Sec. 12.5. It is shown that the solution
may be expressedin terms ofspectral factoriza tion and solution of a Diophantine
equation. Practical aspects, such as selection of the sampling period, are given
in Sec. 12.6.
447

448

Optimal Design Methods: A Polynomial Approach

Chap. 12

12.2 Problem Formulation
It is assumed that the process to be controlled is linear and time-invariant and
that it has one input u and one output y. The dynamics of the process are
characterized by a combination of a time-delay and a rational-transfer function.
It is also assumed that the disturbances may be described as filtered white
noise. A steady-state regulation prohlem is considered. The criterion is based
ou the mean-square deviations of the control signal and the output signal. In
the formal problem statement given next, it is assumed that the model and the
criterion are sampled (compare with Sec. 2.3 and (11 .1)].

Process Dynamics
Assume that the process dynamics are characterized by
x(k) = B1(q) u(k)
At(q)

(12.1)

where Al(q) and B1 (q ) are polynomials in the forward-shift operator.

Disturbances
Assume that the influence of the environment on the process can be characterized by disturbances that are stochastic processes. Because the system is
linear, the principle of superposition can be used to reduce all disturbances to
an equivalent disturbance v at the system output. The output of the system is
thus given by
y(k) ::; x(k) + u(k)

(12.2)

Further assume that the disturbance v may be represented as the output of a
linear system driven by white noise-that is.
v(k)::; C1(q) e(k)
A2 (q)

(12,3)

where C1 (q) and Az(q) are polynomials in the forward-shift operator, and e(k) is
a sequence ofindependentor uncorrelated random variables with zero mean and
standard deviation (J . The disturbance v may be a stationary random process. It
may, however, also be drifting, because the polynomial A2(q) may be unstable.
The model of the process and its environment can be reduced to a standard
form. Eliminate v and x among (12.1), (12.2) , and (12.3), and introduce
A == AIA2
B ; BIA 2

C :::; CIAl

(12.4)

Sec. 12.2

449

Problem Formulation

e

C
A
u

B
A

Figure 12.1 Representation ofa system with one input and stochastic disturbances using one or two noise sources.

The following model is then obtained.
A(q)y(k)

=B(q)u(k) + C(q)e(k)

(12 .5)

This is the canonical model , which will be the basis of the control design. In
the special case when there are no disturbances, the model is simply a rational
pulse-transfer function (see Sec. 2.6).When there is no control signal, the model
is a stochastic process with a rational spectral density or an ARMA process (see
Sec. 10.4). The model (12.5) is a convenient canonical representation of a linear
system perturbed by noise. In Chapter 11 the process was driven by two noise
sources. By using the spectral-factorization theorem (Theorem 10.3) the noise
can be reduced to one source. Compare Fig. 12.1.
When the polynomial C(q) has all its zeros inside the unit diSCI it is called
an innovation's representation, because the random variables e(k) represent the
innovations of the random process. Notice the symmetry between y and e. If e
and u are known up to time k, then y(k) can be computed, and if y and u are
known up to time h, the innovation e(k) can also be computed. Notice that the
calculations of the residuals are governed by the dynamics of the polynomial
C(q). This polynomial can therefore be interpreted as the observer polynomial.
Because (12.5) is an innovations model, the solutions to filtering problems become very simple.
Equation (12.5) can he normalized so that the leading coefficients of the
polynomials A(q) and C(q) are unity. Such polynomials are called monic. The
polynomial C mayalso bemultiplied by an arbitrary power of q, as this does not
change the correlation structure of C(q)e{t). This may be used to normalize C
so that deg C = deg A. The polynomials A(q) and B(q) may have zeros inside or
outside the unit disc. It is assumed that all the zeros ofthe polynomial C(q) are
inside the unit disc. By spectral factorization (Theorem 10.3), the polynomial
C(q) may be changedso that all its zeros are inside the unit disc or on the unit
circle. An example is used to show this important point.
Example 12.1 Modification of the polynomial C

Consider the polynomial
e(z)

=z + 2

Optimal Design Methods: A Polynomial Approach

450

Chap. 12

which has the zero z ; ; ; -2 outside the unit disc. Consider the signal
n(k) = C(q )e(k)

where e(k) is a sequence of uncorrelated random variables with zero mean and
unit variance. The spectral density of 11. is given by

Because

C(z)C(z' ')

= (z + 2)(Z-1 + 2) ;;; (1 + 2z- 1)(1 + 2z)
= (22 + 1)(22- 1 + 1) ;;;; 4(z + 0.5)(Z-1 + 0.5)

the signal n may also be represented as
n(k) ;; C'(q)e(k)

where
C'(z);;;;;2z+1
is the reciprocal of the polynomial C(z) (see Sec. 2.6).

•

If the calculations of (12.4) give a polynomial C (q) that has zeros outside the
unit disc, the polynomial C is factored as

where C- contains all factors with zeros outside the unit disc. The polynomial
C is then replaced by C' C-·.

Criteria
In steady-state regulation it makes sense to express the criteria in terms of
sready-state variances of the control variable and the process output. For regulation ofsystems withone output, the criterion may be to minimize the variance
ofthe output.Thisis discussed in Sec.6.6 . Also compare withFig. 6.7. This leads
to the criterion

(12.6)
where it is assumed that the scales are chosen so that y = 0 corresponds to
the desired set point. A control law that minimizes the criterion (12.6) is called
minimum-variance control. The criterion may also be expressed as

sec, 12.2

Problem Formulaijon

451

Notice that this criterion is an approximation of the continuous-time loss function

1 (T
s; = lim E {T 10 i(t) dt}

(12.7)

T-loOC

Amore accurate approximation, which takes the behavior ofthe signalsbetween
the sampling instants into account, is given in Sec. 11.1. Some consequences of
the approximation are discussed in Sec. 12.6. The properties ofthe control signal
under minimum-variance control depend critically on the sampling period. A
short sampling period gives a large variance of the control signal and a long
sampling period gives a small variance.
In some cases it is desired to trade variancesofcontrol and output signals.
This may be done by introducing the loss function
(12.8)

The control law that minimizes this criterion is called the linear quadratic
control law.

Admissible Controls
It is assumed that the control law is such that u(k), that is, the value of the
control signal at time k, is a function of y(k),y(k-1), ... and u(k -i), u(k- 2), ....
Thus the computational delay is negligible in comparison with the sampling
period. It is very easy to modify the results to take delays in the computations
into account.
There are two versions of the theory. A linear control law may be postulated. It is then sufficient to assume that the disturbances e(i) and eU) are
uncorrelated for i 1- i. If e(i) and eU) are assumed to be independent, it can be
shown that the optimal-control lawis linear. 'The formula for the optimal-control
law is the same in both cases.

Minimum-VarIance Control: An Example

The optimal-control problem defined by the model of (12.5) and the criterionof
(12.6) is solved in a special case. The solution, which is easily obtained from
first principles, gives good insight into the assumptions made. It also indicates
how the general problem should be solved.
Consider the first-order system
y(k + 1) + ay(k) = bu(k) + e(k + 1) + ce(k)

(12.9)

where [c I < 1 and e(k) is a sequence of independent random variables with unit
variance.
Consider the situation at time k. The outputs y(k), y(k - 1), ... have been
observed. 'The control u(k) shouldbe determined so that the output is as close to

452

Optimal Design Methods: A Polynomial Approach

Chap. 12

zero as possible. It follows from (12.9) that y(k + 1) may be changed arbitrarily
by a proper choice of u(k). Because e{k + 1) is independent of y(k) and of the
terms of the right-hand side of (12.9), it follows that
var y(k + 1) ~ vare(k + 1) ::;: 1

(12.10)

The term e(k) may be computed in terms of the known data y(k), y(k - 1),...
and u(k - 1), u(k - 2),.. .. When the variables y(k) and e(k) are known, the
control law
u(k) ::: (ay(k) - ce(k))/b

(12.11)

y(k + 1) =e(k + 1)

(12.12)

gives

which corresponds to the lower bound in (12.10). If the control law in (12.11)
is used in each step, Eq. (12.12) holds for all k. The computation of e(k) from
the data availanle at time k is then trivial and the control law in (12.11) can
be written as
c-a

u(k) = --b- y(k)

(12.13)

The optimal control is thus a proportional feedback with the gain (c - a)/b.
To analyze the properties of the closed-loop system under optimal control,
eliminate u between (12.9) and (12.13). This gives
}'(k + 1) + cy(k) =e(k + 1) + ce(k)

Notice that the closed-loop system has the characteristic polynomial
C(z) = z + c

Thisshows the importance ofthe assumption that the polynomial C(z) is stable.
This difference equationhas the solution

y(k) "" e(k) + (_c)k-ko(y(ko) - e(ko))
Because c is less than one in magnitude, the last term goes to zero as k ko increases toward infinity. Thus control law in (12.13) gives the minimumvariancein steady state.
With this result, some observations are possible. The quantity -ay(k) +
bu(k) + ce(k) can be interpreted as the best estimate of y(k + I), given the data
available at time k. The quantity e(k + 1)is the prediction error. Thecontrol law
in (12.13) implies that the control signal is chosen so that the predictad value
is equal to the reference value, which is zero in this case. The control error
is then equal to the prediction error. The solution to the minimum-variance
control problem is thus closely related to the solution of a prediction problem.
Therefore, the prediction problem is solved before the solution of the general
minimum-variance control problem is attempted.

Sec. 12.3

453

Optimal Prediction

12.3 Optimal Prediction
Prediction theory can be stated in many different ways, which differ in the
assumptions made on the process, the criterion, and the admissible predictors.
One formulation is given in Sec. 11.3. In this sectionthe following assumptions
are made:
• The process to be predicted is generated by filtered white Gaussian noise.
• The best predictor is the one that minimizes the mean-square prediction
error.
• An admissible m-step predictor for y(k + m) is an arbitrary function of
y(k), y(k - 1),....
An intuitive derivationofa predictor is first given. The result is then formalized,

Heuristics
Consider the signal y generated by the model

(12.14)
where A· and C· are the reciprocals of A and C, that is, A·(q-I) =

s:"A(q L and

«' is the backward-shift operator. It is convenient to introduce this operator
because the discussion is based on causality. It is assumed that A and C are of
order n.
Consider the situation at time k. The variables y(k), y(k - 1), ... have
been observed and it is desired to predict y(k + m). A formal series expansion
of C·/ A· in q-l gives
C·(q-l)

y(k + m) = A.(q-l) e(k + m)
= e(k + m) + fIe(k + m - 1) + .. . + fm-le(k + 1)
,

V

J

(12.15)

Unknown at time k

+ fme(k) + fm+le(k - 1) + ...

,

"

.;

Known at time k

The terms of the right-hand side are all independent because e(k) is a sequence
ofindependent random variables. It follows from the model of (12.14) that if the
polynomial C is stable, then e(i) can be computed exactlyfrom y(i),y(i -1), ...
USing

Optimal Design Mettlods: A Polynomial Approach

454

Chap. 12

The first terms of (12.15) are independent of the data at time k. The second
part is known functions of the data available at time k. Thus it follows that the
optimal predictor is given by
y(k + m I k)

= fme(k) + fm+le(k -

1) + fm+2e(k - 2) + ...

and that the prediction error is
y(k + m I k) :: e(k + m) + fle(k + m - 1) + ... + fm -te(k + 1)
Th provide a formal proof it remains to show how the numbers fi can be computed from A and C and how e(k) can be expressed in terms of past data.

Main Result

The main result can be stated as follows.
THEOREM 12.1 OPl1MAL PREDICTION

Let y(k) be a random process gen-

erated by the model in (12.14), where all the zeros ofthe polynomial C(z) are
inside the unit disc, and e(k) is a sequence of independent random variables.
The minimum-variance predictor over m steps is given by
qG(q)
G*(q-l)
y :: y(k + m I k) = C(q) y(k) = C*(q-l) y(k)
A

"

(12.16)

where the polynomials F and G are the quotient and the remainder when
dividing qm-lC by A; that is,
qffl- 1C(q) ;;;; A(q)F(q) + G(q)

(12.17)

The prediction error is a moving average

y(k + m I k) = y(k + m) - y(k + m I k)

=:

F(q)e(k +- 1)

(12.18)

It has zero mean and the variance
(12.19)
Proof The polynomial F is monic ofdegree m - 1 and G is ofdegree less
than n. Hence
q
F() ::: qm-l + f lq rn-2 + ... + f m-l

G(q) ::: goq n-l + glq n-2 + .. . + gn-l

We introduce

Sec. 12.3

455

Optimal Prediction

It follows from (12.17) that
(12.20)
Equation (12.15) can then be written as

By using Equation (12.14) the signal e in the last term can be expressed in
terms of the data available at time k. Hence,
G*( -I}
y(k + m) = F·(q-l}e(k + m) + C.(:-l) y(k)

The first term of the right-hand side is a linear function of e(k + 1}, e(k + 2),
. ,. , e(k +m), which are all independent of the data y(k), y( k - 1), y(k - 2), .. .
available at time k. The last term is a linear function of the data. Let y be an
arbitrary function of y{k), y(k - 1)..... Then

E (Y(k + m) -

Y)

2
:=;

E( F*(q-l}e(k

2

(G.(

-l)

+ m)) + E C~ (:-1) y(ll) -

+ 2E { (F' (q-l)e(k + m))

j

)2

(~:i:=:~ y(k) - j)}

(12.21)

The last term is zero because e(k + m),e{k + m -1), , and e(k + 1} have
zero mean values and are independent of y{k),y(k - 1),
The predictor that
minimizes the mean-square prediction error is thus given by (12.16) and the
prediction error by (12.18). The proofis completed by taking the mean value of
the square of the prediction error (12.18). This gives (12.19).
•

Remark 1. Notice that the best predictor is linear. The linearity does not
depend critically on the minimum-variance criterion. If the probability density
of y(k) is symmetric, the predictor of (12.16) is optimal for all criteria of the
form E g ((y(k + m) - 5')2) for symmetric g.

Remark 2. The assumption that e(i) and eU) are independent for i t- j is
essential for the last term in (12.21) to vanish. If the variables are uncorrelated,
the term will still vanish if the predictor y is restricted to being linear.
Rema.rk 3.

It follows from (12.18) that

j(k+ 11k) == y(k+ l)-y(k+ 11k) =e(k+ 1)
The random variables e(k) can thus be interpreted as the innovations of the
process y(k) (compare with Sec. 10.4).

Optimal Design Methods: A Polynomial Approach

456

Remsrk 4.

Chap. 12

Notice that the function

is the variance of the prediction error over the time interval mho The function
J(m) approaches the variance of y as m ~ 00. A graph of the function J shows
how well the process may be predicted overdifferent horizons. See Example 12.3.

Remark 5. The predictor discussed in this section is equivalent to the
steady-state predictor obtained using the Kalman filter in Sec.II.3 (see Example 11.6).
Calculation of the Optimal Predictor

It follows from (12.17) that F(q) is the quotient and G(q) the remainder when
dividing qm-lC(q) by A(q). The polynomials F and G can thus be determined by
polynomial division. An explicit formula for the coefficients of the polynomials
can also be given. Equating the coefficients of equal powers of q in (12.17) gives
the following equations:
ci

=

C2

= a2 + adl + f2

Cm-l

al

+ fl

= am-l + a m-2fl +

em : ; ; am + am-tfl +
em+l

=am+l + amf} +

+ adm-2 + fm-l
+ adm-l + go
+ a2fm -l +gl

+ aTl-m ... dm-l + gn-m
anfl + an-dz + + an-m+dm-l + gn-m+l

en = an +an-Ifl +

o z:

o = anfm-l + gn-l
These equations are easy to solve recursively. Compare the solution of the Diophantine equation in Chapter 5.
E~ample

12.2 Prediction

Consider the system (12.14) defined by the polynomials

A(q) '" q2 - 1.5q + 0.7
C{q) = q2 - 0.2q + 0.5
and where e has unit variance. Determine first the three-step-ahead prediction of

the output. The identity (12.17) gives
q2(q2 - O + 0.5) :; (q2 - 1.5q +O.7)(q2 + (Iq + (2) +goq + g,
.2q

457

Optimal Prediction

Sec. 12.3

This gives the triangular linear system of equations

fl

q2 :

0.5 = 0.7 - 1.5ft + f2

ql ;

0

= O.7fl -

l :

0

-==

=1.3

f2

q3: -0.2::: -1.5 + fl

= 1.75

go ::: 1.715

1.5f2 + go

gl '" - 1.225

07 f2 + gl

The prediction three steps ahead is thus given by

~(k :ll k) == qG(q) (k) = 1.715q2 - 1.225q (k)

Y

+.

C(q) Y

q2-0.2q+O.5 Y

and the variance of the prediction error is

El = 1 + (1.3r' + (1.75)2 = 5.7525

•

Enmple 12.3 Influence of prediction horizon
Consider the process in Example 12.2. From (12.19) it follows that the variance of
the prediction error will increase with the prediction horizon. Also (12.17) shows
that the F -poJynomial is obtained from the division of the C- and A-polynomials.
That is, the coefficients ~ are the coefficients ofthe impulse response ofthe system.
Thus
y(k} = C(q) e(k) = q2- O.2q + 0.5 e(k)
A{q)
q2 - 1.5q + 0.7
oo

=(1 + 1.3q-1 + 1.75q-2 + 1.715q-3 + ... ) e(k) = E 6e(k - j)
) ",0

and the prediction loss is
"1-1

El{k + m 1 k) == cr 2

E (j
J"'O

Figure 12.2 shows the variance of the prediction error for different values of the
prediction horizon m. It is seen that the variance of the prediction error is monotonically increasing with m. Figure 12.3 shows the output, the predicted output.
and the accumulated prediction loss, '[(y(k) - y(k 1 k - m))2. for different prediction horizons.
. •

~

~
~

'C 10

•

~

>

• • •
• • • • •

•

• • • •

•

• • • • • •

""

t:

r.ilO'---_ _~

o

__'_

10

_.L.

_J

20

Prediction horizon m
Figure 12.2 The variance of the prediction error as function of the prediction horizon m for the system in Example 12.3.

Chap. 12

Optimal Design Methods: A Polynomial Approach

458
(a)

10 r--~---------'------,.o:--~-------,

~101.....---------_.l-~-----------'

o

(b)

100

50

10 , - - - - - - - - - - - - - - r - - -

--~~-_.

\

_1OL..----

o

(c)

100

50

10 .....---~--~-~~-___r_--___..,....------___,

o
. ,'

500

j

100

50

(d)

,

~

---..l..

.

-10 L.-..

.

\

.

- ,,-.---_.------ - .... . ..... . -._._._./

50
Time

."

100

Figure 12.3 The process output (dashed) and the predicted output (solid)

for Bxample 12.3 when (a) m

=I, (b) m =3, (c) m ::; 5, and (d) the accu-

mulated prediction loss, 2:(y(k) - y(k t k - m))2, for m := 1 (dashed-dotted}
m == 2 (dashed), m = 3 (solid), and m ~ 5 (dotted) .

The Case When C Has Zeros on the Unit Circle
The predictor of (12.16) is a dynamic system with the characteristic polynomial
C (z). The assumption that C has all its zeros inside the unit disc thus guarantees that the predictor is stable in steady state. The initial conditions are
irrelevant because their influence will decay exponentially.
It follows from the spectral factorization that C may be chosen to have its
zeros inside the unit disc or on the unit circle. The zeros outside the unit disc
is mirrored in the unit circle. Compare with Example 12.1. Thus it remains to
discuss the case when C has zeros on the unit circle.

Sec. 12.3

459

Optimal Prediction

Example 12.4 Zenls on the unit circle

Consider the process
y(k)

In this case the polynomial C(z)

= e(k) -

(12.22)

e(k -1)

=z -

1 has a zero on the unit circle. Applying
the previous methods formally gives the one-step predictor

Y(k + 11 k)

= -e(k)

Attempting to calculato e(k) from y(k),y(k - 1),... ,y(k o) as was done previously
gives
.II

e(k) =e(ko - 1) + Ly(i)

=e{ko -

1) + z(k)

i=~o

The presence of the term e(ko - 1), which does not go to zero as ko--) -00, shows
the consequences of C being unstable. The Kalman filtering theory can, however,
be used to determine the optimal predictor. The signal given by (12.22) can be

written as
x(k + 1)
y(k)

where R 1
filter is

= R 2 = R 12 = 0'2

= e(k)

=-x(k) + e(k)

with the notations used in Sec. 11.3. The Kalman

i(k + 11 k) :;;; K(k) (Y(k) + i{k I k -

1))

O'2P(k)

P(k + 1)

= P(k) +0-2
0"2

K(k)

==

P(k) + (J'l

with the initial conditions

i(k o I ko - 1) = 0
P(ko) ""

(J2

The predictor for the output is

y(k + 11 k)

= -i(k + 11 k) = -K(k) (Y(k) - y(k I k -1))

Simple calculations give
1

k 11 0

y(k + 11 k) ;: - k _ k + 2 L(n + l)y(k o + n)
e
"",0

The optimum predictor is thug a time-varying system. Notice that the influence
of the initial condition y(ko) goes to zero at the rate 1/(h - ko + 2). This is much
slower than in the cage of stable polynomials C.
•

It follows from the example that the optimal predictor is a time-varying system
if the polynomial C has zeros on the unit circle. Such models should be avoided
if time-invariant predictors are desired. Unfortunately, this fact is not always
noticed, as Example 12.5 illustrates.

Optimal Design Methods: A Polynomial Approach

460

Chap. 12

EX8IIlple 12.5 How to model offsets

The model
A(q)y(k) ::: C(q)e(k} + b

where b is an unknown constant, represents a signal with an offset. The constant
b can be eliminated by taking differences. Hence,
(q -l)A(q)y(k)

=(q -

l)C(q}e(k)

The common factor q - 1 can be eliminated by regarding .o.y(k) ;:; (q - l)y(k) all
the output. The model
A(q}~y(k} = (q - l}C(q)e(k) ;:; C(q)e(k)

is then obtained. In this model the polynomial C apparently has a zero on the unit
circle. This model is, however, not very desirable because the optimal predictor is
8 tirne-varying system. It is much better to model an offset as a Wiener process.
This leads to a process model with A(l) :: 0 that is unstable with a stationary

.

~~~

Other reasons for avoiding models where the polynomial C(z) has zeros close
to the unit circle are given in Sec. 12.6.

12.4 Minimum-Variance Control
Th determine the minimum-variance control law, the special case when the
polynomial B in (12.5) is stable is discussed first. This means that the process
dynamics have a stable inverse. With some abuse oflanguage, this case is also
called the minimum-phase case because the pulse-transfer function has all its
zeros inside the unit disc. The solution to the control problem is very simple
in this special case. The solution also gives insight into the properties of the
control problem.

Systems with Stable Inverses

By introducing the backward-shift operator q-l, the model in (12.5) can be
written as

(12.23)

where
d~degA-degB

>0

Sec. 12.4

461

MinimumNariance Control

is the pole excess of the system (see Sec. 2.6). Further, deg A =deg C =n. The
reciprocal polynomials are introduced to make the discussion based oncausality
arguments more transparent.
It follows from (12.23) that

(12.24)

where Equation (12.20) witb m ~ d has been used to obtain the last equality.
The first term of the right-hand Bide is independent of the data available at
time k and thus also of the second and third terms. The second term can be
computed exactly in terms of data available at time k. 'Io do this, the variable
e(k) is given by (12.23); that is,
e(k) ::

A*

c. y(k) - q-d B" u(k)
C.

where the arguments of the polynomials have been dropped to simplifY the
writing, Using this expression for e, Eq. (12.24) can be written as
y(k + d)

G·

= F*e(k + d) + C* y(k} -

B"G"

B·

q-d A*C. u(k) + A* u(k)

G"
B*F*
~ F*e(k + d) + C* y(k) + c;- u(k)

(12.25)

Now let u(k) be an arbitrary function ofy(k),y(k-l), ... and u(k-l), u(k-2), .. ..
Then

(G*

B*F*)2
Ey2(k + d) = E(F*e(k + d))2 + E C* y(k) + c;- u(k)

(12.26)

The mixed terms vanish because e(k + d), "', e(k + 1) are independent of y(k).
y(k -1), ,.. and u(k), u(k - 1), .... Because the last term in (12.26) is nonnegative, it follows that

where equality is obtained for

(12.27)
which is the desired minimum-variance control law. The result can be summarized as follows.

Optimal Design Methods: A Polynomial Approach

462

Chap. 12

THEOREM 12.2 MINIMUM-VARIANCE CONTROL-STABLE INVERSE

Consider
a process described by (12.5), where e(k) is a sequence ofindependent random
variableswith zero mean values and standard deviations (J. Let the polynomials
Band C have all their zeros inside the unit disc. The minimum-variance control
law is then given by (12.27), where the polynomials r: and O' are given by
(12.20) with m ::: d. This control law gives the output
y(k) : F+(q-l)e(k) ::: e(k) + fle(k - 1) + ... + fd-le(k - d + 1)

•

in steady state .

Remark 1. The theorem still holds when e(i) and eU) are uncorrelated
for i # j if a linear control law is postulated.

Remark 2. The result is closely related to the solution of the prediction
problem (Theorem 12.1). Identity (12.17) or (12.20) was used. in both cases.
The last two terms in (12.25) can be interpreted as the d·step prediction of
the output. The minimum-variance strategy is thus obtained by predicting the
output d steps ahead and choosing a control that makes the prediction equal to
the desired output. The stochastic-control problem can thus be separated into
two problems, one stochastic-prediction problem and one deterministic-control
problem. Theorem 12.2can therefore be interpreted as a separation theorem.

Remark 3. The error under minimum-variance control is a moving average of order d - 1. ThUB the covariance function of the regulation error will
vanish for arguments larger than d - 1. This fact can be used for diagnosis to
determineif a minimum-variance strategy is used.

Remark 4. All process zeros are canceled when the control lawof (12.27)
is used. The consequences of this are discussed later.
It is very easy to calculate the minimum-variance control law for a given
model (12.5), as illustrated by the following example.
E:xample 12.8 Minimum·variance control
Consider a system given by (12.5), where
A(q) ,,; q3 - 1.7q2 + O.7q
B(q) ::;: q + 0.5

C(q) ::;: q3 _ O q2
.9

The pole excess is d = 2. Division ofqd-1C(q) by A(q) gives the quotient

F(q)

=q + 0.8

and the remainder

G(q) ::: O.66q2 - O.56q

Sec. 12.4

463

Minimum-Variance Control

The mintmum-variance control law is thus
u{k) :;; _ q(O.66q - 0.56) y(k)
(q + O.5){q + 0.8)

The variance of the output when the optimal controller is used is

El ~

1 + (0.8)2 ;;. 1.64

•

Example 12.7 Inftuence of the delay
Let the process be described by
A*(q-l)

= 1-1.5q-1 + O.7q-2

B'(q-l)

= q-d(l + O.5q-l)

C' (q-l) "" 1 - O.2q-l + O.5q-2

Compute the minimum-variance controller when d = 1, 3, or 5. The controller is
given by (12.27), where the F·polynomial is given in Example 12.3. Figure 12.4
shows the output and input when the minimum-variance controller is used for
different delays in the process. When d = 1, d ;;:: 3, and d ,,; 5 the output variance
is 1, 5.8, and 10.5, respectively.
_

10

(a)

5

~

a

~

:::1

0 r~_F~

........

o
-10 L---

...J

o
(b)

-5 L -

50

10

--.J

50

0
5

...
=
3;j

o
-10'---

---"

o
(c)

50

-5
0

50

10

-10'---

.....J

o

50
Time

o

50
Time

Figure 12.4 Simulation of the system in Example 12.7 with the control
law given by Theorem 12.2. The output (left) and the input (right) when (a)
d '" I, (b) d '" 3, and (e) d ;:; 5.

Optimal Design Methods: A Polynomial Approach

464

Chap. 12

Interpretation as Pole-Placement Design
The minimum-variance control law can be interpreted in terms of the poleplacement design discussed in Chapter 5. To see the relationships, the closedloop system obtained when the control law of (12.27) is applied to the system
of (12.5) is analyzed. Equations (12.5) and (12.27) can be written as

A(q) -B(q)) [Y(k)) ;: :- [C(q)) e(k)
[ G(q) F(q)B (q)
u(k)
0

(12.28)

The characteristic polynomial of the closed-loop system is the determinant of
the matrix on the left-hand side of (12.28). Hence,
A(q)F(q)B(q) + G(q)B(q) = qri-1B(q)C(q)

(12.29)

where Eq. (12.17), with m : : : d, is used to obtain tbe first equality. The closedloop system is of order 2n - 1. It has 2n - d poles at the zeros of Band C and
an additional d - 1 poles at the origin.
The minimum-variance control strategy can be interpreted as a pole-placement design, where the poles are placed at the zeros given by (12.29). The
similarities to pole placement are seen even more clearly if the control law of
(12.27) is written as

G(q)

u(k)
where S = G and R
by B gives

S(q)

= ~ B(q)F(q) y(k) = - R(q) y(k)

= FB [compare with Eq. (5.2)]. Multiplication of (12.17)

qd-1C (q)B (q) = A(q)F(q)B (q) + G(q)B (q)

= A(q)R(q) + B(q)S(q)

This equation is a special case of the Diophantine equation in (5.22) when
B + = B and with Ae '== qd-1B and Ao = C.

Systems with Unstable Inverses
Remark 4 to Theorem 12.2 mentions that the control law given by (12.27) cancels all process zeros. If there are process zeros outside the unit disc, the closedloop system will tben have unstable modes that are unobservable from the
output. The implications of this are discussed first. Other control laws tbat do
not require all zeros of B (z) to be inside the unit disc are then presented.
Solving Eq. (12.28) for y and u gives

y(k) =

~;i~: e(k)

and

u(k) = -

qd~~:q) e(k)

Sec. 12.4

465

Minimum-Variance Control

4r------~------,.----------_____,

...- 2
~

p,.

;l 0
0_ 2
-4 '----

.1.-

o

50

------'

100

104r------------.,----------~-_.

...

a 0 ~------------....""..n.nJn.n..nlIlJlnnll11

c
....

-ldL.-----------.l.---------------'

o

50

100

Time
Figure 12.5 Simulation of the system in Example 12.8 with the control
law given by Theorem 12.2 that cancels an unstable process zero.

The necessity of the assumption that B is stable is clearly seen from these
equations. If the polynomial B is unstable, the system has unstable modes,
which are excited by the disturbance. These unstable modes are coupled to the
control signal and the control signal grows exponentially. However, the output
signal remains bounded because the unstable modes are not coupled to the
output. An example illustrates what happens.
Example 12.8 Cancellation of unstable process zero
Consider a system described by the polynomials
A(z) "" (z - 1)(z - 0.7)
B(z) ;:: O.9z + 1

C(z) "" z{z- 0.7)

The polynomial B(z) has a zero z

== -10/9, which is outside the unit disc. A
simulation when using (12.27) is shown in Fig. 12.5. The presence ofthe unstable
mode is clearly seen in the control signal, although it is not noticeable in the system
output. Ifthe simulation is continued, the controlsignal will finally be so large that
overflow Of numerical errors occur. In a practical prohlem the signal will quickly
be 80 large that the linear approximation is no longer valid. After a short time the
unstable mode will then be noticeable in the output.
•

The minimum-variance control law is extended to the case when the polynomial
B has zeros outside the unit disc in Theorem 12.3.
THEOREM 12.3

MINIMUM-VARIANCE CONTRoL-GENERAL CASE

system described by (12.5). Factor the polynomial B {z) as

Consider a

Optimal Design Methods: A Polynomial Approach

466

Chap. 12

where B -~ (z) is monic. All zeros ofthe polynomial B+ (z) are inside the unit disc
and all zeros of B - (z) are outsidethe unit disc or on the unit circle. Assume that
all the zeros ofpolynomial C(z) are inside the unit disc and that the polynomials
A(z) and B- (z) donot have any common factors. The minimum-variance control
law is then given by
G(q)
u(k) ;;; - B+ (q)F(q) y(k)

(12.31)

where F(q) and G(q) are polynomials that satisfy the Diophantine equation
(12.32)

in which degF :::: d + deg B- - 1 and degG < degA

= n.

Proof The proof is based on a clever trick introduced by Wiener in his
original work on prediction. An alternative method is used in the proof of Theorem 12.4. Consider the operator

1
qfa

where laJ > 1. This operator is normally interpreted as a causal unstable (unbounded) operator. Because [e] > 1 and the shift operator has the norm Ilq~1 = 1,
the series expansion

1
q +a

==

1
1
q
a1 +1q/ a =;; ( 1 - a+ aq2

)

2 - ...

converges. Thus the operator (q + a)-1 can be interpreted as a noncausal stable
operator; that is,

1 y(k) - 1
- 1 y{k) = - ( 1 y(k + 1) + ""7 y(k + 2) _ ... )
q +a
a
a
a2
With this interpretation, it follows that

(q + a) (q

~ a Y(k)) = y(k)

The calculations required for the proof are conveniently done using the backward-shift operator. It follows from the process model of (12.5) that

We introduce

Sec. 12.4

467

Minimum-Variance Control

where the operator 1/ B-*(q-l) is interpreted as a noncausal stable operator.
The signals y and w have the same steady-state variance because B- and B--+
are reciprocal polynomials and
B- (e- iOJ )
B-"(e-

~--'7--;--7
,
lfl

::;

1

' )

An admissible control law that minimizes the variance of w also minimizes the
variance of y. It follows that

(12.33)
The assumption that A{z) and B- (z) are relatively prime guarantees that
(12.32) has a solution. Equation (12.32) implies that
C*(q-l)B - (q-l) = A*(q-l)F·(q-l) + q-dB-*(q-I)G*(q-l)

Division by A·B -. gives
C*(q-l)B -(q-l) = F·(q-l) + «' G*(q-l)
A"(q-l)B-*(q-l)
B-*(q-l)
A*(q-l)

By using tbis equation, (12.33) can be written as
F*(q-l)
BH(q-l)B-(q-l)
G'(q-l)
w(k + d) :;: B-*(q-l) e(k + d) +
A*(q-l)
u(k) + A*(q-l) e(k) (12.34)

Because the operator 1/B-*(q-l) is interpreted as a bounded noncausal operator
and because degF" = d + deg B - -1, it follows that
F*(q-l)
B-*(q-l) e(k + d)

=ule(k + 1) + a2e(k + 2) + ...

These terms are all independent of the last two terms in (12.34). Using the
arguments given in detail in the proof ofTheorem 12.2, wefind that the optimal
control lawis obtainedby putting the sum ofthe last two terms in (12.34) equal
to zero. This gives
(12.35)
and
B-*(q- l)
y(k) = B (q-l) w(k)

F*(q-l)
F(q)
= B- (q-l) e(k) ::: qd-lB _* (q) e(k)

(12.36)

Elimination of e(k) between (12.35) and (12.36) gives
u(k) =-

G·(q-l)
B+-(q-l) F~( q-l) y(k)

The numerator and the denominator have the same degree because deg G < n
and the control law can then be rewritten as (12.31).
•

Optimal Design Methods: A Polynomial Approach

468

Remark 1.

Chap. 12

Only the stable process zeros are canceled by the optimal

control law.

Remark 2. It follows from the proofs ofTheorems 12.2 and 12.3 that the
variance ofthe outputof a system such as (12.5) may have several local minima
if the polynomial B(z) has zeros outside the unit disc. There is one absolute
minimum given by Theorem 12.2. However, this minimum will give control
signals that are infinitely large. The local minimum given by Theorem 12.3 is
the largest of the local minima. The control signal is bounded in this case.

Remark 3. The factorization of (12.30) is arbitrary because B + could be
multiplied by a number and B - could be divided by the same number. It is
convenient to select the factors so that the polynomial B (q) is monic.
-$

EK:Rmple 12.9 Minimum-variance control with unstable prooe81ll zero
Consider the system in Example 12.8 where d ;;;; 1 and

=1
B-(z) = B(z)

B+(z)

B-·{z);;;;z+0.9

Equation (12.32) becomes
z(z - 0.7)(2 + 0.9)

Let z = O.7 l

Z :=

1, and z

=

(z - 1Hz - O.7){z + fd + (0.9z + l}(goZ + g1)

= -10/9. This gives
O.7go +gl

=0

go +gl ;:: 0.3
ft

=1

The control law thus becomes
u(k} :::: -

G(q)
(k) =_q - 0.7 '(k)
B+(q)F(q)Y
q+1 }

The output is
y(k) =

B~~q()) e(k q

19
d + 1);;;; q +0 e(k)
q+ .

= e(k) + ~O e(k)
q + .9

The variance of the output is
El

= (1+

2

0.1 )
1- 0.92

(J2

20
= - (J2

19

= 1 050'2
.

which is about 5%larger than using the controller in Example 12.8. The variance
of the control signal is 2750'2/19 ;:: 14.470'2. A simulation of the control law is
shown in Fig. 12.6. The figure that the controller performs well. Compare alsowith
Fig. 12.5, which shows the effect of canceling the unstable zero. Figure 12.7 shows
the accumulated output loss E y2(k) and input 1088 E u 2(k) when the controllers
in Example 12.8 and this example are used. The controller (12.27) gives lower
output loss, but an exponentially growing input loss, and the controller based on
(12.31) gives an accumulated input loss that grows linearly with time.
_

Sec. 12.4

469

Minimum-Variance Control

4
2

~

::s

Q.
....
::l

0

-2
-4

0

100

50

10

-10 L -

"-

o

~_

50
Time

____'

100

Figure 12.6 Simulation of the system in Example 12.9.

ol....ot:==---------.l.....------~~-~

o

50

100
2000 .--------------..-----"T---------

oL-----~~~---.L......------

o

50

___.J

100

Time

Firure 12.7 The accumulated output loss Ly2(k) and input loss L u'.l(k)
when the controllers (12.31) (solid) and (12.27) (dashed) are used.

APole..Placement Interpretation
Simple calculations show that the characteristic equation ofthe closed-loop system obtained from (12 .5) and (12.31) is

Thusthe control law of (12.31) can be interpreted as a pole-placement controller,
which gives this characteristic equation.

47D

Optimal Design Methods: A Polynomial Approach

Chap. 12

Multiplication of (12.32) by B+ gives the equation
A(z)R(z) + B (z)S(z)

=:;

zd-1B t (z)B-·(z)C(z)

(12.37)

where R(z) = B +(z)F(z) and S(z) = G(z) . This equation is the same Diophantine equation that was used in the pole-placement design [compare with
Eq. (5.22)]. The closed-loop system has poles corresponding to the observer dynamics, to the stable process zeros, and to the reflections in the unit circle of
the unstable process zeros. Notice that the transfer function B (z)/ A(z) may be
interpreted as having d ::: deg A - deg B zeros at infinity. The reflections of
these zeros in the unit circle also appear as closed-loop poles, which are located
at the origin.
Equation (12.37) shows that the closed-loop system is of order 2n- 1 and
that d - 1 ofthe poles are in the origin. A complete controllerconsistingof a full
Kalman filter observer and feedback from the observed states gives a closedloop system of order 2n. The "missing" pole is due to a cancellationof a pole at
the origin in the controller. This is further discussed in Sec. 12.5.

12.5 Linear Quadratic Gaussian (LQG) Control
The optimal control problem for the systam of (12.5) with the criterion of (12.8)
is now solved. The minimum-variance control law discussed in Sec. 12.4 can
be expressed in terms of a solution to a polynomial equation. The solution to
the LQG-problem can be obtained in a similar way. 'Iwo or three polynomial
equations are needed, however. These equations are discussed before the main
result is given,
The name Gaussian in LQG is actually slightly misleading. The proofs
show that the probahility distribution is immaterial as long as the random
variables e(k) are independent.
Using the state-space solution it is possible to get an interpretation ofthe
properties of the optimal solution. These properties can be expressed in terms
of the poles of the closed-loop system. In this way we can estahlish a connection
between LQG design and pole placement.

Properties ofthe State-Space Solution
The problems discussed in this chapter was solved using state-space methods
in Chapter 11.A stata-space representation ofthe model of (12.5) is first given.
For this purpose it is assumed that the model is normalized, so that degC (z) =
degA(z). The model of (12.5) can then be represented as

x(k + 1) = l1>x(k) + fu(k) + Ke(k)
y(k) == Cx(k) + e(k)

Sec. 12.5

471

Linear Quadratic Gaussian (LOG) Control

where
-al

1 0

0

bl

-az

a

0

b?,

1

f;:;;

et>=
~an-l

-an

1

0 0
0

C:::: ( 1 0 .. .

0

0

K=
bn - l
bn

Cn-l - an-l

0)
(12.38)

Because this is an innovations representation if the matrix <1'1 - K C has all its
eigenvalues inside the unit disc. Thesteady-state Kalman filter is then obtained
by inspection:
x(k + 11 k)

=<l>x{k I k -

1) + fu(k) + K(y(k) - Ci(k I k ~ 1))

(12.39)

The Kalman filter has the characteristic polynomial

det(zl-

(12.40)

(<1'1 - KC)) ;:;; C(z)

This implies that C(z) are some of the closed-loop poles. Assume a computational delay of one sampling period in the control law. The optimal control law
is then
u(k) = -Lx(k 1 k - 1)

and the transfer function of the controller is

Hr(z) ::: -L(zI ~ <I> + KC + FLt K
l

=- ~~:~

(12.41)

where R(z) = det(zI -<I'1+KC + I'L), degR(z) ::: n; and degS(z) < n. It follows
from this discussion and Sec. 11.4 that the closed-loop poles are C(z) and
P(z)

=det(zI - <1'1 + r L)

where P(z) is obtained from the algebraic Riccati equation.
It is more complicated to derive the control law when the admissible control
is such that u(k) is a function of y(k),y(k - 1),., .. The loss function (12.8)
corresponds to (11.9) with Ql = eTc, Q12 = 0, and Q2 = p, From (11.19) and
(11.24) it follows that L = L; <1>. The results from state-space theory (Remark
2 of Theorem 11.7) show that the control law is
u(k) = -Li(k I k) - Lvv(k I k)

= -Lx(k l k) - LvK(y(k) - Ci(k I k -1))
= -L(I(<I> - KC).i(k I k - 1) - LI)Ky(k)

(12.42)

Optimal Design Methods: A Polynomial Approach

472

Chap. 12

where x(k I k -1) is given by (12.39). The controller is still oforder n. Eliminating x between (12.39) and (12.42 }, we find that the controller can be described
by the relation

u(k) = -Lu(<<P - KC)(qI - «P + KCt1(ru(k) + KY(k)) - LuKy(k)
::; -Lu(fl> - KC)(qI - 4> + KCt1ru(k)
- Lu(<t> - KC + ql - <t> + KC)(qI - fl> + KCr1Ky(k)

(12.43)

::: -L u (<1l - KC)(qI- <1l + KCr1ru(k)
- LlJq(qI- (1) + KCrIKy(k}
Introducing R 2 (q) == det(qI - 4> + KC) we get
u(k) ::: - Rt(q) u(k) _ S(q) y(k)
R2(q)
R2(q)

where degRl(z)

= n, degR2(z) < nand degS{z) ~ n with 8(0) = O. Hence
S(q)
S(q)
u(k) == - R1(q) + R2(q) y(k) ;:: - R(q) y(k)

(12.44 )

We thus find that the controller has the property degR(z) ::: degS(z) ::: n.
Furthermore the condition S (0) = 0 implies that deg S· (z) < n.

Spectral Factorization
The LQ-problem is solved in Sec. 11.4 using the state-space approach, which
led to a steady-state Riccati equation. It follows from the Riccati equation that
(12.45)

where the monic polynomial P(z) is the characteristic polynomial ofthe closedloop system. [see Eq. (11.40)). The closed-loop characteristic polynomial can be
obtained by solving a steady-state Riccati equation. An alternative is to find a
polynomial P(z) that satisfies (12.45) directly. A feedback that gives the desired
closed-loop poles can then be detennined by pole placement. The problem of
finding a polynomial P(z) that satisfies (12.45) is called spectral factorization.
First. consider a polynomial of the form

F(z)

= foz 2n + flZ 2n- 1 + ... + fn_1Zn+1 + fnzn + fn_l Z n - 1 + ... + {Iz + fo

Such a polynomial is self-reciprocal because

It then follows that ifz = a is a zero of F(z), then z == 1/a is also a zero. Moreover, if the coefficients fi are real, then z == aand z = 1/ ii are also zeros, where
a is the complex conjugate of a. The following result can now be established.

Sec. 12.5

linearQuadratic Gaussian (LQG) Control

473

LEMMA 12.1
Let the real polynomials A(z) and B(z) be relatively prime
with degA(z) > deg B(z}. Then there exists a unique polynomial P(z) with
deg P(z) = degA{z) = n and all its zeros inside the unit disc or on the unit
circle such that (12.45) holds. If p > 01 then P(z) has no zeros on the unit
circle.

Proof

A self-reciprocal polynomial is obtained if the right-hand side of
(12.45) is multiplied by z1l. The zeros of the right-hand side are thus mirror
images with respect to the unit circle. Because the coefficients are real, the
zeros are also symmetric with respect to the real axis. The right-hand side of
(12,45) cannot have zeros on the unit circle because if z ;: eitv is such a zero.
then

A3 P > 0, this implies that z = exp(iaJ) is a zero of both A(z) and B (z), which
contradicts the assumption that A(z) and B(z) are relatively prime. The condition degP(z) ;: n ensures a unique P(z).
•

Remark 1.

By introducing reciprocal polynomials, Eq. (12.45) can be

written as

rP(z)P-(z) ::;: pA(z)A'(z) + zdB(z)B'{z)

(12.46)

where p·{z) == z"p(z-l). and 80 on.

Remark 2. IfP(z) satisfies (12.45) so does; P(z) • where 1is an arbitrary
integer. 'Ib obtain a unique P we can either specify the degree of P or moose P
as the polynomial of lowest degree that satisfies (12.45). For a control problem
it is natural to interpret P(z) as the closed loop characteristic polynomial under
state feedback. With this interpretation it is natural to require that deg P(z) ::
degA(z) = n. Notice that it is possible to find a P of lower degree when p = 0
or when A(O) := O.

Conceptually the speetral-faetorizetion problem can be solved by finding
the zertlB of the right-hand side of (12.45) and aorting them. There are also
efficient recursive algorithms for solving the problem.
Heuristic Discussion

The LQG-problem will now be related to the pole-placement problem. We will
first give the solution heuristically. A formal solution will be given latsr. First,
recall that the pole-placement problem required specifications ofthe closed-loop
characteristic polynomial, which werechosen as At(z)~{z) when ~ was interpreted as the observer polynomial. In the LQG-problem the observer polynomial
is simply ~(z) = C(z). Compare Theorem 12.1. The polynomial At(z) is equal
to the polynomial P(z) obtained from the spectral factomatioD. When the polynomials Ao{z) ::;: C(z) and At(z) -:= P(z) are specified we can DOW expect that

474

Optimal Design Methods: A Polynomial Approach

Chap. 12

the optimal control law is given by
u(k) ;::: _ S(q) y(k)
R(q)

where R(z) and 8(z) are solutions to the Diophantine equation
A(z)R(z) + B(z)S(z) = P(z)C(z)

(12.47)

The structure of the admissible control laws is determined by the polynomials
R(z) and S(z) . 1b describe a control law such that u(Jt) is a function of y(k),
y{k - 1), .. ' I and u(k -1), u(k - 2L '.., that is, no delay in the controller, the
polynomials R(z) and S(z) should have the same degree. 'Ib describe a control
law such that u(k) is a function of y(k-l),y(k-2)" .', and u(k-l) ,u(k-2), .."
that is, one sampling perioddelay in the controller, the pole excess of8 (z) / R(z)
should be one. The complexity of the control law is determined by the orders of
the polynomials R(z) and S(z).
There are many polynomials R(z) and S(z) that satisfy (12.47). Compare
the discussion in Sec. 5.3. Among all choices we will determine solutions that
minimize the loss function (12.8) . Before making a formal solution we will discuss the problem heuristically.
The solution to the LQG problem based on the state space approach gives
the additional constraints that have to be imposed on the solution to (12.47).
Equation (12.41) gave a polynomial interpretation of the state space solution.
The optimal controller was in fact characterized by the following conditions
on the controller polynomials: degR(z) == nand degS(z) < n. If A and Bare
relative prime the optimal LQG-controller is thus the unique solution to (12.47)
with deg 8(z) < deg A(z).
The problem is more complicated when there is no delay in the controller. The transfer function of the optimal controller in this case was given
by Eq. (12.44) with deg R(z) = deg 8(z) = n, and and degS*(z) < n. These
conditions are more conveniently expressed using another version of the Diophantine equation (12.47). Assuming deg R(~) := deg 8(z) = n, writing (12.47)
with argument z-1 and multiplying it hy z2n we find that
(12.48)
where
d :=: degA(z) - deg B(z)

If deg A·(z) = n the optimal controller is then the unique solution to (12.48)
with degS-(z) < degA·{z). Notice, however, that this does not give the optimal
solution when dsg A'{e) < n, i.e, when A(O} = O. This case will be discussed
in the next section where we give a direct solution of the LQG problem with
polynomial calculations.

Sec. 12.5

475

Linear Quadra1ic Gaussian (LOG) Control

Formal Proof
After the informal discussion we will now give a formal proof of the statements.
For this purpose we will first prove a preliminary result.
Let the polynomial P(z) be a solution to the spectral factorization problem (12.46) and let A(z) be monic. Assume that the polynomials
A(z) and B (z) do not have common roots outside the unit disc or on the unit
circle; then there exists a unique solution to the equations
LEMMA 12.2

= B (z)C·(z)
rP(z)R*(z) = -pA(z)C*(z)

A$(z)X(z) + rP(z)S*(z)
zdB*(z)X(z) -

(12.49)

with degX(z) < n) degR*(z) ~ nand deg S'{z) < n, where n ~ degA(z) .

Proof

First, assume that polynomial P(z) has distinct zeros zi. Since
P(z) is stable we have iZil < 1. The values A" (Zl) and B*(z£) cannot vanish
simultaneously because this would contradict the assumption that A(z) and
B (z) do not have common unstable factors. Evaluating (12.49) for z ;: z, we get
A'(Z,)X(Zi) ;;;; B(Zi)C'(Zi)

z1B* (Z i)X(Zi) = -pA(Zi)C' (Zi)

(12.50)

If hoth A*(.~i) and B* (z.) are different from zero, both equations give the same
result, since it follows from (12.46) that
pA(Zi)
zfB"(Zi)

If A*(Zi) = 0 and B*(Zi) f. 0 it follows from (12.46) that B(Zi) ;:: O. Since A(z)
is monic it also follows that A* (0) =1. This implies that Izd -F O. The equation

is trivially satisfied and the solution to (12.50) is

X(zil == _pA(Zj)C*(ZI)
zy B*(z,)
A similar argument shows that X(ZI) is unique also when B*(zi) = 0
and A(zl) 'f O. We can thus determine degP values X(Zj). Using Lagrange's
interpolation formula the polynomial X (z) of degree degP - 1 which satisfies
(12.50) is thus unique.
It follows from the construction of the polynomial X (z) that the polynomial
A*(z)X(z) - B (z)C*(z) vanishes for the zeros z, of P(z). This implies that it is
divisible by P(z). The quotient

8*(z)

= A*(z)X(z) - B (z)C*(z)
rP(z)

Optimal Design Methods: A Polynomial Approach

476

Chap. 12

is thus a polynomial. It has degree
degS'

~

max(degA* + deg P -l,deg B + degC*) - degP < n

(12.51)

Using the same argument we also find that
R*(z) = zdB*(z)X(z } + pA(z)C*(z)
rP(z)

is a polynomial of degree
degR * s max(d + degB' + degP - 1,degA + degC") - deg P :S n

(12.52)

The solution X(z). S*(z) and R*(z) to (12.49) is continuous in the coefficients
of polynomials A(z) and B(z). If polynomial P(z) has multiple zeros we can the
perturb the coefficients of A(z) and B(z) to obtain a P(z) with distinct zeros
and obtain the results by a limiting procedure. The details of this argument are

.

~~.

Remark 1. Notice that if one solution, Xo, R a So' to Eq. (12.49) has
•
been obtained all other solutions are given by

= Xo(z) + Q(z)rP(z)
R*(z) ;:: Ro(z) + Q(z)zdB" (z)
X(z)

(12.53)

S"(z ) : So(z) - Q(z)A*(z)

where Q(z) is an arbitrary polynomial. This is easilyverified by direct insertion
into the equation.
Remerk 2. The polynomials R(z) and S(z) are given by R(z) = z~R· (Z-l)
and S(z) = zI1S~(z-l) . The conditions A*(O) '=' P*(O) :::c C*(O) = 1 together with
Eq. (12.53) imply that R*(O) :;: 1, hence degR(z) :::: nand degS(z) S nand
deg S* (z) < n.
Remark 3. Eliminating X by multiplying the first equation by zd B· (z)
and the second by A~ (z) and subtracting gives
rPS·zdB* + rPA* R" ; ; ; RC·zdB* + pA·C·

= rPP·C·

where the second equality follows from (12.46). Dividing hy rP shows that the
the polynomials R" and S* satisfy the Diophantine equation (12.48).

Remark 4. In the following we will need another property of the solutions to Eq. (12.49). Adding the first equation multiplied by pA and the second
multiplied by B gives:

(PAA" + zdBB*)X -t prAPS* - ,PBR· = 0
Using the spectral factorization condition (12.46) and dividing by rP now gives:
P*(z)X(z) = B(z)R*(z) - pA(z)S*(z)

(12.54)

After these preliminaries we will now solve the LQG-problem with polynomi.al calculations.

Linear Quadratic Gaussian (LQG) Control

Sec. 12.5

4Tl

Consider the system in (12.5) with degA(z) ~ deg C(z) = n. Assume that all the zeros ofpolynomial C (z) are inside the unit disc, that there are no factors common to all three
ofthe polynomials A(z), B(z). and C(z). and that a possible common factor of
A(z) and B(z) has all its zeros inside the unit disc. Let the monic polynomial
P(z). which has all its zeros inside the unit disc, he the solution to (12.45) with
deg P(z) = n. The admissible control law with no delay that minimizes the
.
criterion of (12.8) is given hy
THEOREM 12.4 LINEAR QUADRATIC GAUSSIAN CONTROL

(12.55)
where polynomials R·(z) and S*(z) are the uniquesolution to Equation (12.49)
with degX(z) < n. With the control law of (12.55), the output becomes
R(q)
y(k) = P(q) e(k)

(12.56)

and the control signal is
u(k)

/

S(q)

=- P(q) e(k)

(12.57)

The minimal value of the loss function is
. E( 2
2) _ 0"2
min y + pu - -2.
In
Prool

f

R(z)R(z-l) + pS(Z)S(Z-l) dz
P() ( 1)
-z
zPz-

(12.58)

Introduce

s

u=v--y
R

(12.59)

where v may be regarded as a transformed control variable, which has to be
determined. Equations (12.5)7 (12.47), and (12.59) give
y

=

BRv + CRe BRv + CRe
AR + BS =
PC

BR

R

= PC u + P e

(12.60)

PC -BS
S
AR
S
PC u- P e = PC v - p e

(12.61)

It then follows from (12.eO) that

u = u-

SBv+SCe

PC

=

The 10s8 function of (12.8) can be written as
R)2
BR
J=E(I+pu 2) = E ( - v t - e +pE (AR - -S)2
-v
e

PC

= Jl + 2J2 + J 3

p

PC

P

Chap. 12

Optimal Design Methods: A Polynomial Approach

478
where

It follows from Remark 2 of Theorem 10.2 and (12.45) that

J

;;;
1

---!...
2ni

f

(B(z)B (z-1) + pA(z)A(z-l) )R(z)R(z-l) V{Z)V(Z-l) dz
P{Z)P(Z-l)C(Z)C(Z-l)
z

:;; i: f R(z)R(z··l) V(Z)V(Z-l) dz = rE (R(q) V)2
21fi

C(Z)C(Z-1)

z

C(q)

For causal controllers with no time delay u(t) can be expressed as v(t) =
V(q)e(t), where V(q) is a rational function with zero pole excess.

J'/,

=~

f B(z}R(z)R(z-l) - pA{z)R(z)S(Z-l) V(z) dz

21ri

P(z)C(Z)P(z-l)

z

It follows from Equation (12 .54) that
B(z)R{z-l) - pA(z)S(z-l) • p{z-l)X(z)

Hence
J ;:
2

~
2Jri

f R(z)X(z) V(z) dz
P(z)C (z)

:=

Z

E ((R(q)X{q) U(k»)e(k»)
P(q)C(q)

It was assumed that P(z) and C(z) are stable and it follows from Lemma 12.2
that degX(z) < n. This implies that

degR{z)X(z) < deg P(z)C(z) = 2n
The quantity

R(q)X(q) tI(k)
P(q)C(q)

is thus a function ofu(k-i), v(k-2) ,.. .. Because aU these termsare independent
ofe(kLJ 2 becomes zero. The loss function can thus be written as

R(q)
J = rE ( C(q) v(k)

)2 +E (R(q) e(k))2 + pE (s(q) e(k) )2
P(q)
P(q)

where P and C are stable polynomials. It follows that the loss function achieves
its minimum (12.58) for u ::;: 0, which by (12.59) corresponds to the control law
of (12.55). Equations (12.56) and (12.57) follow from (12.60) and (12.61), and
Theorem 10.2 and (10.23) give the formula of (12.58) .
•

Sec. 12.5

LInear Quadratic Gaussian (LOG) Control

479

Remark 1. The minimum-variance control law is a special case ofTheorem 12.4 with P = O. It follows from (12.49) that R ~ (z )P(z ) = _zd B' (z)X (2) . BecausedegX(z) < n, we have degR-(z) < n for p =O. Because also deg S'{a] < n
the polynomials R(z) and S(z) have z as a common factor. Introducing B(z) ==
R+(z)B-(z), where B + has all its zeros inside the unit disc and B- all its zeros
outside the unit disc, we get

where

.;r = B-(O). The Diophantine equation (12.47) then becomes

Cancelling the common factor z in R(z) and S{z) to give R(z) and S{z) we get

which is identical to (12.32). Theorem 12.3 has thus been proven in a different
way. The pole-zero cancellation at the origin of the control1aw explains that
there are d-1 instead of d closed-loop poles at the origin. Compare with (12.29) .

Remark 2. If the polynomial A(z) has the form A(z) :::: zlAl(zL where
l ~ d ;;: deg A(z)-deg B [z], it follows from (12.45) that P(z) =: zl P1(z). Equation
(12,47) then implies that 8(z) = zISl(Z) .
The LQG controller will now be illustrated by an example.
Example 12.10 LQG control with unstable process zero
Consider the same system as in Examples 12.8 and 12.9. Instead of using a
minimum-variance control law we will now use an LQG strategy. To do this the
parameter p in the control strategy must be chosen. To guide this choice we will
first calculate the variances ofthe output and control signals obtained for different
values of the loss function. The results are shown in Fig. 12.8. The value p ;:::: 0
corresponds to a minimum-variance strategy. This gives a control signal with large
variance. Compare with Example 12.9. The variance ofthe control signal decreases
rapidly with increasing p. The variance of the output increases slowly.
By choosing a reasonable value of p it is possible to have a control strategy
that gives an output variance that is only marginally higher than with minimumvariance control and a variance ofthe control signal that is substantially lower. A
reasonable value is p ;: : 1. This gives Ey 2 = 1.39 and Eu 2 = 0.22, which can be
compared with minimum-variance control that gives Ey 2 = 1.05 and Eu 2 = 14.47.
The input- and output signals obtained with p ;:::: 1 are shown in Fig. 12.9.
Compare with the corresponding curves for minimum-variance control in Example 12.9. The fluctuations in the output are a little larger, hut the fluctuations
in the control signal are substantially smaller, This way of applying LQG control
where the control weighting is used as a design parameter is very typical.
_

Optimal Design Methods: A Polynomial Approach

480

Chap. 12

lOr-------------r-----------,
\

\
\
\
\
\

,
"

-- - - -

.....

1

1000

Weighting p
Figure 12.8 Variances of input u (dashed line) and output y (solid line)
for LQG controllers having different values ofthe control weighting p for the
system in

Example 12.10

An Interpretation
Theorem 12.4 establishes the relation between LQG-control and pole-placement
control because the polynomial C(z) is the observer polynomial ~(z) and P(z)
is the polynomial Ac(z). The LQQ.controller may thus be considered as a poleplacement controller where the observer polynomial Ao (z) is obtained from the
noise characteristics and the polynomial Ao{z) from the solution to an optimization problem. The solution to the optimization problem also tells what solution
of the Diophantine equation we should choose.

4

2

~

~

0

-4

50

0

100

10
~
Q"
r::

-

-

-""

w-

we

..

...

,,.

......

.....

-~

- ... - .
"~

..n __

..

_n_ ...

-10
0

50
Time

100

Figure 12.9 Simulation of the for the system in Example 12.10 using the
LQG-controller with p =1. The output obtained with the minimum-variance
controller (p =0) is shown in dashed. Also compare with Fig. 12.6.

Sec. 12,5

481

Linear Quadratic Gaussian (LOG) Control

A Computational Procedure
Theorem 12.4 gives a convenient way to compute the LQG-eontrollaw for SISO
systems, which can be described as follows.
1. Rewrite the model of the process and the disturbance in the standard
form (12.5), where C(z) is a stable polynomial. It may be necessary to use
a spectral factorization to obtain this form.
2. Use a spectral factorization to calculate P(z) . If the polynomials A(z) and
B (z) have a stable common factor A2 (e}, the calculations of the control law
can be simplified by first factoring A(z) and B(z) as A(z) = Al(Z)A2(z) and
B(z) = B1(z)A2(z). It follows from (12.45) that A2(z) also divides P(z).
This polynomial can thus be written as P(z) = PI{z)A2(z), where P1(z) is
given by
rPdz)Pl(Z-l)

= pA t (z)A1(z- 1) + Bt{z)B1(z-1)

The polynomial P(z) is then equal to PI (z)A 2(z), which is stahle, because
A2 (z) was assumed stable. Equation (12.47) can also be divided hy A 2 (z)
to give

P1(Z)C (z) = Al (z)R(z) + B1(z)8 (z)
where deg R(z) = deg8(z) = deg C (z) = n, and 8(0)

= O.

3a. If there are no common factors between A and B and if A(O) ~ 0 then
the controller is given by a unique solution to the Diophantine equation
(12.47) such that degR(z) = deg 8(z) = n, and 8(0) = O.
3b. If there are stable common factors of A and B or if A (0) :;: 0 the solution is
obtained from the Equation (12.49) or Diophantine equation (12.47), and
(12.54).
The computational procedure shows that when there are no common factors between A and B and when A(O) ~ 0 then it is sufficient to solve only one
Diophantine equation with the extra constraint S (0) = 0 to obtain a unique
solution. In other cases it is necessary to solve the coupled equations (12.49).
Theorem 12.4 is illustrated by two examples.
Example 12.11 LQG for first order system

Consider a system characterized by

A(z) = z + a
B(z)
C(z)

a f; 0

=b
= z +c

To find the control law that minimizes the criterion of (12.8), the spectral-faetorization problem is first solved. Equation (12.45) can be written as

r(z +Pl)(Z-l + PI) ::: p(z + a)(z-l + a) + b2

Optimal Design Methods: A Polynomial Approach

482

Chap. 12

Equating coefficients of equal powers ofz gives
rpl

r(l +

=pa

pD =p(l + (12) + b2

Elimination ofPI gives

(12.62)
This equation has the solution

where the positive root is chosen to give !PI I < 1. Furthermore

pa

PI = r

Because A and B are relative prime and A(O) f; 0, the solution can be found
from the Diophantine equation (12.47). With degS "" 1 and 8(0) := 0, Eq. (12.47)
becomes

(z + a)(z + rd + bsoz "" (z + pd(z + c)
Putting

z "" -a we get
So

It follows from (12.62) that

Hence

or

which gives

We thus get

(PI - a)(c - a)

= - -=---":-'----.:.
ab

Sec. 12.5

483

Unear Quadratic Gaussian (LQG) Control

Furthermore, equating the constant terms in (12.47) gives

pte
a

oe
r

r1:::: -

::::-

The control law thus becomes
u(k) - _ S(q) (k) __ b(c - a)
9
(k)
- R(q) Y - r(l - apt) q + PlcJa Y

•

The calculations in Example 12.11 do not work when a = 0, because in this case
the solution to the LQG-problem is not uniquely determined by the Diophantine
equation (12.47) and it is necessary to use (12.49).
Example 12.12 LQG for system with a time-delay

Consider the case
A(z) = z
B(z)

=b

C(z)

="

z +c

The spectral factorization problem (12.45) has the solution

r :::: p + b2

P(z) == z

Assuming that it is desired to have a controller withno extra delaywe require that
degS(z) :::: degR(z) ;;;; 1. The Diophantine equation (12.47) with the constraint
degS· (z) = 0 becomes
z{Z

+ 1'1) + bsfjZ

=z(z + c)

Identification of coefficients of equal power of z gives only one equation
r1

+ bso ;;: c

to determine two parameters r1 and 80. The approach with the Diophantine equation thus does not work in this case. Equation (12.49) gives

Xo + rsoz

=b(1+ cz)

bX{jz - r%(1 + rlz) == -pz:(l

+ ca]

Identification of coefficients of equal power of z gives linear equations which have
the solution
%0 ~

b
pc

pc

rl=-:=r
p + b2
So

be

=r

•

484

Optimal Design Methods: A Polynomial Approach

Chap. 12

Uncontrollable and Unstable Modes
Models with the property that polynomials A(z) and B(z) have a common factor that is not a factor of C (z) are important in practice. They appear when
there are modes that are excited by disturbances and uncontrollable from the
input. Compare Sec. 12.2. Because the modes are not controllable, they are not
influenced by feedback.
Theorem 12.4 covers the case of stable common factors, but it does not
work for unstable common factors . Unstable common factors are important in
practice because they give one way ofobtaining regulators with integral action.
Th see what happens when there are unstable common factors, let A 2
denote the greatest common divisor of A and B and let Ai denote the factor of
A2 with zeros outside the unit disc or on the unit circle. Let the feedback be
u(k) ::: _ S(q) y(k)
R(q)

where R(z) and S(z) are relatively prime. It follows from (12.5) that
R(q)C(q)

y(k)

= A(q)R(q) + B(q)S(q) e(k)

S(q)C(q)
u(k) = - A(q)R(q) + B (q)S(q) e(k)

(12.63)
(12.64)

The unstable factor Ai (z) divides the denominators of the right-hand sides of
(12.63) and (12.64). Both y and u will be unbounded unless R(z) or S(z) are
chosen in special ways. The signal y will be bounded if R(z) is divisible by
A2 (z), and u will be bounded if Ai (z) divides B(z). Because R(z) and S(z)
are relatively prime, it is not possible to make both y and u bounded. This is
natural because infinitely large control actions are necessary to compensate for
infinitely large disturbances.
Th describe a prohlem of this type as a meaningful optimization problem,
the criterion of (12.8) must be modified. One possihility is to introduce the
variable

(12.65)
where m

=degAi (z), and to introduce the criterion
(12.66)

Example i2.13 Integral action
Let the system be described by

y(k)

'=

Bdq) u(k) + Cdq) e(k)
q-1

A.(q)

Sec. 12.5

485

Linear Quadratic Gaussian (LOG) Control

which is a special case of Eqs. (12.1) to (12.4) with a drifting disturbance. Hence

A(q) ,,; (q - 1)A 1(q)
B(q)

= (q -

C(q)

=A1(q)C1{q)

l)BI(q)

Unbounded control signals are necessary to compensate for the unbounded disturbanos. This implies tbat tbe modified loss function (12.66) becomes

where

Au(k) = u(k) - u(k -1)
This means that the difference and not the absolute value of the control signal is
penalized. The solution to the LQG-problem givesa controller with integral action.

•
The following result can then be established.
Considerthe system described by (12.5), where A(z) and C(z) are monic polynomials
ofdegree n. Assume that all zeros ofC (z) are inside the unit disc and that there
is no nontrivial polynomial that divides A(z), B(z), and C(z). Let A2(z) be the
greatest common divisor of A(z) and B(z), let Ai(z) of degree l be the factor
of A2 (z) with all its zeros inside the unit diSCI and let Ai (z) of degree m be
the factor of A(z) that has zeros on the unit circle or outside the unit disc. The
admissible control law that minimizes (12.66) is given by
THEOREM 12.5 LQQ..cONTROL WITH UNSTABLE COMMON FACTORS

u(k) = -

~\:\ y(k)

where R(z) and 8(z) are ofdegree n + m
R(;z:) "" A2(z)R(z)
S(z) = zmS(z)

(12.67)

and R(z) and S(z) satisfies
A1(z)A2"(z)R(z) + zmB1(z)S(z) = P1(z)C(z)
A*(z)X(z) + rP(z)S*(z) = s" iJ (z)C*(z)

with degR(z) = deg 8(z)

= n, degX(z) < nand 8(0)
A(z) =: Adz)A2(z)
B (z) ::; B1 (z )A2(z)

B(z)

= Bt{z)A;(z)

= O. Furthermore

(12.68)

Optimal Design Methods: APolynomial Approach

486

Chap. 12

and PI (z) is the solution of the spectral-factorization problem
(12.69)

with degP1(z)

Proof

= degA1(z) + degA 2(z).

Introducing the signal (12.65), the model (12.5) can be written as
A(q)y(k) =B(q)qmw(k) + C(q)e(k)

The polynomials A(q) and B(q) have the common factor A;(z), which has all
its zeros inside the unit disc. but no other common factors with zeros outside
the unit disc or on the unit circle. It then follows from Theorem 12.4that the
optimal control law
w(k) ~ -

~(q) y(k)

R(q)

is obtainedfrom (12.47). Because A(z) and 13 (z) have the stable common factor
A2(z), the polynomial P(z) has the form

where P1(z) is the solution to the spectral-factorization problem (12.69). From
Lemma 12.2 the polynomials R(z) and S{z) satisfy the equations
A(z)R(z) + zm a(z)S(z) =

Ai (z)p}(z)C(z)

A*(z)X(z) + rP(z)S *(z ) = qmB(z)C*(z)

A;

withdegR(z) = degS(z) "" n. Because
dividesA(z) and 13(z) we get (12.68).
Using (12.65) to express the control law in terms of the control variable u gives
~~~

Remark.

.

Notice that using (12.67), Eq. (12.68) can be written as
A(z)R(z) + B(z)S(z) =A2(z)P1(z)C(z)

The LQG.solution can thus be interpreted as a pole-placement controller, where
the poles are positioned at the zeros of A 21 Pl. and C. The controller also has the
property that Ai divides R. This is an example ofthe internal model principle.

Command Signals
The discussion in this chapter has so far been limited to the regulator problem. 'Io introduce command signals, refer to the discussion in Chapter 5. The

Sec. 12.6

487

Practical Aspects

key issue is to introduce the command signals in such a way that they do not
generate unnecessary reconstruction errors. This is achieved by the control law
R(q)u(k) = toAll(q)uc(k) - S(q)y(k)

where Ao(q) is the observer polynomial and to a constant. For the optimal
Kalman filter Ao(q} = C(q), where C(q) is given by (12.40). It then follows
from (12.5) that the output of the system is given by

B (g)
R{q)
y(k) = to P(q) uc(k) + P(q) e(k)
where degR = n.
The pulse-transfer function from the command signal is B (z)jP(z). Tbis
response may be shaped further by cascading with a precompensator that has
an arbitrary stable transfer function Hr(z). The control law hecomes
u(k)

Ao(q)

= R(q) Hr(q)uc(k) -

S(q)
P(q) y(k)

which gives

Because the polynomial P is stable, this may be canceled by the precompensator.
It thus follows that the response for disturbances and command signals may be
shaped differently.
The feedback S j R is first designed to ensure a good response to disturbances. The precompensator H f is then chosen to obtain the desired response
to command signals.

12.6 Practical Aspects
Much of the arbitrariness of design seems to disappear when design problems
are formulated as optimization problems. The model and the criteria are stated,
and the control law is obtained simply as the solution to an optimization prohlem. This simplicity is deceptive because the arbitrariness is instead transferred
to the modeling and the formulation of criteria. A successful application of optimization theory requires insight into how the properties of the model and the
criteria are reflected in the control law. Typical questions are: What should the
model look like in order to get a regulator with integral action?What problem
statements give regulators with a PID-structure? Some ofthese issues are discussedin this section, which alsogives insight into the properties of the optimal
control laws. It turns out that some results can be formulated as design rules.

488

Optimal Design Methods: A Polynomial Approach

Chap. 12

The polynomial approach, which operates directly with the transfer functions,
is well suited to do this.
Other aspects ofpractical relevance, such as sensitivity and robustness, are
also discussed. A brief treatment of the intersample ripple of the loss function
is given, together with some aspects of the choice of the sampling period.
Properties of the Optlmal Regulator

Some properties of the model influencethe optimal-control laws. The basic model
used is given by (12.5)-that is,

A(q)y(k) = B(q)u(k) + C(q)e(k)

(12.70)

The ratio B I A represents the pulse-transfer function of the process, and the ratio CIA represents the pulse-transfer functionthat generates the disturbance of
the process output. The polynomials A, B, and C may have common factors tha t
reflectthe way the control signal and the disturhance are coupled to the system.
There are, however, no factors common to all three polynomials. Compare this
with the discussion in Sec. 12.2, where the model is derived. The presence of
common factors that will directly influence the properties of the regulators will
now be investigated.

The Internal-model principle. Factors that are common to polynomials
A and B correspond to disturbance modes that are not controllable from u. Such
modes will appear as factors of P. Let

A2 = gcd(A, B)
be the greatest common divisor of polynomials A and B. If A2 is stable, it
follows from Theorem 12.4that A2 also divides P. If Az has a factor Ai with all
its zeros outside the unit disc, the corresponding result follows from Theorem
12.5. In this case it also follows from Theorem 12.5 that A2 divides R. This
observation is called the intemal-model principle: it says that to regulate a
system with unstable disturbances, the disturbance dynamicsmust also appear
in the dynamics of the regulator. A few examples illustrate this idea.
Example 12.14 Integral action
A regulator has intsgra' action if z - 1 divides R(z). It follows from Theorem 12.5,
and the internal-model principle, that this will occur if z - 1 divides both A and
B, which means that the model is ofthe fonn

Adq)(q - l)y(k)

==

Bdq)(q -l)u(k) + C(q)e(k)

This means that there is a drifting disturbance.

•

Sec. 12.6

489

Practical Aspects

Example 12.15 Elimination of a sinusoidal disturbance
A narrow-band sinusoidal disturbance with frequency centered at
resented as white noise driving a system with the denominator

D(q)

=;;;

(J)

may be rep-

q2 - 2qcoBWh + 1

If the poles of the system dynamics do not correspond to D, the model becomes
A 1(q )D(q)y(k) ~ B1(q)D(q)u(k) + C(q)e(k)
The optimal regulator is then such that D(z) divides R(z).

•

CanceUation of process poles. A common factor ofA and C corresponds
to controllable modes that are not excited by the disturbances. Let A 2 be the
greatest common divisor of A and C. The polynomial A2 is stable because C is
stable, and it does not divide B because there is no factor that divides all ofA,
B, and C. It follows from (12.47) that A2 also divides the polynomial S, which
is the numerator of the regulator transfer function. Thus stable process poles
that are not excited by the disturbances may be canceled.
CanceUation of process zeros. Common factors ofBand C correspond
to process zeros that block transmission both for the control signal u and for
the disturbance e. Let B2 be the greatest common divisor of Band C. The
polynomial B2 is stable and it does not divide A. It then follows from (12.47)
that B2 divides R. This means that the zeros corresponding to B2 = 0 are
canceled hy the regulator. Therefore, process zeros that are also transmission
zeros for the disturbance C are canceled by the regulator.
For the minimum-variance control, it follows from (12.46) with P :; 0 that

where y'r = B- (0) and from (12.47) that B+ divides R. All stable zeros are
thus canceled by the minimum-variance control law.
An analysisof the properties of the optimal-control law thus gives partial
answers to the classic cancellation problem.
Sensitivity and Robustness

It is important that a control system be insensitive or robust with respect to
measurement errors, plant disturbances, and modeling errors. This may be analyzed as in Sec. 5.5 for the pole-placement problem. The robustness properties
are conveniently expressed in terms of the loop gain:

490

Optimal Design Methods: A Polynomial Approach

Chap . 12

or the return difference
1

BS

H = S "" 1 + AR =
rd

AR + BS

AR

PC
"" AR

The loop gain L( exp iwh) is normally high for low frequencies and small for
high frequencies. The crossover frequency to; is the lowest frequency, where

The closed-loop system is insensitive to plant disturbances at those frequencies
where the loop gain is high. 'lb have low sensitivity to poor modeling of the
high-frequency dynamics ofthe plant, it is desirable that the loop gain decreases
rapidly above the crossover frequency. It is possihle to make sure that the loop
gain is high for certain frequencies by choosing models with special structure,
as was done in Examples 12.14 and 12.15. Plots similar to those in Fig. 5.6
are also useful in evaluating the sensitivity. In a properly designedsample-data
system, there will be antialiasing filters, which eliminate signal transmission
above the Nyquist frequency. The selection of a proper sampling rate is one way
to make sure that the loop gain is low over a given frequency. This also means
that high-frequency modeling errors have little influence. Notice, however, that
plots ofthe loop gain and the return difference will not give the complete picture
because there may be pole-zero cancellations that do not show up in these plots.
An analysis of the characteristic equations is useful in such a case. To
perform such an analysis, assume that the system is governed by
(12.71)
but that a regulator is designed based on a different model, as in (12.70). The
regulators given by Theorems 12.4and 12.5 give a closed-loop system with the
characteristic polynomial
AOR + BOS :. AOR - AR + BOS - BS + AR + BS

=PC + (Ao -

A)R + (B () - B)S

When the model of (12.70) is equal to the system of (12.71) the characteristic
polynomial is PC = P 1A2C, as expected. By continuity it also follows that small
changes in the system give small changes in the closed-loop poles. The system
is sensitive to changes in the parameters if polynomial P, or C have zeros close
to the unit circle.
To guarantee systems with a low sensitivity, it is necessary to impose
further constraints. Recall that both C and P were obtained as solutions to a
spectral-factorization problem.

Sec. 12.6

491

Practical Aspects

Closed-Loop Systems'with Guaranteed Exponenttal Stability
The control laws given by Theorems 12.2, 12.3, 12.4, and 12.5 give closed-loop
systems with poles insidethe unit disc. It is sometimes desirable to have control
laws such that the closed-loop system has its poles inside a circle with radius r.
It is straightforward to formulate optimization problems that give such control
laws.
Introduce the criterion
(12.72)

If a control law that minimizes this criterion can be found, the variables y(k)
and u(k) must converge to zero at least as fast as fk when k increases. To
obtain such a result, it must be assumed that the model of (12.5) is such that
the covariance of e(k) also goes to zero as rk •
Introduce the scaled variables T] , u, and e defined by
y(k) = ;k7J(k)
u(k) :::
e(k)

,il jJ.(k)

= fit E(k)

Because

it follows that

A(q)y(k) ::: A(q)(rtry(k») =

;:11 A(iq)17(k)

Introducing the transformed polynomials

A(z)

=A(rz)

B(z)~B(rz)

C(z) = C(rz)

the model of (12.5) can be written as
A(q)1](k) ::: B(q )1](k) + 6 (q)e(k )

(12.73)

and the criterion of (12.72) becomes
J

= E(11 2 (k) +p,u2(k))

(12.74)

The control law that minimizes (12.74) for the system of (12.73) is then given
by Theorem 12.4. This control law gives a closed-loop system in which all the
zeros or the characteristic equation
P(z)C(z)

:=

0

Optimal Design Methods: A Polynomial Approach

492

Chap. 12

are inside the unit disc. Going back to the original variables results in the
characteristic equation

P(z)C(z) ~

p (~) C(~) = 0

All the zeros of this equation are inside the circle Izi == f.
A simple procedure for obtaining feedback laws that give closed-loop systems with all poles inside the circle Izi ::: f has thus been devised.
Disturbance Reduction
The return difference is

BS AR +BS
Hr d .::::= 1 + L = 1 + AR:;;;: AR
The inverse of the return difference is a measure ofhow effectively the closedloop system eliminates disturbances .
Consider the model of (12.70). Without control the output is
C
A

-e

Yol:;::

With the LQG-controllaw, the output becomes
Ylqg::::

R
pe

Elimination of e between these equations gives
Ylqg

AUR
1
= PC Yol ~ PC Yol ~
_

AUR

1

BS

1+-

Yo1

=

1

Hrd Yol == 5yo'

AR

The sensitivity function thus tells how much disturbances of different frequencies are attenuated.
Selection of the Sampling Period
There is a substantial difference between the minimum-variance control law
discussed in Sec. 12.4 and the LQG-controllaw discussed in Sec. 12.5 in terms of
the influence ofthe sampling period. The choice of sampling period is criticalfor
the minimum-variance control. A short sampling period gives a high-bandwidth
system, which settles quickly. The control actions will also be large when the
sampling period is short. In this respect, the minimum-variance control law is
similar to the deadbeat control law discussed in Sec. 4.3. The sampling period
is less critical for LQG-eontrol. It follows from the analysisofSec. 11.5 that the
control law approaches continuous-time control as the sampling period h goes to
zero. The following discussion therefore concentrates on the minimum-variance
control law.

Sec. 12.6

493

Practical Aspects

tntersample Variation of the Output Variance
The minimum-variance control law minimizes the variance of the output at
the sampling instants . However, the main objective may be to minimize the
continuous-time loss function of (12.7). This may be achieved by first sampling
the continuous-time loss function and to minimize the corresponding discretetime loss function as was discussed in Section 11.1. This results in a complicated
design procedure. The minimum-variance control laws are in many cases a sufficiently good. approximation. It is useful to investigate the intersample variation
ofthe loss function. This analysis is similar to the analysis ofintersample ripple
for deterministic systems of Sec. 3.5. An example is used to illustrate the idea.
Example 12.16 Iatersample variation of the loss function
Consider the continuous-time system

dx

= u dt + du

(12.75)

where v(t) is a Wiener process with incremental covariance C1~ dt, Assume that the
output is observed without antialiasing filters at times tli "" k . h; where h is the
sampling period. Hence.

where E(t.l:) is a sequence of independent random variables with zero mean and
covariance cr:. Sampling of the system gives
x(kh + h) ;;: x(kh) + hu(kh) + u(kh + h) - u(kh)
y(kh) :;;: x(kh) + e{kh)

Hence,
y(kh + h) ~ )'(kh) + hu(kh) + E(kh + h) - £(kh) + v(kh + h) - v(kh)

The disturbance on the right-hand side may be represented as
w(kh + h)

= e(kh + h) + ce(kh)

where e(kh) is a sequence of independent zero-mean random variables with standard deviation cr.
Simple calculations give
c == -1-

(J

2

ha 2
+
2
2cre

_v

at2
c

=--

The minimum-variance oontrollaw for the system is
u(kh)

l+c
=--h-y(kh)

Optimal Design Methods: A Polynomial Approach

494

Chap. 12

The standard deviation of the output under minimum-variance control is

The standard deviation of the state variable x is

Equation (12.75) is integrated to determine the variance of the stete variable between the sampling instante. This gives
x(kh + 8) ;: x(kh) + su(kh) + u(kh + s) - ll(kh)
:; (1 - as)x(kh) - as£(kh) + v(kh + 8) - v(kh)

where

a:: (1 +c)jh
We now introduce

It then follows that the output variance is

The function P)'(s) is shown in Fig. 12.10 when (J(

::

a, ::; 1. Notice that

The variation in Py overa sampling interval thus decreases with decreasing h. •

The analysis is similar in the general case. The only difference is that Theorem
10.5 must be used to compute the state covariance. In the example the variance
is largest at the sampling instants. Thisis not always the case. Also notice that
the correct way ofdealing with intersample ripple is to sample the continuoustime system and the continuous-time loss functions, as was discussed in Section 11.1.

Computational Aspects

The LQ-controllaw can be determined by a combination ofspectral factorization
and solution oflinear Diophantine equations. Recall, however, the fundamental
difficulty that arises from poor numerical conditioning of polynomial equations
(see Sec. 9.6).

sec. 12.7

495

Conclusions

4,....----------....,..-~~-------,

.

~

Cd.

'1:

-

.....

- ._ ~_

.

..

"'

•

••

O'

..

.

" , .

I

'

+. ,

.

.

, . ,
t

·

-

. .' .

I

.

...... . -

._.--.

- -

ll:I

~2r-..

~

~
6

~--~

~

--

~--~

---

-

.... -

~--~

---

-,_

--~

-

- - ~-

O'----~--~------'-~---~--~---'

o

1

2

Time

Figure 12.10 Variations of the output variance Py in Example 12.16 with
time for regulators having the sampling periods h = 0.2 (solid), h =' 0.5
(dashed), h : : 1 (dashed-dotted), and h "" 2 (dotted).

12.7 Conclusions
In this chapter optimal-control problems are solved for systems described by
input-output models. The results given are limitedto single-input-single-output
systems, Acanonical model for the system, Eq. (12.5), is derived first. This model
is characterized by three polynomials, A, B, and C. The underlying continuoustime model may be described as a combination of a time delay and a system
with rational transfer functions. The distnrbances are characterized as filtered
white noise. There are many physical systems that can be described by such
models.
Optimal-control problems characterized by quadratic loss functions are
solved for the system. A special case where the loss function simply is the
variance of the output is considered first. The general problem, in which there
is also a penalty on the control variable, is then treated. Both these problems
are closely related to the prediction problem for a random process with rational
spectraldensity. Thisproblem is also solved. Practical aspects, such as selection
ofthe sampling period, are also discussed.
The solutions to the optimal-eontrol problems give design tools. The solutions also give insight into the character of the optimal solutions. In particular,
they tell that the optimal regulator always cancels stable process zeros that
are also zeros for the process disturbances. Stable process poles are canceled
only if they are not excited by disturbances. The results also give insight into

Optimal Design Methods: A Polynomial Approach

496

Chap. 12

the relationships between the different design methods. For instance, the LQGsolutions can be interpreted as pole-placement regulators, where the process
poles and the observer poles are chosen in special ways.
Calculation ofthe optimal solution is expressed in terms oftwo polynomial
operations, spectral factorization and solution of Diophantine equations.

12.8 Problems
12.1 Consider the process
)'(k)

=2 q2 -1.4q + 0.5 e(k)
q2 - 1.2q + 0.4

where e(k) is white noise with zero mean and unit variance. Determine the optimal
m-step-ahead predicter and the variance of the prediction error when m =1, 2,
and 3.
12.2 Determine the m-step-ahead predictor for the process
y(k) + ay(k -1) :;; e(k) + ce(k -1)

Determine also the variance of the prediction error as a function of m.
12.3 A stochastic process is described by
y{k) - O.9y(k -1)

= e(k) + 5e(k -

1)

(a) Determine an equivalent description such that the zero of a corresponding
polynomial C is inside the unit circle. How large is the variance of y?
(b) Determine the two-step-ahead predictor for the process and the variance of
the prediction error.
12.4 Assume that the demand for a product in an. inventory, Z{k)l can be described as
z(k)

= 300 + 10k + y(k)

where the time unit is months, and y(k) is described by the process
y(k) - O
.7y(k - 1) - O.ly(k - 2}

= 6e(k)

where e(k) is white noise with zero mean and unit variance. Make a prediction
and detennine the expected standard deviation ofthe prediction error for August
through November when the following data are available:

Month

k

z(k }

January

1

320

Febroary
March
April
May
June
July

2

320

3
4

325
330

5

350

6

370

7

375

497

Problems

Sec. 12.8

z
1

y

1- O.5q-l
Figure 12.11

12.5 Consider the process
y(k) - y(k - 1} + O
.5y(k - 2) :; u(k - 2} + O.5u(k - 3)
+ O.5( e{k) + O
.8e(k - 1) + O.25e(k -

2))

Determine the minimum-variance controller and the minimum achievable variance.

12.6 Determine the minimum-variance controller for the system
y(k )- O.5y(k - 1) = u(k - 2) +e(k) - O.7e(k -1)

where e(k) is white noise with mean 2 and unit variance.

12.7 Consider the process
y(k) + ay(k - 1) = u(k - 2) + e(k) + ce(k - 1}

(a) Determine the minimum-variance controller.
(b) Discuss the special casea =O.
12.8 Given the system

y(k} -1.7y(k - 1) + O.7y(k - 2) = u(k - d) + O
.5u(k - d -1)
+ e(k) + l.5e(k - 1) + O.ge(k - 2}

(a) Determine the minimum-variance controller and the variance of the output
for d =1 and 2.
(b) Simulate the open-loop Elystem and the system controlled with the minimumvariance controller. Compare the output and the control signal for the different cases.
12.9 Consider the process in Fig. 12.11. The disturbance z has the spectral density

1
IPz (w)

= 2n- '

1
1.36 + 1.2COBCt.l

(a) Determine a pulse-transfer function H(z) that gives an output with spectral
density ¢ when driven by zero-mean white noise with unit variance.
(b) What is the steady-state variance of y when
u(k)

for K == 17

=-Ky(k)

Optimal Design Methods: A Polynomial Approach

498

Chap. 12

(c) What is the minimum achievable variance for a proportional controller and
how large is the corresponding value of K?

(d) How large is the variance ofy when a minimum-variance controller is used?
12.10 Given the system
y(k) - O.25y(k - 1) + O
.5y(k - 2) :;; u(k - 1) + e(k) + O.5e(k - 1)

where e(k) is whitenoise with unit variance. Assume that the process is controlled
with the proportional controller
u(k)

=- Ky(k)

{a) Show that the variance ofthe output is
2.125 - K
0.5(1.75 - K)(1.25 + K)

and that the lowest variance is ohtained for K :;; 1, which gives the variance
4/3.
(h) The expression above is zero for K :;; 2.125. Explain the paradox.
(c) Compute the minimum-variance controller and the resulting output variance.
12.11 Given the process
y(k) - 1.5y(k - 1) + O.7y(k - 2) =: u(k - 2) - O.5u(k - 3) + v(k}

(a) Assume that u(k) == 0 and compute the deadbeat controller for the system.
(h) Assume that
l){k)

=e(k) - O.2e(k -

1)

where e(k) is white noise. Compute the minimum-variance control law.
(c) What is the steady-state variance of y whenthe deadbeat and the minimumvariance controllers are used on the system when u iii! as in b)?
(d) Simula.te the system using the different controllers. Study the output and
the accumulated loss, that is, the sum of the square of the output.
12.12 Consider the dynamic system
y(k)

:=

B(q)
C(q)
A(q) u(k) +?. D(q) e(k)

where e(k) is white noise and B is stable. The polynomials A, C, and D are
assumed to be monic. Determine the minimum-variance controller for the system.
12.13 Use the result from Problem 12.12 to determine tbe minimum-variance controller
for the system
bq-l

y(k)

= 1 + aq: I u(k) + (1 + cq-l)e(k)

Sec. 12.8

499

Problems

e(k)

C'
-

A"

u(k)

q -IB'

:E

A*

q -1
1+ aq-l

Yl(k)

Y2 (k)

Figure 12.12

12.14 Consider the process in Problem 12.13. Assume that the sampling period is doubled; that is, the control signal can be changed only at every second time unit.
Determine the minimum-variance controller and compare with the case when the
control period is one time unit.
12.15 Consider the system in Fig. 12.12, where e is white noise with zero mean and unit
variance, Further,
A(q) = q - 0.7
C(q) =1- O.5q

B(q)
a

=q

= -0.8

(a) Determine a controller that minimizes the variance of Yl.
(b) Determine the variances of Yl and Y2 when the controller in (a) is used.
(c) Determine It controller that minimizes the variance of yz if only Y2 is measurable, and compute the variances of Yl and Y2-

(d) Determine a controller that minimizes the variance of yz if both Yl and Y2
are measurable.

(e) What are the variances of YI and yz when the controller in (d) is used?
12.16 Given the process
A(q)y(k) ~ B (q)u(k) + C(q)e{k) + D(q)v(k)

where v(k) is a known disturbance. Determine the minimum-variance controller
for the process when degD :;: degB .

12.17 Determine the LQG-controller given by Theorem 12.4 for the process
(! - O.9q-l)y(k)

=u(k -1) + (1- O.5q-l)e(k)

when p ;;;; 1. Calculate the variance of the output and the input for different
values ofp.
12.18 Consider a system with stable inverse. Derive the minimum-variance controller,
where the control signal u(.k) is allowed to be a function of y(k -1), y(k - 2), ... ,
u(k - 1), " .. Derive the characteristic equation ofthe c1osed·!oop system.

500

Optimal Design Methods: A Polynomial Approach

Chap. 12

12.19 Show that the pulse-transfer function from e to y for (12.5) and (12.55) is given
by (12.56). Use (12.45) to derive the minimum-variance controller for a system
where

A(q) == q2 - 1.5q + 0.7
B(q) = q +0.5
C(q) ::= q2 - q + 0.24
Compare with the controller obtained through the identity in (12.17).
12.20 Determine for which systems a digital PID-controller has the same structure as

the optimal minimum-variance controller.
12.21 Consider a system described by

1
q-

1

y(k) "" -

(bu(k) + E{k)) + - 1 w(k)

q-a

where E and w are white-noise processes with zero mean and standard deviations
Ur. and Uw• respectively.
(8) Reduce the system to standard form and determine the minimum-variance
controller.

(h) Interpret the controller in (a) as a Pi-controller and determine how the gain
and the reset time depend on the ratio (J~/(J;.
12.22 Consider the minimum-variance control law of (12.31) for a system with an unstable inverse. The output of the closed-loop system is given by

F(q) e(k)
(k) Y - qd-1B -*(q)
Show that the function F/ B has the series expansion
-0

F(q) = if-I + f qd-2 +... +"

B-.(q)

1

d-l

+ ~2(q)

B-o(q)

wheredegF2(q) < degB -O and
F1(q) ==

if-t + flif- 2 +..' + fd-l

is the quotient of qd-lC(q) and A(q) . Give a convenient way ofcomputing F2• Use
the results of the problem to determine the increase ofthe minimum-variance due
to unstable system zeros.
12.23 Determine the intersample ripple of the loss function when the process

dx, =X2 dt
dX2 =u dt+ dv
y(tk) == .tl(t~) + e(tk)
is controlled hy the minimum-variance regulator. The process u(t) is a Wiener
process with incremental covariance dt; and e(tlt) is white measurement noise

with zero mean and variance

a;.

0';

Sec. 12.8

501

Problems

12.24 Consider the process in Example 12.16. Determine the control law with sampling
period h that minimizes

and compare it with the minimum-variance control.
12.25 Consider a process subject to a disturbance that is characterized as a Wiener
process with incremental covariance dt. Determine the prediction error of the
minimum-variance in each case. Use different prediction horizons and sampling
periods.
(a) The process has an unstable zero z ~ b > 1.
(b) The process has an unstable pole z

~

a

::>

1.

12.26 Consider the system in Problem 12.23 with an extra time delay of1 s. Determine
the minimum-variance as a function of the sampling period.
12.27 Consider the system in Problem 12.23. Determine the output variance as a function of the input covariance for different sampling periods.
12.28 Consider the system

1

q

y(k) = q _ 0.999 u(k) + q _ 0.7 e(k)

Determine the minimum-variance control law for the system. Compare it with
a proportional feedback that gives a corresponding response rate. Discuss the
relative merits of the control laws by calculating their loop gains and return differences. Explain why the minimum-variance control is inferior. (Hint: A bad
optimization problem gives a bad optimal regulator.)
12.29 Given the system
y(k)

:=

1.4y(k -1) - O
.65y(k - 2) + u(k - 1) - O
.2u(k - 2)

+ e(k ) + O.4e (k - 1)
where e

E

N(O, 2)

(a) Determine the minimum-variance controller.

(b) Determine the deadbeat controller.
(c) Compute the variance of y when the controllers in (a) and (b), respectively,
are used.
12.30 Consider the system
y(k) + ay{k - 1) ;;: u(k - 1) + e(k) + ce(k - 1)

where e E N{O, 1).We want to determine the minimum-variance controller for the
process hut the value of c is unknown.

Optimal Design Methods: A Polynomial Approach

502

(a) Assume in the design that c
controller for the system

Chap. 12

= 0 and determine the minimum-variance

y(k) + ay(k -1) == u(k - 1) + elk)

How large will the output variance be if this controller is used on the true
system?
(b) Assume instead that c ,,;

cand redo the calculations in (a).

12.31 Consider the stochastic process
y(k + 2) -l.ly(k + 1) + 0.3y(k) ::: e{k + 2) -1.25e(k + 1)

where e

E

N(O, 1).

(a) Determine the two-step-ahead predictor for y(k).
(b) Calculate the variance of the prediction error.
12.32 Given the system
A(q)y(k) ;:; B(q)u(k) + C(q)e(k)

where

A(q) :::;

q3 -

B{q )

2(q - 0.9)

==

1.7 q2 + 0.8q - 0.1

C(q) :;;: q2(q - 0.1)

and e(k)

E

N(O, 1).

(a) Determine the minimum-variance controller for the system.

(b) Determine the variance of the output when controlling the system with the
controller in (a) .

(c) Redo the calculations in (a) and (b) when
B(q) "" 2(O.9q -1)

12.33 Consider the process in Example 12.9. Compute the output variance when the
controller does not cancel the zero, that is, when the controller is obtained from
the identity

zC

'=

AR + BS

Compare the variances.
12.34 Consider the process in Example 12.9. Compute the controller that minimizes the
loss function (12.7).

503

Problems

Sec. 12.8

12.35 Show that a system with the input-output description
A(q)y(k) ~ B(q)u(k) + C(q)e{k)

where
A(q ) : : : qn + alqll - l + .. + an
B(q ) := b1q n- l + .. . + b;
C(q ) ==qII +Clq n .. l + ... + C
n

has the following state-space description

x(k + 1) ::::: $x(k} + ru(k) + Ke(k + 1)
y(k) = Cx(k)

where the state vector has dimension

n

+ 1 and

1 0

0

b1

- a2 0 1

0

b2

- al

1

r=

$=

K:::::

-an

0 0

1

bn

0

0 0

0

0

C == ( 1 0 0

...

Cn-l

0)

12.38 Consider the system in Problem 12.35. Assume that the polynomial C(z) has all
its zeros inside the unit disc. Show that the Kalman filter for the system can be
written as
x(k + 11 k) ::::: l1>x(k I k) + ru(k)

i(k+ llk +1)

= x(k+

llk ) +K (Y(k+ l )-Ci(k +llk ))

and that the characteristic polynomial of the filter is zC[z].
12.37 Consider the system in Problem 12.35. Assume that minimization of a quadratic
IOSB function gives the feedback law
u(k) : : : - Li (k I k)

Show that the controller has the pulse-transferfunction

Show that the results are the same as those given by
Hc(z)

= Lt.(CI> - KC) (zl - (1 -

r

l

fL v )(<1J - KC)

=zLv(zI - (<I> - KC)(I - rL~)r lK

(I - fLu )K + LvK
(12.76)

Optimal Design Methods: A Polynomial Approach

504

Chap. 12

12.38 Consider the system in Problem 12.35. Assume that b1 f:. O. Determine the
minimum-variance strategy using the state-space representations in (12.38) and
in Problem 12.37. Compare the results. (Hint: The minimum-variance control corresponds to L ;:: (-all 0 .. . 0].)

12.39 Derive the expressions for the transfer function He (z) in Eq. (12.76) using the
matrix inversion Lemma B.l in Appendix B.
12.40 Show that the transfer function Hc (z) in Eq, (12.76) can be written as

He (z)
where a

==

= 8(z) == a

R(z}

+ (L - aC)(zl -

¢I

+ rL + KC - arCt1(K - ra )

LuK. Show that this expression is equivalent to
8(z)
So(z) + aA(z)
==
R(z)
Ro(z) - aB(z)

where 8 0(z) and Ro(z) is the solution to the Diophantine equation
A(z)R(z) + B(z}S(z}

z

P(z)C(z }

with deg R{z) == n and degS(z) < n.

12.9 Notes and References
The treatment of the linear quadratic case is in the spirit of Wiener's work; see
Wiener (1949), Newton, Gould, and Kaiser (1957), and Youla, Bongiorno, and
Jabr (1976).
A thoroughdiscussion of prediction and minimum-variancecontrol is found
in AstroID (1970), which is based on Astrom (1965, 1967).A similar approach to
the stochastic-control problem is found in Box and Jenkins (1970). The theorem
for minimum-variance control of systems with unstable inverses was first published in Peterka (1972). An algebraic approach to the multivariable LQ- and
minimum-variance control problems is given in Kucera (1979). Also see Kucera
(1984, 1991), and Mosca, Giarre, and Casavola (1990). Choice of sampling interval for stochastic control is discussed in the books mentioned before, and also
in MacGregor (1976).
The intersample variation of the variance is discussed in De Souza and
Goodwin (1984) and Lennartson and SOderstrom (1986) .

13
Identification
13.1 Introduction
The notion of a mathematical model is fundamental to science and engineering.
A model is a very useful and compact way to summarize the knowledge about
a process. A model is also a very effective tool for education and communication. The design methods in the previous chapters assume that models for the
process and the disturbances are given. The process models can sometimes be
obtained from first principles of physics. It is more difficult to get the models
of the disturbances, which are equally important. These models often have to
be obtained from experiments. The types of models that are needed for the design methods presented here are either state-space models (internal models)
or input-output models (external models). The models for the disturbances are
for the internal models given as dynamic systems driven by white noise. For
external models the disturbances are given in terms of spectral densities and
covariance functions. Models for disturbances can, however, only rarely be determined from first principles. Experiments are thus often the only way to get
models for the disturbances.
A process cannot be characterized by one mathematical model. A process
should be represented by a hierarchy of models ranging from detailed and complex simulation models to very simple models, which are easy to manipulate
analytically. The simple models are used for exploratory purposes and to obtain
the gross features of the system behavior. The complicated models are used for
a detailed check ofthe perfonnance oftbe control system. The complicatad models take a long time to develop. Between the two extremes, there may be many
different types of models. The trademark of good engineering is to choose the
right model for each specific purpose.
Example 1S.1 Model hierarchies
To describe a drum boiler power unit. several different models may be needed.
For production planning and frequency control, it may be sufficient to characterize

505

Identification

506

Chap. 13

the unit using two or three states describing the energy storage in the drum and
the superheaters. To construct security systems and control systems, it may be
necessary to have a model with 20 to 50 states. Finally, to model temperature and
_
stresses in the turbine unit, several hundred states must be used.

In principle. there are twodifferent ways in which modelscan be obtained:from
prior knowledge-for example, in terms of physical laws or by experimentation
on a process. When attempting to obtain a specific model, it is often beneficial
to combine both approaches.
Mathematical model building based on physical laws is discussed briefly
in Sec. 13.2. In most cases it is not possible to make a complete model only from
physical knowledge. Some parameters must be determined from experiments.
This approach is called system identification and is discussed in Sec. 13.3.There
are many methods for analyzing data obtained from experiments. One basic
approach is the principle of leastsquares (LS), discussed in Sec. 13.4. Recursive
ways to make the computations are given in Sec. 13.5. Examples are given in

Sec. 13.6.

13.2 Mathematical Model Building
There are no general methods that always can be used to get a complete model.

Each process or problem has its own characteristics. Some general guidelines
can be given, but under no circumstances can they replace experience. Model
building using physical laws requires knowledge and insight about the process.
The main problemwhen making a mathematical model is to find the states
of the system. The state variables essentially describe storage of energy and
mass in the system. Typical variables that are chosen as states are positions
and velocities (mechanicalsystems); voltages and currents (electricalsystems);
levels and flows (hydraulicsystems); and temperatures, pressures, and densities
(thermal systems). The relationship hetween the states is determined using
balance equations for force, moment, mass, energy, and constitutive equations.
The advantage of model building from physics is that it gives insight;
also, the different parameters and variables have physicalinterpretations. The
drawback is that it may be difficult and time-consuming to build the model from
first principles. Mathematical model building often has to be combined with
experiments. The references give a more detailed treatment of mathematical
model building.

13.3 System Identification
System identification is the experimental approach to process modeling. System
identification includes the following:
• Experimental planning
• Selection of model structure

Sec. 13.3

System Identification

501

• Criteria
• Parameter estimation
• Model validation
In practice, the procedure of system identification is iterative. When investigating a process where the a priori knowledge is poor, it is reasonable to start with
transient or frequency-response analysis to get crude estimates of the dynamics
and the disturbances. The results can be used to plan further experiments. The
data obtained are then used to estimate the unknown parameters in the model.
Based on the results, the model structure can be improved and new experiments
may be necessary.

Experimental Planning
It is often difficult and costly to experiment with industrial processes. Therefore,

it is desirable to have identification methods that do not require special input
signals. Many "classic" methods depend strongly on having the input be of a
precise form, for example, sinusoids or impulses. Other techniques can handle
virtually any type of input signal, at the expense of increased computations.
One requirement ofthe input signal is that it should excite all the modes of the
process sufficiently. A good identification method should thus be insensitive to
the characteristics of the input signal.
It is sometimes possible to base system identification on data obtained
under closed-loop control of the process. This is useful from the point of view
of applications. For instance, adaptive controllers are based mostly on closedloop identification. The main difficulty with data obtained from a process under
feedback is that it may be impossible to determine all the parameters in the
desired model; that is, the system is not identifiable, even if the parameters can
be determined from an open-loop experiment. Identifiability can be recovered
if the feedback is sufficiently complex. It helpe to make the feedback nonlinear
and time-varying and to change the set points.

Setectlon ofModel Structure
The model structures are derived from prior knowledge of the process and the
disturbances. In some cases the only a priori knowledge is that the process
can be described as a linear system in a particular operating range. It is then
natural to use general representations of linear systems. Such representations
are called black-box models. A typical example is the difference-equation model
A(q)y(k) = B(q)u(k) + C(q)e(k)

(13.1)

where u is the input, y is the output, and e is a white-noise disturbance. The
parameters, as well as the order of the models, are considered as the unknown
parameters.

Identification

508

Chap. 13

Sometimes it is possible to apply physical laws to derive models of the
process that contain only a few unknown parameters . The model may then be
of the form

dx

dt = f(x,u,v ,B)
y

=g(x,u,e, 6)

where B is a vector of unknown parameters, x is the state of the system, and v
and e are disturbances.

Criteria
'When formulating an identification problem, a criterion is postulated to give a
measure of how well a model fits the experimental data. By making statistical
assumptions, it is also possihle to derive criteria from probabilistic arguments.
The criteria for discrete-time systems are often expressed as
N

.1.(0)

= I:g( f(k))
R=l

where e is the input error, the output error, or a generalized error. The prediction
error is a typical example of a generalized error. The function g is frequently
chosen to be quadratic, but it is possible for it to be of many other forms.
The first formulation, solution, and application of an identificationproblem
were given hy Gauss in his famous determination of the orbit of the asteroid
Ceres. Gauss formulated the identification problem as an optimization problem
and introduced the principle of least squares, a method based on the minimization of the sum ofthe squares of the error. Sincethen, the least-squares criterion
has been used extensively
.
The least-squares method is very simple and easy to understand. Under some circumstances it gives estimates with the wrong mean values (bias).
However, this can be overcome by using various extensions. The least-squares
method is restricted to model structures that are linear in the unknown parameters.
When the disturbances of a process are described as stochastic processes,
the identificationproblem can be formulated as a statistical parameter-estimation prohlem. It is then possible to use the maximum-likelihood method, for
example; this method has many attractive statistical properties. It can be interpreted as a least-squares criterion if the quantity to be minimized is taken as
the sum ofsquares of the prediction error. The maximum-likelihood method is a
very general technique that can be applied to a wide variety of model structures.

Parameter Estimation
Solving the parameter-estimation problem requires the following:

Sec. 13.4

The Principle ofLeast Squares

509

• Input-output data from the process
• A class of models
• A criterion

Parameter-estimation problem can then be formulated as an optimization problem, where the best model is the one that best fite the data according to the
given criterion.
The result ofthe estimation problem depends, of course, on how the problem is formulated. For instance, the obtained model depends on the amplitude and frequency content of the input signal. There are many possibilities
for combining experimental conditions, model classes, and criteria. There are
also many different ways to organize the computations. Consequently, there is
a large number ofdifferent identification methods available. One broad distinction is between on-line methods and offline methods. The on-line methods give
estimates recursively as the measurement are obtained and are the only alternative if the identification is going to be used in an adaptive controller or if the
process is time-varying. In many cases the off-line methods give estimates with
higher precision and are more reliable, for instance, in terms of convergence.
The large number ofmethods is confusing for an industrial engineer who
is primarily interested in having a tool to obtain a model. Several attempts to
compare different identification methods have been made. The comparisons are
largely inconclusive in the sense that there is no method that is universally
best. Fortunately, it appears that the choice of method is not crucial. Therefore, it can be recommended that a prospective user learn the classic methods
(frequency- and transient-response analysis and correlation and spectral analysis), the least-squares method with extensions, and the maximum-likelihood
method.

Model Validation
When a model has been obtained from experimental data, it is necessary to
check the model in order to reveal ite inadequacies. For model validation, it
is useful to determine such factors as step responses, impulse responses, poles
and zeros, model errors, and prediction errors. Because the purpose of the model
validation is to scrutinizethe model with respect to inadequacies, it is useful to
look for quantities that are sensitive to model changes.

13.4 The Principle of Least Squares
According to Gauss the principle of least squares is that the unknown parameters of a model should be chosen in such a way that
the sum of the squares ofthe differences between the actually observed and
computed values multiplied bynumbers that measurethe degree ofprecision
is a minimum.

lden1ifica1ion

510

Chap. 13

x

Figure 13.1 Illustration of the variahlss in the least-squares prohlern when
estimating the parameters of a straight line.

To be able to give an analytic solution, the computed values must be linear functions of the unknown parameters. In the framework Df the general formulation
of the identification problem given in the previous sections, the class of models
is such that the model output is linear in the parameters and the criterion is a
quadratic function. The purpose ofthis section is to formulate the least-squares
prohlem and to give its solution.
The General Problem
In the general least-squares problem, it is' assumed that "the computed variable," y, in Gauss' terminology is given by the model

(13.2)
where

are known functions, and 8l,82, ... ,8 n are unknown parameters. Pairs of observations {(xj,yd.i = 1,2, ... ,N} are obtained from an
experiment. The problem is to determinethe parameters in such a way that the
variables y, computed from the model of (13.2) and the experimental values Xi
agree as closely as possible with the measured variables Yi. Assuming that all
measurements have the same precision, the principle of least squares says that
the parameters should be selected in such a way that the loss function
qJl:f{J2, ..• ,f{Jn

1 N

J(9) =

2LET
j.:= 1

is minimal where

i:;:: 1,2, ... ,N

Compare with Fig. 13.1. To simplify the calculations, the following vector nota-

Sec. 13.4

511

The Principle of Least Squares

tions are introduced:

~1

qJn ) T

rp2

qJ=

(

()=

( 91 (}2

On )

T
T

y= ( Y1

Y2

YN )

£ =

£2

eN ) T

( £1

[

4>=

~T(%l) ]
lpT;XN)

The least-squares problem can now be formulated in a compact form. The loss
function J can be written as
(I3.3)
where
e =y -

y

and

ji =

eIl()

Determine the parameter e in such a way that 11£11 2 is minimal. The solution
to the least-squares problem is given by the following theorem.
THEOREM 13.1

LEAST-SQUARES SOLUTION

The function of (13.3) is mini-

mal for parameters fJ such that
4>Tq,O

= <J>T y

(13.4)

H the matrix ell T 4> is nonsingular, the minimum is unique and given by
{) :: (ell T 4> t l 4>TY :::: ell t Y

Proof.

(13.5)

The loss function of (13.3) can be written as
2J((}) ::: eTe = (y - 4>O)T(y - ell8)

= yTy _ yT ell 0 _ OT<l>TY + eTq,T4>O
Because the matrix ell Tellis always nonnegative definite. the function J has a
minimum. Assuming that <J>T ell is nonsingular and using (11.12) the minimum
is obtained for

and the theorem is proved.

•

Chap. 13

Identification

512

Remark 1. Equation (13.4) is called the normal equation.
Remark 2. The matrix tI>t = (tI>TtI»-ItI>T is called the pseudo-inverse of
tI> if the matrix tI> T ¢I is nonsingular.
System Identification
The least-squares method can be used to identify parameters in dynamic systems. Let the system he described by (13.1) with C (q) = q", Further, assume
that A and B are oforder nand n - 1, respectively, Assume that a sequence of
inputs {u(l}, u(2). ... ,u(N)} has been applied to the system and that the corresponding sequence of outputs {y(1),y(2), ... ,y(N)} has been observed. The
unknown parameters are then
8=

(a

1

. ..

aIJ

b1

...

bn

(13.6)

) T

Further, we introduce

tpT(k + 1) = (-y(k) ...

-y(k- n + 1) u(k) ...

u(k - n +

1))

(13.7)

and

The least-squares estimate is then given by (13.5) if ¢IT 4J is nonsingular. For
instance, this is the caseifthe input signalis, loosely speaking, sufficiently rich.
Example 18.2 Least-squares estimate of first-order systems
Determine the least-squares estimate of the parameters

a and b in the model

y(k) '"' -ay(k - I} + bu(k - 1)
in such a way that the criterion
1 N

J(a,b)

= "2 L f(k)2
i .. 2

is minimal, where

e(k) :; y(k) - Y(k)

= y(k) + ay(k -

;;;; y(k) - tpT(k)O

1) - bu{k -1)

513

The Principle of least Squares

Sec. 13.4

A comparison with the general case gives
-y(1)

y(3)

y

=

c(2)

u{l)

-y(2)

y(2)

u(2)

£(3)
E'"

<1>:;;

-y (N - 1) u(N - 1)

y(N )

e(N )

and

Hence

Provided the matrix ¢T <I> is nonsingular, the least-squares estimate of the parameters a and b is now easily obtained. The matrix <l>T cIJ will be nonsingular if
conditions (sufficient richness or persistent excitation) are imposed on the input
signal.
•

StatIstical Interpretation
Th analyze the properties of the least-squares estimator, it is necessary to make

some assumptions. Let the data be generated from the process
y = f1>B o + e

(13.8)

where 80 is the vector of "true" parameters, and e is a vector of noise with
zero-mean value. The foUowing theorem is given without proof.
Consider the estimate (13.5) and assume that the data are generated from (13.8), where e is
white noise with variance 0'2. Then, if n is the number of parameters of 8 and
80 and N is the number of data, the following conditions hold.
THEOREM

I.

PRoPERTIES OF LEAST-SQUARES ESTIMATE

E8 :: Do

2. vare
3.

13.2

s2

=0'2 (<liT f1> t 1

=2J(8)j(N -

n) is an unbiased estimate of 0'2

•

Theorem 13.2 implies that the parameters in (13.1) can be estimated without
bias if C(q) = qn. If C (q) F qn, then the estimates will be biased. This is due
to the correlation between the noise C·(q-l)e(k) and the data in tp(k).

Identification

514

Chap. 13

Extensions of the Least..Squares Method

The least-squares method gives unbiased results of the parameters in (13.1)
only if C(q) ~ q". However, the maximum likelihood method can be used for
the general case. It can be shown that maximizing the likelihood function is
equivalent to minimizing the 108s function of (13.3), where the residuals, e, are
related to the inputs and outputs by
C(q)f(k)

= A(q)y(k) -

B(q)u(k)

The residuals can be interpreted as the one-step-ahead prediction error. However, the loss function is notlinear in the parameters and it has to beminimized
numerically. This can be done using a Newton-Raphson gradient routine, which
involves computation ofthe gradientof J with respect to the parameters, as well
as the matrix ofsecond partial derivatives. The maximum-likelihood method is
thus an off-line method. It is possible to make approximations ofthe maximumlikelihood method that allow on-line computations of the parameters of the
model in (13.1). Some common methods are Extended Least Squares (ELS),
Generalized Least Squares (GLSL and Recursive Maximum Likelihood (RML).

13.5 Recursive Computations
In many cases the observations are obtained sequentially. It may then be desirahle to compute the least-squares estimate for different values of N . If the
least-squares problem has been solved for N observations, it seems to be a
waste ofcomputational resources to start from scratch when a new observation
is obtained, Hence, it is desirahle to arrange the computetions in such a way
that the results obtained for N observations can he used in order to get the estimates for N + 1 observations. An analogous problem occurs when the number
ofparameters is not known in advance. The least-squares estimate may then
be needed for a different number of parameters. The possibility ofcalculating
the least-squares estimate recursively is pursued in this section.
Recurs'on in the Number of Observations

Recursive equations can be derived for the case when the observations are obtained sequentially. The procedure is often referred to as recursive identification. The solution in (13.5) to the least-squares problem can be rewritten to
give recursive equations. Let e(N) denote the least-squares estimate hased on
N measurements. Th derive the equations, N is introduced as a formal parameter in the functions, that is,

y(N)

=

[J

Sec. 13.5

515

Recursive Computations

It is assumed that the matrix ¢IT¢I is nonsingular for all N. The least-squares
estimate B(N} is then given by Eq, (13.5):

When an additional measurement is obtained, a row is added to the matrix <t»
and an element is added to the vector y. Hence

y(N + 1) =

(Y(N)]
YN-l

The estimate O(N + 1) given by (13.5) can then be written as

B(N + 1)

=( ct>T(N + 1)c1}{N + 1)) ¢IT(N + l)y(N + 1)
=(¢IT(N)¢I(N) + ({J(N + l)ql(N + 1)) -1
-1

x (¢JT(N)y(N)

(13.9)

+ rp(N + I)YN+1)

The solution is given by the following theorem.
Assume that the
matrix ¢IT(N)<t>>(N) is positive definite. The least-squares estimate fJ then satisfies the recursive equation
THEOREM 13.3

RECURSIVE LEAST-SQUARES ESTIMATION

O(N + 1) == 8(N) ~ K(N) (YN+1 - cpT (N +1)8(N))

(13.10)

K(N) :: P(N + l)<p(N + 1)
== P(N}tp(N +1)(1 + fPT(N + l)P(NJrp(N + 1})-1

P(N + 1) ==

(1 - K(N){J'T(N +1))P(N)

(13.11)
(13.12)

Proof To simplify the notation in the manipulations that follow, the
argument N of l1> (N) and y (N) and the argument N +1 of ({J T (N + 1) will be
suppressed. Equation (13 .9) can then be written as

O(N + 1) :=;:( ¢ITc1} + tp qJ Tt 1( ¢ITY + ({JYN+l)
:::(¢IT ¢It1¢lTY + ((<t»T¢l + QJtpTr t

+ {¢IT <1> + fP({JTr1rpYNtl
Observe that

-

(c1} T<t» f l) ¢ TY

{13.I3)

Identification

516

Chap. 13

and
(($T<t> + 'P'PTt1 _ ($T$t1)q,T y
::: (<<1>T q, + tpq>Tr1(<t>T tt> - «Il T$ - tptpT)(<f>T «Ilr1<f>T y
~ _(<<1>T $

+ gJrpTt1gJrpT (<<1>Ttt>t 1q>TY

::: _($T<f> + q>gJTt1tprpTiJ

Equation (13.13) can be written as
9(N T 1) = e(N) + K(N) (YN +l

-

q>T (N + l)O(N))

In order to obtain a recursive equation for the weighting factor K(N), it is
convenient to introduce the quantity P defined by
P(N)

= (<<Il T (N)«1>(N)) -1

P is proportional to the variance ofthe estimates (compare withTheorem 13.2).

Applying the matrix. inversion lemma (Lemma B.l) to the matrix. P(N + 1) gives
P(N + 1) = (<<1>T(N + l)<t>{N T l)fl = (<f>T$ + rptp Tt l

= (<<1>T<t>r 1- (<<1>T<t>t 1cp(1 T cpT(<t>T«Il)-lcp) -lcpT(<t>Ttt>t 1
Hence
P(N + 1) :=P(N) - P(N)q>(N + 1)

x (I

T

f/JT (N + l)P(N)tp(N +

1))-1, T(N + I)P(N)

Simple calculations now give
K(N) ::: peN + l)tp(N + 1)
= P(N)q>(N + 1)(I + tpT(N + 1}P(N)tp(N + 1))-1

Notice that a matrix inversion is necessary to compute P. However, the matrix
to be inverted is of the same dimension as the number of measurements; that
is, for a single-output system, it is a scalar.
I

Remark 1. Equation (13.10) has a strong intuitiveappeal. The estimate
o + 1) is obtained by adding a correction to the previous estimate 8(N). The
(N
correction is proportional to YN+l - f/JT (N + 1)8(N), where the last term can
be interpreted as the value of Y at time N + 1 predicted by the model (13.2).
The correction term is thus proportional to the difference between the measured
value of YN+l and the prediction of YN+l based on the previous estimates ofthe
parameters.The components of the vector K (N) are weighting factors that tell
how the correction and the previous estimate should be combined. Notice that
the ith component of K(N) is proportional to rpT(N + 1).

Sec. 13.5

517

Recursive Computations

Remark 2. The least-squares estimate can be interpreted as a Kalman
filter for the process
6(k + 1} = 9(k)

y(k} ::; 'P T (k)6(k) + e(k)

See Section 11.3.
Notice that the matrix P(N) is defined only when the matrix q,T(N)¢»(N)
is nonsingular. Because
N

4>T(N)~(N)

=

L 'P(k)qJT(k)
k-l

it follows that $T q, is always singular if N is sufficiently small. In order to
obtain an initial condition for P, it is necessary to choose an N = No such that
¢»T(No)c1l(No) is nonsingular and determine

P(No) = (<J)T (No)$(No)) -1
..

T

8 = P(No)¢» (Noh(No)

The recursive equations can then be used from N ~ No . It is, however, often
convenient to use the recursive equations in all steps. If the recursive equations
are begun with the initial condition
P(O) = Po

where Po is positive definite, then

P(N) = (pOl + ~T(N)q,(N)) -l
Thiscanbemadearbitrarilyclose to ($T (N)CJ>(N))-1 by choosing Po sufficiently
large.
. Usingthe statisticalinterpretation ofthe least-squares method shows that
this way of starting the recursion corresponds to the situation when the parameters have a prior covariance proportional to Po.
Time-Varying Systems
Usingthe loss function of (13.3), all data points are given the same weight. If
the parameters are time-varying, it is necessary to eliminate the influence of
old data. This can be done by usinga loss function with exponential weighting,
that is,
(13.14)

Identification

518

Chap. 13

The forgetting factor, A, is less than one and is a measure of how fast old
data are forgotten. The least-squares estimate when using the loss function of
(13.14) is given by

B(k + 1) = 8(k) + K(k) (Yk+l - rpT(k + 1)8{k))

K(k) = P(k)ffJ(k + 1)
P(k + 1) :::

(1 + qJT(k + 1)P(k)qJ(k + 1))-1

(13.15)

(I - K(k)rpT(k + 1))P(k)/ A.

It is also possible to model the time-varying parameters by a Markov process,

8(k +1) = 4>8(k) + u(k)
and then use a Kalman filter to estimate 9. See Remark 2 of Theorem 13.3.

Recursion Inthe Number of Parameters
When extra parameters are introduced, the vector fJ will have more components
and there will be additional columns in the matrix 4>. The calculations can be
arranged so that it is possible to make a recursion in the number of parameters in the model. The recursion involves an inversion of a matrix of the same
dimension as the number of added parameters.
U-D Covariance Factorization

Equation (13.15) is oneway to mechanize the recursive updats of the estimates
and the covariance matrix. These equations are not well-conditioned from a numerical point of view. however. A better way ofdoing the calculation is to update
the square-root ofP instead of updating P. Another way to do the calculations
is to use the U-D algorithm by Bierman and Thorton. This method is baaed on
a factorization of Pas

P= UDU T
where D is diagonal and U is an upper-triangular matrix. This method is a
square-root type ae UD1/2. is the square root of P. The U-D factorization method
does not include square-root calculations and is therefore well suited for small
computers and real-time applications. Details about the algorithm canbe found
in the References.
A Pascal program for least-squares estimationbased on U~D factorization
is given in Listing 13.1. The program gives estimates of the parameters ofthe
process
y(k) + aly(k -1) +...+ anay(k - na)
= b1u(k -1) +... + bllbU(k -nb) + e(k)
The notations used in the program are

(13.16)

Sec. 13.5

519

Recursive Computations

Variable

Notation in
the program

u(k)

u

y(k)
na
na+ nb

y

na
n

n(n - 1){2

notI
B(k) compare (13.6)
theta
tpT (k) compare (13.7) fi
A
lambda

Listing 13.1 Pascal program for least-squares estimation nfthe parameters
of the process of {13.16) using V-D factorization.

const npar=lOi{maximum number of estimated parameters}
noff~45i{noff=npar*(npr-l)/2}

type vecl=array[1 .. apar] of real;
vec2=array[1 . .noff] of real;
estpartyp = record
n,na: integer;
theta: vecl;
fi:vecl;
diag:vecli
offdiag:vec2;
end;
var y,u,lambda:real;
eststate:eBtpartyp;
Procedure LS(u,y,lambda:real;var 8ststate:estpartyp);
{Computes the least-squares estimate using the U-D method
after Bierman and Thornton}
var kf.ku,i,j:integer;
perr.fj,vj,alphaj,ajlast.pj,w:real;
k:vec1;

begin
with eststate do {Calculate prediction error}
begin
perr = y;
for i:=1 to n do perr:~perr-theta(i]*fi[i];

IdentKication

520

Liltin,l!.1 (Continued)

{Calculate gain and covariance using the U-D method}
fj :·fi[l];
yj : -diag (1) "'fj i

1(1) :-vj:
alphaj:-l.0+vj*fj;
diag[1]:-diag(1]/alphaj/lambda:
it u"l then

begin
kf:-Oi
ku:-O;

for j:-2 to n do
begin
fj :fi(j] :

for 1:-1 to j-l do
begin {f-U.U}
kf: -kf+l i
tj : -f j+fi (i) 'offdiag [kf]

end: {i}
vj : -fj.d1ag[jl; {v-Dtf}
k [j] ;-vj;

ajlast:-alpbaj;
alpbaj:-ajla't+vj-fj;
diagljl;-diag[j].ajlaat/alphaj/laabda;
pj:--tj/ajlasti
for 1:-1 to j-l do
begin
{kj+l:-kj +vj.uj}
{uj:-uj+pj'kj}
ku~-ku.1i

v:-offdiag[ku]+k(iJ~j.

k(i] :-k[i) +otfdiag [ku] .vj;

o:ffdiag[ku):av
end;

{n

end: {j}
end; {i:f u>1 then}
{Opdate parameter estimates}
for 1:-1 to n do theta(i]:-theta[1]+perr*k(i]/alphaj:
{lJpdatiag of :f1}
:for 1:-1 to a-1 do f1[n.1-i]:-f1(n-i];

nru ;--y;

fi [na+1l :-u
end {w1th .atata.te do}

end:

{LS}

Chap. 13

521

Examples

Sec. 13.6

...

~

.flo

6

0
-10

o
1

-1 .

500
....--

-

-

,.....

~

r--

1.......0

0.....- " - -

o

500
Time

Figure 13.2 Input and output when the system of (13.17) is simulated.
The input is a PRBS sequence.

13.6 Examples
Some examples show the use ofidentification methods. The first example shows
the importance of using the correct model structure when estimating a model.
Enmple 13.3 Influence of model structure
Let the system be described by the model
y(k)-1.5y(k - 1) + 0,7y(k- 2)
,;: u(k - 1) + O.5u(k - 2) + elk) - e(k - 1) + O.Ze(k - 2)

{13.17)

where e has zero mean and standard deviation 0.5. This is a "standard" system
that has been used often in the literature to test different identification methods.
In (13.17), C(q) F q", which implies that the least-squares method will give biased
estimates. However, the input-output relation of the process can be approximated
by using the least-squares method for a higher-order model. Figure 13.2 shows a
simulation of the system. The input is a Pseudo Random Binary Signal (PRBS)
sequence with amplitude ±t Thedata havebeenusedto identify models ofdifferent
orders using the least-squares and maximum-likelihood methods.
Figure 13.3 shows the step responses ofthe true system in (13.17) and ofthe
estimated models when using the least-squares method with model orders n :; ; ; 1,
2, and 4, and the maximum-likelihood method when the model order is 2. The
least-squares method gives a poor description for a second-order model, and a good
model is obtained when the model order is increased to 4. The maximum-likelihood
znethod gives vel)' good estimates of the dynamics and the noise characteristics for
a second-order model. The estimated parameters for second-order models when
using the least-squares method and the maximum-hkeliheod method are shown in
Table 13.1.
•

Identification

522
(b)

Chap. 13

10...------------,
1\

tv:__--.

-I

7

011.........---------1
o
100
(c)

0 " - - - - - - - - - -......

otl.....--------........l
o
100
Time

100

0

<d)

10

10~----------,

0 " - - - - - - - - -......
o
100
Time

Figure 13.3 Step responses of the deterministic part of the system of
(13.17) (dashed) and of the estimated models (solid) obtained when using
the least-squares (LS) method with (a) n "" 1, (b) n ;;;:: 2, (c) n == 4, and (d)
the maximum-likelihood (ML) method with n =2.
Table 13.1 Estimated parameters and standard deviations for
second-order models of the process in {13.17) when using the
least-squares (LS) and the maximum-likelihood (ML) methods.

Parameter True Value
al

-1.5

a2

0.7
1.0
0.5
-1.0
0.2

bl

b2
Cl
C2

LS n:::: 2
-1.265 ± 0,029

MLn:: 2
~ 1.513 ± 0.008

0.517 ±0,023
0.959 ± 0.101
0.972±0.131

0.704 ±0.006
1.041 ± 0.050
0.394 ± 0.071
-1.081 ±0.045
0.215 ±0.044

The second example illustrates recursive estimation using the least-squares

method.
Example 13.4 Recursive estimation
Consider the process

y(k) + ay(k - 1) :: bu(k - 1) + ~(k)

with a. :; -O.B and b ::: 0.5. The variance of the noise e is 0.25. The input signal is
assumed to be a PRBS signal with amplitude ±1. The input and the output data
are shown in Fig. 13.4. The recursive equations (13.10) to (13.12) have been used

523

Examples

Sec. 13.6

o

500

1

.......

r--

--

-1

o

r--

~

~

-

.... .....

'-

500

Time
Figure 13.4 Input-output data for the process in Example 13.4.

to estimate a and b. 'The estimates are shown in Fig. 13.5 when the initial values of
the parameters are zero and when P(O) is 10times the unit matrix. The estimates
are after a few observations dose to the true values. For the data in Fig. 13.4 we
have
a(5001 )
( -0.799 )
( b(500) 0.513

P(500}

=

0.880 1.560)
3
( 1.560 4.771 . 10-

From Theorem 13.2 we get the following standard deviations for the estimates
(J{I

= 0.5/s.80 . 10-2 = 0.015

(Jb '"

-~

0.5V47.71 ·1O-2

--

=:

0.035

-

o

500
Time

Figure 13.5 Recursive-parameter estimates when (13.10) to (13.12) are
used on the data shown in Fig. 13.4. 'The true values are indicated by the
dashed lines.

Ident~ica~on

524

o

Chap. 13

500
Time

Figure 13.6 Recursive-parameter estimates forthe system in Example 13.4
when the input is a unit pulse at time t =25. The true values are indicated
by the dashed lines.

The estimates are well within one standard deviation of their their true values.
Now assume that the input signal is changed from a PRES signal to a unit pulse
at time t = 25. The estimates for the new experiment are shown in Fig. 13.6. The
estimate of b is now very poor because the input signal is not sufficiently exciting.
The estimate of a is, however, better because the output is excited by the noise
and thus the output contains information about the parameter a .
_

The influence offeedback is illustrated in the next example.
Example 13.5 Influence of feedback
The system in Example 13,4is simulated and the input is generated via feedback
as
u(k) = -ky(k)

= -O.2y(k)

(13.18)

The phase plane of the estimates is shown in Fig. 13.7. The identifiability of the
parameters is lost due to the feedback. The estimates converge to a subspace that
is determined by

b =b + ~ (a -

ci)

= -3.5 -

5a

The least-squares loss function has the samevalues for all parameters on this line.
The problem with the loss of identifiability disappears if a feedback law of
sufficiently high complexity is used. In this example it is sufficient to introduce a
delay in the controller and use

u(k)

=:

-O.32y(k - 1)

(13.19)

The control laws (13.18) and (13.19) give approximately the same speed and output
variance of the closed-loop system. The phase plane of the estimates axe shown in
Fig. 13.8. The estimates converge from all initial values to the correct value. I

525

Examples

Sec, 13.6

1
\

~\

~~.
\

't:l

~
e
....

'

.

~ 0

\

~\

J

\~
,

~\

-1

-2

-1
0
Parameter estimate 6

1

Figure 13.7 Recursive-parameter estimates fur thesystem in Example 13.5
when the input is generated by the feedback (13.18). The dashed line shows
40the identifiable subspace. The dot shows the true values parameter values.

1

-1

-2

-1
0
Parameter estimate 5

1

Figure 18.8 Recursive-parameter estimates for thesystem in Example 13.5
when the input is generated bythe feedback (13.19). The dot shows the true
values parameter values.

Identification

526

Chap. 13

13.7 Summary
Thischapter gives a short review of the identification problem. The presentation
is concentrated on the least-squares method. hecause it is the basis for many
other methods. On many occasions it is important to make the estimationin real
time, and it is shown how the least-squares estimate can he obtained recursively.
This is used, for instance, in adaptive controllers.

13.8 Problems
13.1 The following experiment has been made to determine the normal acceleration, g.
A steel ball has been dropped without initial velocity from a high TV antenna. The
position of the ball, l, has been determined at different times, giving the following
measurements:

Time, s

Length offall, in meters

1

8.49

2

20.05
50.65

3

,'

72.19
129.85
171.56

4

5
6

The times of the measurements are exact, but there is an error in the measurement ofthe position. Determine the normal acceleration using the method ofleast

.squares from the model
2

l

gt
=-2

+e

13.2 Derive recursive equations forincreasingthe number ofparameters for the method
of least squares. (Hint: Use the same idea as when making the observations recursively.)
18..8 Consider the process

y(k) + ay(k -1)

=bu(k -1) + e(k) + ce(k-

1)

where u and e are independent white-noise processes with zero mean and unit
variance. Assume that the method of least squares is used to estimate a and b,
as in Example 13.2. Determine the expected values of and bas a function of a,
b, and c.
.

a

13.4 The parameters b1 and b2 in the system
y(k)

=b1u(k -

1) + b2u(k - 2) + e(k)

are determined using the method ~f least squares. Let the input be a step at time
k ::: O. Can the parameters bi and b2 be determined with arbitrary accuracy when
the number of observations increases? Will there be any changes if it is known
that b2 '" 0

Sec, 13.9

527

Notes and References

13.6 Consider the system

y(k)

=-ay(k - 1} + bu(k -1) + e(k)

where e is zero-mean white noise, An experiment is done on the system to estimate
a and b. The following data were calculated:

= so
ty(k + l)y(k) = 1
ri(k)

Iy(k + l)u(k)
All sums are from k

= 1 te

ru2 (k) = 50
ry{k)u(k)= 20

=36

k =- 999. Determine the least-squares estimate of a

and b.

13.9 Notes and References
There are many books and papers dealing with identification methods. Some
basic references in book form are Jenkins and Watts (1968), Eykhoff (1974),
Goodwin andPayne (1977).I,Jung and &jderstJi)m (1983), Norton (1986), IJung
(1987), S()derstri)m and Stoica (1989), and Johansson (1993). An early survey
ofsystem identification is given in Astrom and Eykhoff (1971).
Good sources for further references are Biermann (1977), Eykhoff (1981),
Isermann (1981), Lawson and Hansson (1974), and the special issue on "Identification and system parameter estimation," Automatica, 17, no. 1 (January
1981).

Forsomeone interested in historical notes, see Gauss (1809) andSorensen
(1970).

A
Examples
Examples used in the book as "standard processes" are presented in this appendix.
Example At Double integrator

The double integrator is used throughout the book as a main example to illustrate
the theories presented, The process is described hy the differential equation
d 2y

~""U

dt 2

(A.l)

The transfer function is G(s) ;: 1/82. We introduce 'Y and y as the states Xl and
%2, respectively, of the system. The state-space representation is then

~~ = (~ ~)x+ (~)u
y= (1 o)x

(A.2)

Sampling (A.2) using a zero-order hold with the sampling period h gives the
discrete-time system (see Example 2.2)

x(kh + h} ""
y(kh)::::

(~ ~) x(kh) + (h~2) u(kh)

(1 0) x(kh)

(A.3)

The pulse-transfer operator of (A,3) is given by
2(q

H(q} = h + I}
2(q - 1)2

(A.4)

There are several physical processes that can be described as double integrators.
One such is the attitude of a satellite, which can be described by the equation

528

529

Examples

App.A

Torque motor
u

Figure A.I Schematic illustration of the ball and beam.
where 8 is the attitude angle, Me is the control torque, Md is the disturbing torque,
and J is the moment of inertia.
Another example that can be described by the double integrator is a rolling
ball on a tilting beam (see Fig. A.I) . The equation of the ball and beam can be
described by
d2 fJ
J dt2 ::; mgrsin rp ::::; mgrrp
x -= r8

or

where 8 is the angle of the ball, g is the normal acceleration, x is the position of
_
the hall, and rp is the tilting angle of the beam.
Example A.2 Motor

A DC motor can be described by a second-order model with one integrator and one
time constant (see Fig. A2). The input is the voltage to the motor and the output is
the shaft position. The time constant is due to the mechanical parts of the system.
and the dynamics due to the electrical parts are neglected. A normalized model of
the process is then given by
1

Y(s)

= s(s + 1) U(s)

Introduce the velocity and the position ofthe motor shaft as states (see Fig. A.2).
The state-space model of the motor is then given by
dx

dt y==

(-11 ~) x + (~) u
(0 1) x

Figure A.2 Normalized model of a DC motor.

(A.5)

Examples

530

App.A

II.

Figure A.3 Pendulum.
Sampling (A.5) using a zero-order hold gives the discrete-time model
x(kh + h) = (

y(kh);;;;

e-h

1-e

-h

0) x(kh) + [1
1

h
e-

h ·1+e

-h

)

u(kh)

(A.6)

(0 1) x(kh)

(seeExample 2.3). A current-controlled DC motor with the shaft velocity 88 output
can also be described by the model of (AS) . Still another example that can be
characterized by an integrator and a single pole is a ship. Let the input be the
rudder angle and the output be the heading. The ship can then be described by
the transfer function
0(8) _ ---.,.-----K_
- 8(1 + Ts)

where the time constant mayhe positive or negative depending on the type ofship.
_
For instance. large tankers are unstable.
Example A.3 Harmonic oscillator
Consider 8 pendulum (see Fig. A3). The acceleration of the pivot point is the input
and the angle y is the output. The system is then described hy the normalized
nonlinear equations

where Xl is the angle and .t2 is the angular velocity. Linearizing around u ;;;;

Xl

=0

gives

~; == (~1 ~) x + (~) u
Y= (1 O)x

(A7)

App.A

531

Examples
Thick stock
flow, U

Drying

Basis

section

Head box

weight.y
l

Figure A.4 Schematic diagram of a paper machine.

The transfer function of (A.7) is given by

G(s):= -,
2
8

1

~

+1

This transfer function can be generalized to

G(s):=

2

w2

')

s + or

One state-space representation for this transfer function is

~~ (_Ow ~) x + (:)
:=

v

>

U

(A.S)

(0 1) x(t)

Sampling (A.B) using a zero-order hold gives the discrete-time system
x(kh + h) "'

y(kh)

COS

(

wh

.
- sin wh

= (1

sin (j)h )
( 1 - cos wh )
x(kh) + .
u(kh)
cos wh
sin mh

(A.9)

0) x(kh)

An overhead crane can also be modeled by (A.S) .

•

Example A.4 Time-delay process
Many industrial processes can be approximated by first-order dynamics and 11 time
delay. One example is a paper machine (see Fig. A.4). The input is the thick stock
flow, that is, the amount of pulp. The output is the basic weight. that is, the
thickness of the paper. The equations describing the system can be normalized to
the transfer function
(AIO)
Another physical process that can be described by (A.IO) if! a mixing system with
long pipes. Ex.ample 2.8 gives the zero-order-hold sampling of (A.l0).
•

532

Examples

App.A

Example A.5 An inventory model
An inventory is a typical example that can naturally be described as a discretetime system. Orders and deliveries are obtained at regular intervals tied to the
calendar-for example, each day or week.
Let y(k) be the inventory at time k before any transaction 18 started. The
deliveries to the inventory that are ordered at time k are u(k). It is assumed that
there is a delay of one period from the order until the goods start coming into
the inventory. Finally, the delivery from the inventory is v(k) . Introduce the state
variables Xl (k) == y(k) and x2(k) == u(k -1) . The inventory can be described by the
following discrete-time state equations:

xdk + 1)

=xdk) + xz(k) - v(k)

x2(k + 1) "" u(k)
or
x(k + 1)

=

y(k) ==

(~ ~) x(k) + (~) u(k) + (-0

1

) v(k)
(A.H)

(1 0) x(k)

The input-output relation is given by

y(k) - y(k - 1) = u(k - 2) - v(k -1)

(A.12)

•

B
Matrices
8.1 Matrix Functions
In connection with sampled-data systems functions like expA and InA, where
A is a matrix, are of interest. The matrix exponential and matrix logarithm are
both matrix functions. This section gives some properties of matrix functions
and discusses some ways to compute them.
A useful property ofa square matrix is given by Theorem B.l.
THEOREM

B.l THE CAYLEY·IiAMrLTON THEOREM

Let

be the characteristic equation of the square matrix A. Then A satisfies the

following equation

That is, the matrix satisfies its own characteristic equation.

•

Let A be an n x n square matrix and f(A) a scalar function of a scalar argument A. We now want to extend the function f(l) to a function with a matrix
argument, that is, f(A). If f(A.) is a polynomical

then the matrix function f{A) is defined as

The eigenvalues of f(A) can be found using the following theorem.
533

Matrices

534
THEOREM B.2

nomial in A and
then

SO

ei

App.B

EIGENVALUES OF A MATRIX FUNCTION If f(A) is a polythe eigenvectors of A associated with the eigenvalues Ai l

((Ai) is an eigenvalue of f(A) and ei is the corresponding eigenvector.

-

Further, if f(A) can be defined by the power series
oc

f(A)

= LCi AI
i",O

which is assumed to be convergent for IAI < R, then the matrix function
~

f(A) =

LCi Ai
j",O

is convergent if all the eigenvalues of A, Ai satisfy IA < R.
il
By using the Cayley-Hamilton theorem, it can be shown that for every
function f there is a polynomial p of degree less than n such that

From Theorem B.2 we get

i ::: 1,... , n

(B.2)

If the eigenvalues are distinct, then these conditions are sufficient to determine
at. i =: 0,. ,. , n - 1. If there is a multiple eigenvalue with multiplicity m, then
the additional conditions

(B.3)

hold, where f(i) is the ith derivative with respect to A.
By using (B.I) and the conditions in (B.2) and (B.3), it is possibleto compute matrix functions. For low-order systems, this is a very convenient method
for hand calculations.

Sec. B.1

535

Matrix Functions

Example B.l Computation of matrix exponential
Let

and determine
~h

= aoAh + all

Ah has the eigenvalues ±ih; the system of equations

eill
e-

llt

=aoih + at
= -aoih + al

holds, giving
1 (Ih
~ih)
e - e

sinh
=-h-

an

= 2ih

at

I
= 2(eill + e- 'il =cos h
I

)

Finally,
eAh

=sin h (0
-1

1) + cos h (1 0)
0
0 1

= (COSh Sinh)
- sinh cosh

•
Example B.2 Computation of matrix logarithm
Let

~=(~ ~)
and compute In CI>. The eigenvalues are given by (A - 1)2 = o-that is, multiple
eigenvalues exist. The matrix logarithm can now be written as

In CI>

=ao~ + all

where a 0 and (X 1 are given by
In 1 = ao + al

:..t (In A)I A-I = ao
which gives

Finally,

In~ = (~ ~) - (~ ~) = (~ ~)
•

Matrices

536

App. B

Remark.

Instead ofstarting with the characteristic polynomial, it is possible to use the minimal polynomial of the matrix. The degree of the series in
(B.l) will then be the degree of the minimal polynomial minus one. In general,
this will not reduce the computing time because the minimal polynomial--or,
alternatively, the Jordan form-has to be computed.

8.2 Matrix-Inversion lemma
The following lemma is used in Sec. 13.5 to invert a matrix.
LEMMA B.l MATRIX-INVERSION LEMMA
nonsingular square matrices; then

Proof

Let A, C, and C- 1 t DA-IB be

By direct substitution,

(AtBCD)(A- 1 -A-1B(C- 1 + DA-1Br1DA- 1)
=1 + BCDA- 1 - B(C - 1 + DA- 1Bt1DA - 1
- BCDA- 1 B(C- 1 + DA-1Bt1DA- 1
=1 + BCDA- 1 - BC(C- 1 + DA-1B)(C- 1+ DA-1Bt1DA- 1

::::1 + BCDA- 1 - BCDA- 1 = I

•

B.3 Notes and Refersnces
Further properties of matrices can be found in Gantmacher (1960), Bellman
(1970), Barnett (1971), and Golub and Van Loan (1989),

Bibliography
AcKERMANN,

J. (1972). Abtastregelung. Springer-Verlag, Berlin.

(1996). Sampled-Data Control Systems-Analysis and Synthesis, Robust Design.
Springer-Verlag, Berlin.

-

B. D, 0., and J. B.
Englewood Cliffs, N.J.

ANDERSON,

MOORE

(1971). Linear Optimal Control. Prentice Hall,

- (1979). OptimalFiltering. Prentice Hall, Englewood Cliffs, N.J.
- (1990). OptimalControl-Linea.r Qua.dratic Methods. Prentice Hall, Englewood Cliffs,
N.J.
ANToNIOU, A. (1979). Digital Filters: Analysis and Design. McGraw-Hill, New York.

ARAKI, M., and Y. ITO (1993). "Frequency-response ofsampled-data systems I: Open-loop
consideration." In Preprints of the IFAC 12th World Congress, vol, 7, pp. 289-292.
Sydney.
Ill, A. F., and A. J. LAUB (1984). "Generalized eigenproblem algorithms and
software for algebraic Riccati equations." Proc. IEEE, 72, pp. 1746-1754.

ARNOLD

AsTRoM, K. J.

(1963) . "On the choice of sampling rates in optimal linear systems."
Technical Report. IBM San Jose Research Laboratory.

- (1965). "Notes on the regulation problem." Technical Report CT211. IBM Nordic
Laboratory, Lidingo.
- (1967). "Computer control of a paper machine: An application of linear stochastic
control theory." IBM J. Res. Dev., Il , pp. 389-405.
- (1970). Introduction to Stochastic Control Theory, Academic Press, New York.
- (1980). "Piece-wise detarministic signals." In O. D. ANDERSON, Ed., Time Series. North
Holland. Amsterdam.
-

(1983a). "Computer-aided modeling, analysis and design of control systems: A
perspective," IEEE Control Syst. Mag., 3:2, pp. 4-16.

- (1983b) . "Theory and application of adaptive control." Automatica, 19, pp. 471-486.
- (1987). "Adaptive feedback control." Proc. IEEE, 75, pp. 185-217.

537

538

Bibliography

AsTROM, K. J., and P. E. EYKHOFF (1971). "System identification: A survey."

Autometice;

7, pp. 123-162.

K. J., P. HAGANDER, and J.
Automeiics, 20, pp. 31-38.

AsrROM,

STERN£Y

(1984). "Zeros of sampled systems."

K. J., and T. HAGGLUND (1995). PID Controllers: Theory, Design, and Timing,
2nd ed. Instrument Society ofAmerica, Research Triangle Park, N.C.

AsTROM,

AsTRbM, K. J., and J. KANNlAH (1994). "A fast adaptive controller for motion control." J.

Syst. Eng., 4, pp, 70--75.
K J., and B.
pp. 185-199.

AsrROM,

WIITENMARK

(1973). "On self-tuning regulators." Automatics, 9,

- (1980). "Self-tuning controllers based on pole-zero placement." Proc. lEE, pt. D, 127,
pp. 120-130.
- (1995). Adaptive Control, 2nd ed, Addison-Wesley, Reading, Mass.

ATHANs, M., and P. L. FALB (1966). Optimal Control. McGraw-Hill, New York.
ATHERTON,

D. P. (1975). Nonlinear Control Engineering-Describing Function Analysis

end Design. Van Nostrand Reinhold, London.

- (1982). "Limit cycles in relay systems." Electron. Lett., 18, pp. 922-923.
BALCHEN, J. G., and K I. MUMME (1988).

Process Control. Van Nostrand Reinhold, New

York.

R. H. (1952). "The pulse transfer function and its applications to sampling
servosystems." Proc. lEE, 99, pp. 302-317.

BARKER,

BARNES,

J. G. P (1982). Programming in Ada. Addison-Wesley, New York.

BARNE'IT, S, (1971). Matrices in Control Theory. Van Nostrand Reinhold, New York.
- (1983). Polynomials and Linear Control Systems. Marcel Dekker, New York.
BELLMAN,

R. (1957). Dynamic Programming. Princeton University Press, Princeton, N.J.

- (1961). Adaptive Control: A Guided 7bur. Princeton University Press, Princeton, N.J.
- (1970). Introduction to MBtrix Analysis.

McGraw~Hill,

New York.

1. GLICKSBERG, and O. A. GROSS (1958). "Some aspects ofthe mathematical
theory of control processes." Technical Report R-313. The RAND Corporation. Santa
Monica, Calif.

BELLMAN, R,

P, A. L. LAUB, and V. MEHRMANN (1995). "A collection of benchmark examples
for the numerical solution of algebraic Riccati equations II: Discrete-time case."
Technical Report SPC 95_23. Fak. f. Mathematik, TV Chemnitz-Zwickau, Chemnitz,
FRG.

BENNER,

BERNHARDSSON. B. (1990). "The predictive first order hold circuit." In Proceedings
29th IEEE Coaterence on Decision and Control, pp. 1890-1891. Honolulu.

Qfthe

- (1993). "Sampling of state space systems with several time delays." In Preprints of
the IFAC 12th rforld Congress, PP. 361-364. Sydney, Australia.

J. E. (1958). "The effect ofquantization in sampled-feedback systems." 7tans.
AlEE, 77, pp. 177-182.

BERTRAM,

539

Bibliography

BIERMANN, G. (1977). Fectorisstion Methods for Discrete Estimation. Academic Press,

New York.
BITIANTI, S., A.

J.

LAUB, and

J. C. WILLEMS (1991). The Ricani Equation. Springer-

Verlag, Berlin.
BJORK, G.,

A. DAHLQV1ST, and N. ANDERSSON /1974) . Numeries! Methods. Prentice Hall,

Englewood Cliffs I N.J.
W. A. (1963). "A new version of the euclidean algorithm." Amer. Math.
Monthly, 70, pp. 742-745.

BLANKENSHIP,

H., and R. YLINEN (1983) . Algebraic Theory for Multivariable LinearSystems.
Academic Press, New York.

BLOMBERG,

BOUDREAU, J. A. (1976).

"Integrated flight control system design for CCV." In Proceedings
ofthe AL4A Conierence on Flight Mech8nics, Guidance 8nd Control.

Box, G. E. P, and G. M. JENKINS (1970) . Time Series Analysis, Forecasting, and Control.
Holden-Day, San Francisco.
~

(1976). Time Series Analysis and Control Holden-Day, San Francisco.

BRINCH-HANSEN, p. (1973).

Operating System Principles. Prentice Hall, Englewood Cliffs,

N.J.

E. H. (1977). "Design and programming control algorithms for DDC systems."
Control Eng., January, pp. 24-26.

BRISTOL,

- (1980). "Strategic design: A practical chapter in a textbook on control." In Preprints
of the JACC. Paper WA4-A. San Francisco.

G. S., and D. P. CAMPBELL (1948). Principles ofServomechanisms. John Wiley,
New York.

BROWN,

BRYSON, A. E., and Y-C. Ho (1969) . Applied Optimal Control-Gptimizatiou, Estimation,

and Control. Ginn, Waltham, Mass.
BUCKLEY. P. S. (1964). Techniques of Process Control. John Wiley, New York.

(1978) . "Distillation column design using variable control, Part 1: Process and
control design; Part 2: Economics, energy, and equipment." Instrumentetion Tech.
September. 115-122; October, 49-53.
Bncv, R. S. (195~) _ "Optimum finite time filters for a special nonstationary class of
inputs." Technical Report. Applied Physics Laboratory, Johns Hopkins University,
Baltimore.

Concurrent Programming. International Computer
Science Series. Addison-Wesley, Reading, Mass.

BURNS, A, and G. DAVIES (1993).

BURNs. A., and A WELLINGS (1990). Real-time systems and their programming languages. International computer science series. Addison-Wesley, Reading, Mass.
B. R. A (1976). "Fly-by-wire and control configured vehicles-Rewards and risks."
Aeronaut. J, February.

BURNS,

M. (1977). "'Elimination of limit cycles in digital filters with very low increase
in quantization noise." IEEE Trans. Circ. Syst; CAS-24, pp. 300-304.

BUTrNER,

Bibliography

540
CAINES,

P. E. (1988). Linear Stochestie Systems. John Wiley, New York.

F., J. RABAEY, G. GoOSSENS, J. L. V MEEREERGER I R. JAIN, H. J. D. MAN,
and J. VANDEWALLE (1988). "Architectural strategies for an application-specific

CATfHOOR,

synchronous multiprocessor environment." IEEE 'frans. Acoust., 36, pp. 265-284.
CELLlER,

F. E. (1991). Continuous System Modeling. Springer-Verlag, New York.

CHAR, B. W. (1992). First Leaves: A Tutorial Introduction to MJ1ple V Springer-Verlag,
New York.
CHESTNUT,

H., and R. W. MAYER (1959). Servomechanisms and Regulating System

Design, vol. 1. John Wiley, New York.
CHUNG,

K. 1. (1974) . A Course in Probability Theory. Academic Press, New York,

A. (1922). "Uber die Anzahl der Wurzeln einerAlgebraisehen Gleiehung in einem
Kreise." Matematische Zeitschrift, 14, pp. 110-148.

COHN,

CROCHIEVE, R. E., and L. R. RABINER (1983). Multirate Digital SignalProcessing. Prentice

Hall, Englewood Cliffs, N.J.
CURRY, E. E. (1967). "The analysis ofround-off and truncation errors in a hybrid control
system," IEEE fuws. Automat. Control, AC.12, pp, 601-604.

DAHLIN, E. B. (1968) . "Designing and tuning digital controllers." Insttum. Control Syst.,
41:6, pp. 77--83.
DE SOUZA, C. E., and G. C. GooDWIN (1984) . "Intersample variances in discrete minimum
variance control." IEEE Trans. Automat. Control, AC-29. pp. 759-761.

to the Applications of the Laplace and Z·'fransforms. Van
Nostrand Reinhold, New York.

DoETSCH, G. (1971). Guide

C., and R. H. BlSHOP (1995). Modem Control Systems, 7th ed. Addison-Wesley,
Reading, Mass.

DORF, R.

J. C., and G. STEIN (1981). "Multivariable feedback design: Concepts for a
classical/modem synthesis." IEEE 1Tans. Automat. Control, AC·26, pp. 4-16.

DOYLE,

A., and G. F. FRANKLIN {1980). "Comments on 'The numerical solution of
the discrete time algebraic Riccati equation'." IEEE 'lhms. Automat. Control, AC·25,

EMAMI-NAEINI,

pp. 1015-1016.
EVKHOFF, P. (1974).

System Ideatilicstio»: Pstsmeter and State Estimation. John Wiley,

London.
- Ed. (1981). Trends and Progress in System Identification. Pergamon Press, Oxford.
FATEMAN, R. J. (1982). "High-level language implications of the proposed IEEE floating-

point standard." ACM Treas. Prog. Lang. Syst., 4:2, pp. 239-257.

P. WINDETf, and S. C. FORGE (1971). l<Aspect8 of the Frequency
Response Testing of Simple Sampled Systems!' Int. J Control, 14, pp. 881-896.

FLOWER, J. 0., G.

Foss, A. S. (1973). "Critique ofchemical process control theory." IEEE Trans. Automat.
Control, AC-18, pp. 646-652,
G. F., and J. D. POWELL (1989). Digital Control a/Dynamic Systems, 2nd ed.
Addison-Wesley, Reading, Mass.

FRANKLIN,

541

Bibliography

FRANKLIN, G. F. , J. D. POWELL, and A. EMAMI-NAEINI (1994). Feedback Control of
Dyn/JI1Jic Systems, 3rd ed. Addison-Wesley, Reading, Mass.

F. R. (1960). The Theory of Matrices, vol. I and II. Chelsea, New York.

GANTMACHER,
GARDENHIRE,

L. W. (1964) . "Selection of sample rates." ISA J., April, pp. 59-64.

K F. (1809). Tbeoris Matus Corporum Ooelestium (Theory uf motion of the
heavenly bodies). (English trans., 1963.) Dover, New York.

GAUSS,

GAwrHROP,

P. J . (1980). "Hybrid self-tuning control." Proc. lEE, 127, pp. 229-236.

GEVERS. M., and G. 11 (1993) . Parametrizations in Control, Estimation, and Filtering
Problems: Accuracy Aspects. Springer-Verlag, London.

J. C., M. J . PELEGRIN, and P.
McGraw-Hill, New York.

GILLE,

GoFF, K.

DECAULNE

(1959). Feedback Contro) Systems.

W. (1966). "Asyetemie approach to DOC -design," [SA J., December, pp. 44--54.

H., and C. F. VAN WAN (1989). Matrix Computations. 2nd ed. John Hopkins
University Press, Baltimore.

GoLUB, G.

G. C,. and R. L, PAYNE (1977). Dynamic System Identification: Experiment
Design and Data Analysis. Academic Press, New York.

GooDWIN,

G. C., and K S., SIN (1984), Adaptive Filtering, Prediction end Control.
Prentice Hall, Englewood Cliffs, N.J.

GooDWIN,

GoRDON,

G. (1969) . System Simulation. Prentice Hall. Englewood Cliffs, N.J.

GRiEBE, S. F., and A. L.B. AHLiN (1996). "Dynamic transfer among alternative controllers
and its relation to antiwindup controller design." IEEE 1Tans. Control Syst. Thch.,
4, pp, 92-99.

Ill, T. L., and G. F. FRANKLIN (1963). "A general solution for linear sampled
data control." frans. ASME J. Basic Eng., 86·D, pp. 197-201.

GUNKEL,

M. M., Ed. (1986). Adaptive Methods for Control System Design. IEEE Press,
New York.

GuPTA,

K, and P. HAGANDER (1991). "Discrete-time LQG with cross-terms in the
lOBS function and noise description." Technical Report TFRT·7475. Department of
Automatic Control, Lund Institute ofTechnology.

GUSTAFSSON,

K, M. LUNDH, and G. SODERLlND (1988) . "A PI stepsize control for the
numerical solution of ordinary differential equations," BIT (Nordisk Tidskriii
Informationsbehandling), 28:2, pp. 270-287.

GuSTAFSSON,

ror

P., and A lfA!.;SSON (1996). "How to solve singular discrete-time Riccatiequations." In Preprints of the [FAC World Congress, vol. C, pp. 313-318. San

HAGANDER,

Francisco.
HAlRER, E., and G.

WANNER

(1991). Solving Ordinary Differential Equations II-Stiff.

andDifferenti81-Algebraic Problema. Springer-Verlag, New York.
R. (1988). "Antiwindup and bumpleas transfer: A survey." In Proceedings of the
12th World Congress on Scientific Computation, lMACS, vol. 2, pp. 59-65. Paris.

HANIJS,

HIGHAM, J. D. (1968). "Single-term' control offirst- and second-order processes with dead

time." Control, February, pp. 136-140.

Bibliography

542
HUREWICZ, W.

(1947). "Filters and servo systemswith pulsed data,"In H.M. JAMES et al.,
EdA.• Thenry of Servomechanism. McGraw-Hill, New York.

R. (1989). DigitIJl Control Systems, Vol. 1: Fundamentals, Deterministic
Control, 2nd ed. Springer-Verlag, Berlin.

ISERMANN,

- (1991). Digital Control Systems, l'ol. 2: Stochastic Control, Multiv8riabJe Control,
Adaptive ControL Applications. 2nd ed. Springer.Verlag, Berlin.
- Ed. (19Bl). System Identification. Tutorial presented at the 5th IFAC Symposium
on Identification and System Parameter Estimation, Darmstadt. Pergamon Press,

Oxford.
interaction of roundoff noise and dynamic range in
digital filters." Bell Syst. Tech. J., 49, pp. 159--184.

JACKSON, L. B. (1970a). "On the

- (1970b). "Roundoff noise analysis for fixed-point digital filters realized in cascade of
parallel form." IEEE Trans. Audio Electroecoust.; AU·18, pp. 107-122.
- (1979). "Limit cycles in state-space structures for digital filters." IEEE Trans. eire.
Syst., CAS.26, pp. 67-68.
H. M., N . B. NICHOLS, and R. S. PHIL1P8 (1947). Theory of Servomechanisms.
McGraw·Hill, New York.

JAMES,

JENKINS, G. M., and

D. G. WAITS (1968) . Spectral Analysis and Its Applications. Holden-

Day, San Francisco.

J. (1977). "The Shannon sampling theorem-Its various extensions and
applications: A tutorial review." Ptoc. IEEE. 65, pp. 1565-1595.

JERRI, A

J. (1982). "New algorithm for minimal solution oflinear polynomial equations."
KybBrnetica. 18, pp. 505-516 .

JEZEK,

JOHANSSON, R. (1993).

System Modeling and Identification. Prentice Hall, Englewood

Cliffs, N. J.
JURY,

E. I. (1956). "Synthesis and critical study ofsampled-data control systems." AlEE

Trsns., 75, pt. U, pp. 141-151.

- {1957}. "Hidden oscillations in sampled-data control systems." AlEE Trans., 75,
pp. 391-395.
- (1958). Sampled-Data Control Systems. John Wiley, New York.

- (1961). "Sampling schemes in sampled-data control systems ," IRE Thms . Automat.
Control, AC.6, pp. 88-90.
- (1967a). "A general z-transform formula for sampled-data systems." IEEE 'frans.
Automat. Control, AC.12, pp. 6O~8.
- (1967h) . "Anote on multirate sampled-data systems." IEEE Thms. Automat. Control,
AC·12, pp, 319-320.
-

(1980). 'Sampled-data systems, revisited: Reflections, recollections, and reassessments." Trens. ASME, J Dyn. Syst., Measure., Control, 102, pp. 208-216.

- (1982). Theory 8nd Applicetion of the z-Transform Method. Krieger, Malabar, Fla.
E.!., and J. BLANCHARD (1961) . "'A stability test for linear discrete time systems
in table form." Proc. IRE, 49, pp. 1947-1948.

JURY,

543

Bibliography
E. 1, and Y. Z.
7, pp. 89-107.

JURY,

KAlLATH. T. (1980).

TsYPKIN

(1971). "On the theory of discrete systems." Autom.aticB,

Linear Systems. Prentice Hall, Englewood Cliffs. N.J.

KALMAN, R E. (1960a). "Contrihutions to the theory of optimal control." Boletin de 18
Sociedsd Matematica Mexicana, 5, pp, 102-119.
- (l960h). "Anew approach to linear filtering and prediction problems," Trans. ASME,
Ser. D. J. Basic Eng' l 82 1 pp, 34-45.
- (1961). "On the general theory of control systems." In Proceedings ofthe First [FAC
Congress, pp. 481-492.
KALMAN, R E., and J . E. BERTRAM (1958). "General synthesis procedure for computer
control ofsingle and multiloop linear systems." AlEE Trans, 77, pp. 602--609.
- (1960). "Control system analysis and design via the second method of Lyapunov: II.
Discrete-time systems." Trsns. ASME Ser. D. J. Basic Eng., 82:8. pp. 394-400.

KALMAN, R. E., and R. S. Bucv (1961). "New results in linear filtering and prediction
theory." '1hms. ASME, Ser. D., J. Basic Eng., 83, pp. 95-107.
KALMAN, R. E., P. L. FALB, and M. A. ARBm (1969). Topics in Mathematiaal System
Theory, McGraw-Hill, New York.

KALMAN, R. E., Y. C. Ho, and K. S. NARENDRA (1963). "Controllability of linear dynamical
systems." In Contributions to Differet1t Equations, vol, I, pp. 189-213. John Wiley,
New York.
KARLIN, S. (1966). A First Course in Stochastic Processes. Academic Press, New York.

KHEIR, N. A. (1988). Systems Modeling end Computer Simulation. Marcel Dekker, New
York.

D. L. (1968). "On an iterative technique for Riccati equation computations."
IEEE Trans. Automat. Control, AC.13, pp. 114-115.

KLEINMAN,

KNOWLES, J. R, and R. EDWARDS

(1965). "Effect of a finite-ward-length computer in a
sampled-data feedback system." Proc. lEE, 112, pp. 1197-1207.

A. N. (1941). "Interpelation and extrapolation of stationary random
sequences." Technical Report. Ser. Math. 5, Moscow University.

KOLMOGOROV,

KONAR, A. F., and J. K. MAHESH (1978). "Analysis methods for multirate digital control

systems." Honeywell Report No F0636·TRl. Honeywell Systems andResearch Center,
Minneapolis, Minn.

V. A. (1933). "On the transmission capacity of 'Ether' and wire in
electrocommunication." In Proceedings First All-union Conference on Questions of
Communicstion. Moscow.

KOTELNIKOV,

KRANe, G. M. (1957). "Input-output analysis ofmultirate feedback systems." IRE 'frans.
Automat. Control, AC.3, pp. 21-28.

KuCERA, V (1979) , Discrete Linear Control Academia, Prague.
- (1984). "The LQG problem: A study ofcommon factors." Probl. Controllnfonn. Theory;
13, pp. 239-251.

Bibliography

544
-

(1991). Analysis and Design of Discrete Linear Control Systems. Prentice-Hall
International, London,

- (1993). "Diophantine equations in control: A survey." Automsiice, 29, pp, 1361-1375.

P. R., and P. VARAIYA (1986). Stochastic Systems: Estimation, Identification and
Adaptive Control. Prentice Hall, Englewood Cliffs, N.J.

KUMAR,

Kuo, B. C. (1980). Digital Control Systems. Holt-Saunders. Tokyo.
KWAKERNAAK, H., and R. SWAN (1972). Linear Optimal Control Systems. John Wiley,
New York.
KWONG, R. H. (1991). "On the linear quadratic Gaussian problem with correlated noise
and its relation to minimum variance control." SIAM J. of Control Optim., 29,

pp. 139-152.
LANING, J, H., and R. H. BA'rnN (1956). Random Processes in Automatic Control.
McGraw-Hill, New York.
LAWOEN, D. F. (1951). u.A general theory of sampling servomechanisms." Proc. lEE, 98,

pp.31-36.

R. J. HANSSON (1974). Solving Least Squares Problems. Prentice
Hall, Englewood Cliffs) N.J.

LAwsON, C. L., and

A. (1988) . "Programmable DSP architectures; Part 1." IEEE ASSP Mag., 5:4,
October, pp. 4-19.

LEE. E.

LENNARTSON t B. (1987). "On the choice of controller and sampling period for linear

stochastic control." Preprints of the 10th [F'AC World Congress, 9 t pp. 241-246.

B., and T. SODERSTROM (1986). "An investigation of the intersample
variance for linear stochastic control." Preprint» of the 25th IEEE Conference on
Decision and Control, pp. 177~ 1775.

L&NNARTSON,

T., J. L. MEIRYt and R. E. CURRY (1972). "On the ideal-sampler approximation."
IEEE Trans. Automat. Control, AC·17, pp. 167-168.

LI, Y.

LINDORFF, D. P. (1965).

Theory ofSampJed-Data Control System.s. John Wiley, New York.

LINVILL, W. K (1951). "Sampled-data control systems studied through comparison

sampling with amplitude modulation." AlEE Trsns., 70, pt. II, pp. 1778-1788.
WUNG, L. (1987). System Identification: Theory for the User. Prentice Hall, Englewood
Cliffs, N.J.
L., and T. SODERSTROM (1983). Theory and Practice ofRecursive Identification.
The MIT Press, Cambridge, Mass.

lJuNG,

LUCAS, M. P. (1986). Distributed Control System.s-Their Evaluation and Design. Van

Nostrand Reinhold, New York.
LUENBERGER, D. G. (1964). "Observing the state of a linear system." IEEE Trsns. Mil.

Electron. , MILoS, pp. 74-80.
- (1971). "An introduction to observers." IEEETrans. Automat. Control, AC.18, pp.596603.
M!\c:COLL, L. A. (1945). Fundamental Theory of Servomechanisms. D. Van Nostrand,

New York.

545

Bibliography

MAcGREGOR, J. F. (1976). "Optimal choice of the sampling interval for discrete process
control" Technometrics, 18:2, pp. 151-160.

S.-E.. M. ANDERSSON, and K. J. AsTROM (1993). "Object-oriented modeling
and simulation." In D. A LINKENS, Ed., CAD for Control Systems, pp. 31-69. Marcel
Dekker, New York.

MATTSSON,

McGARTY, T. P. (1974). Stochastic Systems andState Estimation. John Wiley, New York.
MELZER, S, M.,

and B. C. Kuo (1971). "Sampling period sensitivityof the optimal sampled
data linear regulator." Automatic8, 7, pp. 367-370.

MIDDLETO~,

R. H., and G. C, GoODWIN (1987). "Improved finite word length charactaristics in digital control using delta operators." IEEE Trans. Automat. Control, AC-31,
pp. 1015-1021.

- (1989). Digital Control and Estimation: A Unified Approach. Prentice Hall, Englewood
Cliffs, N.J.

"An algoritlun for pole assignment of time
invariant linear systems." Int. J. Control, 35:2, pp. 341-354.

MIMINIS, G. S., and C. C. PAIGE (1982).

- (1988). "Adirect algorithm for pole assignment of time-invariant multi-input systems
using state feedback." Automatics, 24, pp. 343-356.

and J. H. LEE 0991). "Model predictive control: The good, the bad, and the
ugly." In Chemical Process Control. CPCIV, pp. 419-442. Padre Island, Texas.

MOHARI, M.,

MORARI, M., and E. ZAFIRIOU (1989). RobustProcess Control. Prentice Hall, Englewood

Cliffs, N.J.
P (1983) . Issues in the Implementation of Digital Feedback Compenseters.
The MIT Press, Cambridge, Mass.

MORONEY,

A. CASAVOLA (1990) . "On the polynomial equations for the
MIMO LQstochastic: regulator." IEEE Trans. Automat. Control, AC·35, pp. 320-322.

MOSCA, E., L. GIARRE, and

NEUMAN, C. P" and C. S. BARADELLO (1979). "Digital transfer functions for microcomputer

control." IEEE Trans. Syst., Man, Cybem., SMC·9, pp. 856-860.
G. C" L. A GoULD, and J. F. KAISER (1957). Analytical Design ofLinear
Feedback Controls. John Wiley, New York.

NEWTON, JR,

NORTON,

J. P. (1986). An Introduction to Identification. Academic: Press, London.

NYQUIST, H. (1928). "Certain topics in telegraph transmission theory."

AlEE Trens., 47,

pp.617-644.
OLDENBURG,

R. C.,and H. SARTORIUS (1948). The Dynamics ofAutomatic Control. ASME,

New York.

A. V., and R. W. SCHAFER (1989). Discrere-Time Signal Processing. Prentice
Hall, Englewood Cliffs, N.J.

OPPENHElM.

A. (1965). Probability, Random Variables, andStochastic Processes. McGrawHill, New York.

PAPOULIB,

T., A. J. LAUB, and N. R. SANDELL, JR (1980). "On the numerical solution of the
discrete time Ricc:ate equation." IEEE 1rans. Automat. Control, AC·26. pp. 631-641.

PAPPAS,

Bibliography

546

S. R., and S. F. HESS (1971). "Limit cycle oscillations in digital filters." IEEE
Trans. eire. Theory, CT-18, pp. 687-697.

PARKER.

PARZEN, E. (1962).

Stochastic Processes. Holden-Day, San Francisco,

L. (1981). "An algebraic theory for the design of controllers for multivariable
systems-Part I: Structure matrices and feedforward design; Part II: Feedback
realizations and feedback design." IEEE 718IIs. Autamat. Control, AC-26, pp. 171182 and 183-194.

PERNEBO,

PETERKA,

V. (1972). "On steady-state minimum variance control strategy." Kybernetika.

8, pp.

21~232.

PETKOV, P. H., N. D. CHRIS'fOV, and M. M. KONSTANTlNOV (1984) . "A computational

algorithm for pole assignment of linear input systems:' In Preprints of the 23rd
IEEE Conference on Decision and Control, pp. 177~1773.
POLYA, G. (1945).

How to Soll'e It. Princeton University Press. Princeton, N.J.

L. S., V. G. BOLTYANSKII. R. V. GAMKRELIDZE, and E. F. MISCHENKO (1962).
The Mathematical Theory of Optimal Processes. John Wiley~ New York.

PONTRYAGlN.

R., and B. GoLD (1975). Theory andApplication of Digital Signal Processing.
Prentice Hall, Englewood Cliffs, NJ.

RABINER, L.

J. R., and G. F. FRANKLIN (1958). Sampled-Data Control Systems. McGrawHill, New York.

RAGAZZINI,

J. R., and L. A. ZADEH (1952) . "The snalysis of sampled-data systems." AlEE
Trsns.; 71, pt. II, pp. 221)..234.

RAGAZZINI,

J., A RAULT, J. L. TF.sTUD, and J . PAPON (1978). "Model predictive heuristic
control: Applications to industrial processes." Automatics, 14, pp. 413-428.

RICHALET.

Y.

(1979). "Performance of state regulator systems with
floating-point computation." IEEE Trans. Automat. Control, AC·24, pp. 411-421.

RINK, R. E., and H.

CHONG

J. (1960) . "Control system synthesis by analogue computer based on 'Generalized linear feedback' concept." In Proceedings of the Symposium on Analog Computation Applied to the Study of Chemical Processes, pp. 1-13. Brussels.

RlSSANEN ,

RONNBAcK, S., K.

S. WAl.GAMA, and J. STERNBY (1992). "An extension to the generalized
anti-windup compensator." In P. BoRNE et al., Eds., Mathematics of the Analysis 11I1d
Design of Process Control. W. 275-285. Elsevier. Amsterdam.

ROSENBROCK. H. H.

(1970). State-Space and Multivariable Theory. Nelson, London.

M. G. (1980). Stability 11I1d Robustness of Maltivariable Feedback Systems.
The MIT Press, Cambridge, Mass.

SAFONOV,

R , and P. ALBERTOS (1995). 'Design of ripple-free controllers." In Proceedings
ofthe ::ltd European Control ConferenCB, pp. 3660-3664. Rome.

SANCHIS,

J. (1918). "tiber Potenzreihen, die im inn.eren des Einheitskreises beschiinkt
sind. II." Zeitschrift fiir die reine WJd angewandta Matematik, 148, pp, 122-145.

SCHUR,

SHANNON,

C. E. (1949). "Communication in presence of noise." Proc. IRE, 37, pp. 10--21.

SHINBKEY,

F. G. (1988). Process Control SystamB. McGraw-Hill, New York.

547

Bibliography

SIMON, H. A. (1956). "Dynamic programming under uncertainty with quadratic criterion

function." Econometrica, 24, p. 74.
J . B. (1964) . "Quantization errors digital control systems." IEEE
Automat. Control, AC·9, pp. 70-74.

SLAUGHTER.,

TI-ans.

O. J. M. (1957). "Closer control ofloops with deadtime." Chem. Eng. Prog., 53,
pp. 217-219.

SMITH,

and P. STOICA (1989) . System Identification. Prentice-Hall International,
Hemel Hempstead, U.K.

SODERSTROM, T.,

H. W. (1970). "Least-squares estimation: From Gauss to Kalman." IEEE
Spectrum, 7:7, pp. 63-68.

SoRENSEN,

Y. C. S. CHAN, and D. M. AusLt\NDER (1971). "Parametereinstellung bei
linearen DDC-Algorithmen." Regelungsteclmik und Process-Detenversrbeitung, 19,

'TAKAHASHI,

pp.237-244 .

Tou, J. T. (1959) . Digital and Sampled-Data Systems. McGraw-Hill, New York.
TsCHAUNER,

J. (1963a). "A general formulation of the stability constraints for sampled-

data controller systems." ?roc. IEEE, 51, pp. 619-620.
- (l963b). "Stability of sampled-data systems," Proc. IEEE, 51, pp. 621~22.
TsIEN,

HI S. (1955). Engineering Cybernetics. McGraw·HiIl I New York.

TsYPKIN I

Y. Z. (1949). "Theory of discontinuous control I and 11." Avtomst i Telemekh,

10, pp. 189-224 and 342-361.

- (1950). "Theory of discontinuous control III." Avtomat j Thlemekh, 11, pp. 300-319.
-

(1958) . Theory of Impulse Systems. Stata Publisher for Physical Mathematical
Literature. Moscow.

- (1984). Relay Control Syswms. Cambridge University Press, Cambridge, Mass.

VAN DoOREN, P. (1981). "A generalized eigenvalue approach for solving Rieeati equations."
SIAM J. Sci. Statist. Comput., 2, pp. 121-135.

R. F. (1980). "Multirate digital control systemswith simulation applications."
Report AFWAL-TR-BO·3101, vols. I. II. and III. Flight Dynamics Laboratory, Air Force
Wright Aeronautical Laboratory, Wright-Patterson Air Force Base, Ohio.

WHITBECK.

p. (1963). Prediction and Regulation by LinearLeast-Squares Methods. English
Universities Press, London.

WHlTILE,

WIENER, N. (1949). Extrapolation, Interpolation & Smoothing of Stationary Time Series.
The MIT Press, Cambridge, Mass.
WILLEMS, J . L., and H. VAN DE VOORDE (1978). "The return difference for discrete-time

optimal feedback systems." Automatics, 14, pp. 511~13.
WILLIAMS, A. B. (1981) . Network Analysis and S)'nthesis.

McGraw-Hill, New York.

D. (1991). Digital Control end Implementation: Finite Wordlength Considerations. Prentice Hall, Englewood Cliffs, N.J.

WILLIAMSON,

WILLSKY, A. S. (1979). Digital Signal Processing and Control and Estimation Theory.

The MIT Press, Cambridge, Mass.

Bibliography

548

WILLSON, JR, A. N. (1972a). "Limit cycles due to adder overflow in digital filters." IEEE
1Tans. eire. Theory, CT·19, pp. 342-346.

- (1972b). "Some effects of quantization and adder overflow on the forced response of
digital filters." Bell Syst. Tech. J., 51, pp. 863-887.
WIRTH, N. (1979). Algorithms + Data Structures = Programs. Prentice Hall, Englewood

Cliffs, N.J.
WI'ITENMARK, B. (1985a). "Design of digital controllers-The servo problem." In
S. TzAFESTAS, Ed., Applied Digital Control. Elsevier, Amsterdam.

- (1985b). "Sampling of a system with a time-delay." IEEE Trans. Automat. Control,
AC..aO, pp. 507--510.
WOLFRAM, S. (1988). Mathen18tica: A System for Doing Mathematics. Addison.Wesley,
Reading, Mass.
WOLOWICH,

W. A. (1974). Linear Multivariable Systems. Springer-Verlag, New York.

WONHAM, W. M. (1974). Linear Multivariable

Control: A Geometric Approach. Springer-

Verlag, New York.

YAMAMOTO, y. (1994). "A function space approach to sampled-data control systems and
tracking problems." IEEE 1Tans. Automat. Control, AC·39, pp. 703-712.
YAMAMOTO, Y., and M. ARAKI (1994) . "Frequency responses for sampled-data systams---

their equivalence and relationships." Linear Algebra Appl., 205-206, pp. 1319-1339.
Y., and P. P. K.HARGoNEKAR (1996). "Frequency response of sampled-data
systems." IEEE Trsns. Automat. Control, AC41, pp. 166-176.

YAMAMOTO.

YOULA, D. C., J. J. BONGIOKNO, and H. A JABR (1976). "Modern Wiener-Hopf design

of optimal controllers. Part I: The single-input-single-output ease; Part II: The
multivariable case." IEEE 1Tans. Automat. Control, AC.21, pp. 319-338.
ZIEGLER, J. G., and N. B. NICHOU; (1942). "Optimum settings for automatic controllers."

1Tans. ASME, 64, pp. 759-768.

Index
A
A-D converter, 1, 32, 243, 340
A-D quantization, 342
absolute algorithm, 309
Ackermann's formula, 127
Ackermann, J., 29
active damping, 211
actuator, 331
adaptive control, 28
Ahlen, A. L. B., 369
Albertos, P, 119
algebraic system theory, 27
aliasing, 17, 20, 249
amplitude margin, 87
analog design translation, 293
Anderson, B. D.O., 407, 446
Andersson, M., 119
antialiasing filter, 20, 252
antireset windup, 310, 331, 332, 334
Antoniou, A., 323
approximation,
- backward difference, 294- bilinear, 294
- differentiation, 294
- Euler, 294
- of analog design, 293
- ramp invariance, 297
- state model, 301

- step invariance, 297
- trapezoidal, 294
- 'Iustin, 294
AR process, 382
Araki, M., 292
~ process, 382
ARMAX process, 382
Arnold III, A. F., 446

Aryabhatta's identity, 170
AstrOm, K. J., 28, 29, 75, 119, 223, 292.
323, 407, 446, 504, 527
asymptotic stability, 78
Athans, M., 446
Atherton, D. P., 369
autocovariance function (see also covariance function), 379
automatic tuning, 28
autoregression, 382
autospectral density, 379

B
backward difference, 294
backward-shift operator, 48
Balchen, J. G., 241
Baradello, C. S., 75
Barker, R. H., 26, 29
Barnes, J. G. P, 369
Barnett, S., 223
Battin, R. H., 407
Bellman, R., 27, 29, 76, 413, 446
Benner, P., 446
Bemhardsson, B., 76, 292
Bertram, J. E., 26, 75, 119, 164. 369
Bessel filter, 253
Bezout identity, 170
Bierman. G., 446, 518, 527
bilinear transformation, 294
Bishop, R. H., 241
Bittanti, S" 446
Bjork, G., 369
Blanchard, J., 119
Blankenship, W A., 223
.
Blomberg, a, 27, 29
Bode diagram, 83
549

Index

550
Boudreau, J. A , 241
bounded-input bounded-output stability,
79
Bowns, D. K, 277

Box, G. E. P., 407, 504
Brinch-Hansen, P., 369

Bristol, E. H., 241, 323
Brown, G, S., 369, 407
Bryson, A. E., 446
Buckley, P. S., 241
Bucy, R. S., 407, 446
bumpless parameter changes, 313
bumpless transfer, 312, 337
Burns, A., 369
Bums. B. R. A., 241
Butterworth filter, 252
Buttner, M.. 369

C
Caines, P E., 407

Campbell, D. P., 369, 407
canonical fonn,
- controllable, 96
- diagonal, 45
- Jordan, 45
- observable, 99
Catthoor, F., 369
Cayley-Hamilton theorem, 533
CeUier, F. E., 119
certainty equivalence principle, 409
Char, B. w" 76
characteristic equation, 43
characteristic polynomial, 53

Chestnut, H., 407
Chong, H. Y, 369
Chung, K t, 407
Cohn, A., 80, 118

companion form (see also canonical
form), 100

complementary sensitivity function, 91
complete state information, 411
completing the squares, 412
computational delay, 328
computer technology, 2
computer-control theory, 11
- direct digital control, 4
- operator guide, 4
- set point control, 4
computer-controlled system, 1, 2, 336

- model, 30, 242
- modulation model sampler, 262
concurrent programming, 361
continuous-time signal, sampling, 31
continuous-time system, sampling, 32
control principle, 23U
controllability, 93
- inverse, 97
- definition of, 94
controllability matrix, 94
controllable canonical form, 96
controller, design of, 224
controller polynomial, 167
convolution, 57
coordinate change, 44
correlation function, 380
covariance function, 378
Crochieve, R. E., 292
cross-covariance function, 378
cross-spectral density, 379
Curry, E. E., 369

o
D-A converter, 1, 32, 243, 340

Dahlin, E. B., 223
Dahlin-Higham algorithm, 214
damping, 128
Davies, G., 369

DDC-package, 363
De Souza, C. E., 504
deadbeat control, 16, 17, 131
deadbeat observer, 139
decomposition, Kalman's, 101
delay,
- computational, 328
- internal, 41
- sampling a system with, 38
delay operator, 48
o-operator, 354
derivative time, 307
describing function analysis, 343
design, 224
- bottom-up, 229, 233
- frequency-response, 305
- of simple loops, 237
- top-down, 229, 230
design of controller, 121
design specification, 238
detectability, 93, 98

551

Index
diagonal form, 45
difference approximation (see approximation), 294
difference equation, 21, 25, 30
differentiation approximation, 294
digital controller implementation (Bee
implementation), 324
digital controller, realization, 349
digital redesign, 293
digital simulation, 106
Diophantine equation, 167, 170
- solution of, 172
Diophantus, 170
direct digital control (DOC), 4
discrete Laplace transform, 26
discrete-time equivalent (see approximation},293
discrete-time Riccati equation, 416
discrete-time system. 2, 30, 42
- analysis of, 77
distribution function, 378
disturbance generator, 403
disturbances, 370
- classical model, 104, 370
- periodic, 105
- piecewise deterministic, 373
- reduction by feedback, 372
- reduction by feedforward, 372
- reduction by prediction, 373
- reduction of, 371
- stochastic model, 376
Doetsch, G., 75
Dorf, R. C., 241
double integrator, 35, 52, 107, 124, 127,
132, 137, 139, 141, 143, 147, 155,
169, 170, 195, 261, 262, 346, 348,
355, 421, 424, 528
- with delay, 40, 52
Doyle, J. C., 446
duality, 438
dynamic programming, 413

E
Edwards, R., 369
Emami-Nasini, A.,446
error feedback, 213
estimation, 235
Euclid~ wgoritiun, 172
- extended, 173

Euler equation, 424
Euler's method, 294
exponential forgetting, 518
Eykhoff, P., 28, 29, 527

F
Falb, P. L., 446
fast algorithm, 440
Fateman, R. J., 369
feedback control, 233
feedforward, 234
fictitious sampler, 282
filter,
- Bessel, 253
- Butterworth, 252
- ITAE. 252
filtering, 429, 432
final-value theorem, 57
finite impulse response (FIR) system,
47

first-order hold, 248
fixed-point arithmetic, 341
Boating-point arithmetic, 341
Flower, J. 0" 292
forgetting factor, 518
forward difference, 294
forward-shift. operator 48
,
Foss, A. S" 241
Franklin, G. F., 26, 29, 75, 241 , 292,
323, 446

Freeman, H., 26
frequency folding, 249, 252
frequency prewarping, 295
frequency response, 268
frequency-response curve, 83
frequency-response design method, 305
Friedland, B., 26

G
Gain, 307
Gantmacher, F. R.. 76
Gardenhire, L. W 292
.,
Gauss, K F., 508, 509, 527
Gaussian random process, 378
Gawthrop, P. J., 369
generating function, 26
Oevers, M., 369
Gille, J. C., 407
Goff, K. w., 323

Index

552

Gold, B., 323
Golub, G. H, 76, 369
Goodwin, G. C., 28, 29, 369, 527
Gordon, G., 119
Grsebe, S. F.. 369
Gunkel. Ill, T. L., 446
Gupta. M. M., 29
Gustafsson, K.. 29, 446

H
Hagander, P., 446
Hagglund, T., 28, 29,323
Hairer, E., 29
Hansson, A, 446
Hansson. R. J., 527
Hanus. R., 369
harmonic oscillator, 37, 79, 203, 530
Hess, S. F., 369
hidden oscillation, 26, 102, 111
Higham, J. D., 223
higher-order hold, 248

Ha, Y-C., 446
hold circuit, 263, 267
- first order, 248
- higher order, 248
- predictive, 248
- zero-order hold, 247
Hurewiez, W., 26, 29

integrator in controller, 145, 179, 306,
484
integrator windup, 310, 331
internal time delay, 41
internal-model control (IMe), 217
internal-model principle, 143, 488
interrupt, 4
inters ample behavior, 42, 60, 493
intersample ripple (see also hidden oscillation), 111
inventory model, 532
inverse z-transform, 56, 279
hermann, R., 29, 527
ITAE filter, 252
Ito,'Y., 292

J
Jackson, L. B., 369
Jagannathan, It, 292
James, H. M., 407
Jenkins, G. M., 407, 504, 527
Jerri , A J., 291
Jezek, J., 223
Johansson, R, 28, 29, 527

Jordan form, 45
Jury's stability criterion, 81
Jury, E. 1., 26, 28, 29, 75, 80, 119, 292,
407

K
identification (see system identification),
505
implementation, 324
impulse, 104
impulse invariant sampling, 323
impulse-train modulation, 263
incomplete state information, 411
incremental algorithm, 309
incremental covariance, 398
index set, 377
inherently sampled system, 22
initial-value theorem, 57
initialization, 338
innovation, 394, 455, 471
innovation's representation. 393, 449
input-output model, 46
integral action, 145, 150, 188
integration offset, 317
integration time, 307

Kailath, T., 75, 164
Kalman filter, 409,429.517
- frequency domain properties, 434
Kalman's decomposition, 101
Kalman, R E., 26, 27, 29, 75, 93, 119,
407,446
Karlin, S., 407
Khargonekar, P. P., 292
Kh.eir, N. A., 119
Kleinman, D. L., 446
Knowles, J. 8., 369
Kelmogorov, A. N., 377, 407
Kanar, A F., 292
Kotelnikov, V. A., 29, 291
Krane, G. M., 26, 292
Kucera, v., 27, 29, 75, 223, 446, 504
Kumar, P R., 407
Kuo, B. e.. 29, 323. 446

Kuo, F. F., 368

553

Index
Kwakernaak, H.
Kwong, R. H., 446

L
ladder realization, 352
Laning, J. R., 407
Laub, A. J., 446
Lawden, D, F., 29
Lawson, C. L., 527
least squares method,
- normal equation, 512
- principle of, 508, 509
- recursive computation, 514
- statistical interpretation, 513

- exponential weighting, 517
- extensions, 514
- time-varying system, 517
- U-D factorization, 518
Lee, E. A., 369
~e , J. H., 223
Lefschetz, S., 27
Lennartson, B., 446, 504
Li, G., 369

u, Y. T., 292
Lindorif, D. P., 292
linear quadratic (LQ) control, 408, 413,
451
- complete state information, 419
- deterministic case, 413
- properties, 422
linear quadratic Gaussian (LQG) eon-

trol, 27, 408, 436, 470
Linvill, W. K , 26, 29, 263, 292
Ljung, L., 28, 29, 527
load disturbance. 104
wan, C. F. v; 76,369
loop-transfer function, 90, 195
loss function, 410, 451
- sampling of, 411
Lucas, M. P., 29
Luenberger observer, 141
Luenberger, D. G., 164
Lundh, M., 29
Lyapunov equation, 89
Lyapunov function, 88
l&'apunov'$. stability method, 87

M
MA process, 382

MacCoU, L. A., 26, 29, 263, 292
MacGregor, J. F., 504
Mahesh, J. K., 292
~arkov process, 382
mathematical model, 505
MATLAB®, 107
matrix, 533

matrix exponential, calculation of, 34,
533

matrix function, 533
matrix inversion lemma, 536
MATRIXX®, 107
Mattsson, S.-E., 119
maximum likelihood method, 514
Mayer, R. W., 407

McGarty, T. P., 407
mean-value, 378
measurement error, 104
Melzer, S. M., 446
Middleton, R. H., 369
Miminis, G. 8., 164
minimum-variance control, 450. 451,
460
model building, 506
Models,
- computer-oriented, 30
- process-oriented, 242
Modifiad z-transform, 26, 60
modulation function, 264
modulation model, 262
monic polynomial, 166
Moore, J. R, 407, «6
Morari, M., 223
Moroney, P., 369
Mosca, E., 504
motor, 36, 180, 182, 300, 529
moving average, 382
multirate sampling, 12, 286

Mumme, K. 1, 241

N
natural frequency, 128
Neuman, C. P., 75
Newton, Jr, G. C., 407,504
Nichols, N. B., 314, 323
nonlinear actuator, 331
nonminimum phase system, 65
nonnalequation, 512
normal process, 378

Index

554
Petkov, P H., 164-

Norton, J. P.. 28, 29,527
notch filter, 210
numerics, 340

phase margin, 87
Pllr-controller,
- digital, 306

Nyquist criterion, 83

- digital, absolute form , 309
- digital, incremental form, 309

Nyquist curve, 83
Nyquist diagram, 83
Nyquist frequency, 20, 31, 246
Nyquist, H., 25, 291

- digital, position form, 309
- incremental, 309

- operational aspects, 311
- position, 309
- tuning of, 314
- tuning rule, 314, 315
piecewise deterministic disturbances,
373

a
observability, 93, 98
observability matrix, 99
observable canonical form, 99

observer, 135, 138

pole, 53, 61

- deadbeat, 139

- mapping, 61
pole excess, 49
pole-placement,
- design procedure, 186
- integral action, 145, 188
- output feedback, 141
- polynomial approach, 165
- sampling interval, 194

- direct calculation, 135
- Luenberger, 141

- using dynamic system, 137
observer polynomial, 167
- influence of, 191
Oldenburg. R. C., 25, 29

operational aspect, 336
operator guide. 4
operator interface, 336
Oppenheim, A. v., 323. 369
optimal control, 236, 239, 408. 447

- sensitivity, 183
- state-feedback approach, 124

- state-space approach, 120
pole-zero cancellation, 175
Polya, G., 241

optimal design, 408
- polynomial approach, 447
- state-spcee, 408
optimal estimation (see Kalman filter)
429
optimal prediction, 453
order, of a system, 53

outlier, 330
overflow, 340

p
Paige, C. C., 164
Papoulis, A., 407
Pappas, T., 446

parameter estimation, 508
parameterization, 338
Parker, S. R., 369
Parzen, E., 407
Payne. R. L., 527
periodic system, 13, 264

Pemebo, L., 223
persistent excitation, 513
Peterka, v; 504

'

polynomial design, 165, 447
Pontryagin, L. S., 27, 29
position algorithm, 309
postsampling filter, 256

Powell, J. D., 29, 323
prediction, 235, 429

- horizon, 457
- optimal, 453
predictive first-order-hold, 248, 256
prefilter, 328
prefiltering, 252
presampling filter, 20
prewarping, 295
principle of optimality, 413
programm~ble logic controller (PLC), 7
programmmg, 360
proportional gain, 307
pseudo-inverse, 512
pulse, 104
pulse response, 46

pulse-transfer function, 56, 278
pulse-transfer operator, 51

555

Index
Q

quadratic form, 418
quantization, 340, 342
- describing function analysis, 343

root locus, 213
Rosenbrock, H. H., 27, 29, 75, 164
roundoff, 340, 342

S
R
Rabiner, L. R., 292. 323
Ragazzini, J. R., 26, 29, 75, 292
ramp, 105
ramp invariance approximation, 297
random process, (see stochastic process), 376
rational spectral density, 390
reachability, 93
- definition of, 94
- loss of, 102
real-time operating systam, 361, 362
real-time programming, 361
realization (see als» implementation),
324, 326, 349, 377
- companion form, 351
- g-operator, 354
- direct, 351
- Jordan, 351
- ladder form, 352
- sensitivity, 350
- well-conditioned, 351
reciprocal polynomial, 49
reconstruction, 244, 246
recursive identification, 514
regulation problem, 121
regulator design, 224
representation, 325
reset time, 307
reset windup (see integrator windup),
310
Riecati equation, 416
- algebraic, 426
- discrete-time, 416
- solution, 440
Richalet. J., 223
ringing (see also hidden oscillation),

111
Rink, R. E., 369
Rissanen, J., 164
robot arm, 156, 208
robustness, 89, 91
robustness (see also sensitivity), 489
Ronnbaek, S., 369

Safonov, M. G., 446
sample-and-hold circuit, 263
sample-and-hold, idealized, 265
sampled signal, 31, 244
sampled-data system, 2, 243
- frequency response, 268
- inherently sampled, 22
sampling, 244
- frequency, 31
- instant, 11
- internal delay, 41
- interval (see sampling, period), 11
- inverse of, 36
- of a signal, 31
- of a system , 32
- period, 11, 31
- periodic. 31
- stochastic differential equation, 402
- system with time delay, 38
- theorem, 25, 244 .
- time, 31
sampling-period selection, 66, 110, 130,
194~ 299, 316, 440, 492
sampling-time convention, 123
Sanchis, R., 119
Sandell, N. R, 446
Sarachik, P. E., 26
Sartorius, H., 25, 29

scalar-product calculation, 341
Schafer, R. W., 323, 369
Schur, J., SO, 118
selector control, 234
self-reciprocal polynomial, 49
sensitivity (see also robustness) , 89,
183,489
sensitivity function. 91, 195
- complementary, 91
separation theorem, 436
servo problem, 121, 147, 239
set-point control, 4
Shannon reeenstruction, 247
Shannon's sampling theorem, 244
Shannon. C. E., 25, 29, 291
shift-operator calculus, 48

Index

556
shift-operator, backward, 48
Shinskey, F. G., 241, 323
sideband, 270
signal reconstruction, 244
- higher-order hold, 248
- predictive first-order hold, 248
- Shannon, 247
- zero-order hold, 247
Simnon@, 107
Simon, H. A., 446
simulation, 106
SIMULIN~, 107
Sin, K. S., 28, 29
sinusoidal signal, 105
Sivan, R. , 446
Sklansky, J., 26
Slaughter, J. B., 369
Smith, O. J. M., 223
Smith-predictor, 215
smoothing, 429
Stiderlind, G., 29
Soderstrom, T., 28, 29, 504, 527
Sorensen, H. W., 527
specification, 238
spectral density, 379
- interpretation, 379
spectral factorization, 390, 472
stability, 77
- asymptotic, 78
- bounded-input bounded-output
(BlBO),79
- exponential, 491
- input-output, 79
- Jury's criterion, 81
- Lyapunov's methed, 87
- margin, 184
- Nyquist criterion, 83
- test of, 79
state estimator (see observer), 135
state feedback, integral action, 145
state-space design, 120, 408
state-space model, 32, 398
- coordinate change, 44
state-space theory, 27
stationary process, 379
- filtering, 389, 401
steady-state value, 106
Stein, G., 446
step, 105
step invariance approximation, 297

step-response method, 314stochastic control theory, 27
stochastic difference equation, 383
- property of, 383
stochastic differential equation, 398
- sampling of, 402
stochastic models of disturbances, 376
stochastic process, 377
- AR, 382
- ARMA, 382
- ARMAX, 382
- completely deterministic, 377
- continuous-time, 397
- discrete-time, 377
- Gaussian. 378
- input-output model, 387
~

MA, 382

- normal, 378
- realization, 377
- state-space model, 382
- stationary, 379
- weakly stationary, 379
- white noise, 380. 397
- Wiener process, 398
Stoica, P., 28, 29, 527
stroboscopic model, 32, 242
structuring, 229
switch decomposition, 288
Sylvester matrix, 175
system equation, 33
- solution of, 43
system identification, 28, 505, 506, 512
- recursive, 514
system order, 53

T
Takahashi, Y., 323
Thorton, C. L., 518
time delay (see delay), 38
time-delay process, 39, 41, 215, 531
torque observer, 219
Tou{ J. T., 26, 29
tracking mode. 333, 337
trajectory following, 97
transform method, 25
transformation of state-space model, 44
transition probability, 383
.
trapezoidal approximation, 294
Tschauner,J., 369

557

Index

Tsien, H. S., 401
Tsypkin) Y. Z., 26, 28, 29, 75, 369
Tustin approximation, 294
two-degree-of-freedom controller, 150

YouIa, D. C., 504
Youla-Kueera parameterization, 189
Yule-Walker equation, 405

Z

U

z-transform, 26, 53, 279, 285

U-D factorization, 518
ultimate-sensitivity method, 315
undamped frequency {see natural frequency], 128
underflow, 340

-

unstable inverse, 65, 464

V
Van De Voorde, H., 446
Van Dooren, P., 446
Varaiya, P., 407
variance, 378
- calculation of, 395

W
w-transform method, 306
Wanner. G., 29
Watts, D. G., 527
weakly stationary process, 379

weighting function, 47
Wenings, A" 369
Whitbeck, R. F., 292
white noise, 380
Whittle. P., 407
Wiener process, 398

Wiener, N., 407, 466, 504
Willems. J. L., 446
Williams, A B.• 368
Williamson, D., 369
Willeky, A. S., 323, 369
Willson) Jr, A. N., 369
windup (see integrator windup), 310
Wirth, N., 241
Wittenmark) B., 28, 29, 76, 164, 223
Wolfram, S, 76 '
Wolowich, W. A., 164, 223
Wonham, W. M., 27, 29
word-length. 341

y
Yamamoto, Y. 292
Ylinen, R) 27, 29

definition, 56
delayed, 26
inverse, 56, 279
modified, 26, 60
property of, 57
Zadeh, L. A., 26, 29
Zafiriou, E., 223
zero, 53, 61, 63
zero, mapping, 63

zero-order hold, 247
- circuit, 33
- sampling, 32
Ziegler, J. G., 314, 323
Ziegler-Nichols tuning rules, 314

