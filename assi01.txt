Fachgebiet UNIVERSITAT MUNCHEN
TECHNISCHE
Fakult¨t f¨r Elektrotechnik und Informationstechnik
a u
Geometrische Optimierung
Fachgebiet f¨r Geometrische Optimierung und Maschinelles Lernen
und Maschinelles Lernen
Prof. Dr. Martin Kleinsteuber
Non-convex Optimization for Analyzing Big Data
Assignment #1, May 9, 2014
Due date: 13.05.2013, 15:00
Your solutions should be submitted via Moodle. Submissions should either be done by
Latex or written by hand and then scanned.
Hilbert Spaces and Inner Products
Task 1: (5 points)
[ _to('140519073609') ]

• Given two Hilbert spaces H1 , H2 with scalar products ·, ·
tively. We deﬁne
H1 ,
H2 ,
respec-
H1 ⊕ H2 := {(x1 , x2 ) : x1 ∈ H1 , x2 ∈ H2 }
with the inner product
(x1 , x2 ), (y1 , y2 )
H1 ⊕H2
:= x1 , y1
H1
+ x2 , y2
H2 .
(1)
Show that H1 ⊕ H2 is a Hilbert space. Find the orthogonal complement of the
subspace {(x1 , 0) : x1 ∈ H1 }.
Diﬀerentiation
Task 2: (5 points)
• Let f : R2 → R be given by
 x2 + y 2 ,
f (x, y) =
− x2 + y 2 ,
y > 0,
y = 0,
y < 0.
Show that (a) every directional derivative of f exists in (0,0) and (b) f is not
diﬀerentiable in (0,0).
• Given the function f : R2 → R deﬁned by
 √ x·y , (x, y) = (0, 0),
x2 +y 2
f (x, y) :=
0,
(x, y) = (0, 0).
Show that f is continuous and partially diﬀerentiable, but not diﬀerentiable.
• Given the function
A → log (det(A)) .
Determine the derivative Df (A). Hint: Use the fact that log (det(A)) = tr (log(A))
which was proven in the tutorial.
